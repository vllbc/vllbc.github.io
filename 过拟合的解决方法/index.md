# 过拟合的解决方法

1. 数据增强，即增加样本，也可以半监督如UDA。
2. 正则化（Dropout等）
3. Batch norm。本质是加快训练，让训练更稳定，但也可以缓解过拟合。配合relu也会缓解dead relu问题。
4. early-stop，在过拟合之前停下来。
5. 降低模型复杂度，与第2点类似。
6. 学习率衰减，按照固定的epoch后衰减学习率。
7. 特征选择，选择主要的特征进行训练，本质也是降低模型复杂度。
