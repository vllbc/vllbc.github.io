# Data Engineering for Scaling Language Models to 128K Context


# Data Engineering for Scaling Language Models to 128K Context

***

## <span style="color: #1B5E20"><span style="background-color: #f1f8e9">ğŸ’¡ Meta Data</span></span>

| <span style="background-color: #dbeedd">Title</span>     | <span style="background-color: #dbeedd">Data Engineering for Scaling Language Models to 128K Context</span>                                                                                                 |
| -------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| <span style="background-color: #f3faf4">Journal</span>   |                                                                                                                                                                                                             |
| <span style="background-color: #dbeedd">Authors</span>   | <span style="background-color: #dbeedd">Yao Fu; Rameswar Panda; Xinyao Niu; Xiang Yue; Hannaneh Hajishirzi; Yoon Kim; Hao Peng</span>                                                                       |
| <span style="background-color: #f3faf4">Pub. date</span> | <span style="background-color: #f3faf4">2024-02-15</span>                                                                                                                                                   |
| <span style="background-color: #dbeedd">æœŸåˆŠæ ‡ç­¾</span>      |                                                                                                                                                                                                             |
| <span style="background-color: #f3faf4">DOI</span>       | <span style="background-color: #f3faf4"><a href="https://doi.org/10.48550/arXiv.2402.10171" rel="noopener noreferrer nofollow">10.48550/arXiv.2402.10171</a></span>                                         |
| <span style="background-color: #dbeedd">é™„ä»¶</span>        | <span style="background-color: #dbeedd"><a href="zotero://open-pdf/0_Z5AQISDH" rel="noopener noreferrer nofollow">Fu et al_2024_Data Engineering for Scaling Language Models to 128K Context.pdf</a></span> |

## <span style="color: #E65100"><span style="background-color: #fff8e1">ğŸ“œ ç ”ç©¶èƒŒæ™¯ &#x26; åŸºç¡€ &#x26; ç›®çš„</span></span>

***

<span style="color: rgb(6, 6, 7)"><span style="background-color: rgb(255, 255, 255)">è®ºæ–‡ä¸»è¦ç ”ç©¶äº†å¦‚ä½•é€šè¿‡æ•°æ®å·¥ç¨‹çš„æ–¹æ³•ï¼Œå°†è¯­è¨€æ¨¡å‹çš„ä¸Šä¸‹æ–‡é•¿åº¦æ‰©å±•åˆ°128Kä¸ªtokenã€‚è¿™é¡¹ç ”ç©¶çš„é‡ç‚¹åœ¨äºæ•°æ®å·¥ç¨‹ï¼Œä½œè€…ä»¬æå‡ºäº†ä¸€ä¸ªå‡è®¾ï¼šé•¿ä¸Šä¸‹æ–‡å»ºæ¨¡çš„èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åˆ©ç”¨ä»»æ„è¾“å…¥ä½ç½®ä¿¡æ¯çš„èƒ½åŠ›ï¼Œä¸»è¦æ˜¯é€šè¿‡å¤§è§„æ¨¡é¢„è®­ç»ƒè·å¾—çš„ï¼Œå¹¶ä¸”è¿™ç§èƒ½åŠ›å¯ä»¥é€šè¿‡è½»é‡çº§çš„æŒç»­é¢„è®­ç»ƒåœ¨é€‚å½“çš„æ•°æ®æ··åˆä¸Šæ‰©å±•åˆ°è®­ç»ƒæœŸé—´æœªè§è¿‡çš„æ›´é•¿ä¸Šä¸‹æ–‡ï¼ˆä¾‹å¦‚ï¼Œä»4Kæ‰©å±•åˆ°128Kï¼‰ã€‚</span></span>

## <span style="color: #2E7D32"><span style="background-color: #f1f8e9">ğŸ“Š ç ”ç©¶å†…å®¹</span></span>

***

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FZ5AQISDH%22%2C%22annotationKey%22%3A%22CJM6DHQP%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B218.221%2C393.004%2C271.165%2C401.911%5D%2C%5B75.366%2C381.049%2C271.165%2C389.956%5D%2C%5B75.366%2C369.094%2C269.518%2C378.001%5D%2C%5B75.366%2C357.138%2C270.341%2C366.045%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%221%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Z5AQISDH?page=1&#x26;annotation=CJM6DHQP">â€œ(1) for quantity, we show that 500 million to 5 billion tokens are enough to enable the model to retrieve information anywhere within the 128K context;â€</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/P3J78PXW">Fu ç­‰, 2024, p. 1</a></span>)</span> æ•°æ®é‡è¾ƒå°‘

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FZ5AQISDH%22%2C%22annotationKey%22%3A%22T4THUP8D%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B75.037%2C345.183%2C271.169%2C354.09%5D%2C%5B75.366%2C333.228%2C270.764%2C342.135%5D%2C%5B75.007%2C321.273%2C269.512%2C330.23%5D%2C%5B75.366%2C309.318%2C269.518%2C318.225%5D%2C%5B75.366%2C297.363%2C270.761%2C306.27%5D%2C%5B75.366%2C285.407%2C271.165%2C294.314%5D%2C%5B75.366%2C273.452%2C93.149%2C282.359%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%221%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Z5AQISDH?page=1&#x26;annotation=T4THUP8D">â€œ(2) for quality, our results equally emphasize domain balance and length upsampling. Concretely, we find that na ÌˆÄ±vely upsampling longer data on certain domains like books, a common practice of existing work, gives suboptimal performance, and that a balanced domain mixture is important.â€</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/P3J78PXW">Fu ç­‰, 2024, p. 1</a></span>)</span> å¯¹äºè´¨é‡æ¥è¯´ä½¿ç”¨ä¸Šé‡‡æ ·å¯ä»¥å¤§å¹…æé«˜èƒ½åŠ›

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FZ5AQISDH%22%2C%22annotationKey%22%3A%22AHKRN8DL%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B307.082%2C529.114%2C541.445%2C538.021%5D%2C%5B307.44%2C517.158%2C541.437%2C526.065%5D%2C%5B307.44%2C505.203%2C541.438%2C514.11%5D%2C%5B306.115%2C493.248%2C355.629%2C502.155%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%221%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Z5AQISDH?page=1&#x26;annotation=AHKRN8DL">â€œwhich asks the model to precisely recite the information in a given sentence where the sentence (the â€œneedleâ€) is placed in an arbitrary location of a 128K long document (the â€œhaystackâ€).â€</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/P3J78PXW">Fu ç­‰, 2024, p. 1</a></span>)</span> å¹²è‰å †æµ‹è¯•çš„å®šä¹‰

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FZ5AQISDH%22%2C%22annotationKey%22%3A%22H3DCD7N4%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B325.054%2C331.853%2C463.996%2C340.76%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%221%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Z5AQISDH?page=1&#x26;annotation=H3DCD7N4">â€œattention has quadratic complexityâ€</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/P3J78PXW">Fu ç­‰, 2024, p. 1</a></span>)</span> transformeråŸå§‹æ³¨æ„åŠ›å°±æ˜¯ä¸€ä¸ªå¹³æ–¹å¤æ‚åº¦çš„æ³¨æ„åŠ›

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FZ5AQISDH%22%2C%22annotationKey%22%3A%22NFME4Y23%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B306.972%2C194.369%2C541.436%2C203.276%5D%2C%5B307.44%2C182.414%2C542.108%2C191.321%5D%2C%5B307.44%2C170.458%2C543.093%2C179.365%5D%2C%5B307.44%2C158.503%2C484.139%2C167.41%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%221%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Z5AQISDH?page=1&#x26;annotation=NFME4Y23">â€œWe hypothesize that the capability to utilize information at arbitrary locations within long context length is (mostly) already acquired during pretraining, even for models pretrained on substantially shorter 4K contexts.â€</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/P3J78PXW">Fu ç­‰, 2024, p. 1</a></span>)</span> ä½œè€…è®¤ä¸ºæ¨¡å‹åœ¨é¢„è®­ç»ƒè¿‡ç¨‹å°±å­¦ä¹ åˆ°äº†åˆ©ç”¨ä½ç½®ä¿¡æ¯çš„èƒ½åŠ›

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FZ5AQISDH%22%2C%22annotationKey%22%3A%22X5VSAXJP%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B55.44%2C295.099%2C291.093%2C304.006%5D%2C%5B55.44%2C283.144%2C181.377%2C292.051%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%222%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Z5AQISDH?page=2&#x26;annotation=X5VSAXJP">â€œbecause, as we observe, this results in perplexiy degradations in other domains (Table 5).â€</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%222%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/P3J78PXW">Fu ç­‰, 2024, p. 2</a></span>)</span> åªæ˜¯å•ç‹¬å¯¹ä¸€ä¸ªé‚»åŸŸçš„æ•°æ®ä¸Šé‡‡æ ·ä¼šä½¿å¾—å…¶å®ƒé‚»åŸŸçš„æ€§èƒ½ä¸‹é™ã€‚

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FZ5AQISDH%22%2C%22annotationKey%22%3A%225QEXM69Z%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B450.837%2C695.966%2C541.439%2C703.982%5D%2C%5B55.162%2C685.007%2C261.661%2C693.023%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%223%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Z5AQISDH?page=3&#x26;annotation=5QEXM69Z">â€œwe use 80K compared to Togetherâ€™s 32K, which does not generalizes beyond 32K;â€</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%223%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/P3J78PXW">Fu ç­‰, 2024, p. 3</a></span>)</span> ä½¿ç”¨80kçš„ä¸Šä¸‹æ–‡è¿›è¡Œè®­ç»ƒ

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FZ5AQISDH%22%2C%22annotationKey%22%3A%22XW9MQ3AJ%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B276.666%2C685.007%2C541.444%2C693.023%5D%2C%5B55.44%2C674.048%2C196.774%2C682.064%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%223%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Z5AQISDH?page=3&#x26;annotation=XW9MQ3AJ">â€œdata mixture: we use SlimPajama which has balanced domains compared to YaRN, which uses book-only PG19;â€</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%223%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/P3J78PXW">Fu ç­‰, 2024, p. 3</a></span>)</span> ä½¿ç”¨é‚»åŸŸæ•°æ®æ›´å¹³è¡¡çš„æ··åˆæ•°æ®é›†

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FZ5AQISDH%22%2C%22annotationKey%22%3A%22KCAPRVRH%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B211.846%2C674.048%2C543.006%2C682.064%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%223%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Z5AQISDH?page=3&#x26;annotation=KCAPRVRH">â€œlength upsampling: we upsample long sequences compared to LongLoRA, which does not.â€</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%223%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/P3J78PXW">Fu ç­‰, 2024, p. 3</a></span>)</span> é‚»åŸŸæ•°æ®è¿›è¡Œå¹³è¡¡æ€§çš„é•¿æ–‡æœ¬ä¸Šé‡‡æ ·

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FZ5AQISDH%22%2C%22annotationKey%22%3A%22Y3JBRINU%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B55.082%2C223.737%2C289.8%2C232.644%5D%2C%5B55.44%2C211.781%2C289.437%2C220.688%5D%2C%5B55.082%2C199.826%2C289.444%2C208.733%5D%2C%5B55.44%2C187.871%2C291.185%2C196.778%5D%2C%5B55.131%2C175.916%2C291.094%2C184.823%5D%2C%5B55.44%2C163.961%2C291.215%2C172.868%5D%2C%5B55.44%2C152.006%2C289.437%2C160.913%5D%2C%5B55.44%2C140.05%2C289.788%2C148.957%5D%2C%5B55.44%2C128.095%2C291.091%2C137.002%5D%2C%5B55.44%2C116.14%2C289.438%2C125.047%5D%2C%5B55.44%2C104.185%2C289.436%2C113.092%5D%2C%5B55.44%2C92.23%2C119.091%2C101.137%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%223%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Z5AQISDH?page=3&#x26;annotation=Y3JBRINU">â€œAnother important related work is the previous LLaMA Long (Xiong et al., 2023) work and the concurrent XVERSE (XVerse, 2024) work, which continue pretraining the model on 32K sequences for about 500 billion tokens. These works are implicitly motivated by the view that longcontext modeling is a new capability that must be â€œinjectedâ€ through large-scale training. We instead hypothesize that the base model has mostly already acquired this capability through large-scale pretraining, and thus a lightweight continual pretraining on relatively small data (e.g., 5B tokens) is enough to extend these capabilities to much longer context lengths (Fig. 3).â€</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%223%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/P3J78PXW">Fu ç­‰, 2024, p. 3</a></span>)</span> ä¸å¦ä¸€ç§è§‚ç‚¹å¯¹æ¯”ï¼Œå¦ä¸€ç§è§‚ç‚¹æ˜¯å¤§æ¨¡å‹çš„é•¿ä¸Šä¸‹æ–‡èƒ½åŠ›æ˜¯é€šè¿‡å¤§è§„æ¨¡çš„ç»§ç»­é¢„è®­ç»ƒæ³¨å…¥çš„ã€‚

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FZ5AQISDH%22%2C%22annotationKey%22%3A%22LZLDCTVD%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B306.972%2C527.153%2C541.613%2C536.06%5D%2C%5B307.44%2C515.198%2C543.093%2C524.105%5D%2C%5B307.44%2C503.243%2C543.096%2C512.15%5D%2C%5B307.44%2C491.288%2C541.437%2C500.195%5D%2C%5B307.44%2C479.332%2C542.687%2C488.239%5D%2C%5B307.092%2C467.377%2C543.096%2C476.284%5D%2C%5B307.44%2C455.422%2C350.049%2C464.329%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%223%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Z5AQISDH?page=3&#x26;annotation=LZLDCTVD">â€œWe use the SlimPajama (Soboleva et al., 2023) dataset for continual pretraining. This dataset is an open-source reproduction of the LLaMA (Touvron et al., 2023a) pretraining data mixture, consisting of 82% web data (67% from CommonCrawl and 15% from C4), 4.5% code (Github), 4.5% Wikipedia, 4.5% books, 2.5% Arxiv, and 2.0% StackExchange.â€</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%223%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/P3J78PXW">Fu ç­‰, 2024, p. 3</a></span>)</span> æœ¬æ–‡ä½¿ç”¨çš„SlimPajamaæ•°æ®é›†çš„æ„æˆ

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FZ5AQISDH%22%2C%22annotationKey%22%3A%22YRFJETBI%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B354.611%2C455.422%2C541.437%2C464.329%5D%2C%5B307.44%2C443.467%2C543.092%2C452.374%5D%2C%5B307.44%2C431.512%2C541.438%2C440.419%5D%2C%5B307.44%2C419.556%2C524.027%2C428.463%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%223%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Z5AQISDH?page=3&#x26;annotation=YRFJETBI">â€œSince this dataset closely mirrors that used to pretrain the LLaMA models, there is less concern of distribution shift during continual pretraining; it is therefore used by many recent works like Fuzhao Xue &#x26; You (2023).â€</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%223%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/P3J78PXW">Fu ç­‰, 2024, p. 3</a></span>)</span> å³æœ¬æ–‡ç»§ç»­é¢„è®­ç»ƒä½¿ç”¨çš„æ•°æ®é›†ä¸llamaé¢„è®­ç»ƒä½¿ç”¨çš„æ•°æ®é›†ç›¸æ¯”åˆ†å¸ƒæ¯”è¾ƒæ¥è¿‘ï¼Œåç§»è¾ƒå°‘ï¼Œå¯¹é¢„è®­ç»ƒæƒé‡å½±å“ä¸å¤§ã€‚

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FZ5AQISDH%22%2C%22annotationKey%22%3A%22N65J3N2C%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B422.195%2C341.848%2C541.445%2C350.755%5D%2C%5B307.44%2C329.893%2C541.437%2C338.8%5D%2C%5B307.44%2C317.938%2C541.437%2C326.845%5D%2C%5B307.44%2C305.982%2C543.093%2C314.889%5D%2C%5B307.44%2C294.027%2C462.53%2C302.934%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%223%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Z5AQISDH?page=3&#x26;annotation=N65J3N2C">â€œDirectly upsampling long data changes the domain mixture, e.g., upsampling sequences longer than 100K will increase the portion of the books domain. Likewise, changes in the domain mixture will result in shifts of the length distribution.â€</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%223%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/P3J78PXW">Fu ç­‰, 2024, p. 3</a></span>)</span> ä¸èƒ½ç›´æ¥ä¸Šé‡‡æ ·ï¼Œä¼šæ”¹å˜ä¸åŒé‚»åŸŸæ•°æ®çš„æ··åˆæ¯”ä¾‹\
ğŸ”¤ç›´æ¥ä¸Šé‡‡æ ·é•¿æ•°æ®ä¼šæ”¹å˜åŸŸæ··åˆï¼Œä¾‹å¦‚ï¼Œä¸Šé‡‡æ ·åºåˆ—å¤§äº100Kä¼šå¢åŠ å›¾ä¹¦åŸŸçš„æ¯”ä¾‹ã€‚åŒæ ·ï¼ŒåŸŸæ··åˆçš„å˜åŒ–ä¹Ÿä¼šå¯¼è‡´é•¿åº¦åˆ†å¸ƒçš„å˜åŒ–ã€‚ğŸ”¤

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FZ5AQISDH%22%2C%22annotationKey%22%3A%22D7NT48L5%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B307.44%2C108.722%2C543.089%2C117.748%5D%2C%5B307.44%2C96.767%2C543.187%2C105.674%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%223%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Z5AQISDH?page=3&#x26;annotation=D7NT48L5">â€œPer-source Upsampling: This retains the domain mixture, then upsamples long documents within each domain.â€</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%223%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/P3J78PXW">Fu ç­‰, 2024, p. 3</a></span>)</span> æ ¸å¿ƒåšæ³•

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FZ5AQISDH%22%2C%22annotationKey%22%3A%22WGK374Y9%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%224%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B307.44%2C254.531%2C541.437%2C263.438%5D%2C%5B307.44%2C242.576%2C541.437%2C251.483%5D%2C%5B307.44%2C230.621%2C541.437%2C239.528%5D%2C%5B307.44%2C218.666%2C542.687%2C227.573%5D%2C%5B307.44%2C206.711%2C541.437%2C215.618%5D%2C%5B307.44%2C194.756%2C541.442%2C203.663%5D%2C%5B307.44%2C182.8%2C541.437%2C191.707%5D%2C%5B307.44%2C170.845%2C541.437%2C179.752%5D%2C%5B307.44%2C158.89%2C541.437%2C167.797%5D%2C%5B307.44%2C146.935%2C541.442%2C155.842%5D%2C%5B307.44%2C134.98%2C434.543%2C143.887%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%224%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Z5AQISDH?page=4&#x26;annotation=WGK374Y9">â€œFor training, we use a constant learning rate 2e-5. We modify the base of RoPE positional encoding to adjust it to longer context, as in Xiong et al. (2023). We pack all data to 80K chunks regardless of the document boundary, following common practice (Raffel et al., 2020; Touvron et al., 2023a). We set the batch size to be 4M tokens. Note that this batch size is the same as training on 4K context length, as we increase the length of a chunk but decrease the number of chunks in a batch. We train the model on 5B tokens, which translates to 5B (size of data) / 4M (batch size) = 2000 optimization steps.â€</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%224%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/P3J78PXW">Fu ç­‰, 2024, p. 4</a></span>)</span> è®­ç»ƒçš„ä¸€äº›è¶…å‚æ•°

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FZ5AQISDH%22%2C%22annotationKey%22%3A%22WMY68AJ5%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%225%22%2C%22position%22%3A%7B%22pageIndex%22%3A4%2C%22rects%22%3A%5B%5B307.44%2C146.518%2C541.437%2C155.425%5D%2C%5B307.44%2C134.563%2C542.684%2C143.47%5D%2C%5B307.44%2C122.608%2C540.228%2C131.515%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%225%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Z5AQISDH?page=5&#x26;annotation=WMY68AJ5">â€œIn Table 3 we show that our method not only improves precise retrieval, but maintains short context performance, evidenced by strong MMLU (Hendrycks et al., 2020) scoreâ€</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%225%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/P3J78PXW">Fu ç­‰, 2024, p. 5</a></span>)</span> MMLUæ˜¯ä¸€ç§çŸ­æ–‡æœ¬æµ‹è¯„æ–¹æ³•

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FZ5AQISDH%22%2C%22annotationKey%22%3A%22M26JU5GR%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B95.518%2C367.941%2C289.437%2C376.848%5D%2C%5B55.44%2C355.986%2C289.437%2C364.893%5D%2C%5B55.44%2C344.031%2C289.437%2C352.938%5D%2C%5B55.44%2C332.075%2C289.436%2C340.982%5D%2C%5B55.44%2C320.12%2C291.093%2C329.027%5D%2C%5B55.44%2C308.165%2C289.437%2C317.072%5D%2C%5B55.44%2C296.21%2C289.44%2C305.117%5D%2C%5B55.082%2C284.255%2C289.445%2C293.162%5D%2C%5B55.44%2C272.3%2C289.444%2C281.207%5D%2C%5B55.082%2C260.344%2C289.445%2C269.251%5D%2C%5B55.44%2C248.389%2C251.076%2C257.296%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%226%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Z5AQISDH?page=6&#x26;annotation=M26JU5GR">â€œOur method outperforms LongLoRA and Yarn Mistral (even though Mistral 7B is a stronger base model than LLaMA 2 7B we use). Our 13B model performance closes the gap to GPT-4 128K, and we anticipate that future scaling and instruction tuning will further improve performance. While there are other long-context benchmarks in InfiniBench (Zhang et al., 2023), in our initial experiments we found that models often had trouble understanding the instruction (because they are not instruction tuned). Hence we focus on the BookQA benchmark where base LLMs performed reasonably without instruction tuning.â€</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/P3J78PXW">Fu ç­‰, 2024, p. 6</a></span>)</span> å…¶å®ƒçš„é•¿ä¸Šä¸‹åˆåŸºå‡†ç¨‹åºéƒ½æ˜¯åŸºäºæŒ‡ä»¤çš„ï¼Œä½†æœ¬æ–‡å¹¶æ²¡æœ‰å¯¹æ¨¡å‹è¿›è¡Œinstruct tune å› æ­¤æ¨¡å‹éš¾ä»¥ç†è§£æŒ‡ä»¤ã€‚

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FZ5AQISDH%22%2C%22annotationKey%22%3A%22ANHTQP8Z%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B172.563%2C180.693%2C289.438%2C189.6%5D%2C%5B55.44%2C168.738%2C291.098%2C177.645%5D%2C%5B55.44%2C156.783%2C289.438%2C165.69%5D%2C%5B55.44%2C144.828%2C291.185%2C153.735%5D%2C%5B55.44%2C132.873%2C291.093%2C141.78%5D%2C%5B55.44%2C120.918%2C289.439%2C129.825%5D%2C%5B55.44%2C108.962%2C289.437%2C117.869%5D%2C%5B55.082%2C97.007%2C289.436%2C105.914%5D%2C%5B55.44%2C85.052%2C226.428%2C93.959%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%226%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Z5AQISDH?page=6&#x26;annotation=ANHTQP8Z">â€œOur hypothesis is that precise retreival over long-range context is an intrinsic capability obtained by large-scale pretraining, even when the pretraining context length is substantially shorter (4K in many cases). If this hypothesis is true, then lightweight continual pretraining should be enough to extend this capability to much longer context lengths than see in training. That is, we would not need data-intensive continual pretraining as used by Xiong et al. (2023) and XVerse (2024).â€</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/P3J78PXW">Fu ç­‰, 2024, p. 6</a></span>)</span> æœ¬æ–‡çš„è§‚ç‚¹

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FZ5AQISDH%22%2C%22annotationKey%22%3A%22YD6ZRCBU%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B467.894%2C236.182%2C543.09%2C245.089%5D%2C%5B307.44%2C224.227%2C541.438%2C233.134%5D%2C%5B307.44%2C212.272%2C543.09%2C221.179%5D%2C%5B307.44%2C200.317%2C543.093%2C209.224%5D%2C%5B307.44%2C188.361%2C541.442%2C197.268%5D%2C%5B307.44%2C176.406%2C353.443%2C185.313%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%226%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Z5AQISDH?page=6&#x26;annotation=YD6ZRCBU">â€œAt 500M to 1B tokens, the model achieves relatively good performance within its continually pretrained 80K context, but does not generalize to 80K-128K range. After 5B tokens, the model performs well on 0-80K, and can generalize to unseen lengths 80K-128K.â€</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/P3J78PXW">Fu ç­‰, 2024, p. 6</a></span>)</span> æ•°æ®é›†è¶Šå¤§åˆ™æ¨¡å‹çš„å¤„ç†é•¿ä¸Šä¸‹æ–‡èƒ½åŠ›ä¹Ÿè¶Šå¼ºï¼Œä¸è¿‡æœ€ç»ˆä¼šæ”¶æ•›

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FZ5AQISDH%22%2C%22annotationKey%22%3A%227UAFKUN3%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B178.185%2C355.636%2C289.61%2C364.543%5D%2C%5B55.44%2C343.681%2C291.092%2C352.588%5D%2C%5B55.44%2C331.725%2C289.792%2C340.632%5D%2C%5B55.44%2C319.77%2C289.445%2C328.677%5D%2C%5B55.44%2C307.815%2C289.441%2C316.722%5D%2C%5B55.44%2C295.86%2C289.44%2C304.767%5D%2C%5B55.44%2C283.905%2C291.095%2C292.812%5D%2C%5B55.44%2C271.95%2C289.438%2C280.857%5D%2C%5B55.44%2C259.994%2C290.68%2C268.901%5D%2C%5B55.082%2C248.039%2C289.61%2C256.946%5D%2C%5B55.44%2C236.084%2C289.438%2C244.991%5D%2C%5B55.44%2C224.129%2C259.883%2C233.036%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%227%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Z5AQISDH?page=7&#x26;annotation=7UAFKUN3">â€œOur results suggest that for supervised finetuning, since training on long-context is substantially cheaper than previously thought, future work may dive deeper on the solutions for 100K length finetuning and reasoning, which so far has almost no open-source work to our knowledge. For pretraining research, currently there is no definite answer as to whether long-context continual pretraining should be combined with other capabilities, such as math (Azerbayev et al., 2023) and code (Chen et al., 2021), which typically require hundreds of billions of tokens. Our results suggest that long-context continual pretraining could be a separate stage after code and math pretraining.â€</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%227%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/P3J78PXW">Fu ç­‰, 2024, p. 7</a></span>)</span> å¯¹æœªæ¥çš„å±•æœ›ï¼Œè¡¨ç¤ºæœ¬æ–‡çš„æ–¹æ³•å¯åŠ å…¥ä½œä¸ºé¢„è®­ç»ƒçš„ä¸€ç¯

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FZ5AQISDH%22%2C%22annotationKey%22%3A%22HVNPP79N%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B229.489%2C168.388%2C289.444%2C177.295%5D%2C%5B55.44%2C156.433%2C289.438%2C165.34%5D%2C%5B55.44%2C144.478%2C290.27%2C153.385%5D%2C%5B55.44%2C132.523%2C289.692%2C141.43%5D%2C%5B55.44%2C120.567%2C289.442%2C129.474%5D%2C%5B55.44%2C108.612%2C289.442%2C117.519%5D%2C%5B55.44%2C96.657%2C161.276%2C105.564%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%227%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Z5AQISDH?page=7&#x26;annotation=HVNPP79N">â€œRecall that this strategy keeps the mixture ratio of the data sources the same as the original data, i.e., 67% CommonCrawl (CC), 15% C4, 4.5% Github, 4.5% Wikipedia, 4.5% books, 2.5% Arxiv and 2.0% StackExchange for SlimPajama. Then in each of the domains, we upsample sequences longer than 4K from about 30% to about 70%.â€</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%227%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/P3J78PXW">Fu ç­‰, 2024, p. 7</a></span>)</span> æ³¨æ„æ˜¯æ¯ä¸€ä¸ªé‚»åŸŸä¸­éƒ½åˆ†åˆ«è¿›è¡Œä¸Šé‡‡æ ·

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FZ5AQISDH%22%2C%22annotationKey%22%3A%22ELC3SDEK%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B462.352%2C367.591%2C541.792%2C376.498%5D%2C%5B307.44%2C355.636%2C543.093%2C364.543%5D%2C%5B307.44%2C343.681%2C541.438%2C352.588%5D%2C%5B307.44%2C331.725%2C541.437%2C340.632%5D%2C%5B307.44%2C319.77%2C383.076%2C328.677%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%227%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Z5AQISDH?page=7&#x26;annotation=ELC3SDEK">â€œIn contrast, globally upsampling long sequences (without considering their domain), or intentionally upsampling code/ book/ Arxiv (since they are long) changes both the domain mixture and the length distribution.â€</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%227%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/P3J78PXW">Fu ç­‰, 2024, p. 7</a></span>)</span> per-sourceä¸Šé‡‡æ ·åªæ”¹å˜äº†è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦åˆ†å¸ƒï¼Œè€Œå…¶ä½™çš„è¿™äº›æ–¹æ³•ä¸ä»…æ”¹å˜äº†é•¿åº¦åˆ†å¸ƒï¼Œä¹Ÿæ”¹å˜äº†é‚»åŸŸçš„æ··åˆæ¯”ä¾‹

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FZ5AQISDH%22%2C%22annotationKey%22%3A%22LSKDMQV5%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B307.131%2C212.174%2C541.44%2C221.081%5D%2C%5B307.44%2C200.219%2C543.093%2C209.126%5D%2C%5B307.44%2C188.263%2C541.438%2C197.17%5D%2C%5B307.44%2C176.308%2C543.093%2C185.215%5D%2C%5B307.44%2C164.353%2C542.687%2C173.26%5D%2C%5B307.44%2C152.398%2C430.703%2C161.305%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%227%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Z5AQISDH?page=7&#x26;annotation=LSKDMQV5">â€œTable 5 compares the per-domain loss differences of all the data mixture against the baseline original mixture. We report the differences of the validation loss, where a more than 0.01 loss change is considered significant, following common pretraining practice (Kaplan et al., 2020; Peng et al., 2023; Hoffmann et al., 2022).â€</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%227%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/P3J78PXW">Fu ç­‰, 2024, p. 7</a></span>)</span> é€šè¿‡å¯¹æ¯”å®ç°æ¥è¯´æ˜per-sourceæ˜¯æœ€å¹³è¡¡çš„ä¸€ç§æ–¹æ³•ï¼Œä¸ä¼šæé«˜å¤ªå¤šçŸ­æ–‡æœ¬çš„æŸå¤±

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FZ5AQISDH%22%2C%22annotationKey%22%3A%229NI36D2A%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%228%22%2C%22position%22%3A%7B%22pageIndex%22%3A7%2C%22rects%22%3A%5B%5B87.159%2C218.249%2C289.44%2C227.156%5D%2C%5B55.44%2C206.294%2C289.61%2C215.201%5D%2C%5B55.44%2C194.339%2C289.437%2C203.246%5D%2C%5B55.44%2C182.384%2C291.096%2C191.291%5D%2C%5B55.44%2C170.429%2C289.793%2C179.336%5D%2C%5B55.44%2C158.473%2C289.437%2C167.38%5D%2C%5B55.44%2C146.518%2C291.18%2C155.425%5D%2C%5B55.131%2C134.563%2C289.788%2C143.47%5D%2C%5B55.44%2C122.608%2C289.438%2C131.515%5D%2C%5B55.44%2C110.653%2C289.437%2C119.56%5D%2C%5B55.44%2C98.698%2C289.44%2C107.605%5D%2C%5B55.44%2C86.742%2C130.983%2C95.649%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%228%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Z5AQISDH?page=8&#x26;annotation=9NI36D2A">â€œNote that LongLoRA (Chen et al., 2023b) uses the original data mixture without length upsampling, so our results also explains why we achieve better performance than LongLoRA (Fig. 1). We see that the original data mixture without length upsampling, despite achieving a very close loss, underperforms on precise retrieval. Per-source length upsampling significantly improves precise retrieval. This observation also serves as strong evidence why only using test loss, the evaluation used in most prior work (Chen et al., 2023a; Peng et al., 2023; Chen et al., 2023b; Xiao et al., 2023; Anthropic, 2023), may conceal the underlying model differences.â€</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%228%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/P3J78PXW">Fu ç­‰, 2024, p. 8</a></span>)</span> æ²¡æœ‰ä¸Šé‡‡æ ·è™½ç„¶æŸå¤±ç›¸è¿‘ï¼Œä½†æ˜¯åœ¨å¹²è‰å †ä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³ã€‚å› æ­¤å¦‚æœåªæ˜¯ä½¿ç”¨æŸå¤±æ¥è¿›è¡Œæ¨¡å‹çš„è¯„ä¼°æ˜¾ç„¶æ˜¯ç‰‡é¢çš„ï¼Œè¿™ä¼šæ©ç›–æ¨¡å‹æ½œåœ¨çš„å·®å¼‚ã€‚

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FZ5AQISDH%22%2C%22annotationKey%22%3A%22U4JVRYZG%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%228%22%2C%22position%22%3A%7B%22pageIndex%22%3A7%2C%22rects%22%3A%5B%5B307.44%2C346.752%2C541.437%2C355.659%5D%2C%5B307.44%2C334.797%2C541.437%2C343.704%5D%2C%5B307.44%2C322.841%2C541.438%2C331.748%5D%2C%5B307.44%2C310.886%2C543.098%2C319.793%5D%2C%5B307.44%2C298.931%2C541.438%2C307.838%5D%2C%5B307.44%2C286.976%2C543.093%2C295.883%5D%2C%5B307.44%2C275.021%2C541.442%2C283.928%5D%2C%5B307.082%2C263.066%2C528.939%2C271.973%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%228%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Z5AQISDH?page=8&#x26;annotation=U4JVRYZG">â€œLong-context language model research at the 100K-level is still a developing research area. This work only studies continual pretraining, and research on instruction finetuning language models on tasks of 100K context length (e.g., repolevel code understanding) is still limited. So far there seems to no open-source instruction-finetuned 100K context language models. We hope our work serve as a basis for future work on 100K-level long context superivsed finetuning.â€</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10533898%2Fitems%2FP3J78PXW%22%5D%2C%22locator%22%3A%228%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/P3J78PXW">Fu ç­‰, 2024, p. 8</a></span>)</span> 100kçº§åˆ«ä¸Šä¸‹æ–‡çš„å¾®è°ƒä»ç„¶æ˜¯ä¸€ä¸ªé—®é¢˜

## <span style="color: #4A148C"><span style="background-color: #f5f5f5">ğŸš© ç ”ç©¶ç»“è®º</span></span>

***

<span style="color: rgb(6, 6, 7)"><span style="background-color: rgb(255, 255, 255)">è®ºæ–‡æ€»ç»“äº†ç ”ç©¶æˆæœï¼ŒæŒ‡å‡ºé€šè¿‡æŒç»­é¢„è®­ç»ƒå¯ä»¥æœ‰æ•ˆåœ°æ‰©å±•è¯­è¨€æ¨¡å‹çš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œå¹¶ä¸ºæœªæ¥çš„é•¿ä¸Šä¸‹æ–‡æŒ‡ä»¤å¾®è°ƒç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚</span></span>

## <span style="color: #006064"><span style="background-color: #e0f7fa">ğŸ“Œ æ„Ÿæƒ³ &#x26; ç–‘é—®</span></span>

***

è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§é€šè¿‡æ•°æ®å·¥ç¨‹çš„æ–¹æ³•æ¥è¿›è¡Œé•¿ä¸‹æ–‡å»ºæ¨¡ï¼Œä¸»è¦æ˜¯é€šè¿‡åŠ é•¿ç»§ç»­é¢„è®­ç»ƒçš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œå¹¶ä¸”é€‰ç”¨æ–°çš„æ··åˆé‚»åŸŸæ•°æ®é›†ï¼Œå¯¹æ¯ä¸€ä¸ªé‚»åŸŸéƒ½è¿›è¡Œé•¿æ–‡æœ¬çš„ä¸Šé‡‡æ ·ï¼Œä»è€Œæé«˜äº†æ•°æ®è´¨é‡ï¼Œå®éªŒè¯æ˜é€šè¿‡è¿™ç§æ–¹æ³•å¾—åˆ°çš„æ¨¡å‹åœ¨å¹²è‰å †å®éªŒä¸Šçš„æ•ˆæœä¸chatgptæ¥è¿‘ï¼Œå¹¶ä¸”ä¸ä¼šæŸå¤±å¤ªå¤šåœ¨çŸ­æ–‡æœ¬ä¸Šçš„æ€§èƒ½ã€‚

