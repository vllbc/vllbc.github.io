
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="vllbc的个人网站">
      
      
      
        <meta name="author" content="vllbc">
      
      
        <link rel="canonical" href="https://vllbc.top/NLP/Word%20Embedding/">
      
      <link rel="icon" href="../../assets/images/favicon.ico">
      <meta name="generator" content="mkdocs-1.2.3, mkdocs-material-7.3.6">
    
    
      
        <title>Word Embedding - Vllbc的个人博客</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.a57b2b03.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.3f5d1f46.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style>
      
    
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    
      


    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
  
    
    <script>function __prefix(e){return new URL("../..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#_1" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Vllbc的个人博客" class="md-header__button md-logo" aria-label="Vllbc的个人博客" data-md-component="logo">
      
  <img src="../../assets/images/favicon.ico" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Vllbc的个人博客
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Word Embedding
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Vllbc的个人博客" class="md-nav__button md-logo" aria-label="Vllbc的个人博客" data-md-component="logo">
      
  <img src="../../assets/images/favicon.ico" alt="logo">

    </a>
    Vllbc的个人博客
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        首页
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          算法相关
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="算法相关" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          算法相关
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/1/" class="md-nav__link">
        isbn号码
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/2/" class="md-nav__link">
        我做的第一个打表题
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/3/" class="md-nav__link">
        位运算的应用
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/4/" class="md-nav__link">
        位运算的应用(2)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/python_lq/" class="md-nav__link">
        python刷题
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/5/" class="md-nav__link">
        最小公众前缀
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/6/" class="md-nav__link">
        移除元素
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/7/" class="md-nav__link">
        有效的数独
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/8/" class="md-nav__link">
        旋转图像
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/9/" class="md-nav__link">
        去掉重复字母
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/10/" class="md-nav__link">
        字符串转整数
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/11/" class="md-nav__link">
        使用最小花费爬楼梯
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/12/" class="md-nav__link">
        最大子序和
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/13/" class="md-nav__link">
        打家劫舍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/14/" class="md-nav__link">
        外观数列
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/15/" class="md-nav__link">
        计数质数
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/16/" class="md-nav__link">
        分发饼干
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/17/" class="md-nav__link">
        按序打印
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/18/" class="md-nav__link">
        交换性别
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/19/" class="md-nav__link">
        打印零和奇偶数
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/20/" class="md-nav__link">
        零钱兑换
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/21/" class="md-nav__link">
        翻转二叉树
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/22/" class="md-nav__link">
        验证二叉搜索树
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/23/" class="md-nav__link">
        交替打印字符串
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/24/" class="md-nav__link">
        无重叠区域
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/25/" class="md-nav__link">
        种花问题（2021第一题）
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/26/" class="md-nav__link">
        合并区间
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/27/" class="md-nav__link">
        三数之和
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/28/" class="md-nav__link">
        对角线遍历
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/29/" class="md-nav__link">
        最长回文子串
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/30/" class="md-nav__link">
        长度最小的子数组
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/31/" class="md-nav__link">
        删除排序数组中的重复项
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/32/" class="md-nav__link">
        合并两个有序链表
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/33/" class="md-nav__link">
        使括号有效的最小添加
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/34/" class="md-nav__link">
        平衡括号字符串的最少插入次数
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/35/" class="md-nav__link">
        阶乘函数后K个零
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/36/" class="md-nav__link">
        搜索旋转排序数组
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/37/" class="md-nav__link">
        两两交换链表中的节点
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/38/" class="md-nav__link">
        把数字翻译成字符串
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/39/" class="md-nav__link">
        检查平衡性
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/40/" class="md-nav__link">
        可获得的最大点数
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/41/" class="md-nav__link">
        字符串的排列
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/42/" class="md-nav__link">
        至少有k个重复字符的最长字串
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/43/" class="md-nav__link">
        丑数系列
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/44/" class="md-nav__link">
        最大数
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/45/" class="md-nav__link">
        采购方案
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/46/" class="md-nav__link">
        和为s的连续正数序列
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/47/" class="md-nav__link">
        滑动窗口的中位数
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/48/" class="md-nav__link">
        对称二叉树
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/49/" class="md-nav__link">
        最长递增子序列
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/50/" class="md-nav__link">
        分割等和子集
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Python
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Python" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Python
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../python/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../python/plotly/" class="md-nav__link">
        Plotly
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../python/thread/" class="md-nav__link">
        多线程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../python/asyncio/" class="md-nav__link">
        asyncio模块异步编程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../python/skill/" class="md-nav__link">
        技巧
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../python/WTF/" class="md-nav__link">
        WTFpython学习
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../python/pyqt/" class="md-nav__link">
        PyQt学习
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../python/logging/" class="md-nav__link">
        Logging模块学习
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../python/pyplot/" class="md-nav__link">
        Matplotlib.pyplot学习
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          Numpy & Pandas
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Numpy & Pandas" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Numpy & Pandas
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pandas/learn_one/" class="md-nav__link">
        笔记1
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pandas/learn_two/" class="md-nav__link">
        笔记2
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pandas/learn_four/" class="md-nav__link">
        补充学习
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pandas/learn_three/" class="md-nav__link">
        实训笔记
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pandas/task1/" class="md-nav__link">
        协会任务(大一)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pandas/task2/" class="md-nav__link">
        pandas小练习
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pandas/shixun/main/" class="md-nav__link">
        实训作业
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pandas/task3/main/" class="md-nav__link">
        mathorcup杯比赛
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_9" type="checkbox" id="__nav_4_9" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_9">
          api学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="api学习" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_9">
          <span class="md-nav__icon md-icon"></span>
          api学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pandas/melt/" class="md-nav__link">
        melt
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5">
          Pytorch
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Pytorch" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Pytorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_1" type="checkbox" id="__nav_5_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5_1">
          实践
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="实践" data-md-level="2">
        <label class="md-nav__title" for="__nav_5_1">
          <span class="md-nav__icon md-icon"></span>
          实践
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pytorch/%E5%AE%9E%E8%B7%B5/regression/" class="md-nav__link">
        pytorch线性回归
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pytorch/start/" class="md-nav__link">
        pytorch基础
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pytorch/detach/" class="md-nav__link">
        detach
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pytorch/%E8%AE%A1%E7%AE%97%E5%9B%BE/" class="md-nav__link">
        计算图
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pytorch/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%8F%AF%E8%A7%86%E5%8C%96/" class="md-nav__link">
        神经网络结构可视化
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6" type="checkbox" id="__nav_6" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6">
          Sklearn
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Sklearn" data-md-level="1">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          Sklearn
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_1" type="checkbox" id="__nav_6_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_1">
          实践
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="实践" data-md-level="2">
        <label class="md-nav__title" for="__nav_6_1">
          <span class="md-nav__icon md-icon"></span>
          实践
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/%E7%AE%80%E5%8D%95%E7%9A%84%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" class="md-nav__link">
        简单的线性回归
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/%E5%A4%8D%E6%9D%82%E7%9A%84%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" class="md-nav__link">
        复杂的线性回归
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/Logistic%20Regression/" class="md-nav__link">
        Logistic Regression
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/KNN/" class="md-nav__link">
        KNN
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/SVM/" class="md-nav__link">
        SVM
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/Decision%20Tree/" class="md-nav__link">
        Decision Tree
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_2" type="checkbox" id="__nav_6_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_2">
          preprocessing
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="preprocessing" data-md-level="2">
        <label class="md-nav__title" for="__nav_6_2">
          <span class="md-nav__icon md-icon"></span>
          preprocessing
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/" class="md-nav__link">
        数据预处理
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_3" type="checkbox" id="__nav_6_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_3">
          model_selection
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="model_selection" data-md-level="2">
        <label class="md-nav__title" for="__nav_6_3">
          <span class="md-nav__icon md-icon"></span>
          model_selection
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF/%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF/" class="md-nav__link">
        learning_curve
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/%E9%AA%8C%E8%AF%81%E6%9B%B2%E7%BA%BF/%E9%AA%8C%E8%AF%81%E6%9B%B2%E7%BA%BF/" class="md-nav__link">
        validation_curve
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81/" class="md-nav__link">
        交叉验证
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_4" type="checkbox" id="__nav_6_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_4">
          feature_selection
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="feature_selection" data-md-level="2">
        <label class="md-nav__title" for="__nav_6_4">
          <span class="md-nav__icon md-icon"></span>
          feature_selection
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/feature_selection/SelectFromModel/" class="md-nav__link">
        SelectFromModel
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_4_2" type="checkbox" id="__nav_6_4_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_4_2">
          包裹式
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="包裹式" data-md-level="3">
        <label class="md-nav__title" for="__nav_6_4_2">
          <span class="md-nav__icon md-icon"></span>
          包裹式
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/feature_selection/RFE/" class="md-nav__link">
        RFE
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_5" type="checkbox" id="__nav_6_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_5">
          feature_extraction
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="feature_extraction" data-md-level="2">
        <label class="md-nav__title" for="__nav_6_5">
          <span class="md-nav__icon md-icon"></span>
          feature_extraction
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/feature_extraction/CountVectorizer/" class="md-nav__link">
        CountVectorizer
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/feature_extraction/TfidfTransformer/" class="md-nav__link">
        TfidfTransformer
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7" type="checkbox" id="__nav_7" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7">
          Machine Learning
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Machine Learning" data-md-level="1">
        <label class="md-nav__title" for="__nav_7">
          <span class="md-nav__icon md-icon"></span>
          Machine Learning
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/ROC%E6%9B%B2%E7%BA%BF/ROC/" class="md-nav__link">
        ROC曲线
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/EM%E7%AE%97%E6%B3%95/" class="md-nav__link">
        EM算法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87/" class="md-nav__link">
        性能指标
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_4" type="checkbox" id="__nav_7_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7_4">
          关联规则
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="关联规则" data-md-level="2">
        <label class="md-nav__title" for="__nav_7_4">
          <span class="md-nav__icon md-icon"></span>
          关联规则
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E7%AE%97%E6%B3%95/%E6%A6%82%E5%BF%B5/" class="md-nav__link">
        概念
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E7%AE%97%E6%B3%95/Apriori%E7%AE%97%E6%B3%95/" class="md-nav__link">
        Apriori算法
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_5" type="checkbox" id="__nav_7_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7_5">
          降维算法
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="降维算法" data-md-level="2">
        <label class="md-nav__title" for="__nav_7_5">
          <span class="md-nav__icon md-icon"></span>
          降维算法
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95/PCA/" class="md-nav__link">
        PCA
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95/LDA/" class="md-nav__link">
        LDA
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95/SVD/" class="md-nav__link">
        SVD
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_6" type="checkbox" id="__nav_7_6" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7_6">
          回归算法
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="回归算法" data-md-level="2">
        <label class="md-nav__title" for="__nav_7_6">
          <span class="md-nav__icon md-icon"></span>
          回归算法
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" class="md-nav__link">
        线性回归
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95/%E6%A0%91%E5%9B%9E%E5%BD%92/" class="md-nav__link">
        树回归
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_7" type="checkbox" id="__nav_7_7" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7_7">
          分类算法
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="分类算法" data-md-level="2">
        <label class="md-nav__title" for="__nav_7_7">
          <span class="md-nav__icon md-icon"></span>
          分类算法
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/%E6%A6%82%E8%BF%B0/" class="md-nav__link">
        概述
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/bayes/" class="md-nav__link">
        贝叶斯算法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/Logistic%E5%9B%9E%E5%BD%92/" class="md-nav__link">
        Logistic回归
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E6%A6%82%E8%BF%B0/" class="md-nav__link">
        线性分类
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/KNN/" class="md-nav__link">
        KNN
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/%E5%86%B3%E7%AD%96%E6%A0%91/" class="md-nav__link">
        决策树
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/SVM/" class="md-nav__link">
        SVM
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90/" class="md-nav__link">
        线性判别分析
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_8" type="checkbox" id="__nav_7_8" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7_8">
          聚类算法
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="聚类算法" data-md-level="2">
        <label class="md-nav__title" for="__nav_7_8">
          <span class="md-nav__icon md-icon"></span>
          聚类算法
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/kmeans/kmeans/" class="md-nav__link">
        K-means
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/%E5%B1%82%E6%AC%A1%E8%81%9A%E7%B1%BB/" class="md-nav__link">
        层次聚类
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/DBSCAN/" class="md-nav__link">
        DBSCAN
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_9" type="checkbox" id="__nav_7_9" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7_9">
          集成学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="集成学习" data-md-level="2">
        <label class="md-nav__title" for="__nav_7_9">
          <span class="md-nav__icon md-icon"></span>
          集成学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/Ensemble%20Learning/" class="md-nav__link">
        概述
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/Boosting/GBDT/" class="md-nav__link">
        GBDT
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/Stacking/" class="md-nav__link">
        Stacking
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E6%A6%82%E5%BF%B5/" class="md-nav__link">
        一些概念
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_8" type="checkbox" id="__nav_8" >
      
      
      
      
        <label class="md-nav__link" for="__nav_8">
          Deep Learning
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Deep Learning" data-md-level="1">
        <label class="md-nav__title" for="__nav_8">
          <span class="md-nav__icon md-icon"></span>
          Deep Learning
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_8_1" type="checkbox" id="__nav_8_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_8_1">
          项目练习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="项目练习" data-md-level="2">
        <label class="md-nav__title" for="__nav_8_1">
          <span class="md-nav__icon md-icon"></span>
          项目练习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Deep%20Learning/%E9%A1%B9%E7%9B%AE%E7%BB%83%E4%B9%A0/%E5%85%B7%E6%9C%89%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%80%9D%E7%BB%B4%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/nnLogistic/" class="md-nav__link">
        具有逻辑回归思维的神经网络
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_8_2" type="checkbox" id="__nav_8_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_8_2">
          优化算法
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="优化算法" data-md-level="2">
        <label class="md-nav__title" for="__nav_8_2">
          <span class="md-nav__icon md-icon"></span>
          优化算法
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Deep%20Learning/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/" class="md-nav__link">
        梯度下降算法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Deep%20Learning/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/Adam%E7%AE%97%E6%B3%95/" class="md-nav__link">
        Adan算法
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Deep%20Learning/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95/Backpropagation/" class="md-nav__link">
        反向传播算法推导
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Deep%20Learning/RNN/" class="md-nav__link">
        RNN
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Deep%20Learning/softmax%E7%90%86%E8%A7%A3/" class="md-nav__link">
        softmax理解
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_9" type="checkbox" id="__nav_9" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_9">
          NLP
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="NLP" data-md-level="1">
        <label class="md-nav__title" for="__nav_9">
          <span class="md-nav__icon md-icon"></span>
          NLP
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../%E6%A6%82%E8%BF%B0/" class="md-nav__link">
        概述
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_9_2" type="checkbox" id="__nav_9_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_9_2">
          实战
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="实战" data-md-level="2">
        <label class="md-nav__title" for="__nav_9_2">
          <span class="md-nav__icon md-icon"></span>
          实战
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/%E6%96%87%E6%9C%AC%E7%9B%B8%E4%BC%BC%E5%BA%A6/" class="md-nav__link">
        文本相似度
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/%E8%AF%8D%E5%B9%B2%E6%8F%90%E5%8F%96/" class="md-nav__link">
        词干提取
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_9_3" type="checkbox" id="__nav_9_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_9_3">
          概率图模型
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="概率图模型" data-md-level="2">
        <label class="md-nav__title" for="__nav_9_3">
          <span class="md-nav__icon md-icon"></span>
          概率图模型
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/%E6%A6%82%E8%BF%B0/" class="md-nav__link">
        概述
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../tokenization/" class="md-nav__link">
        tokenization综述
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../%E8%AF%8D%E8%A2%8B%E6%A8%A1%E5%9E%8B/" class="md-nav__link">
        词袋模型
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../TF-IDF/" class="md-nav__link">
        TF-IDF
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../%E5%85%B1%E7%8E%B0%E7%9F%A9%E9%98%B5/" class="md-nav__link">
        共现矩阵
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../PPMI/" class="md-nav__link">
        PPMI
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/" class="md-nav__link">
        主题模型
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../BM25/" class="md-nav__link">
        BM25
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../TextRank/" class="md-nav__link">
        TextRank
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E5%8F%96/" class="md-nav__link">
        文本关键词提取
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../HMM/" class="md-nav__link">
        HMM
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Word Embedding
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Word Embedding
      </a>
      
        


<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    介绍
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    语言模型
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    特征工程阶段(基于计数的方法)
  </a>
  
    <nav class="md-nav" aria-label="特征工程阶段(基于计数的方法)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#one-hot" class="md-nav__link">
    One-Hot
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    词袋模型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tfidf" class="md-nav__link">
    TFIDF
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    共现矩阵
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ppmi" class="md-nav__link">
    PPMI
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    主题模型
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    浅层表征阶段
  </a>
  
    <nav class="md-nav" aria-label="浅层表征阶段">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#nnlm" class="md-nav__link">
    NNLM
  </a>
  
    <nav class="md-nav" aria-label="NNLM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    介绍
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    参数解释
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_11" class="md-nav__link">
    优点与缺点
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_12" class="md-nav__link">
    代码
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#word2vec" class="md-nav__link">
    word2vec
  </a>
  
    <nav class="md-nav" aria-label="word2vec">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_13" class="md-nav__link">
    训练思路
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_14" class="md-nav__link">
    推导
  </a>
  
    <nav class="md-nav" aria-label="推导">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_15" class="md-nav__link">
    目标函数：负似然对数
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_16" class="md-nav__link">
    训练
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_17" class="md-nav__link">
    负采样
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#softmax" class="md-nav__link">
    层序softmax
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_18" class="md-nav__link">
    标准设置
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_19" class="md-nav__link">
    代码
  </a>
  
    <nav class="md-nav" aria-label="代码">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_20" class="md-nav__link">
    简单
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_21" class="md-nav__link">
    复杂
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#glove" class="md-nav__link">
    GloVe
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_22" class="md-nav__link">
    参考
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../NER/" class="md-nav__link">
        NER
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/" class="md-nav__link">
        预训练模型
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../CoVe/" class="md-nav__link">
        Cove
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ELMo/" class="md-nav__link">
        ELMo
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../seq2seq/" class="md-nav__link">
        seq2seq
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Attention/" class="md-nav__link">
        Attention
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Transformer/" class="md-nav__link">
        Transformer
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../GPT/" class="md-nav__link">
        GPT
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../BERT/" class="md-nav__link">
        Bert
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_10" type="checkbox" id="__nav_10" >
      
      
      
      
        <label class="md-nav__link" for="__nav_10">
          面经
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="面经" data-md-level="1">
        <label class="md-nav__title" for="__nav_10">
          <span class="md-nav__icon md-icon"></span>
          面经
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E9%9D%A2%E7%BB%8F/LR%E4%B8%BA%E4%BB%80%E4%B9%88%E7%94%A8%E4%BA%A4%E5%8F%89%E7%86%B5/" class="md-nav__link">
        LR为什么使用交叉熵
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E9%9D%A2%E7%BB%8F/%E5%89%8D%E7%BC%80%E6%A0%91/" class="md-nav__link">
        前缀树
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_11" type="checkbox" id="__nav_11" >
      
      
      
      
        <label class="md-nav__link" for="__nav_11">
          数学建模
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="数学建模" data-md-level="1">
        <label class="md-nav__title" for="__nav_11">
          <span class="md-nav__icon md-icon"></span>
          数学建模
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Mathematical%20Modeling/%E5%B1%82%E6%AC%A1%E5%88%86%E6%9E%90%E6%B3%95/" class="md-nav__link">
        层次分析法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Mathematical%20Modeling/%E4%BC%98%E5%8A%A3%E8%A7%A3%E8%B7%9D%E7%A6%BB%E6%B3%95Topsis/" class="md-nav__link">
        Topsis
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_11_3" type="checkbox" id="__nav_11_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_11_3">
          插值算法
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="插值算法" data-md-level="2">
        <label class="md-nav__title" for="__nav_11_3">
          <span class="md-nav__icon md-icon"></span>
          插值算法
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Mathematical%20Modeling/%E6%8F%92%E5%80%BC%E7%AE%97%E6%B3%95/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E6%8F%92%E5%80%BC/" class="md-nav__link">
        拉格朗日插值法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Mathematical%20Modeling/%E6%8F%92%E5%80%BC%E7%AE%97%E6%B3%95/%E7%89%9B%E9%A1%BF%E6%8F%92%E5%80%BC/" class="md-nav__link">
        牛顿插值法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Mathematical%20Modeling/%E6%8F%92%E5%80%BC%E7%AE%97%E6%B3%95/Hermite/" class="md-nav__link">
        Hermite插值法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Mathematical%20Modeling/%E6%8F%92%E5%80%BC%E7%AE%97%E6%B3%95/%E5%88%86%E6%AE%B5%E7%BA%BF%E6%80%A7%E6%8F%92%E5%80%BC/" class="md-nav__link">
        分段线性插值法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Mathematical%20Modeling/%E6%8F%92%E5%80%BC%E7%AE%97%E6%B3%95/%E6%A0%B7%E6%9D%A1%E6%8F%92%E5%80%BC/" class="md-nav__link">
        样条插值法
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Mathematical%20Modeling/%E5%85%B8%E5%9E%8B%E7%9B%B8%E5%85%B3%E5%88%86%E6%9E%90/" class="md-nav__link">
        典型相关分析
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Mathematical%20Modeling/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0/" class="md-nav__link">
        相关系数
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Mathematical%20Modeling/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/" class="md-nav__link">
        回归分析
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Mathematical%20Modeling/%E5%9B%A0%E5%AD%90%E5%88%86%E6%9E%90/" class="md-nav__link">
        因子分析
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Mathematical%20Modeling/%E7%81%B0%E8%89%B2%E5%85%B3%E8%81%94%E5%88%86%E6%9E%90/" class="md-nav__link">
        灰色关联分析
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Mathematical%20Modeling/%E7%81%B0%E8%89%B2%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B/" class="md-nav__link">
        灰色预测模型
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_12" type="checkbox" id="__nav_12" >
      
      
      
      
        <label class="md-nav__link" for="__nav_12">
          比赛相关
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="比赛相关" data-md-level="1">
        <label class="md-nav__title" for="__nav_12">
          <span class="md-nav__icon md-icon"></span>
          比赛相关
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%AF%94%E8%B5%9B%E7%9B%B8%E5%85%B3/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E6%AF%94%E8%B5%9B/" class="md-nav__link">
        数据挖掘比赛
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_13" type="checkbox" id="__nav_13" >
      
      
      
      
        <label class="md-nav__link" for="__nav_13">
          其他
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="其他" data-md-level="1">
        <label class="md-nav__title" for="__nav_13">
          <span class="md-nav__icon md-icon"></span>
          其他
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../others/vim/" class="md-nav__link">
        vim
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../others/git/" class="md-nav__link">
        git
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../others/regex/" class="md-nav__link">
        regex
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../others/sql/" class="md-nav__link">
        sql
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../others/one_test/" class="md-nav__link">
        博客后台案例
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../others/linux/" class="md-nav__link">
        linux学习
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../others/jupyter_pdf/" class="md-nav__link">
        浅谈jupyter导出为pdf
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../others/others/" class="md-nav__link">
        常用学习网站书籍
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    介绍
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    语言模型
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    特征工程阶段(基于计数的方法)
  </a>
  
    <nav class="md-nav" aria-label="特征工程阶段(基于计数的方法)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#one-hot" class="md-nav__link">
    One-Hot
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    词袋模型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tfidf" class="md-nav__link">
    TFIDF
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    共现矩阵
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ppmi" class="md-nav__link">
    PPMI
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    主题模型
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    浅层表征阶段
  </a>
  
    <nav class="md-nav" aria-label="浅层表征阶段">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#nnlm" class="md-nav__link">
    NNLM
  </a>
  
    <nav class="md-nav" aria-label="NNLM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    介绍
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    参数解释
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_11" class="md-nav__link">
    优点与缺点
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_12" class="md-nav__link">
    代码
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#word2vec" class="md-nav__link">
    word2vec
  </a>
  
    <nav class="md-nav" aria-label="word2vec">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_13" class="md-nav__link">
    训练思路
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_14" class="md-nav__link">
    推导
  </a>
  
    <nav class="md-nav" aria-label="推导">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_15" class="md-nav__link">
    目标函数：负似然对数
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_16" class="md-nav__link">
    训练
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_17" class="md-nav__link">
    负采样
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#softmax" class="md-nav__link">
    层序softmax
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_18" class="md-nav__link">
    标准设置
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_19" class="md-nav__link">
    代码
  </a>
  
    <nav class="md-nav" aria-label="代码">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_20" class="md-nav__link">
    简单
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_21" class="md-nav__link">
    复杂
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#glove" class="md-nav__link">
    GloVe
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_22" class="md-nav__link">
    参考
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="_1">词嵌入<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h1>
<h2 id="_2">介绍<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h2>
<blockquote>
<p>**词嵌入**是<a href="https://baike.baidu.com/item/自然语言处理">自然语言处理</a>（NLP）中<a href="https://baike.baidu.com/item/语言模型">语言模型</a>与<a href="https://baike.baidu.com/item/表征学习">表征学习</a>技术的统称。概念上而言，它是指把一个维数为所有词的数量的高维空间嵌入到一个维数低得多的连续<a href="https://baike.baidu.com/item/向量空间">向量空间</a>中，每个单词或词组被映射为实数<a href="https://baike.baidu.com/item/域">域</a>上的向量。</p>
<p>词嵌入的方法包括<a href="https://baike.baidu.com/item/人工神经网络">人工神经网络</a>、对词语同现矩阵<a href="https://baike.baidu.com/item/降维">降维</a>、<a href="https://baike.baidu.com/item/概率模型">概率模型</a>以及单词所在上下文的显式表示等。</p>
<p>在底层输入中，使用词嵌入来表示词组的方法极大提升了NLP中<a href="https://baike.baidu.com/item/语法分析器">语法分析器</a>和<a href="https://baike.baidu.com/item/文本情感分析">文本情感分析</a>等的效果。</p>
</blockquote>
<p>以上是百度百科中对词嵌入的定义。本文只介绍传统的词向量，也就是固定的词向量。deep contextualized词向量模型在本博客预训练模型内容里面。词嵌入也可以称为词表征(word representation)，可以粗略得把它分为三个阶段：</p>
<p><strong>一、特征工程阶段，以词袋模型为典型代表。</strong></p>
<p><strong>二、浅层表证阶段，以word2vec为典型代表。</strong></p>
<p><strong>三、深层表征阶段，以基于transformer的Bert为典型代表。</strong></p>
<p>本文介绍了一、二两部分内容</p>
<h2 id="_3">语言模型<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h2>
<p>一句话，语言模型是这样一个模型：<strong>对于任意的词序列，它能够计算出这个序列是一句话的概率</strong>。</p>
<p>具体的详见本博客有关语言模型的文章。</p>
<p>为什么要介绍语言模型，因为NLP的做预训练一般选择用语言模型任务来做的。</p>
<p>语言模型主要有： N-gram LM、FeedForward Neural Network LM、RNN LM和GPT系列</p>
<p>本文会涉及到Neural Network LM，其本质是一个语言模型，词向量只是其在训练过程中的一个副产物。</p>
<h2 id="_4">特征工程阶段(基于计数的方法)<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h2>
<h3 id="one-hot">One-Hot<a class="headerlink" href="#one-hot" title="Permanent link">&para;</a></h3>
<p>最简单的方法是将单词表示为 one-hot 向量：对于词汇表中的第 i 个单词，向量在第 i 个维度上具有 1，在其余维度上具有 0。在机器学习中，这是表示分类特征的最简单方法。</p>
<p>One-Hot的缺点很明显，它对自己代表的词一无所知，没有捕捉到词的意义。</p>
<h3 id="_5">词袋模型<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h3>
<p>详见本博客词袋模型内容</p>
<h3 id="tfidf">TFIDF<a class="headerlink" href="#tfidf" title="Permanent link">&para;</a></h3>
<p>权重也可以作为词向量表示。</p>
<p>详见本博客TFIDF内容</p>
<h3 id="_6">共现矩阵<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h3>
<h3 id="ppmi">PPMI<a class="headerlink" href="#ppmi" title="Permanent link">&para;</a></h3>
<p><a href="../PPMI/">PPMI</a></p>
<p>中文名字为正点互信息，公式如下</p>
<div class="arithmatex">
<div class="MathJax_Preview">
PPMI(w, c) = max(0, PMI(w, c)) \\
PMI(w, c) = log\frac{P(w,c)}{P(w)P(c)} = log \frac{N(w,c)|(w,c)|}{N(w)N(c)}
</div>
<script type="math/tex; mode=display">
PPMI(w, c) = max(0, PMI(w, c)) \\
PMI(w, c) = log\frac{P(w,c)}{P(w)P(c)} = log \frac{N(w,c)|(w,c)|}{N(w)N(c)}
</script>
</div>
<p>事实证明，word2vec被证明可以隐式逼近PMI矩阵的因式分解。</p>
<div class="highlight"><pre><span></span><code>『Neural Word Embedding as Implicit Matrix Factorization』这篇论文就详细讨论了这个问题。
</code></pre></div>
<h3 id="_7">主题模型<a class="headerlink" href="#_7" title="Permanent link">&para;</a></h3>
<p>详见本博客主题模型内容<a href="../%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/">主题模型</a></p>
<h2 id="_8">浅层表征阶段<a class="headerlink" href="#_8" title="Permanent link">&para;</a></h2>
<h3 id="nnlm">NNLM<a class="headerlink" href="#nnlm" title="Permanent link">&para;</a></h3>
<h4 id="_9">介绍<a class="headerlink" href="#_9" title="Permanent link">&para;</a></h4>
<p>先来张经典的图片</p>
<p><img alt="jpg" src="../pic/NNLM.jpg" /></p>
<p>这就是大名鼎鼎的神经网络语言模型（其它的语言模型详见本博客语言模型部分）</p>
<p>学习任务是输入某个句中单词<span class="arithmatex"><span class="MathJax_Preview">W_t=i</span><script type="math/tex">W_t=i</script></span>前面句子的t-1个单词，要求网络正确预测单词<span class="arithmatex"><span class="MathJax_Preview">W_t=i</span><script type="math/tex">W_t=i</script></span>，即最大化：</p>
<div class="arithmatex">
<div class="MathJax_Preview">
P(W_t=i | W_1, W_2, \dots W_{(t-1)}; \theta)
</div>
<script type="math/tex; mode=display">
P(W_t=i | W_1, W_2, \dots W_{(t-1)}; \theta)
</script>
</div>
<p>前面任意单词 <span class="arithmatex"><span class="MathJax_Preview">W_i</span><script type="math/tex">W_i</script></span>用Onehot编码（比如：0001000）作为原始单词输入，之后乘以矩阵Q后获得向量 <span class="arithmatex"><span class="MathJax_Preview">C(W_i)</span><script type="math/tex">C(W_i)</script></span>，每个单词的 <span class="arithmatex"><span class="MathJax_Preview">C(W_i)</span><script type="math/tex">C(W_i)</script></span> 拼接，上接隐层，然后接softmax去预测后面应该后续接哪个单词。</p>
<p>这个<span class="arithmatex"><span class="MathJax_Preview">C(W_i)</span><script type="math/tex">C(W_i)</script></span>是什么？</p>
<p>这其实就是单词对应的Word Embedding值，那个矩阵Q包含V行，V代表词典大小，每一行内容代表对应单词的Word embedding值。只不过Q的内容也是网络参数，需要学习获得，训练刚开始用随机值初始化矩阵Q，当这个网络训练好之后，矩阵Q的内容被正确赋值，每一行代表一个单词对应的Word embedding值。</p>
<p>所以你看，通过这个网络学习语言模型任务，这个网络不仅自己能够根据上文预测后接单词是什么，同时获得一个副产品，就是那个矩阵Q，这就是单词的Word Embedding是被如何学会的。</p>
<h4 id="_10">参数解释<a class="headerlink" href="#_10" title="Permanent link">&para;</a></h4>
<ul>
<li>训练样本(Context(w), w),w是语料C的每一个词，Context(w)为取其前n-1个词</li>
<li>投影层向量<span class="arithmatex"><span class="MathJax_Preview">X_w</span><script type="math/tex">X_w</script></span>: 将该训练样本(Context(w), w)的前n-1个词的词向量首尾拼接在一起，这里的词向量可以用独热编码表示。<span class="arithmatex"><span class="MathJax_Preview">X_w</span><script type="math/tex">X_w</script></span>的形状为 <span class="arithmatex"><span class="MathJax_Preview">(n-1)\times m</span><script type="math/tex">(n-1)\times m</script></span>，这里的m为词汇表的所有词的个数。</li>
<li>隐藏层向量<span class="arithmatex"><span class="MathJax_Preview">Z_w</span><script type="math/tex">Z_w</script></span>:</li>
</ul>
<div class="arithmatex">
<div class="MathJax_Preview">
Z_w = tanh(WX_w+p)
</div>
<script type="math/tex; mode=display">
Z_w = tanh(WX_w+p)
</script>
</div>
<ul>
<li>输出层向量<span class="arithmatex"><span class="MathJax_Preview">y_w</span><script type="math/tex">y_w</script></span>: 维度为N=|D|,即词典D中词的个数。</li>
</ul>
<p>$$
y_w = Uz_w + q
$$
在对<span class="arithmatex"><span class="MathJax_Preview">y_w</span><script type="math/tex">y_w</script></span>做softmax后，<span class="arithmatex"><span class="MathJax_Preview">y_w</span><script type="math/tex">y_w</script></span>的分量就表示当前词是w的概率</p>
<div class="arithmatex">
<div class="MathJax_Preview">
p(w|Context(w)) = \frac{e^{y_w,iw}}{\sum_{i-1}^N e^{y^{w, i}} }
</div>
<script type="math/tex; mode=display">
p(w|Context(w)) = \frac{e^{y_w,iw}}{\sum_{i-1}^N e^{y^{w, i}} }
</script>
</div>
<h4 id="_11">优点与缺点<a class="headerlink" href="#_11" title="Permanent link">&para;</a></h4>
<p>NNLM相对于N-grams语言模型，有以下优点：</p>
<ol>
<li>词语与词语间的相似度可以通过词向量来体现</li>
<li>基于词向量的模型自带『平滑化』功能，无需额外处理。</li>
</ol>
<p>当然也有缺点，缺点就是计算量太大。</p>
<p>下面就重点介绍一下word2vec，相比于NNLM来说这是专门训练词向量的一种工具，而词向量对于NNLM来说只是一个副产物，其本质还是一个语言模型。</p>
<h4 id="_12">代码<a class="headerlink" href="#_12" title="Permanent link">&para;</a></h4>
<p>代码来自<a href="https://github.com/graykode/nlp-tutorial">https://github.com/graykode/nlp-tutorial</a></p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>

<span class="k">def</span> <span class="nf">make_batch</span><span class="p">():</span>
    <span class="n">input_batch</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">target_batch</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">sen</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">:</span>
        <span class="n">word</span> <span class="o">=</span> <span class="n">sen</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> <span class="c1"># space tokenizer</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="p">[</span><span class="n">word_dict</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">word</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span> <span class="c1"># create (1~n-1) as input</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">word_dict</span><span class="p">[</span><span class="n">word</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span> <span class="c1"># create (n) as target, We usually call this &#39;casual language model&#39;</span>

        <span class="n">input_batch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="n">target_batch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">input_batch</span><span class="p">,</span> <span class="n">target_batch</span>

<span class="c1"># Model</span>
<span class="k">class</span> <span class="nc">NNLM</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NNLM</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">n_class</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">H</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_step</span> <span class="o">*</span> <span class="n">m</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">U</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_class</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_step</span> <span class="o">*</span> <span class="n">m</span><span class="p">,</span> <span class="n">n_class</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_class</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">C</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c1"># X : [batch_size, n_step, m]</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_step</span> <span class="o">*</span> <span class="n">m</span><span class="p">)</span> <span class="c1"># [batch_size, n_step * m]</span>
        <span class="n">tanh</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">H</span><span class="p">(</span><span class="n">X</span><span class="p">))</span> <span class="c1"># [batch_size, n_hidden]</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">U</span><span class="p">(</span><span class="n">tanh</span><span class="p">)</span> <span class="c1"># [batch_size, n_class]</span>
        <span class="k">return</span> <span class="n">output</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">n_step</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># number of steps, n-1 in paper</span>
    <span class="n">n_hidden</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># number of hidden size, h in paper</span>
    <span class="n">m</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># embedding size, m in paper</span>

    <span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;i like dog&quot;</span><span class="p">,</span> <span class="s2">&quot;i love coffee&quot;</span><span class="p">,</span> <span class="s2">&quot;i hate milk&quot;</span><span class="p">]</span>

    <span class="n">word_list</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> <span class="c1"># [&#39;i&#39;, &#39;like&#39;, &#39;dog&#39;, &#39;dog&#39;, &#39;i&#39;, &#39;love&#39;, &#39;coffee&#39;, &#39;i&#39;, &#39;hate&#39;, &#39;milk&#39;]</span>
    <span class="n">word_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">word_list</span><span class="p">))</span> <span class="c1"># [&#39;i&#39;, &#39;like&#39;, &#39;dog&#39;, &#39;love&#39;, &#39;coffee&#39;, &#39;hate&#39;, &#39;milk&#39;]</span>
    <span class="n">word_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">w</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">word_list</span><span class="p">)}</span> <span class="c1"># {&#39;i&#39;:0, &#39;like&#39;:1, &#39;dog&#39;:2, &#39;love&#39;:3, &#39;coffee&#39;:4, &#39;hate&#39;:5, &#39;milk&#39;:6}</span>
    <span class="n">number_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">w</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">word_list</span><span class="p">)}</span> <span class="c1"># {0:&#39;i&#39;, 1:&#39;like&#39;, 2:&#39;dog&#39;, 3:&#39;love&#39;, 4:&#39;coffee&#39;, 5:&#39;hate&#39;, 6:&#39;milk&#39;}</span>
    <span class="n">n_class</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_dict</span><span class="p">)</span>  <span class="c1"># number of Vocabulary, just like |V|, in this task n_class=7</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">NNLM</span><span class="p">()</span>

    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>

    <span class="n">input_batch</span><span class="p">,</span> <span class="n">target_batch</span> <span class="o">=</span> <span class="n">make_batch</span><span class="p">()</span>
    <span class="n">input_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">input_batch</span><span class="p">)</span>
    <span class="n">target_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">target_batch</span><span class="p">)</span>

    <span class="c1"># Training</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5000</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_batch</span><span class="p">)</span>

        <span class="c1"># output : [batch_size, n_class], target_batch : [batch_size]</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target_batch</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch:&#39;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">%04d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="s1">&#39;cost =&#39;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">{:.6f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">loss</span><span class="p">))</span>

        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="c1"># Predict</span>
    <span class="n">predict</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_batch</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Test</span>
    <span class="nb">print</span><span class="p">([</span><span class="n">sen</span><span class="o">.</span><span class="n">split</span><span class="p">()[:</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">sen</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">],</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">number_dict</span><span class="p">[</span><span class="n">n</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">predict</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()])</span>
</code></pre></div>
<h3 id="word2vec">word2vec<a class="headerlink" href="#word2vec" title="Permanent link">&para;</a></h3>
<p>Word2Vec是从大量文本语料中以无监督的方式学习语义知识的一种模型，它被大量地用在自然语言处理（NLP）中。那么它是如何帮助我们做自然语言处理呢？Word2Vec其实就是通过学习文本来用词向量的方式表征词的语义信息，即通过一个嵌入空间使得语义上相似的单词在该空间内距离很近。Embedding其实就是一个映射，将单词从原先所属的空间映射到新的多维空间中，也就是把原先词所在空间嵌入到一个新的空间中去。</p>
<p>Word2Vec和NNLM不一样，NNLM的主要任务是要学习一个解决语言模型任务的网络结构，语言模型就是要看到上文预测下文，而word embedding只是无心插柳的一个副产品。但是Word2Vec目标不一样，它单纯就是要word embedding的，这是主产品，所以它完全可以随性地这么去训练网络。
(skip-gram与CBOW只是word2vec的变体。)</p>
<h4 id="_13">训练思路<a class="headerlink" href="#_13" title="Permanent link">&para;</a></h4>
<p>Word2Vec 是一个模型，其参数是词向量。这些参数针对某个目标进行迭代优化。目标迫使词向量“知道”一个词可能出现的上下文：训练向量以预测相应词的可能上下文。正如您从分布假设中所记得的那样，如果向量“知道”上下文，它们就“知道”单词的含义。</p>
<ul>
<li>获取一个巨大的文本语料库；</li>
<li>使用滑动窗口浏览文本，一次移动一个单词。在每一步，都有一个中心词和上下文词（此窗口中的其他词）；</li>
<li>对于中心词，计算上下文词的概率；</li>
<li>调整向量以增加这些概率。</li>
</ul>
<h4 id="_14">推导<a class="headerlink" href="#_14" title="Permanent link">&para;</a></h4>
<p>以Skip-grams模型为例，首先清楚几个概念，中心词、背景词（上下文词）、负采样词。中心词就是我们的输入，因为skip-grams相当于在一句话中扣去一个词，然后用这个词预测这句话的其余词。形式上给人的感觉就是一对多，这里的一句话其实不是一句话，是我们设定的窗口大小，比如一句话&rdquo;I miss xwh very much&rdquo;，
设置中心词为xwh，窗口大小为1，那么背景词就是&rdquo;miss&rdquo;和&rdquo;very&rdquo;。那么对于我们的模型来说，miss和very就是正例，就是我们的预测值(sigmoid后)的值接近于1的，而其余的词就是负例，就是使其值接近于0的。所以负采样就是从这些负例中随机抽取一些负例，不然每次都要计算单词表中所有单词的sigmoid值，这个计算量很大，而使用负采样就大大缩小了计算量。</p>
<p><img alt="png" src="../pic/window1.png" />
<img alt="png" src="../pic/window2.png" /></p>
<h5 id="_15">目标函数：负似然对数<a class="headerlink" href="#_15" title="Permanent link">&para;</a></h5>
<p>对于每个位置<span class="arithmatex"><span class="MathJax_Preview">t=1,\dots, T</span><script type="math/tex">t=1,\dots, T</script></span>，在文本语料库中，Word2Vec在给定中心词的m大小窗口内预测上下文词<span class="arithmatex"><span class="MathJax_Preview">w_t</span><script type="math/tex">w_t</script></span>:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
Likelihood=L(\theta)=\prod_{t=1}^T\prod_{-m\leq j\leq m, j\neq0} P(w_{t+j} | w_t, \theta)
</div>
<script type="math/tex; mode=display">
Likelihood=L(\theta)=\prod_{t=1}^T\prod_{-m\leq j\leq m, j\neq0} P(w_{t+j} | w_t, \theta)
</script>
</div>
<p>目标函数<span class="arithmatex"><span class="MathJax_Preview">J(\theta)</span><script type="math/tex">J(\theta)</script></span>为平均负对数似然</p>
<div class="arithmatex">
<div class="MathJax_Preview">
Loss = J(\theta) = -\frac{1}{T}\sum_{t=1}^T\sum_{-m\leq j\leq m, j\neq0} logP(w_{t+j}|w_t, \theta)
</div>
<script type="math/tex; mode=display">
Loss = J(\theta) = -\frac{1}{T}\sum_{t=1}^T\sum_{-m\leq j\leq m, j\neq0} logP(w_{t+j}|w_t, \theta)
</script>
</div>
<p>对于每个单词w我们都有两个向量：</p>
<ul>
<li><span class="arithmatex"><span class="MathJax_Preview">v_w</span><script type="math/tex">v_w</script></span>当w是中心词</li>
<li><span class="arithmatex"><span class="MathJax_Preview">u_w</span><script type="math/tex">u_w</script></span>当w时背景词</li>
</ul>
<p>训练完毕后，我们只使用<span class="arithmatex"><span class="MathJax_Preview">v_w</span><script type="math/tex">v_w</script></span>，即只使用从输入层到隐藏层的权重。</p>
<p>对于中心词w，上下文词c的概率为：</p>
<div class="arithmatex">
<div class="MathJax_Preview">
P(c|w) = \frac{exp(u_c^Tv_w)}{\sum_{o\in V}exp(u_o^Tv_w)}
</div>
<script type="math/tex; mode=display">
P(c|w) = \frac{exp(u_c^Tv_w)}{\sum_{o\in V}exp(u_o^Tv_w)}
</script>
</div>
<p>这就是softmax函数。</p>
<h5 id="_16">训练<a class="headerlink" href="#_16" title="Permanent link">&para;</a></h5>
<p><span class="arithmatex"><span class="MathJax_Preview">\theta^{new} = \theta^{old} - \alpha \nabla_\theta J(\theta)</span><script type="math/tex">\theta^{new} = \theta^{old} - \alpha \nabla_\theta J(\theta)</script></span></p>
<p>一次进行一次更新，每次更新都是针对一对中心词和其中一个背景词。损失函数：</p>
<div class="arithmatex">
<div class="MathJax_Preview">
Loss = J(\theta) = -\frac{1}{T}logL(\theta)= -\frac{1}{T}\sum_{t=1}^T\sum_{-m\leq j\leq m, j\neq0} logP(w_{t+j}|w_t, \theta)\\=\frac{1}{T}\sum_{t=1}^T\sum_{-m\leq j\leq m, j\neq0}J_{t,j}(\theta).
</div>
<script type="math/tex; mode=display">
Loss = J(\theta) = -\frac{1}{T}logL(\theta)= -\frac{1}{T}\sum_{t=1}^T\sum_{-m\leq j\leq m, j\neq0} logP(w_{t+j}|w_t, \theta)\\=\frac{1}{T}\sum_{t=1}^T\sum_{-m\leq j\leq m, j\neq0}J_{t,j}(\theta).
</script>
</div>
<p>其中<span class="arithmatex"><span class="MathJax_Preview">J_{t,j}(\theta) = -logP(w_{t+j}|w_t, \theta)</span><script type="math/tex">J_{t,j}(\theta) = -logP(w_{t+j}|w_t, \theta)</script></span></p>
<p>以&rdquo;I miss xwh very much&rdquo;这句话为例子，中心词为&rdquo;xwh&rdquo;，其中一个背景词为miss，则损失项为</p>
<div class="arithmatex">
<div class="MathJax_Preview">
J_{t,j}(\theta) = -logP(miss|xwh) = -log\frac{exp(u_{miss}^Tv_{xwh})}{\sum_{o\in V}exp(u_o^Tv_{xwh})} = \\-u_{miss}^Tv_{xwh}+log\sum_{o\in V} exp(u_o^Tv_{xwh})
</div>
<script type="math/tex; mode=display">
J_{t,j}(\theta) = -logP(miss|xwh) = -log\frac{exp(u_{miss}^Tv_{xwh})}{\sum_{o\in V}exp(u_o^Tv_{xwh})} = \\-u_{miss}^Tv_{xwh}+log\sum_{o\in V} exp(u_o^Tv_{xwh})
</script>
</div>
<p>这是中心词对应其中一个背景词的损失函数，如果要求总的损失，则将所有背景词的损失相加，然后将所有样本的损失求平均，就是上面的Loss。其实这就是交叉熵损失函数，是个多分类问题，预测的target相当于miss对应的数字，也就是序列值，具体的pytorch代码为</p>
<p><code>loss = (-output_layer[:, Y] + torch.log(torch.sum(torch.exp(output_layer), dim=1))).mean()</code></p>
<p>这里的output_layer就是神经网络的输出层，注意这里的都是对batch操作，这里求出的loss是这个batch上最终的loss，而不是一对中心词与背景词的loss。理解了这个简单的word2vec模型就算理解了。
下面求一下梯度：
注意这里的c为center word, o为上下文词
$$
\frac{\partial logP(w_o|w_c)}{\partial v_c} =
\frac{\partial}{\partial v_c}log\frac{exp(u_0<sup>Tv_c)}{\sum_{i=1}</sup>{|V|}exp(u_i^Tv_c)}\=
\frac{\partial}{\partial v_c}log\, exp(u_o^Tv_c) - \frac{\partial}{\partial v_c}log\sum_{i=1}<sup>{|V|}exp(u_i</sup>Tv_c)
$$</p>
<p>左边的：</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\frac{\partial}{\partial v_c}log\, exp(u_o^Tv_c)=\frac{\partial}{\partial v_c}u_o^Tv_c=u_o
</div>
<script type="math/tex; mode=display">
\frac{\partial}{\partial v_c}log\, exp(u_o^Tv_c)=\frac{\partial}{\partial v_c}u_o^Tv_c=u_o
</script>
</div>
<p>第二部分推导</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\begin{aligned}
\frac{\partial}{\partial \boldsymbol{v}_{c}} \log \sum_{i=1}^{|V|} \exp \left(\boldsymbol{u}_{i}^{T} \boldsymbol{v}_{c}\right) &amp;=\frac{1}{\sum_{i=1}^{|V|} \exp \left(\boldsymbol{u}_{i}^{T} \boldsymbol{v}_{c}\right)} \cdot \frac{\partial}{\partial \boldsymbol{v}_{c}} \sum_{x=1}^{|V|} \exp \left(\boldsymbol{u}_{x}^{T} \boldsymbol{v}_{c}\right) \\
&amp;=\frac{1}{A} \cdot \sum_{x=1}^{|V|} \frac{\partial}{\partial \boldsymbol{v}_{c}} \exp \left(\boldsymbol{u}_{x}^{T} \boldsymbol{v}_{c}\right) \\
&amp;=\frac{1}{A} \cdot \sum_{x=1}^{|V|} \exp \left(\boldsymbol{u}_{x}^{T} \boldsymbol{v}_{c}\right) \frac{\partial}{\partial \boldsymbol{v}_{c}} \boldsymbol{u}_{x}^{T} \boldsymbol{v}_{c} \\
&amp;=\frac{1}{\sum_{i=1}^{|V|} \exp \left(\boldsymbol{u}_{i}^{T} \boldsymbol{v}_{c}\right)} \sum_{x=1}^{|V|} \exp \left(\boldsymbol{u}_{x}^{T} \boldsymbol{v}_{c}\right) \boldsymbol{u}_{x} \\
&amp;=\sum_{x=1}^{|V|} \frac{\exp \left(\boldsymbol{u}_{x}^{T} \boldsymbol{v}_{c}\right)}{\sum_{i=1}^{|V|} \exp \left(\boldsymbol{u}_{i}^{T} \boldsymbol{v}_{c}\right)} \boldsymbol{u}_{x} \\
&amp;=\sum_{x=1}^{|V|} P\left(w_{x} \mid w_{c}\right) \boldsymbol{u}_{x}
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
\frac{\partial}{\partial \boldsymbol{v}_{c}} \log \sum_{i=1}^{|V|} \exp \left(\boldsymbol{u}_{i}^{T} \boldsymbol{v}_{c}\right) &=\frac{1}{\sum_{i=1}^{|V|} \exp \left(\boldsymbol{u}_{i}^{T} \boldsymbol{v}_{c}\right)} \cdot \frac{\partial}{\partial \boldsymbol{v}_{c}} \sum_{x=1}^{|V|} \exp \left(\boldsymbol{u}_{x}^{T} \boldsymbol{v}_{c}\right) \\
&=\frac{1}{A} \cdot \sum_{x=1}^{|V|} \frac{\partial}{\partial \boldsymbol{v}_{c}} \exp \left(\boldsymbol{u}_{x}^{T} \boldsymbol{v}_{c}\right) \\
&=\frac{1}{A} \cdot \sum_{x=1}^{|V|} \exp \left(\boldsymbol{u}_{x}^{T} \boldsymbol{v}_{c}\right) \frac{\partial}{\partial \boldsymbol{v}_{c}} \boldsymbol{u}_{x}^{T} \boldsymbol{v}_{c} \\
&=\frac{1}{\sum_{i=1}^{|V|} \exp \left(\boldsymbol{u}_{i}^{T} \boldsymbol{v}_{c}\right)} \sum_{x=1}^{|V|} \exp \left(\boldsymbol{u}_{x}^{T} \boldsymbol{v}_{c}\right) \boldsymbol{u}_{x} \\
&=\sum_{x=1}^{|V|} \frac{\exp \left(\boldsymbol{u}_{x}^{T} \boldsymbol{v}_{c}\right)}{\sum_{i=1}^{|V|} \exp \left(\boldsymbol{u}_{i}^{T} \boldsymbol{v}_{c}\right)} \boldsymbol{u}_{x} \\
&=\sum_{x=1}^{|V|} P\left(w_{x} \mid w_{c}\right) \boldsymbol{u}_{x}
\end{aligned}
</script>
</div>
<p>综上所述</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\frac{\partial \log P\left(w_{o} \mid w_{c}\right)}{\partial \boldsymbol{v}_{c}}=\boldsymbol{u}_{o}-\sum_{j \in V} P\left(w_{j} \mid w_{c}\right) \boldsymbol{u}_{j}
</div>
<script type="math/tex; mode=display">
\frac{\partial \log P\left(w_{o} \mid w_{c}\right)}{\partial \boldsymbol{v}_{c}}=\boldsymbol{u}_{o}-\sum_{j \in V} P\left(w_{j} \mid w_{c}\right) \boldsymbol{u}_{j}
</script>
</div>
<p>通过上面计算得到梯度后，我们可以使用随机梯度下降来不断迭代模型参数<span class="arithmatex"><span class="MathJax_Preview">v_c</span><script type="math/tex">v_c</script></span>。其它模型参数<span class="arithmatex"><span class="MathJax_Preview">u_o</span><script type="math/tex">u_o</script></span>的迭代方式同理可得。最终，对于词典中任一索引为i的词，我们均得到该词作为中心词和背景词的两组词向量<span class="arithmatex"><span class="MathJax_Preview">v_i</span><script type="math/tex">v_i</script></span>和<span class="arithmatex"><span class="MathJax_Preview">u_i</span><script type="math/tex">u_i</script></span></p>
<h4 id="_17">负采样<a class="headerlink" href="#_17" title="Permanent link">&para;</a></h4>
<p>在上面的示例中，对于每对中心词及其上下文词，我们必须更新上下文词的所有向量。这是非常低效的：对于每一步，进行更新所需的时间与词汇量大小成正比。</p>
<p>但是为什么我们必须在每一步都考虑词汇表中的所有上下文向量呢？例如，假设在当前步骤中，我们考虑的不是所有单词的上下文向量，而是当前目标和几个随机选择的单词。</p>
<p><img alt="png" src="../pic/negative_sampling-min.png" /></p>
<p>以跳字模型为例讨论负采样。词典 <span class="arithmatex"><span class="MathJax_Preview">V</span><script type="math/tex">V</script></span> 的大小之所以会在目标函数中出现，是因为中心词 <span class="arithmatex"><span class="MathJax_Preview">w_{c}</span><script type="math/tex">w_{c}</script></span> 生成背景词 <span class="arithmatex"><span class="MathJax_Preview">w_{o}</span><script type="math/tex">w_{o}</script></span> 的概率 <span class="arithmatex"><span class="MathJax_Preview">P\left(w_{o} \mid w_{c}\right)</span><script type="math/tex">P\left(w_{o} \mid w_{c}\right)</script></span> 使用了 softmax，而 softmax 考虑到了背景词可能是词 典中任一词，并体现在了 softmax 的分母上
我们不妨换个角度，假设中心词 <span class="arithmatex"><span class="MathJax_Preview">w_{c}</span><script type="math/tex">w_{c}</script></span> 生成背景词 <span class="arithmatex"><span class="MathJax_Preview">w_{o}</span><script type="math/tex">w_{o}</script></span> 由以下两个互相独立的联合事件组成来近 似</p>
<ol>
<li>
<p>中心词 <span class="arithmatex"><span class="MathJax_Preview">w_{c}</span><script type="math/tex">w_{c}</script></span> 和背景词 <span class="arithmatex"><span class="MathJax_Preview">w_{o}</span><script type="math/tex">w_{o}</script></span> 同时出现在该训练数据窗口</p>
</li>
<li>
<p>中心词 <span class="arithmatex"><span class="MathJax_Preview">w_{c}</span><script type="math/tex">w_{c}</script></span> 和噪声词不同时出现在该训练数据窗口</p>
</li>
<li>
<p>中心词 <span class="arithmatex"><span class="MathJax_Preview">w_{c}</span><script type="math/tex">w_{c}</script></span> 和第 1 个噪声词 <span class="arithmatex"><span class="MathJax_Preview">w_{1}</span><script type="math/tex">w_{1}</script></span> 不同时出现在训练数据窗口（噪声词 <span class="arithmatex"><span class="MathJax_Preview">w_{1}</span><script type="math/tex">w_{1}</script></span> 按噪声词 分布 <span class="arithmatex"><span class="MathJax_Preview">P(w)</span><script type="math/tex">P(w)</script></span> 随机生成)</p>
</li>
<li>....</li>
<li>中心词 <span class="arithmatex"><span class="MathJax_Preview">w_{c}</span><script type="math/tex">w_{c}</script></span> 和第 <span class="arithmatex"><span class="MathJax_Preview">K</span><script type="math/tex">K</script></span> 个噪声词 <span class="arithmatex"><span class="MathJax_Preview">w_{k}</span><script type="math/tex">w_{k}</script></span> 不同时出现在训练数据窗口 (噪声词 <span class="arithmatex"><span class="MathJax_Preview">w_{K}</span><script type="math/tex">w_{K}</script></span> 按噪声 词分布 <span class="arithmatex"><span class="MathJax_Preview">P(w)</span><script type="math/tex">P(w)</script></span> 随机生成)</li>
</ol>
<p>我们可以使用 <span class="arithmatex"><span class="MathJax_Preview">\sigma(x)=\frac{1}{1+\exp (-x)}</span><script type="math/tex">\sigma(x)=\frac{1}{1+\exp (-x)}</script></span> 函数来表达中心词 <span class="arithmatex"><span class="MathJax_Preview">w_{c}</span><script type="math/tex">w_{c}</script></span> 和背景词 <span class="arithmatex"><span class="MathJax_Preview">w_{o}</span><script type="math/tex">w_{o}</script></span> 同时出现在训练数据 窗口的概率:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
P\left(D=1 \mid w_{o}, w_{c}\right)=\sigma\left(\boldsymbol{u}_{o}^{T}, \boldsymbol{v}_{c}\right)
</div>
<script type="math/tex; mode=display">
P\left(D=1 \mid w_{o}, w_{c}\right)=\sigma\left(\boldsymbol{u}_{o}^{T}, \boldsymbol{v}_{c}\right)
</script>
</div>
<p>那么，中心词 <span class="arithmatex"><span class="MathJax_Preview">w_{c}</span><script type="math/tex">w_{c}</script></span> 生成背景词 <span class="arithmatex"><span class="MathJax_Preview">w_{o}</span><script type="math/tex">w_{o}</script></span> 的对数概率可以近似为</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\log P\left(w_{o} \mid w_{c}\right)=\log \left[P\left(D=1 \mid w_{o}, w_{c}\right) \prod_{k=1, w_{k} \sim P(w)}^{K} P\left(D=0 \mid w_{k}, w_{c}\right)\right]
</div>
<script type="math/tex; mode=display">
\log P\left(w_{o} \mid w_{c}\right)=\log \left[P\left(D=1 \mid w_{o}, w_{c}\right) \prod_{k=1, w_{k} \sim P(w)}^{K} P\left(D=0 \mid w_{k}, w_{c}\right)\right]
</script>
</div>
<p>其中后面的表示中心词和噪声词不同时出现在训练数据窗口的概率。
假设噪声词 <span class="arithmatex"><span class="MathJax_Preview">w_{k}</span><script type="math/tex">w_{k}</script></span> 在词典中的索引为 <span class="arithmatex"><span class="MathJax_Preview">i_{k}</span><script type="math/tex">i_{k}</script></span> ，上式可改写为</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\log P\left(w_{o} \mid w_{c}\right)=\log \frac{1}{1+\exp \left(-\boldsymbol{u}_{o}^{T} \boldsymbol{v}_{c}\right)}+\sum_{k=1, w_{k} \sim P(w)}^{K} \log \left[1-\frac{1}{1+\exp \left(-\boldsymbol{u}_{i_{k}}^{T} \boldsymbol{v}_{c}\right)}\right]
</div>
<script type="math/tex; mode=display">
\log P\left(w_{o} \mid w_{c}\right)=\log \frac{1}{1+\exp \left(-\boldsymbol{u}_{o}^{T} \boldsymbol{v}_{c}\right)}+\sum_{k=1, w_{k} \sim P(w)}^{K} \log \left[1-\frac{1}{1+\exp \left(-\boldsymbol{u}_{i_{k}}^{T} \boldsymbol{v}_{c}\right)}\right]
</script>
</div>
<p>因此，有关中心词 <span class="arithmatex"><span class="MathJax_Preview">w_{c}</span><script type="math/tex">w_{c}</script></span> 生成背景词 <span class="arithmatex"><span class="MathJax_Preview">w_{o}</span><script type="math/tex">w_{o}</script></span> 的损失函数是(<span class="arithmatex"><span class="MathJax_Preview">1-\sigma(x) = \sigma(-x)</span><script type="math/tex">1-\sigma(x) = \sigma(-x)</script></span>):</p>
<p>$$
\begin{aligned}
-\log P\left(w_{o} \mid w_{c}\right)=-\log \frac{1}{1+\exp \left(-\boldsymbol{u}<em>{o}^{T} \boldsymbol{v}</em>{c}\right)}-\sum_{k=1, w_{k} \sim P(w)}^{K} \log \frac{1}{1+\exp \left(\boldsymbol{u}<em>{i</em>{k}}^{T} \boldsymbol{v}<em>{c}\right)}  \
= -\log \sigma(u_o^Tv_c) - \sum</em>{k=1, w_k\sim P(w)} ^ K \log\sigma (-u_{ik}^Tv_c) </p>
<p>\end{aligned}
$$</p>
<h4 id="softmax">层序softmax<a class="headerlink" href="#softmax" title="Permanent link">&para;</a></h4>
<p>层序softmax利用了二叉树，树的每个节点代表了词典V中的每个词。每个词<span class="arithmatex"><span class="MathJax_Preview">w_i</span><script type="math/tex">w_i</script></span>对应词向量<span class="arithmatex"><span class="MathJax_Preview">v_i</span><script type="math/tex">v_i</script></span>。</p>
<p><img alt="png" src="../pic/softmax.png" /></p>
<p>设 <span class="arithmatex"><span class="MathJax_Preview">L(w)</span><script type="math/tex">L(w)</script></span> 为从二叉树根节点到代表词 <span class="arithmatex"><span class="MathJax_Preview">w</span><script type="math/tex">w</script></span> 的叶子节点的路径上的节点数，并设 <span class="arithmatex"><span class="MathJax_Preview">n(w, i)</span><script type="math/tex">n(w, i)</script></span> 为该路径上第 <span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span> 个节点，该节点的向量为 <span class="arithmatex"><span class="MathJax_Preview">\boldsymbol{u}_{n(w, j)}</span><script type="math/tex">\boldsymbol{u}_{n(w, j)}</script></span> 。以上图为例， <span class="arithmatex"><span class="MathJax_Preview">L\left(w_{3}\right)=4</span><script type="math/tex">L\left(w_{3}\right)=4</script></span> 。那么，跳字模型和连续词袋模型所需 要计算的任意词 <span class="arithmatex"><span class="MathJax_Preview">w_{i}</span><script type="math/tex">w_{i}</script></span> 生成词 <span class="arithmatex"><span class="MathJax_Preview">w</span><script type="math/tex">w</script></span> 的概率为:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
P\left(w \mid w_{i}\right)=\prod_{j=1}^{L(w)-1} \sigma\left(\left[n(w, j+1)=l e f t_{-} \operatorname{child}(n(w, j))\right] \cdot \boldsymbol{u}_{n(w, j)}^{T} \boldsymbol{v}_{i}\right)
</div>
<script type="math/tex; mode=display">
P\left(w \mid w_{i}\right)=\prod_{j=1}^{L(w)-1} \sigma\left(\left[n(w, j+1)=l e f t_{-} \operatorname{child}(n(w, j))\right] \cdot \boldsymbol{u}_{n(w, j)}^{T} \boldsymbol{v}_{i}\right)
</script>
</div>
<p>其中，如果 <span class="arithmatex"><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span> 为真， <span class="arithmatex"><span class="MathJax_Preview">[x]=1</span><script type="math/tex">[x]=1</script></span> ；反之 <span class="arithmatex"><span class="MathJax_Preview">[x]=-1</span><script type="math/tex">[x]=-1</script></span>
由于 <span class="arithmatex"><span class="MathJax_Preview">\sigma(x)+\sigma(-x)=1, w_{i}</span><script type="math/tex">\sigma(x)+\sigma(-x)=1, w_{i}</script></span> 生成词典中任何词的概率之和为 1 :</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\sum_{w=1}^{V} P\left(w \mid w_{i}\right)=1
</div>
<script type="math/tex; mode=display">
\sum_{w=1}^{V} P\left(w \mid w_{i}\right)=1
</script>
</div>
<p>上面公式可能比较抽象，下面举个具体的例子，计算 <span class="arithmatex"><span class="MathJax_Preview">w_{i}</span><script type="math/tex">w_{i}</script></span> 生成 <span class="arithmatex"><span class="MathJax_Preview">w_{3}</span><script type="math/tex">w_{3}</script></span> 的概率，由于在二叉树中由根到 <span class="arithmatex"><span class="MathJax_Preview">w_{3}</span><script type="math/tex">w_{3}</script></span> 的路径需要向左、向右、再向左地遍历，所以得到</p>
<div class="arithmatex">
<div class="MathJax_Preview">
P\left(w_{3} \mid w_{i}\right)=\sigma\left(\boldsymbol{u}_{n\left(w_{3}, 1\right)}^{T} \boldsymbol{v}_{i}\right) \cdot \sigma\left(-\boldsymbol{u}_{n\left(w_{3}, 2\right)}^{T} \boldsymbol{v}_{i}\right) \cdot \sigma\left(\boldsymbol{u}_{n\left(w_{3}, 3\right)}^{T} \boldsymbol{v}_{i}\right)
</div>
<script type="math/tex; mode=display">
P\left(w_{3} \mid w_{i}\right)=\sigma\left(\boldsymbol{u}_{n\left(w_{3}, 1\right)}^{T} \boldsymbol{v}_{i}\right) \cdot \sigma\left(-\boldsymbol{u}_{n\left(w_{3}, 2\right)}^{T} \boldsymbol{v}_{i}\right) \cdot \sigma\left(\boldsymbol{u}_{n\left(w_{3}, 3\right)}^{T} \boldsymbol{v}_{i}\right)
</script>
</div>
<p>由此，我们就可以使用随机梯度下降在跳字模型和连续词袋模型中不断迭代计算词典中所有词向量 <span class="arithmatex"><span class="MathJax_Preview">\boldsymbol{v}</span><script type="math/tex">\boldsymbol{v}</script></span></p>
<p>最后一个问题，层序 softmax 的二叉树是如何建立的?</p>
<p><strong>这里的二叉树 Huffman 树，权重是语料库中 word 出现的频率</strong></p>
<h4 id="_18">标准设置<a class="headerlink" href="#_18" title="Permanent link">&para;</a></h4>
<ul>
<li>模型: 带负采样的Skip-Gram(SGNS)</li>
<li>负采样的数目: 较小的数据集,15-20;较大的数据集,2-5。</li>
<li>词嵌入维度: 经常用的为300</li>
<li>滑动窗口大小: 5-10</li>
</ul>
<h4 id="_19">代码<a class="headerlink" href="#_19" title="Permanent link">&para;</a></h4>
<h5 id="_20">简单<a class="headerlink" href="#_20" title="Permanent link">&para;</a></h5>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">random_batch</span><span class="p">():</span>
    <span class="n">random_inputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">random_labels</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">random_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">skip_grams</span><span class="p">)),</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">random_index</span><span class="p">:</span>
        <span class="n">random_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">voc_size</span><span class="p">)[</span><span class="n">skip_grams</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]])</span>  <span class="c1"># target 相当于onehot编码</span>
        <span class="n">random_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">skip_grams</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># context word</span>

    <span class="k">return</span> <span class="n">random_inputs</span><span class="p">,</span> <span class="n">random_labels</span>

<span class="c1"># Model</span>
<span class="k">class</span> <span class="nc">Word2Vec</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Word2Vec</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># W and WT is not Traspose relationship</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">voc_size</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1"># voc_size &gt; embedding_size Weight</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">WT</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">embedding_size</span><span class="p">,</span> <span class="n">voc_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1"># embedding_size &gt; voc_size Weight</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="c1"># X : [batch_size, voc_size]</span>
        <span class="n">hidden_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c1"># hidden_layer : [batch_size, embedding_size]</span>
        <span class="n">output_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">WT</span><span class="p">(</span><span class="n">hidden_layer</span><span class="p">)</span> <span class="c1"># output_layer : [batch_size, voc_size]</span>
        <span class="k">return</span> <span class="n">output_layer</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># mini-batch size</span>
    <span class="n">embedding_size</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># embedding size</span>

    <span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;apple banana fruit&quot;</span><span class="p">,</span> <span class="s2">&quot;banana orange fruit&quot;</span><span class="p">,</span> <span class="s2">&quot;orange banana fruit&quot;</span><span class="p">,</span>
                 <span class="s2">&quot;dog cat animal&quot;</span><span class="p">,</span> <span class="s2">&quot;cat monkey animal&quot;</span><span class="p">,</span> <span class="s2">&quot;monkey dog animal&quot;</span><span class="p">]</span>

    <span class="n">word_sequence</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">word_list</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">word_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">word_list</span><span class="p">))</span>
    <span class="n">word_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">w</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">word_list</span><span class="p">)}</span>
    <span class="n">voc_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_list</span><span class="p">)</span>

    <span class="c1"># Make skip gram of one size window</span>
    <span class="n">skip_grams</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_sequence</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">word_dict</span><span class="p">[</span><span class="n">word_sequence</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
        <span class="n">context</span> <span class="o">=</span> <span class="p">[</span><span class="n">word_dict</span><span class="p">[</span><span class="n">word_sequence</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]],</span> <span class="n">word_dict</span><span class="p">[</span><span class="n">word_sequence</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]]]</span>
        <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">context</span><span class="p">:</span>
            <span class="n">skip_grams</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">target</span><span class="p">,</span> <span class="n">w</span><span class="p">])</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Word2Vec</span><span class="p">()</span>

    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>

    <span class="c1"># Training</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5000</span><span class="p">):</span>
        <span class="n">input_batch</span><span class="p">,</span> <span class="n">target_batch</span> <span class="o">=</span> <span class="n">random_batch</span><span class="p">()</span>
        <span class="n">input_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">input_batch</span><span class="p">)</span>
        <span class="n">target_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">target_batch</span><span class="p">)</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_batch</span><span class="p">)</span>

        <span class="c1"># output : [batch_size, voc_size], target_batch : [batch_size] (LongTensor, not one-hot)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target_batch</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch:&#39;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">%04d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="s1">&#39;cost =&#39;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">{:.6f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">loss</span><span class="p">))</span>

        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">word_list</span><span class="p">):</span>
        <span class="n">W</span><span class="p">,</span> <span class="n">WT</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">W</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">textcoords</span><span class="o">=</span><span class="s1">&#39;offset points&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;bottom&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<p>这是没有任何训练技巧的版本，使用Linear的话要注意输入是独热编码的形式，而且设置bias=False，因为需要的只是权重矩阵，不需要偏置。下面是引入了负采样的技巧的版本，直接使用了nn.Embedding。</p>
<h5 id="_21">复杂<a class="headerlink" href="#_21" title="Permanent link">&para;</a></h5>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.utils.data</span> <span class="k">as</span> <span class="nn">Data</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="kn">import</span> <span class="nn">copy</span>

<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%(asctime)s</span><span class="s1"> - </span><span class="si">%(levelname)s</span><span class="s1"> - </span><span class="si">%(message)s</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>

<span class="n">C</span> <span class="o">=</span> <span class="mi">3</span> <span class="c1"># window size</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">15</span>  <span class="c1"># Number of negitive samples</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">MAX_VOCAB_SIZE</span> <span class="o">=</span> <span class="mi">10000</span> <span class="c1"># 单词表的长度</span>
<span class="n">EMBEDDING_SIZE</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># 词嵌入的维数</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span> 
<span class="n">lr</span> <span class="o">=</span> <span class="mf">1e-3</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;./text8/text8.train.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>

<span class="n">vocab_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">text</span><span class="p">)</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="n">MAX_VOCAB_SIZE</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">vocab_dict</span><span class="p">[</span><span class="s2">&quot;&lt;UNK&gt;&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">vocab_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>

<span class="n">word2idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">word</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())}</span>
<span class="n">idx2word</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">word</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())}</span>

<span class="n">word_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">count</span> <span class="k">for</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">vocab_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>
<span class="n">word_freqs</span> <span class="o">=</span> <span class="n">word_counts</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">word_counts</span><span class="p">)</span>
<span class="n">word_freqs</span> <span class="o">=</span> <span class="n">word_freqs</span> <span class="o">**</span> <span class="p">(</span><span class="mi">3</span><span class="o">/</span><span class="mi">4</span><span class="p">)</span>  <span class="c1"># 经验</span>


<span class="k">class</span> <span class="nc">WordEmbeddingDataset</span><span class="p">(</span><span class="n">Data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">word2idx</span><span class="p">,</span> <span class="n">word_freqs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">WordEmbeddingDataset</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_encoded</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span>
            <span class="p">[</span><span class="n">word2idx</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">word2idx</span><span class="p">[</span><span class="s2">&quot;&lt;UNK&gt;&quot;</span><span class="p">])</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">text</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2idx</span> <span class="o">=</span> <span class="n">word2idx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word_freqs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">word_freqs</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="n">center_words</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoded</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="n">pos_indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">index</span><span class="o">-</span><span class="n">C</span><span class="p">,</span> <span class="n">index</span><span class="p">))</span> <span class="o">+</span> \
            <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">index</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">index</span><span class="o">+</span><span class="n">C</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">pos_indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_encoded</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">pos_indices</span><span class="p">]</span>
        <span class="n">pos_words</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoded</span><span class="p">[</span><span class="n">pos_indices</span><span class="p">]</span>
        <span class="n">select_weights</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">word_freqs</span><span class="p">)</span>
        <span class="n">select_weights</span><span class="p">[</span><span class="n">center_words</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">select_weights</span><span class="p">[</span><span class="n">pos_words</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">neg_words</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span>
            <span class="n">select_weights</span><span class="p">,</span> <span class="n">K</span> <span class="o">*</span> <span class="n">pos_words</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">center_words</span><span class="p">,</span> <span class="n">pos_words</span><span class="p">,</span> <span class="n">neg_words</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_encoded</span><span class="p">)</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">WordEmbeddingDataset</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">word2idx</span><span class="p">,</span> <span class="n">word_freqs</span><span class="p">)</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">Data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_lables</span><span class="p">,</span> <span class="n">pos_labels</span><span class="p">,</span> <span class="n">neg_labels</span><span class="p">):</span>
        <span class="n">input_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">input_lables</span><span class="p">)</span> <span class="c1"># [batch_size, embedding_size]</span>
        <span class="n">pos_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding2</span><span class="p">(</span><span class="n">pos_labels</span><span class="p">)</span> <span class="c1"># [batch_size, window * 2, embedding_size]</span>
        <span class="n">neg_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding2</span><span class="p">(</span><span class="n">neg_labels</span><span class="p">)</span> <span class="c1"># [batch_size, K * window * 2, embedding_size]</span>

        <span class="n">input_embedding</span> <span class="o">=</span> <span class="n">input_embedding</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># [batch_size, embedding_size, 1]</span>

        <span class="n">pos_dot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">pos_embedding</span><span class="p">,</span> <span class="n">input_embedding</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># [batch_size, window * 2]</span>
        <span class="c1">## bmm == batch matrix multiply</span>
        <span class="n">neg_dot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">neg_embedding</span><span class="p">,</span> <span class="n">input_embedding</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># [batch_size, K * window * 2]</span>

        <span class="n">log_pos</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">logsigmoid</span><span class="p">(</span><span class="n">pos_dot</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># [batch_size]</span>
        <span class="n">log_neg</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">logsigmoid</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">neg_dot</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># [batch_size]</span>

        <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="n">log_pos</span> <span class="o">+</span> <span class="n">log_neg</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="c1"># 对应上文推导的公式</span>

    <span class="k">def</span> <span class="nf">input_embedding</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">MAX_VOCAB_SIZE</span><span class="p">,</span> <span class="n">EMBEDDING_SIZE</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">input_labels</span><span class="p">,</span> <span class="n">pos_labels</span><span class="p">,</span> <span class="n">neg_labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
        <span class="n">input_labels</span> <span class="o">=</span> <span class="n">input_labels</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">pos_labels</span> <span class="o">=</span> <span class="n">pos_labels</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">neg_labels</span> <span class="o">=</span> <span class="n">neg_labels</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_labels</span><span class="p">,</span> <span class="n">pos_labels</span><span class="p">,</span> <span class="n">neg_labels</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">, batch: </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">, loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">embedding_weights</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">input_embedding</span><span class="p">()</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="sa">f</span><span class="s2">&quot;embedding-</span><span class="si">{</span><span class="n">EMBEDDING_SIZE</span><span class="si">}</span><span class="s2">.pth&quot;</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;word2idx.pkl&quot;</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">word2idx</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;idx2word.pkl&quot;</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">idx2word</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;embedding_weights.pkl&quot;</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">embedding_weights</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</code></pre></div>
<h3 id="glove">GloVe<a class="headerlink" href="#glove" title="Permanent link">&para;</a></h3>
<p>GloVe 模型是基于计数的方法和预测方法（例如 Word2Vec）的组合。模型名称 GloVe 代表“Global Vectors”，体现了它的思想：该方法利用 语料库中的全局信息来学习向量。</p>
<p>正如我们之前看到的，最简单的基于计数的方法使用共现计数来衡量单词 w 和上下文c之间的关联：<span class="arithmatex"><span class="MathJax_Preview">N(w,c)</span><script type="math/tex">N(w,c)</script></span>。 GloVe 也使用这些计数来构建损失函数：
​
$$
J(\theta) = \sum_{w,c\in V}f(N(w,c)) \cdot(u_c<sup>Tv_w+b_c+\bar{b_w}-logN(w,c)</sup>2)
$$</p>
<p>其中：</p>
<div class="arithmatex">
<div class="MathJax_Preview">
f(x) = \begin{cases}
        (\frac{x}{x_{max}})^{0.75}, \quad if \;x &lt; x_{max} \\
        1, \quad if \; x\geq x_{max}
        \end{cases}
</div>
<script type="math/tex; mode=display">
f(x) = \begin{cases}
        (\frac{x}{x_{max}})^{0.75}, \quad if \;x < x_{max} \\
        1, \quad if \; x\geq x_{max}
        \end{cases}
</script>
</div>
<p>具体的推导可以看这个博客：<a href="https://www.cnblogs.com/Lee-yl/p/11172255.html">https://www.cnblogs.com/Lee-yl/p/11172255.html</a></p>
<p>可以看到GloVe并没有使用神经网络的方法。</p>
<p>与 Word2Vec 类似，我们也有不同的 中心词和上下文词向量——这些是我们的参数。此外，该方法对每个词向量都有一个标量偏置项。</p>
<p>特别有趣的是 GloVe 控制稀有词和频繁词影响的方式：每对 ( w , c ) 的损失以如下方式加权</p>
<ul>
<li>罕见事件受到惩罚，</li>
<li>非常频繁的事件不会被过度加权。</li>
</ul>
<h2 id="_22">参考<a class="headerlink" href="#_22" title="Permanent link">&para;</a></h2>
<p>参考：</p>
<blockquote>
<p><a href="https://blog.csdn.net/malefactor/article/details/83961886">https://blog.csdn.net/malefactor/article/details/83961886</a>
<a href="https://www.zybuluo.com/Dounm/note/591752">https://www.zybuluo.com/Dounm/note/591752</a>
<a href="https://lena-voita.github.io/nlp_course/word_embeddings.html">https://lena-voita.github.io/nlp_course/word_embeddings.html</a>
<a href="https://wmathor.com/index.php/archives/1430/">https://wmathor.com/index.php/archives/1430/</a>
<a href="https://zhuanlan.zhihu.com/p/27234078">https://zhuanlan.zhihu.com/p/27234078</a>\
Rong X . word2vec Parameter Learning Explained[J]. Computer Science, 2014.</p>
</blockquote>
                
              
              
                


              
            </article>
          </div>
        </div>
        
      </main>
      
        
<footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../HMM/" class="md-footer__link md-footer__link--prev" aria-label="Previous: HMM" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              HMM
            </div>
          </div>
        </a>
      
      
        
        <a href="../NER/" class="md-footer__link md-footer__link--next" aria-label="Next: NER" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              NER
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        
          Made with
          <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
            Material for MkDocs
          </a>
        
        
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../..", "features": [], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../../assets/javascripts/workers/search.fcfe8b6d.min.js", "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.b1047164.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>