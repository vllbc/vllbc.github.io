
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="vllbc的个人网站">
      
      
      
        <meta name="author" content="vllbc">
      
      
        <link rel="canonical" href="https://vllbc.top/NLP/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/">
      
      <link rel="icon" href="../../assets/images/favicon.ico">
      <meta name="generator" content="mkdocs-1.2.3, mkdocs-material-7.3.6">
    
    
      
        <title>主题模型 - Vllbc的个人博客</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.a57b2b03.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.3f5d1f46.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style>
      
    
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    
      


    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="" data-md-color-accent="">
  
    
    <script>function __prefix(e){return new URL("../..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script>
    
      <script>var palette=__get("__palette");if(null!==palette&&"object"==typeof palette.color)for(var key in palette.color)document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#主题模型" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Vllbc的个人博客" class="md-header__button md-logo" aria-label="Vllbc的个人博客" data-md-component="logo">
      
  <img src="../../assets/images/favicon.ico" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Vllbc的个人博客
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              主题模型
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="" data-md-color-accent=""  aria-label="暗色模式"  type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="暗色模式" for="__palette_2" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31z"/></svg>
            </label>
          
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="" data-md-color-accent=""  aria-label="亮色模式"  type="radio" name="__palette" id="__palette_2">
          
            <label class="md-header__button md-icon" title="亮色模式" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22z"/></svg>
            </label>
          
        
      </form>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Vllbc的个人博客" class="md-nav__button md-logo" aria-label="Vllbc的个人博客" data-md-component="logo">
      
  <img src="../../assets/images/favicon.ico" alt="logo">

    </a>
    Vllbc的个人博客
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        首页
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          算法相关
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="算法相关" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          算法相关
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/1/" class="md-nav__link">
        isbn号码
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/2/" class="md-nav__link">
        我做的第一个打表题
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/3/" class="md-nav__link">
        位运算的应用
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/4/" class="md-nav__link">
        位运算的应用(2)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/python_lq/" class="md-nav__link">
        python刷题
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/5/" class="md-nav__link">
        最小公众前缀
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/6/" class="md-nav__link">
        移除元素
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/7/" class="md-nav__link">
        有效的数独
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/8/" class="md-nav__link">
        旋转图像
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/9/" class="md-nav__link">
        去掉重复字母
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/10/" class="md-nav__link">
        字符串转整数
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/11/" class="md-nav__link">
        使用最小花费爬楼梯
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/12/" class="md-nav__link">
        最大子序和
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/13/" class="md-nav__link">
        打家劫舍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/14/" class="md-nav__link">
        外观数列
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/15/" class="md-nav__link">
        计数质数
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/16/" class="md-nav__link">
        分发饼干
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/17/" class="md-nav__link">
        按序打印
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/18/" class="md-nav__link">
        交换性别
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/19/" class="md-nav__link">
        打印零和奇偶数
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/20/" class="md-nav__link">
        零钱兑换
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/21/" class="md-nav__link">
        翻转二叉树
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/22/" class="md-nav__link">
        验证二叉搜索树
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/23/" class="md-nav__link">
        交替打印字符串
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/24/" class="md-nav__link">
        无重叠区域
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/25/" class="md-nav__link">
        种花问题（2021第一题）
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/26/" class="md-nav__link">
        合并区间
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/27/" class="md-nav__link">
        三数之和
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/28/" class="md-nav__link">
        对角线遍历
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/29/" class="md-nav__link">
        最长回文子串
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/30/" class="md-nav__link">
        长度最小的子数组
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/31/" class="md-nav__link">
        删除排序数组中的重复项
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/32/" class="md-nav__link">
        合并两个有序链表
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/33/" class="md-nav__link">
        使括号有效的最小添加
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/34/" class="md-nav__link">
        平衡括号字符串的最少插入次数
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/35/" class="md-nav__link">
        阶乘函数后K个零
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/36/" class="md-nav__link">
        搜索旋转排序数组
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/37/" class="md-nav__link">
        两两交换链表中的节点
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/38/" class="md-nav__link">
        把数字翻译成字符串
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/39/" class="md-nav__link">
        检查平衡性
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/40/" class="md-nav__link">
        可获得的最大点数
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/41/" class="md-nav__link">
        字符串的排列
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/42/" class="md-nav__link">
        至少有k个重复字符的最长字串
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/43/" class="md-nav__link">
        丑数系列
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/44/" class="md-nav__link">
        最大数
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/45/" class="md-nav__link">
        采购方案
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/46/" class="md-nav__link">
        和为s的连续正数序列
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/47/" class="md-nav__link">
        滑动窗口的中位数
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/48/" class="md-nav__link">
        对称二叉树
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/49/" class="md-nav__link">
        最长递增子序列
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sf/50/" class="md-nav__link">
        分割等和子集
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Python
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Python" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Python
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../python/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../python/plotly/" class="md-nav__link">
        Plotly
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../python/thread/" class="md-nav__link">
        多线程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../python/asyncio/" class="md-nav__link">
        asyncio模块异步编程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../python/skill/" class="md-nav__link">
        技巧
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../python/WTF/" class="md-nav__link">
        WTFpython学习
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../python/pyqt/" class="md-nav__link">
        PyQt学习
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../python/logging/" class="md-nav__link">
        Logging模块学习
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../python/pyplot/" class="md-nav__link">
        Matplotlib.pyplot学习
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          Numpy & Pandas
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Numpy & Pandas" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Numpy & Pandas
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pandas/learn_one/" class="md-nav__link">
        笔记1
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pandas/learn_two/" class="md-nav__link">
        笔记2
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pandas/learn_four/" class="md-nav__link">
        补充学习
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pandas/learn_three/" class="md-nav__link">
        实训笔记
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pandas/task1/" class="md-nav__link">
        协会任务(大一)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pandas/task2/" class="md-nav__link">
        pandas小练习
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pandas/shixun/main/" class="md-nav__link">
        实训作业
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pandas/task3/main/" class="md-nav__link">
        mathorcup杯比赛
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_9" type="checkbox" id="__nav_4_9" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_9">
          api学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="api学习" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_9">
          <span class="md-nav__icon md-icon"></span>
          api学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pandas/melt/" class="md-nav__link">
        melt
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5">
          Pytorch
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Pytorch" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Pytorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_1" type="checkbox" id="__nav_5_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5_1">
          实践
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="实践" data-md-level="2">
        <label class="md-nav__title" for="__nav_5_1">
          <span class="md-nav__icon md-icon"></span>
          实践
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pytorch/%E5%AE%9E%E8%B7%B5/regression/" class="md-nav__link">
        pytorch线性回归
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pytorch/start/" class="md-nav__link">
        pytorch基础
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pytorch/detach/" class="md-nav__link">
        detach
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pytorch/%E8%AE%A1%E7%AE%97%E5%9B%BE/" class="md-nav__link">
        计算图
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pytorch/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%8F%AF%E8%A7%86%E5%8C%96/" class="md-nav__link">
        神经网络结构可视化
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6" type="checkbox" id="__nav_6" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6">
          Sklearn
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Sklearn" data-md-level="1">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          Sklearn
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_1" type="checkbox" id="__nav_6_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_1">
          实践
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="实践" data-md-level="2">
        <label class="md-nav__title" for="__nav_6_1">
          <span class="md-nav__icon md-icon"></span>
          实践
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/%E7%AE%80%E5%8D%95%E7%9A%84%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" class="md-nav__link">
        简单的线性回归
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/%E5%A4%8D%E6%9D%82%E7%9A%84%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" class="md-nav__link">
        复杂的线性回归
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/Logistic%20Regression/" class="md-nav__link">
        Logistic Regression
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/KNN/" class="md-nav__link">
        KNN
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/SVM/" class="md-nav__link">
        SVM
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/Decision%20Tree/" class="md-nav__link">
        Decision Tree
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_2" type="checkbox" id="__nav_6_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_2">
          preprocessing
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="preprocessing" data-md-level="2">
        <label class="md-nav__title" for="__nav_6_2">
          <span class="md-nav__icon md-icon"></span>
          preprocessing
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/" class="md-nav__link">
        数据预处理
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_3" type="checkbox" id="__nav_6_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_3">
          model_selection
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="model_selection" data-md-level="2">
        <label class="md-nav__title" for="__nav_6_3">
          <span class="md-nav__icon md-icon"></span>
          model_selection
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF/%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF/" class="md-nav__link">
        learning_curve
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/%E9%AA%8C%E8%AF%81%E6%9B%B2%E7%BA%BF/%E9%AA%8C%E8%AF%81%E6%9B%B2%E7%BA%BF/" class="md-nav__link">
        validation_curve
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81/" class="md-nav__link">
        交叉验证
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_4" type="checkbox" id="__nav_6_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_4">
          feature_selection
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="feature_selection" data-md-level="2">
        <label class="md-nav__title" for="__nav_6_4">
          <span class="md-nav__icon md-icon"></span>
          feature_selection
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/feature_selection/SelectFromModel/" class="md-nav__link">
        SelectFromModel
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_4_2" type="checkbox" id="__nav_6_4_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_4_2">
          包裹式
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="包裹式" data-md-level="3">
        <label class="md-nav__title" for="__nav_6_4_2">
          <span class="md-nav__icon md-icon"></span>
          包裹式
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/feature_selection/RFE/" class="md-nav__link">
        RFE
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_5" type="checkbox" id="__nav_6_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_5">
          feature_extraction
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="feature_extraction" data-md-level="2">
        <label class="md-nav__title" for="__nav_6_5">
          <span class="md-nav__icon md-icon"></span>
          feature_extraction
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/feature_extraction/CountVectorizer/" class="md-nav__link">
        CountVectorizer
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/feature_extraction/TfidfTransformer/" class="md-nav__link">
        TfidfTransformer
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7" type="checkbox" id="__nav_7" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7">
          Machine Learning
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Machine Learning" data-md-level="1">
        <label class="md-nav__title" for="__nav_7">
          <span class="md-nav__icon md-icon"></span>
          Machine Learning
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_1" type="checkbox" id="__nav_7_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7_1">
          性能指标
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="性能指标" data-md-level="2">
        <label class="md-nav__title" for="__nav_7_1">
          <span class="md-nav__icon md-icon"></span>
          性能指标
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87/ROC%E6%9B%B2%E7%BA%BF/ROC/" class="md-nav__link">
        ROC曲线
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87/%E7%B2%BE%E7%A1%AE%E7%8E%87%E5%92%8C%E5%8F%AC%E5%9B%9E%E7%8E%87/" class="md-nav__link">
        精确率和召回率
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_2" type="checkbox" id="__nav_7_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7_2">
          关联规则
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="关联规则" data-md-level="2">
        <label class="md-nav__title" for="__nav_7_2">
          <span class="md-nav__icon md-icon"></span>
          关联规则
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E7%AE%97%E6%B3%95/%E6%A6%82%E5%BF%B5/" class="md-nav__link">
        概念
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E7%AE%97%E6%B3%95/Apriori%E7%AE%97%E6%B3%95/" class="md-nav__link">
        Apriori算法
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_3" type="checkbox" id="__nav_7_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7_3">
          降维算法
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="降维算法" data-md-level="2">
        <label class="md-nav__title" for="__nav_7_3">
          <span class="md-nav__icon md-icon"></span>
          降维算法
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95/PCA/" class="md-nav__link">
        PCA
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95/LDA/" class="md-nav__link">
        LDA
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95/SVD/" class="md-nav__link">
        SVD
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_4" type="checkbox" id="__nav_7_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7_4">
          回归算法
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="回归算法" data-md-level="2">
        <label class="md-nav__title" for="__nav_7_4">
          <span class="md-nav__icon md-icon"></span>
          回归算法
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" class="md-nav__link">
        线性回归
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95/%E6%A0%91%E5%9B%9E%E5%BD%92/" class="md-nav__link">
        树回归
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_5" type="checkbox" id="__nav_7_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7_5">
          分类算法
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="分类算法" data-md-level="2">
        <label class="md-nav__title" for="__nav_7_5">
          <span class="md-nav__icon md-icon"></span>
          分类算法
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/%E6%A6%82%E8%BF%B0/" class="md-nav__link">
        概述
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/bayes/" class="md-nav__link">
        贝叶斯算法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/Logistic%E5%9B%9E%E5%BD%92/" class="md-nav__link">
        Logistic回归
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E6%A6%82%E8%BF%B0/" class="md-nav__link">
        线性分类
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/KNN/" class="md-nav__link">
        KNN
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/%E5%86%B3%E7%AD%96%E6%A0%91/" class="md-nav__link">
        决策树
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/SVM/" class="md-nav__link">
        SVM
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90/" class="md-nav__link">
        线性判别分析
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%AE%97%E6%B3%95/" class="md-nav__link">
        感知机
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_6" type="checkbox" id="__nav_7_6" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7_6">
          聚类算法
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="聚类算法" data-md-level="2">
        <label class="md-nav__title" for="__nav_7_6">
          <span class="md-nav__icon md-icon"></span>
          聚类算法
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/kmeans/kmeans/" class="md-nav__link">
        K-means
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/%E5%B1%82%E6%AC%A1%E8%81%9A%E7%B1%BB/" class="md-nav__link">
        层次聚类
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/%E8%B0%B1%E8%81%9A%E7%B1%BB/" class="md-nav__link">
        谱聚类
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/DBSCAN/" class="md-nav__link">
        DBSCAN
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_7" type="checkbox" id="__nav_7_7" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7_7">
          集成学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="集成学习" data-md-level="2">
        <label class="md-nav__title" for="__nav_7_7">
          <span class="md-nav__icon md-icon"></span>
          集成学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_7_1" type="checkbox" id="__nav_7_7_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7_7_1">
          Boosting
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Boosting" data-md-level="3">
        <label class="md-nav__title" for="__nav_7_7_1">
          <span class="md-nav__icon md-icon"></span>
          Boosting
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/Boosting/GBDT/" class="md-nav__link">
        GBDT
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_7_2" type="checkbox" id="__nav_7_7_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7_7_2">
          Bagging
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Bagging" data-md-level="3">
        <label class="md-nav__title" for="__nav_7_7_2">
          <span class="md-nav__icon md-icon"></span>
          Bagging
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/Bagging/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/" class="md-nav__link">
        随机森林算法
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/Ensemble%20Learning/" class="md-nav__link">
        概述
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/Stacking/" class="md-nav__link">
        Stacking
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/%E6%A6%82%E5%BF%B5/" class="md-nav__link">
        一些概念
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Machine%20Learning/EM%E7%AE%97%E6%B3%95/" class="md-nav__link">
        EM算法
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_8" type="checkbox" id="__nav_8" >
      
      
      
      
        <label class="md-nav__link" for="__nav_8">
          Deep Learning
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Deep Learning" data-md-level="1">
        <label class="md-nav__title" for="__nav_8">
          <span class="md-nav__icon md-icon"></span>
          Deep Learning
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_8_1" type="checkbox" id="__nav_8_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_8_1">
          项目练习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="项目练习" data-md-level="2">
        <label class="md-nav__title" for="__nav_8_1">
          <span class="md-nav__icon md-icon"></span>
          项目练习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Deep%20Learning/%E9%A1%B9%E7%9B%AE%E7%BB%83%E4%B9%A0/%E5%85%B7%E6%9C%89%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%80%9D%E7%BB%B4%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/nnLogistic/" class="md-nav__link">
        具有逻辑回归思维的神经网络
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_8_2" type="checkbox" id="__nav_8_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_8_2">
          优化算法
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="优化算法" data-md-level="2">
        <label class="md-nav__title" for="__nav_8_2">
          <span class="md-nav__icon md-icon"></span>
          优化算法
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Deep%20Learning/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/" class="md-nav__link">
        梯度下降算法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Deep%20Learning/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/Adam%E7%AE%97%E6%B3%95/" class="md-nav__link">
        Adam算法
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Deep%20Learning/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95/Backpropagation/" class="md-nav__link">
        反向传播算法推导
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Deep%20Learning/Dropout%E6%AD%A3%E5%88%99%E5%8C%96/" class="md-nav__link">
        Dropout
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Deep%20Learning/RNN/" class="md-nav__link">
        RNN
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Deep%20Learning/softmax%E7%90%86%E8%A7%A3/" class="md-nav__link">
        softmax理解
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_9" type="checkbox" id="__nav_9" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_9">
          NLP
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="NLP" data-md-level="1">
        <label class="md-nav__title" for="__nav_9">
          <span class="md-nav__icon md-icon"></span>
          NLP
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../%E6%A6%82%E8%BF%B0/" class="md-nav__link">
        概述
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_9_2" type="checkbox" id="__nav_9_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_9_2">
          任务
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="任务" data-md-level="2">
        <label class="md-nav__title" for="__nav_9_2">
          <span class="md-nav__icon md-icon"></span>
          任务
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../%E4%BB%BB%E5%8A%A1/%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8/" class="md-nav__link">
        序列标注
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../%E4%BB%BB%E5%8A%A1/%E6%96%87%E6%9C%AC%E7%9B%B8%E4%BC%BC%E5%BA%A6/" class="md-nav__link">
        文本相似度
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../%E4%BB%BB%E5%8A%A1/%E8%AF%8D%E5%B9%B2%E6%8F%90%E5%8F%96/" class="md-nav__link">
        词干提取
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../%E4%BB%BB%E5%8A%A1/%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E5%8F%96/" class="md-nav__link">
        文本关键词提取
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_9_3" type="checkbox" id="__nav_9_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_9_3">
          实战
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="实战" data-md-level="2">
        <label class="md-nav__title" for="__nav_9_3">
          <span class="md-nav__icon md-icon"></span>
          实战
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_9_3_1" type="checkbox" id="__nav_9_3_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_9_3_1">
          transformers
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="transformers" data-md-level="3">
        <label class="md-nav__title" for="__nav_9_3_1">
          <span class="md-nav__icon md-icon"></span>
          transformers
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/transformers/%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/" class="md-nav__link">
        情感分析
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_9_4" type="checkbox" id="__nav_9_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_9_4">
          概率图模型
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="概率图模型" data-md-level="2">
        <label class="md-nav__title" for="__nav_9_4">
          <span class="md-nav__icon md-icon"></span>
          概率图模型
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/%E6%A6%82%E8%BF%B0/" class="md-nav__link">
        概述
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_9_4_2" type="checkbox" id="__nav_9_4_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_9_4_2">
          贝叶斯网络
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="贝叶斯网络" data-md-level="3">
        <label class="md-nav__title" for="__nav_9_4_2">
          <span class="md-nav__icon md-icon"></span>
          贝叶斯网络
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91%E7%BB%9C/HMM/" class="md-nav__link">
        HMM
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_9_4_3" type="checkbox" id="__nav_9_4_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_9_4_3">
          马尔科夫网络
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="马尔科夫网络" data-md-level="3">
        <label class="md-nav__title" for="__nav_9_4_3">
          <span class="md-nav__icon md-icon"></span>
          马尔科夫网络
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E7%BD%91%E7%BB%9C/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/" class="md-nav__link">
        CRF
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_9_5" type="checkbox" id="__nav_9_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_9_5">
          词法分析
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="词法分析" data-md-level="2">
        <label class="md-nav__title" for="__nav_9_5">
          <span class="md-nav__icon md-icon"></span>
          词法分析
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../tokenization/" class="md-nav__link">
        tokenization综述
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_9_6" type="checkbox" id="__nav_9_6" >
      
      
      
      
        <label class="md-nav__link" for="__nav_9_6">
          句法分析
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="句法分析" data-md-level="2">
        <label class="md-nav__title" for="__nav_9_6">
          <span class="md-nav__icon md-icon"></span>
          句法分析
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Dependency%20Parsing/" class="md-nav__link">
        依存句法分析
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Constituency%20Parsing/" class="md-nav__link">
        成分句法分析
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../%E5%9B%9B%E4%B8%AA%E5%9F%BA%E6%9C%AC%E4%BB%BB%E5%8A%A1/" class="md-nav__link">
        四个基本任务
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../TF-IDF/" class="md-nav__link">
        TF-IDF
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../%E5%85%B1%E7%8E%B0%E7%9F%A9%E9%98%B5/" class="md-nav__link">
        共现矩阵
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../PPMI/" class="md-nav__link">
        PPMI
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          主题模型
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        主题模型
      </a>
      
        


<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#词袋模型" class="md-nav__link">
    词袋模型
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lsa" class="md-nav__link">
    LSA
  </a>
  
    <nav class="md-nav" aria-label="LSA">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#单词-文本矩阵" class="md-nav__link">
    单词-文本矩阵
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#单词-主题矩阵" class="md-nav__link">
    单词-主题矩阵
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#主题-文本矩阵" class="md-nav__link">
    主题-文本矩阵
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#从单词向量空间到主题向量空间的线性变换" class="md-nav__link">
    从单词向量空间到主题向量空间的线性变换
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#潜在语义分析" class="md-nav__link">
    潜在语义分析
  </a>
  
    <nav class="md-nav" aria-label="潜在语义分析">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#截断奇异值分析" class="md-nav__link">
    截断奇异值分析
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#plsa" class="md-nav__link">
    PLSA
  </a>
  
    <nav class="md-nav" aria-label="PLSA">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#生成模型" class="md-nav__link">
    生成模型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#共现模型" class="md-nav__link">
    共现模型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#与潜在语义分析的关系" class="md-nav__link">
    与潜在语义分析的关系
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#概率潜在语义分析的算法" class="md-nav__link">
    概率潜在语义分析的算法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#总结算法" class="md-nav__link">
    总结算法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#用法" class="md-nav__link">
    用法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#优点与不足" class="md-nav__link">
    优点与不足
  </a>
  
    <nav class="md-nav" aria-label="优点与不足">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#优点" class="md-nav__link">
    优点
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#不足" class="md-nav__link">
    不足
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lda" class="md-nav__link">
    LDA
  </a>
  
    <nav class="md-nav" aria-label="LDA">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#多项分布" class="md-nav__link">
    多项分布
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#狄利克雷分布" class="md-nav__link">
    狄利克雷分布
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#二项分布与贝塔分布" class="md-nav__link">
    二项分布与贝塔分布
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#基本想法" class="md-nav__link">
    基本想法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lda与plsa的关系" class="md-nav__link">
    LDA与PLSA的关系
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#模型定义" class="md-nav__link">
    模型定义
  </a>
  
    <nav class="md-nav" aria-label="模型定义">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#模型要素" class="md-nav__link">
    模型要素
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#生成过程" class="md-nav__link">
    生成过程
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#总结" class="md-nav__link">
    总结
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#概率计算" class="md-nav__link">
    概率计算
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#吉布斯抽样" class="md-nav__link">
    吉布斯抽样
  </a>
  
    <nav class="md-nav" aria-label="吉布斯抽样">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#基本思想" class="md-nav__link">
    基本思想
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#算法流程" class="md-nav__link">
    算法流程
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#训练与推断" class="md-nav__link">
    训练与推断
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#代码" class="md-nav__link">
    代码
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#本质与使用条件" class="md-nav__link">
    本质与使用条件
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#总结_1" class="md-nav__link">
    总结
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#参考" class="md-nav__link">
    参考
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../BM25/" class="md-nav__link">
        BM25
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../TextRank/" class="md-nav__link">
        TextRank
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" class="md-nav__link">
        语言模型
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Word%20Embedding/" class="md-nav__link">
        Word Embedding
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../NER/" class="md-nav__link">
        NER
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/" class="md-nav__link">
        预训练模型
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../CoVe/" class="md-nav__link">
        Cove
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ELMo/" class="md-nav__link">
        ELMo
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../seq2seq/" class="md-nav__link">
        seq2seq
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Attention/" class="md-nav__link">
        Attention
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Transformer/" class="md-nav__link">
        Transformer
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../GPT/" class="md-nav__link">
        GPT
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../BERT/" class="md-nav__link">
        Bert
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_10" type="checkbox" id="__nav_10" >
      
      
      
      
        <label class="md-nav__link" for="__nav_10">
          信息检索
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="信息检索" data-md-level="1">
        <label class="md-nav__title" for="__nav_10">
          <span class="md-nav__icon md-icon"></span>
          信息检索
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2/%E6%A6%82%E8%BF%B0/" class="md-nav__link">
        概述
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_11" type="checkbox" id="__nav_11" >
      
      
      
      
        <label class="md-nav__link" for="__nav_11">
          大数据
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="大数据" data-md-level="1">
        <label class="md-nav__title" for="__nav_11">
          <span class="md-nav__icon md-icon"></span>
          大数据
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%A6%82%E8%BF%B0/" class="md-nav__link">
        概述
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_12" type="checkbox" id="__nav_12" >
      
      
      
      
        <label class="md-nav__link" for="__nav_12">
          面经
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="面经" data-md-level="1">
        <label class="md-nav__title" for="__nav_12">
          <span class="md-nav__icon md-icon"></span>
          面经
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E9%9D%A2%E7%BB%8F/LR%E4%B8%BA%E4%BB%80%E4%B9%88%E7%94%A8%E4%BA%A4%E5%8F%89%E7%86%B5/" class="md-nav__link">
        LR为什么使用交叉熵
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E9%9D%A2%E7%BB%8F/%E7%BC%96%E8%BE%91%E8%B7%9D%E7%A6%BB/" class="md-nav__link">
        编辑距离
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E9%9D%A2%E7%BB%8F/B%E6%A0%91/" class="md-nav__link">
        B树
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E9%9D%A2%E7%BB%8F/kd%E6%A0%91/" class="md-nav__link">
        kd树
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E9%9D%A2%E7%BB%8F/%E5%89%8D%E7%BC%80%E6%A0%91/" class="md-nav__link">
        前缀树
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_13" type="checkbox" id="__nav_13" >
      
      
      
      
        <label class="md-nav__link" for="__nav_13">
          数学建模
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="数学建模" data-md-level="1">
        <label class="md-nav__title" for="__nav_13">
          <span class="md-nav__icon md-icon"></span>
          数学建模
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Mathematical%20Modeling/%E5%B1%82%E6%AC%A1%E5%88%86%E6%9E%90%E6%B3%95/" class="md-nav__link">
        层次分析法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Mathematical%20Modeling/%E4%BC%98%E5%8A%A3%E8%A7%A3%E8%B7%9D%E7%A6%BB%E6%B3%95Topsis/" class="md-nav__link">
        Topsis
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_13_3" type="checkbox" id="__nav_13_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_13_3">
          插值算法
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="插值算法" data-md-level="2">
        <label class="md-nav__title" for="__nav_13_3">
          <span class="md-nav__icon md-icon"></span>
          插值算法
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Mathematical%20Modeling/%E6%8F%92%E5%80%BC%E7%AE%97%E6%B3%95/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E6%8F%92%E5%80%BC/" class="md-nav__link">
        拉格朗日插值法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Mathematical%20Modeling/%E6%8F%92%E5%80%BC%E7%AE%97%E6%B3%95/%E7%89%9B%E9%A1%BF%E6%8F%92%E5%80%BC/" class="md-nav__link">
        牛顿插值法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Mathematical%20Modeling/%E6%8F%92%E5%80%BC%E7%AE%97%E6%B3%95/Hermite/" class="md-nav__link">
        Hermite插值法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Mathematical%20Modeling/%E6%8F%92%E5%80%BC%E7%AE%97%E6%B3%95/%E5%88%86%E6%AE%B5%E7%BA%BF%E6%80%A7%E6%8F%92%E5%80%BC/" class="md-nav__link">
        分段线性插值法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Mathematical%20Modeling/%E6%8F%92%E5%80%BC%E7%AE%97%E6%B3%95/%E6%A0%B7%E6%9D%A1%E6%8F%92%E5%80%BC/" class="md-nav__link">
        样条插值法
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Mathematical%20Modeling/%E5%85%B8%E5%9E%8B%E7%9B%B8%E5%85%B3%E5%88%86%E6%9E%90/" class="md-nav__link">
        典型相关分析
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Mathematical%20Modeling/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0/" class="md-nav__link">
        相关系数
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Mathematical%20Modeling/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/" class="md-nav__link">
        回归分析
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Mathematical%20Modeling/%E5%9B%A0%E5%AD%90%E5%88%86%E6%9E%90/" class="md-nav__link">
        因子分析
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Mathematical%20Modeling/%E7%81%B0%E8%89%B2%E5%85%B3%E8%81%94%E5%88%86%E6%9E%90/" class="md-nav__link">
        灰色关联分析
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Mathematical%20Modeling/%E7%81%B0%E8%89%B2%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B/" class="md-nav__link">
        灰色预测模型
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_14" type="checkbox" id="__nav_14" >
      
      
      
      
        <label class="md-nav__link" for="__nav_14">
          比赛相关
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="比赛相关" data-md-level="1">
        <label class="md-nav__title" for="__nav_14">
          <span class="md-nav__icon md-icon"></span>
          比赛相关
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%AF%94%E8%B5%9B%E7%9B%B8%E5%85%B3/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E6%AF%94%E8%B5%9B/" class="md-nav__link">
        数据挖掘比赛
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_15" type="checkbox" id="__nav_15" >
      
      
      
      
        <label class="md-nav__link" for="__nav_15">
          其他
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="其他" data-md-level="1">
        <label class="md-nav__title" for="__nav_15">
          <span class="md-nav__icon md-icon"></span>
          其他
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../others/vim/" class="md-nav__link">
        vim
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../others/git/" class="md-nav__link">
        git
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../others/regex/" class="md-nav__link">
        regex
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../others/sql/" class="md-nav__link">
        sql
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../others/one_test/" class="md-nav__link">
        博客后台案例
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../others/linux/" class="md-nav__link">
        linux学习
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../others/jupyter_pdf/" class="md-nav__link">
        浅谈jupyter导出为pdf
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../others/others/" class="md-nav__link">
        常用学习网站书籍
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#词袋模型" class="md-nav__link">
    词袋模型
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lsa" class="md-nav__link">
    LSA
  </a>
  
    <nav class="md-nav" aria-label="LSA">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#单词-文本矩阵" class="md-nav__link">
    单词-文本矩阵
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#单词-主题矩阵" class="md-nav__link">
    单词-主题矩阵
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#主题-文本矩阵" class="md-nav__link">
    主题-文本矩阵
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#从单词向量空间到主题向量空间的线性变换" class="md-nav__link">
    从单词向量空间到主题向量空间的线性变换
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#潜在语义分析" class="md-nav__link">
    潜在语义分析
  </a>
  
    <nav class="md-nav" aria-label="潜在语义分析">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#截断奇异值分析" class="md-nav__link">
    截断奇异值分析
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#plsa" class="md-nav__link">
    PLSA
  </a>
  
    <nav class="md-nav" aria-label="PLSA">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#生成模型" class="md-nav__link">
    生成模型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#共现模型" class="md-nav__link">
    共现模型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#与潜在语义分析的关系" class="md-nav__link">
    与潜在语义分析的关系
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#概率潜在语义分析的算法" class="md-nav__link">
    概率潜在语义分析的算法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#总结算法" class="md-nav__link">
    总结算法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#用法" class="md-nav__link">
    用法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#优点与不足" class="md-nav__link">
    优点与不足
  </a>
  
    <nav class="md-nav" aria-label="优点与不足">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#优点" class="md-nav__link">
    优点
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#不足" class="md-nav__link">
    不足
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lda" class="md-nav__link">
    LDA
  </a>
  
    <nav class="md-nav" aria-label="LDA">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#多项分布" class="md-nav__link">
    多项分布
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#狄利克雷分布" class="md-nav__link">
    狄利克雷分布
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#二项分布与贝塔分布" class="md-nav__link">
    二项分布与贝塔分布
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#基本想法" class="md-nav__link">
    基本想法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lda与plsa的关系" class="md-nav__link">
    LDA与PLSA的关系
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#模型定义" class="md-nav__link">
    模型定义
  </a>
  
    <nav class="md-nav" aria-label="模型定义">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#模型要素" class="md-nav__link">
    模型要素
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#生成过程" class="md-nav__link">
    生成过程
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#总结" class="md-nav__link">
    总结
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#概率计算" class="md-nav__link">
    概率计算
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#吉布斯抽样" class="md-nav__link">
    吉布斯抽样
  </a>
  
    <nav class="md-nav" aria-label="吉布斯抽样">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#基本思想" class="md-nav__link">
    基本思想
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#算法流程" class="md-nav__link">
    算法流程
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#训练与推断" class="md-nav__link">
    训练与推断
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#代码" class="md-nav__link">
    代码
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#本质与使用条件" class="md-nav__link">
    本质与使用条件
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#总结_1" class="md-nav__link">
    总结
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#参考" class="md-nav__link">
    参考
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="主题模型">主题模型<a class="headerlink" href="#主题模型" title="Permanent link">&para;</a></h1>
<p>主题模型也可以看成一种词向量表达，主要有LSA、PLSA、LDA。按照这个顺序来逐渐发展的</p>
<h2 id="词袋模型">词袋模型<a class="headerlink" href="#词袋模型" title="Permanent link">&para;</a></h2>
<p>将所有词语装进一个袋子里，不考虑其词法和语序的问题，即每个词语都是独立的</p>
<p>例子：</p>
<div class="highlight"><pre><span></span><code><span class="n">句子1</span><span class="err">：</span><span class="n">我</span> <span class="n">爱</span> <span class="n">北</span> <span class="n">京</span> <span class="n">天</span> <span class="n">安</span> <span class="n">门</span>
<span class="n">转换为</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

<span class="n">句子2</span><span class="err">：</span><span class="n">我</span> <span class="n">喜</span> <span class="n">欢</span> <span class="n">上</span> <span class="n">海</span>
<span class="n">转换为</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;This is the first document.&#39;</span><span class="p">,</span>
    <span class="s1">&#39;This document is the second document.&#39;</span><span class="p">,</span>
    <span class="s1">&#39;And this is the third one.&#39;</span><span class="p">,</span>
    <span class="s1">&#39;Is this the first document?&#39;</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>
<span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
</code></pre></div>
<p>结果：</p>
<div class="highlight"><pre><span></span><code>[[0 1 1 1 0 0 1 0 1]
 [0 2 0 1 0 1 1 0 1]
 [1 0 0 1 1 0 1 1 1]
 [0 1 1 1 0 0 1 0 1]]
</code></pre></div>
<h2 id="lsa">LSA<a class="headerlink" href="#lsa" title="Permanent link">&para;</a></h2>
<p>LSA就是潜在语义分析。特点是通过矩阵分解发现文本与单词之间基于主题（话题）的语义关系。
首先要清楚几个概念：</p>
<h3 id="单词-文本矩阵">单词-文本矩阵<a class="headerlink" href="#单词-文本矩阵" title="Permanent link">&para;</a></h3>
<div class="arithmatex">\[
X=\left[\begin{array}{cccc}
x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1 n} \\
x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2 n} \\
\vdots &amp; \vdots &amp; &amp; \vdots \\
x_{m 1} &amp; x_{m 2} &amp; \cdots &amp; x_{m n}
\end{array}\right]
\]</div>
<p>这是一个 <span class="arithmatex">\(m \times n\)</span> 矩阵, 元素 <span class="arithmatex">\(x_{i j}\)</span> 表示单词 <span class="arithmatex">\(w_i\)</span> 在文本 <span class="arithmatex">\(d_j\)</span> 中出现的频数或权值。由于单 词的种类很多, 而每个文本中出现单词的种类通常较少, 所以单词-文本矩阵是一个稀 疏矩阵。
权值通常用单词频率-逆文本频率 (term frequency-inverse document frequency, TF-IDF）表示，其定义是</p>
<div class="arithmatex">\[
\operatorname{TFIDF}_{i j}=\frac{\mathrm{tf}_{i j}}{\mathrm{tf}_{\bullet j}} \log \frac{\mathrm{df}}{\mathrm{df}_i}, \quad i=1,2, \cdots, m ; \quad j=1,2, \cdots, n
\]</div>
<p>直观上讲，可以直接用每一列作为文本语义表达， 因此可以通过余弦相似度等计算文本之间的相似性，并且矩阵稀疏，计算量较少。但其并不关心文本中词语出现的顺序等信息，因此需要改进。</p>
<h3 id="单词-主题矩阵">单词-主题矩阵<a class="headerlink" href="#单词-主题矩阵" title="Permanent link">&para;</a></h3>
<p>假设所有文本共含有 <span class="arithmatex">\(k\)</span> 个话题。假设每个话题由一个定义在单词集合 <span class="arithmatex">\(W\)</span> 上的 <span class="arithmatex">\(m\)</span> 维向量表示, 称为话题向量, 即</p>
<div class="arithmatex">\[
t_l=\left[\begin{array}{c}
t_{1 l} \\
t_{2 l} \\
\vdots \\
t_{m l}
\end{array}\right], \quad l=1,2, \cdots, k
\]</div>
<p>其中 <span class="arithmatex">\(t_{i l}\)</span> 是单词 <span class="arithmatex">\(w_i\)</span> 在话题 <span class="arithmatex">\(t_l\)</span> 的权值, <span class="arithmatex">\(i=1,2, \cdots, m\)</span>, 权值越大, 该单词在该话题中 的重要度就越高。这 <span class="arithmatex">\(k\)</span> 个话题向量 <span class="arithmatex">\(t_1, t_2, \cdots, t_k\)</span> 张成一个话题向量空间 (topic vector
话题向量空间 <span class="arithmatex">\(T\)</span> 也可以表示为一个矩阵, 称为单词-主题矩阵 (word-topic matrix）, 记作</p>
<div class="arithmatex">\[
T=\left[\begin{array}{cccc}
t_{11} &amp; t_{12} &amp; \cdots &amp; t_{1 k} \\
t_{21} &amp; t_{22} &amp; \cdots &amp; t_{2 k} \\
\vdots &amp; \vdots &amp; &amp; \vdots \\
t_{m 1} &amp; t_{m 2} &amp; \cdots &amp; t_{m k}
\end{array}\right]
\]</div>
<h3 id="主题-文本矩阵">主题-文本矩阵<a class="headerlink" href="#主题-文本矩阵" title="Permanent link">&para;</a></h3>
<p>将单词-文本矩阵中的文本<span class="arithmatex">\(x_j\)</span>投影到主题向量空间<span class="arithmatex">\(J\)</span>中，得到在主题空间中的一个向量<span class="arithmatex">\(y_j\)</span>。</p>
<div class="arithmatex">\[
Y=\left[\begin{array}{cccc}
y_{11} &amp; y_{12} &amp; \cdots &amp; y_{1 n} \\
y_{21} &amp; y_{22} &amp; \cdots &amp; y_{2 n} \\
\vdots &amp; \vdots &amp; &amp; \vdots \\
y_{k 1} &amp; y_{k 2} &amp; \cdots &amp; y_{k n}
\end{array}\right]
\]</div>
<h3 id="从单词向量空间到主题向量空间的线性变换">从单词向量空间到主题向量空间的线性变换<a class="headerlink" href="#从单词向量空间到主题向量空间的线性变换" title="Permanent link">&para;</a></h3>
<p>单词-文本矩阵<span class="arithmatex">\(X\)</span>可以近似表示为单词-主题矩阵<span class="arithmatex">\(T\)</span>与主题-文本矩阵<span class="arithmatex">\(Y\)</span>的乘积，这就是潜在语义分析：</p>
<div class="arithmatex">\[
X\approx TY
\]</div>
<h3 id="潜在语义分析">潜在语义分析<a class="headerlink" href="#潜在语义分析" title="Permanent link">&para;</a></h3>
<p>给定单词-文本矩阵<span class="arithmatex">\(X\)</span>，每一行代表一个单词，每一列代表一个文本。其中的元素代表单词在文本中的权重或者频数（词袋模型）。</p>
<h4 id="截断奇异值分析">截断奇异值分析<a class="headerlink" href="#截断奇异值分析" title="Permanent link">&para;</a></h4>
<div class="arithmatex">\[
X \approx U_k \Sigma_k V_k^{\mathrm{T}}=\left[\begin{array}{llll}
u_1 &amp; u_2 &amp; \cdots &amp; u_k
\end{array}\right]\left[\begin{array}{cccc}
\sigma_1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; \sigma_2 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; \ddots &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; \sigma_k
\end{array}\right]\left[\begin{array}{c}
v_1^{\mathrm{T}} \\
v_2^{\mathrm{T}} \\
\vdots \\
v_k^{\mathrm{T}}
\end{array}\right]
\]</div>
<p>接下来考虑文本在主题空间中的表示。</p>
<div class="arithmatex">\[
\begin{aligned}
X &amp;=\left[\begin{array}{llll}
x_1 &amp; x_2 &amp; \cdots &amp; x_n
\end{array}\right] \approx U_k \Sigma_k V_k^{\mathrm{T}} \\
&amp;=\left[\begin{array}{llll}
u_1 &amp; u_2 &amp; \cdots &amp; u_k
\end{array}\right]\left[\begin{array}{cccc}
\sigma_1 &amp; &amp; &amp; \\
&amp; \sigma_2 &amp; 0 &amp; \\
0 &amp; \ddots &amp; \\
&amp; &amp; \sigma_k
\end{array}\right]\left[\begin{array}{cccc}
v_{11} &amp; v_{21} &amp; \cdots &amp; v_{n 1} \\
v_{12} &amp; v_{22} &amp; \cdots &amp; v_{n 2} \\
\vdots &amp; \vdots &amp; &amp; \vdots \\
v_{1 k} &amp; v_{2 k} &amp; \cdots &amp; v_{n k}
\end{array}\right] \\
&amp;=\left[\begin{array}{llll}
u_1 &amp; u_2 &amp; \cdots &amp; u_k
\end{array}\right]\left[\begin{array}{cccc}
\sigma_1 v_{11} &amp; \sigma_1 v_{21} &amp; \cdots &amp; \sigma_1 v_{n 1} \\
\sigma_2 v_{12} &amp; \sigma_2 v_{22} &amp; \cdots &amp; \sigma_2 v_{n 2} \\
\vdots &amp; \vdots &amp; &amp; \vdots \\
\sigma_k v_{1 k} &amp; \sigma_k v_{2 k} &amp; \cdots &amp; \sigma_k v_{n k}
\end{array}\right]
\end{aligned}
\]</div>
<p>其中:</p>
<div class="arithmatex">\[
u_l = \begin{bmatrix}u_{1l} \\u_{2l} \\ \vdots \\u_{ml} \end{bmatrix}, \quad l= 1, 2, \dots, k
\]</div>
<p>代表单词对主题的权重。</p>
<p>由式知, 矩阵 <span class="arithmatex">\(X\)</span> 的第 <span class="arithmatex">\(j\)</span> 列向量 <span class="arithmatex">\(x_j\)</span> 满足</p>
<div class="arithmatex">\[
\begin{aligned}
x_j &amp; \approx U_k\left(\Sigma_k V_k^{\mathrm{T}}\right)_j \\
&amp;=\left[\begin{array}{llll}
u_1 &amp; u_2 &amp; \cdots &amp; u_k
\end{array}\right]\left[\begin{array}{c}
\sigma_1 v_{j 1} \\
\sigma_2 v_{j 2} \\
\vdots \\
\sigma_k v_{j k}
\end{array}\right] \\
&amp;=\sum_{l=1}^k \sigma_l v_{j l} u_l, \quad j=1,2, \cdots, n
\end{aligned}
\]</div>
<p>则<span class="arithmatex">\(\Sigma_kV_k^T\)</span>每一个列向量是一个文本在主题向量空间中的表示。</p>
<h2 id="plsa">PLSA<a class="headerlink" href="#plsa" title="Permanent link">&para;</a></h2>
<h3 id="生成模型">生成模型<a class="headerlink" href="#生成模型" title="Permanent link">&para;</a></h3>
<p>假设有单词集合 <span class="arithmatex">\(W=\left\{w_1, w_2, \cdots, w_M\right\}\)</span>, 其中 <span class="arithmatex">\(M\)</span> 是单词个数; 文本 (指标) 集 合 <span class="arithmatex">\(D=\left\{d_1, d_2, \cdots, d_N\right\}\)</span>, 其中 <span class="arithmatex">\(N\)</span> 是文本个数; 话题集合 <span class="arithmatex">\(Z=\left\{z_1, z_2, \cdots, z_K\right\}\)</span>, 其中 <span class="arithmatex">\(K\)</span> 是预先设定的话题个数。随机变量 <span class="arithmatex">\(w\)</span> 取值于单词集合; 随机变量 <span class="arithmatex">\(d\)</span> 取值于文本集 合, 随机变量 <span class="arithmatex">\(z\)</span> 取值于话题集合。概率分布 <span class="arithmatex">\(P(d)\)</span> 、条件概率分布 <span class="arithmatex">\(P(z \mid d)\)</span> 、条件概率分 布 <span class="arithmatex">\(P(w \mid z)\)</span> 皆属于多项分布, 其中 <span class="arithmatex">\(P(d)\)</span> 表示生成文本 <span class="arithmatex">\(d\)</span> 的概率, <span class="arithmatex">\(P(z \mid d)\)</span> 表示文本 <span class="arithmatex">\(d\)</span> 生 成话题 <span class="arithmatex">\(z\)</span> 的概率, <span class="arithmatex">\(P(w \mid z)\)</span> 表示话题 <span class="arithmatex">\(z\)</span> 生成单词 <span class="arithmatex">\(w\)</span> 的概率。</p>
<p>每个文本 <span class="arithmatex">\(d\)</span> 拥有自己的话题概率分布 <span class="arithmatex">\(P(z \mid d)\)</span>, 每个话题 <span class="arithmatex">\(z\)</span> 拥有自己的单词概率分 布 <span class="arithmatex">\(P(w \mid z)\)</span>; 也就是说一个文本的内容由其相关话题决定, 一个话题的内容由其相关单词决定。</p>
<p>生成模型通过以下步骤生成文本-单词共现数据:
(1) 依据概率分布 <span class="arithmatex">\(P(d)\)</span>, 从文本 (指标) 集合中随机选取一个文本 <span class="arithmatex">\(d\)</span>, 共生成 <span class="arithmatex">\(N\)</span> 个文本; 针对每个文本, 执行以下操作;
(2) 在文本 <span class="arithmatex">\(d\)</span> 给定条件下, 依据条件概率分布 <span class="arithmatex">\(P(z \mid d)\)</span>, 从话题集合随机选取一个 话题 <span class="arithmatex">\(z\)</span>, 共生成 <span class="arithmatex">\(L\)</span> 个话题, 这里 <span class="arithmatex">\(L\)</span> 是文本长度;
(3) 在话题 <span class="arithmatex">\(z\)</span> 给定条件下, 依据条件概率分布 <span class="arithmatex">\(P(w \mid z)\)</span>, 从单词集合中随机选取一 个单词 <span class="arithmatex">\(w\)</span> 。</p>
<p>生成模型中, 单词变量 <span class="arithmatex">\(w\)</span> 与文本变量 <span class="arithmatex">\(d\)</span> 是观测变量, 话题变量 <span class="arithmatex">\(z\)</span> 是隐变量。也就 是说模型生成的是单词-话题-文本三元组 <span class="arithmatex">\((w, z, d)\)</span> 的集合, 但观测到的是单词-文本二 元组 <span class="arithmatex">\((w, d)\)</span> 的集合, 观测数据表示为单词-文本矩阵 <span class="arithmatex">\(T\)</span> 的形式, 矩阵 <span class="arithmatex">\(T\)</span> 的行表示单词, 列表示文本, 元素表示单词-文本对 <span class="arithmatex">\((w, d)\)</span> 的出现次数。</p>
<p>从数据的生成过程可以推出, 文本-单词共现数据 <span class="arithmatex">\(T\)</span> 的生成概率为所有单词-文本 对 <span class="arithmatex">\((w, d)\)</span> 的生成概率的乘积,</p>
<div class="arithmatex">\[
P(T)=\prod_{(w, d)} P(w, d)^{n(w, d)}
\]</div>
<p>这里 <span class="arithmatex">\(n(w, d)\)</span> 表示 <span class="arithmatex">\((w, d)\)</span> 的出现次数, 单词-文本对出现的总次数是 <span class="arithmatex">\(N \times L\)</span> 。每个单 词-文本对 <span class="arithmatex">\((w, d)\)</span> 的生成概率由以下公式决定:</p>
<div class="arithmatex">\[
\begin{aligned}
P(w, d) &amp;=P(d) P(w \mid d) \\
&amp;=P(d) \sum_z P(w, z \mid d) \\
&amp;=P(d) \sum_z P(z \mid d) P(w \mid z)
\end{aligned}
\]</div>
<p>即生成模型的定义。
生成模型假设在话题 <span class="arithmatex">\(z\)</span> 给定条件下, 单词 <span class="arithmatex">\(w\)</span> 与文本 <span class="arithmatex">\(d\)</span> 条件独立, 即</p>
<div class="arithmatex">\[
P(w, z \mid d)=P(z \mid d) P(w \mid z)
\]</div>
<p><img alt="" src="../image/Pasted%20image%2020221012121216.png" /></p>
<h3 id="共现模型">共现模型<a class="headerlink" href="#共现模型" title="Permanent link">&para;</a></h3>
<div class="arithmatex">\[
P(T)=\prod_{(w, d)} P(w, d)^{n(w, d)}
\]</div>
<p>每个单词-文本对 <span class="arithmatex">\((w, d)\)</span> 的概率由以下公式决定:</p>
<div class="arithmatex">\[
P(w, d)=\sum_{z \in Z} P(z) P(w \mid z) P(d \mid z)
\]</div>
<p>式 (18.5) 即共现模型的定义。容易验证, 生成模型 (18.2) 和共现模型 (18.5) 是等价的。 共现模型假设在话题 <span class="arithmatex">\(z\)</span> 给定条件下, 单词 <span class="arithmatex">\(w\)</span> 与文本 <span class="arithmatex">\(d\)</span> 是条件独立的, 即</p>
<div class="arithmatex">\[
P(w, d \mid z)=P(w \mid z) P(d \mid z)
\]</div>
<p>直观解释：
<img alt="" src="../image/Pasted%20image%2020221014225958.png" /></p>
<h3 id="与潜在语义分析的关系">与潜在语义分析的关系<a class="headerlink" href="#与潜在语义分析的关系" title="Permanent link">&para;</a></h3>
<p>共现模型也可以表示为三个矩阵乘积的形式。这样, 概率潜在语义分析与 潜在语义分析的对应关系可以从中看得很清楚。下面是共现模型的矩阵乘积形式:</p>
<div class="arithmatex">\[
\begin{aligned}
X^{\prime} &amp;=U^{\prime} \Sigma^{\prime} V^{\prime \mathrm{T}} \\
X^{\prime} &amp;=[P(w, d)]_{M \times N} \\
U^{\prime} &amp;=[P(w \mid z)]_{M \times K} \\
\Sigma^{\prime} &amp;=[P(z)]_{K \times K} \\
V^{\prime} &amp;=[P(d \mid z)]_{N \times K}
\end{aligned}
\]</div>
<h3 id="概率潜在语义分析的算法">概率潜在语义分析的算法<a class="headerlink" href="#概率潜在语义分析的算法" title="Permanent link">&para;</a></h3>
<p>Plsa是含有隐变量的模型，其学习通常使用EM算法。
E步是计算Q函数，M步是极大化Q函数。</p>
<p>设单词集合为 <span class="arithmatex">\(W=\left\{w_1, w_2, \cdots, w_M\right\}\)</span>, 文本集合为 <span class="arithmatex">\(D=\left\{d_1, d_2, \cdots, d_N\right\}\)</span>, 话 题集合为 <span class="arithmatex">\(Z=\left\{z_1, z_2, \cdots, z_K\right\}\)</span> 。给定单词-文本共现数据 <span class="arithmatex">\(T=\left\{n\left(w_i, d_j\right)\right\}, i=\)</span> <span class="arithmatex">\(1,2, \cdots, M, j=1,2, \cdots, N\)</span>, 目标是估计概率潜在语义分析模型（生成模型）的 参数。如果使用极大似然估计, 对数似然函数是</p>
<div class="arithmatex">\[
\begin{aligned}
L &amp;=\sum_{i=1}^M \sum_{j=1}^N n\left(w_i, d_j\right) \log P\left(w_i, d_j\right) \\
&amp;=\sum_{i=1}^M \sum_{j=1}^N n\left(w_i, d_j\right) \log \left[\sum_{k=1}^K P\left(w_i \mid z_k\right) P\left(z_k \mid d_j\right)\right]
\end{aligned}
\]</div>
<p>但是模型含有隐变量, 对数似然函数的优化无法用解析方法求解, 这时使用 EM算法。 应用 EM算法的核心是定义 <span class="arithmatex">\(Q\)</span> 函数。
<span class="arithmatex">\(\mathrm{E}\)</span> 步：计算 <span class="arithmatex">\(Q\)</span> 函数
<span class="arithmatex">\(Q\)</span> 函数为完全数据的对数似然函数对不完全数据的条件分布的期望。针对概率潜 在语义分析的生成模型, <span class="arithmatex">\(Q\)</span> 函数是</p>
<div class="arithmatex">\[
Q=\sum_{k=1}^K\left\{\sum_{j=1}^N n\left(d_j\right)\left[\log P\left(d_j\right)+\sum_{i=1}^M \frac{n\left(w_i, d_j\right)}{n\left(d_j\right)} \log P\left(w_i \mid z_k\right) P\left(z_k \mid d_j\right)\right]\right\} P\left(z_k \mid w_i, d_j\right)
\]</div>
<p>式中 <span class="arithmatex">\(n\left(d_j\right)=\sum_{i=1}^M n\left(w_i, d_j\right)\)</span> 表示文本 <span class="arithmatex">\(d_j\)</span> 中的单词个数, <span class="arithmatex">\(n\left(w_i, d_j\right)\)</span> 表示单词 <span class="arithmatex">\(w_i\)</span> 在文本 <span class="arithmatex">\(d_j\)</span> 中出现的次数。条件概率分布 <span class="arithmatex">\(P\left(z_k \mid w_i, d_j\right)\)</span> 代表不完全数据, 是已知变量。条件概 率分布 <span class="arithmatex">\(P\left(w_i \mid z_k\right)\)</span> 和 <span class="arithmatex">\(P\left(z_k \mid d_j\right)\)</span> 的乘积代表完全数据, 是末知变量。
由于可以从数据中直接统计得出 <span class="arithmatex">\(P\left(d_j\right)\)</span> 的估计, 这里只考虑 <span class="arithmatex">\(P\left(w_i \mid z_k\right), P\left(z_k \mid d_j\right)\)</span> 的估计, 可将 <span class="arithmatex">\(Q\)</span> 函数简化为函数 <span class="arithmatex">\(Q^{\prime}\)</span></p>
<div class="arithmatex">\[
Q^{\prime}=\sum_{i=1}^M \sum_{j=1}^N n\left(w_i, d_j\right) \sum_{k=1}^K P\left(z_k \mid w_i, d_j\right) \log \left[P\left(w_i \mid z_k\right) P\left(z_k \mid d_j\right)\right]
\]</div>
<p><span class="arithmatex">\(Q^{\prime}\)</span> 函数中的 <span class="arithmatex">\(P\left(z_k \mid w_i, d_j\right)\)</span> 可以根据贝叶斯公式计算</p>
<div class="arithmatex">\[
P\left(z_k \mid w_i, d_j\right)=\frac{P\left(w_i \mid z_k\right) P\left(z_k \mid d_j\right)}{\sum_{k=1}^K P\left(w_i \mid z_k\right) P\left(z_k \mid d_j\right)}
\]</div>
<p>其中 <span class="arithmatex">\(P\left(z_k \mid d_j\right)\)</span> 和 <span class="arithmatex">\(P\left(w_i \mid z_k\right)\)</span> 由上一步迭代得到。
<span class="arithmatex">\(\mathrm{M}\)</span> 步: 极大化 <span class="arithmatex">\(Q\)</span> 函数。
通过约束最优化求解 <span class="arithmatex">\(Q\)</span> 函数的极大值, 这时 <span class="arithmatex">\(P\left(z_k \mid d_j\right)\)</span> 和 <span class="arithmatex">\(P\left(w_i \mid z_k\right)\)</span> 是变量。因为 变量 <span class="arithmatex">\(P\left(w_i \mid z_k\right), P\left(z_k \mid d_j\right)\)</span> 形成概率分布, 满足约束条件</p>
<div class="arithmatex">\[
\begin{aligned}
&amp;\sum_{i=1}^M P\left(w_i \mid z_k\right)=1, \quad k=1,2, \cdots, K \\
&amp;\sum_{k=1}^K P\left(z_k \mid d_j\right)=1, \quad j=1,2, \cdots, N
\end{aligned}
\]</div>
<p>应用拉格朗日法, 引入拉格朗日乘子 <span class="arithmatex">\(\tau_k\)</span> 和 <span class="arithmatex">\(\rho_j\)</span>, 定义拉格朗日函数 <span class="arithmatex">\(A\)</span></p>
<div class="arithmatex">\[
\Lambda=Q^{\prime}+\sum_{k=1}^K \tau_k\left(1-\sum_{i=1}^M P\left(w_i \mid z_k\right)\right)+\sum_{j=1}^N \rho_j\left(1-\sum_{k=1}^K P\left(z_k \mid d_j\right)\right)
\]</div>
<p>将拉格朗日函数 <span class="arithmatex">\(\Lambda\)</span> 分别对 <span class="arithmatex">\(P\left(w_i \mid z_k\right)\)</span> 和 <span class="arithmatex">\(P\left(z_k \mid d_j\right)\)</span> 求偏导数, 并令其等于 0 , 得到下面 的方程组</p>
<div class="arithmatex">\[
\begin{aligned}
&amp;\sum_{j=1}^N n\left(w_i, d_j\right) P\left(z_k \mid w_i, d_j\right)-\tau_k P\left(w_i \mid z_k\right)=0, \quad i=1,2, \cdots, M ; \quad k=1,2, \cdots, K \\
&amp;\sum_{i=1}^M n\left(w_i, d_j\right) P\left(z_k \mid w_i, d_j\right)-\rho_j P\left(z_k \mid d_j\right)=0, \quad j=1,2, \cdots, N ; \quad k=1,2, \cdots, K
\end{aligned}
\]</div>
<p>解方程组得到 <span class="arithmatex">\(M\)</span> 步的参数估计公式:</p>
<div class="arithmatex">\[
P\left(w_i \mid z_k\right)=\frac{\sum_{j=1}^N n\left(w_i, d_j\right) P\left(z_k \mid w_i, d_j\right)}{\sum_{m=1}^M \sum_{j=1}^N n\left(w_m, d_j\right) P\left(z_k \mid w_m, d_j\right)}
\]</div>
<div class="arithmatex">\[
P(z_k\mid d_j) = \frac{\sum_{i=1}^Mn(w_i, d_j)P(z_k\mid w_i,d_j)}{n(d_j)}
\]</div>
<h3 id="总结算法">总结算法<a class="headerlink" href="#总结算法" title="Permanent link">&para;</a></h3>
<p>输入: 设单词集合为 <span class="arithmatex">\(W=\left\{w_1, w_2, \cdots, w_M\right\}\)</span>, 文本集合为 <span class="arithmatex">\(D=\left\{d_1, d_2, \cdots, d_N\right\}\)</span>, 话题集合为 <span class="arithmatex">\(Z=\left\{z_1, z_2, \cdots, z_K\right\}\)</span>, 共现数据 <span class="arithmatex">\(\left\{n\left(w_i, d_j\right)\right\}, i=1,2, \cdots, M, j=1\)</span>, <span class="arithmatex">\(2, \cdots, N\)</span>;
输出: <span class="arithmatex">\(P\left(w_i \mid z_k\right)\)</span> 和 <span class="arithmatex">\(P\left(z_k \mid d_j\right)\)</span> 。
(1) 设置参数 <span class="arithmatex">\(P\left(w_i \mid z_k\right)\)</span> 和 <span class="arithmatex">\(P\left(z_k \mid d_j\right)\)</span> 的初始值。
(2) 迭代执行以下 <span class="arithmatex">\(\mathrm{E}\)</span> 步, <span class="arithmatex">\(\mathrm{M}\)</span> 步, 直到收敛为止。
<span class="arithmatex">\(\mathrm{E}\)</span> 步:</p>
<div class="arithmatex">\[
P\left(z_k \mid w_i, d_j\right)=\frac{P\left(w_i \mid z_k\right) P\left(z_k \mid d_j\right)}{\sum_{k=1}^K P\left(w_i \mid z_k\right) P\left(z_k \mid d_j\right)}
\]</div>
<p>M 步:</p>
<div class="arithmatex">\[
\begin{aligned}
P\left(w_i \mid z_k\right) &amp;=\frac{\sum_{j=1}^N n\left(w_i, d_j\right) P\left(z_k \mid w_i, d_j\right)}{\sum_{m=1}^M \sum_{j=1}^N n\left(w_m, d_j\right) P\left(z_k \mid w_m, d_j\right)} \\
P\left(z_k \mid d_j\right) &amp;=\frac{\sum_{i=1}^M n\left(w_i, d_j\right) P\left(z_k \mid w_i, d_j\right)}{n\left(d_j\right)}
\end{aligned}
\]</div>
<h3 id="用法">用法<a class="headerlink" href="#用法" title="Permanent link">&para;</a></h3>
<p>与LSA类似，可以把文档对各个主题的概率看作是文档的表示，最后用到的就是<span class="arithmatex">\(P(z_k\mid d_j)\)</span>。</p>
<p><img alt="" src="../image/Pasted%20image%2020221018125347.png" />
k就是我们自己设定的主题数，一般来说K远远小于文档个数和词汇表大小，这样也达到了降维的目的。</p>
<h3 id="优点与不足">优点与不足<a class="headerlink" href="#优点与不足" title="Permanent link">&para;</a></h3>
<h4 id="优点">优点<a class="headerlink" href="#优点" title="Permanent link">&para;</a></h4>
<p>pLSA是在一套比较完整的思想的基础上提出来的，模型中各项参数有明确的物理含义，可解释性比较强。相比LSA，pLSA对人类生成文本机制的刻画更加细致、更加符合我们的常识，比如，pLSA基于条件概率，引入了一个“隐含变量”（相对于可以看到的文档和词语，是不可观测变的），即主题，来描述文本生成的过程。</p>
<h4 id="不足">不足<a class="headerlink" href="#不足" title="Permanent link">&para;</a></h4>
<p>pLSA的理论与我们的实践不是那么的统一:
(1) 我们说话的时候，根本不会考虑&rdquo; 我说这段话的概率大小&rdquo;，即 <span class="arithmatex">\(p\left(d_t\right)\)</span>
(2) pLSA认为，我们说话时面向的主题分布，取决于 &ldquo;文档&rdquo; （实际上是文档ID)。这个假设显然是不合理的，小说家不会因为自己写到第666回而调整 主题。
(3) 类似 (2)，随着上下文的变化，我们围绕一个主题说话的内容和方式也 会发生改变。在主题模型中，这种改变的体现，就是一个主题下的词语概率分 布会发生改变。而pLSA忽略了这样的事实。</p>
<p>从计算复杂度的角度看pLSA有两个比较大的缺陷:
(1) pLSA中，对文档 出现的概率估计，来自对训练语料的学习。而对于一个 末知文档，我们是无法估计它出现的概率的一一因此pLSA无法对训练语料之 外的文档进行处理。pLSA的这个特点决定了，在在线(online) 场景中(数据是 持续增加的)，那么文档处理系统就需要定时使用pLSA对整个语料库进行计 算。因此，pLSA比较适合允许一定时滞的离线计算。
(2) pLSA认为一个文档对各个主题的隶属度是一定的——而一个主题对各个词语的隶属度也是一定的，因此pLSA在生成一个文档的各个词语时、使用了相同的词语概率分布。这样，pLSA需要为每一个文档记录一个专门的随着语料数据集规模的增加，pLSA的参数规模也会增加，导致模型训练越来越困难。</p>
<h2 id="lda">LDA<a class="headerlink" href="#lda" title="Permanent link">&para;</a></h2>
<p>LDA模型是文本集合的生成概率模型。</p>
<p>LDA 的文本集合的生成过程如下: 首先随机生成一个文本的话题分布, 之后在该 文本的每个位置, 依据该文本的话题分布随机生成一个话题, 然后在该位置依据该话 题的单词分布随机生成一个单词, 直至文本的最后一个位置, 生成整个文本。重复以 上过程生成所有文本。</p>
<p>LDA 模型是含有隐变量的概率图模型。模型中, 每个话题的单词分布, 每个文 本的话题分布, 文本的每个位置的话题是隐变量; 文本的每个位置的单词是观测变 量。LDA 模型的学习与推理无法直接求解, 通常使用吉布斯抽样 (Gibbs sampling) 和 变分 EM算法 (variational EM algorithm), 前者是蒙特卡罗法, 而后者是近似算法。</p>
<h3 id="多项分布">多项分布<a class="headerlink" href="#多项分布" title="Permanent link">&para;</a></h3>
<p>(多项分布) 若多元离散随机变量 <span class="arithmatex">\(X=\left(X_1, X_2, \cdots, X_k\right)\)</span> 的概率质 量函数为</p>
<div class="arithmatex">\[
\begin{aligned}
P\left(X_1=n_1, X_2=n_2, \cdots, X_k=n_k\right) &amp;=\frac{n !}{n_{1} ! n_{2} ! \cdots n_{k} !} p_1^{n_1} p_2^{n_2} \cdots p_k^{n_k} \\
&amp;=\frac{n !}{\prod_{i=1}^k n_{i} !} \prod_{i=1}^k p_i^{n_i}
\end{aligned}
\]</div>
<p>其中 <span class="arithmatex">\(p=\left(p_1, p_2, \cdots, p_k\right), p_i \geqslant 0, i=1,2, \cdots, k, \sum_{i=1}^k p_i=1, \sum_{i=1}^k n_i=n\)</span>, 则称随机变 量 <span class="arithmatex">\(X\)</span> 服从参数为 <span class="arithmatex">\((n, p)\)</span> 的多项分布, 记作 <span class="arithmatex">\(X \sim \operatorname{Mult}(n, p)\)</span> 。</p>
<p>当试验的次数 <span class="arithmatex">\(n\)</span> 为 1 时, 多项分布变成类别分布 (categorical distribution)。类 别分布表示试验可能出现的 <span class="arithmatex">\(k\)</span> 种结果的概率。显然多项分布包含类别分布。</p>
<h3 id="狄利克雷分布">狄利克雷分布<a class="headerlink" href="#狄利克雷分布" title="Permanent link">&para;</a></h3>
<p>狄利克雷分布 (Dirichlet distribution) 是一种多元连续随机变量的概率分布, 是 贝塔分布 (beta distribution) 的扩展。在贝叶斯学习中, 狄利克雷分布常作为多项分 布的先验分布使用。
(狄利克雷分布) 若多元连续随机变量 <span class="arithmatex">\(\theta=\left(\theta_1, \theta_2, \cdots, \theta_k\right)\)</span> 的概率密 度函数为</p>
<div class="arithmatex">\[
p(\theta \mid \alpha)=\frac{\Gamma\left(\sum_{i=1}^k \alpha_i\right)}{\prod_{i=1}^k \Gamma\left(\alpha_i\right)} \prod_{i=1}^k \theta_i^{\alpha_i-1}
\]</div>
<p>其中 <span class="arithmatex">\(\sum_{i=1}^k \theta_i=1, \theta_i \geqslant 0, \alpha=\left(\alpha_1, \alpha_2, \cdots, \alpha_k\right), \alpha_i&gt;0, i=1,2, \cdots, k\)</span>, 则称随机变量 <span class="arithmatex">\(\theta\)</span> 服从参数为 <span class="arithmatex">\(\alpha\)</span> 的狄利克雷分布, 记作 <span class="arithmatex">\(\theta \sim \operatorname{Dir}(\alpha)\)</span> 。
式中 <span class="arithmatex">\(\Gamma(s)\)</span> 是伽马函数, 定义为</p>
<div class="arithmatex">\[
\Gamma(s)=\int_0^{\infty} x^{s-1} \mathrm{e}^{-x} \mathrm{~d} x, \quad s&gt;0
\]</div>
<p>具有性质：</p>
<div class="arithmatex">\[
\Gamma(s+1) = s\Gamma(s)
\]</div>
<p>当s为自然数时，有：</p>
<div class="arithmatex">\[
\Gamma(s+1) = s!
\]</div>
<p>令</p>
<div class="arithmatex">\[
\mathrm{B}(\alpha)=\frac{\prod_{i=1}^k \Gamma\left(\alpha_i\right)}{\Gamma\left(\sum_{i=1}^k \alpha_i\right)}
\]</div>
<p>则狄利克雷分布的密度函数可以写成</p>
<div class="arithmatex">\[
p(\theta \mid \alpha)=\frac{1}{\mathrm{~B}(\alpha)} \prod_{i=1}^k \theta_i^{\alpha_i-1}
\]</div>
<p><span class="arithmatex">\(\mathrm{B}(\alpha)\)</span> 是规范化因子, 称为多元贝塔函数 (或扩展的贝塔函数)。由密度函数的性质</p>
<div class="arithmatex">\[
\int \frac{\Gamma\left(\sum_{i=1}^k \alpha_i\right)}{\prod_{i=1}^k \Gamma\left(\alpha_i\right)} \prod_{i=1}^{\alpha_i-1} \mathrm{~d} \theta=\frac{\Gamma\left(\sum_{i=1}^k \alpha_i\right)}{\prod_{i=1}^k \Gamma\left(\alpha_i\right)} \int \prod_{i=1}^k \theta_i^{\alpha_i-1} \mathrm{~d} \theta=1
\]</div>
<p>得</p>
<div class="arithmatex">\[
\mathrm{B}(\alpha)=\int \prod_{i=1}^k \theta_i^{\alpha_i-1} \mathrm{~d} \theta
\]</div>
<h3 id="二项分布与贝塔分布">二项分布与贝塔分布<a class="headerlink" href="#二项分布与贝塔分布" title="Permanent link">&para;</a></h3>
<p>二项分布是多项分布的特殊情况, 贝塔分布是狄利克雷分布的特殊情况。
二项分布是指如下概率分布。 <span class="arithmatex">\(X\)</span> 为离散随机变量, 取值为 <span class="arithmatex">\(m\)</span>, 其概率质量函数为</p>
<div class="arithmatex">\[
P(X=m)=\left(\begin{array}{c}
n \\
m
\end{array}\right) p^m(1-p)^{n-m}, \quad m=0,1,2, \cdots, n
\]</div>
<p>其中 <span class="arithmatex">\(n\)</span> 和 <span class="arithmatex">\(p(0 \leqslant p \leqslant 1)\)</span> 是参数。</p>
<p>贝塔分布是指如下概率分布, <span class="arithmatex">\(X\)</span> 为连续随机变量, 取值范围为 <span class="arithmatex">\([0,1]\)</span>, 其概率密度 函数为</p>
<div class="arithmatex">\[
p(x)= \begin{cases}\frac{1}{\mathrm{~B}(s, t)} x^{s-1}(1-x)^{t-1}, &amp; 0 \leqslant x \leqslant 1 \\ 0, &amp; \text { 其他 }\end{cases}
\]</div>
<p>其中 <span class="arithmatex">\(s&gt;0\)</span> 和 <span class="arithmatex">\(t&gt;0\)</span> 是参数, <span class="arithmatex">\(\mathrm{B}(s, t)=\frac{\Gamma(s) \Gamma(t)}{\Gamma(s+t)}\)</span> 是贝塔函数, 定义为</p>
<div class="arithmatex">\[
\mathrm{B}(s, t)=\int_0^1 x^{s-1}(1-x)^{t-1} \mathrm{~d} x = \frac{\Gamma(s)\Gamma(t)}{\Gamma(s+t)}
\]</div>
<p>当 <span class="arithmatex">\(s, t\)</span> 是自然数时(<span class="arithmatex">\(\Gamma(s+1) = s!\)</span>),</p>
<div class="arithmatex">\[
\mathrm{B}(s, t)=\frac{(s-1) !(t-1) !}{(s+t-1) !}
\]</div>
<p>当 <span class="arithmatex">\(n\)</span> 为 1 时, 二项分布变成伯努利分布（Bernoulli distribution）或 0-1 分布。 伯努利分布表示试验可能出现的 2 种结果的概率。显然二项分布包含伯努利分布。给出几种概率分布的关系。
<img alt="" src="../image/Pasted%20image%2020221017225107.png" /></p>
<h3 id="基本想法">基本想法<a class="headerlink" href="#基本想法" title="Permanent link">&para;</a></h3>
<p>在LDA主题模型下，一篇文章由词语的序列组成。首先以一定概率选择一个主题，其次以一定概率在这个主题中选择一个词。如果一篇文章由1000个词组成，那么就把上述方式重复1000遍，就能组成这篇文章。那么值得注意的是，以一定概率选择一个主题是服从多项式分布的，而多项式分布的参数是服从Dirichlet分布的。以一定概率在特定主题中选择一个词也是服从多项式分布的，多项式分布的参数是服从Dirichlet分布的。为什么呢？因为Dirichlet分布是多项式分布的共轭分布，也就是说由贝叶斯估计得到的后验分布仍然是Dirichlet分布。
<img alt="" src="../image/Pasted%20image%2020221017233927.png" /></p>
<h3 id="lda与plsa的关系">LDA与PLSA的关系<a class="headerlink" href="#lda与plsa的关系" title="Permanent link">&para;</a></h3>
<p>二者都是概率模型，都是利用概率生成模型对文本集合进行主题分析的无监督学习方法。</p>
<p>PLSA是用了频率派的方法，利用极大似然进行学习，而LDA使用了贝叶斯派的方法，进行贝叶斯推断。</p>
<p>二者都假设存在两个分布：话题是单词的多项分布，文本是话题的多项分布，不同的在于LDA认为多项分布的参数也服从一个分布，而不是固定不变的，使用狄利克雷分布作为多项分布的先验分布，也就是多项分布的参数服从狄利克雷分布。</p>
<p>引入先验概率的作用可以防止过拟合。为啥选择狄利克雷分布呢？因为它是多项分布的共轭先验分布，先验分布与后验分布形式相同，便于由先验分布得到后验分布。</p>
<p>LDA是在Plsa的基础上，为单词分布和主题分布增加了两个狄利克雷先验。
<img alt="" src="../image/Pasted%20image%2020221020102411.png" />
<img alt="" src="../image/Pasted%20image%2020221020102417.png" /></p>
<h3 id="模型定义">模型定义<a class="headerlink" href="#模型定义" title="Permanent link">&para;</a></h3>
<h4 id="模型要素">模型要素<a class="headerlink" href="#模型要素" title="Permanent link">&para;</a></h4>
<p>潜在狄利克雷分配 (LDA) 使用三个集合: 一是单词集合 <span class="arithmatex">\(W=\left\{w_1, \cdots, w_v, \cdots\right.\)</span>, <span class="arithmatex">\(\left.w_V\right\}\)</span>, 其中 <span class="arithmatex">\(w_v\)</span> 是第 <span class="arithmatex">\(v\)</span> 个单词, <span class="arithmatex">\(v=1,2, \cdots, V, V\)</span> 是单词的个数。二是文本集合 <span class="arithmatex">\(D=\left\{\mathbf{w}_1, \cdots, \mathbf{w}_m, \cdots, \mathbf{w}_M\right\}\)</span>, 其中 <span class="arithmatex">\(\mathbf{w}_m\)</span> 是第 <span class="arithmatex">\(m\)</span> 个文本, <span class="arithmatex">\(m=1,2, \cdots, M, M\)</span> 是文本 的个数。文本 <span class="arithmatex">\(\mathbf{w}_m\)</span> 是一个单词序列 <span class="arithmatex">\(\mathbf{w}_m=\left(w_{m 1}, \cdots, w_{m n}, \cdots, w_{m N_m}\right)\)</span>, 其中 <span class="arithmatex">\(w_{m n}\)</span> 是 文本 <span class="arithmatex">\(\mathbf{w}_m\)</span> 的第 <span class="arithmatex">\(n\)</span> 个单词, <span class="arithmatex">\(n=1,2, \cdots, N_m, N_m\)</span> 是文本 <span class="arithmatex">\(\mathbf{w}_m\)</span> 中单词的个数。三是主题集合集合 <span class="arithmatex">\(Z=\left\{z_1, \cdots, z_k, \cdots, z_K\right\}\)</span>, 其中 <span class="arithmatex">\(z_k\)</span> 是第 <span class="arithmatex">\(k\)</span> 个话题, <span class="arithmatex">\(k=1,2, \cdots, K, K\)</span> 是话题的个数。</p>
<p>每一个话题 <span class="arithmatex">\(z_k\)</span> 由一个单词的条件概率分布 <span class="arithmatex">\(p\left(w \mid z_k\right)\)</span> 决定, <span class="arithmatex">\(w \in W\)</span> 。分布 <span class="arithmatex">\(p\left(w \mid z_k\right)\)</span> 服从多项分布 (严格意义上类别分布), 其参数为 <span class="arithmatex">\(\varphi_k\)</span> 。参数 <span class="arithmatex">\(\varphi_k\)</span> 服从狄利克雷分布 (先验分布), 其超参数为 <span class="arithmatex">\(\beta\)</span> 。参数 <span class="arithmatex">\(\varphi_k\)</span> 是一个 <span class="arithmatex">\(V\)</span> 维向量 <span class="arithmatex">\(\varphi_k=\left(\varphi_{k 1}, \varphi_{k 2}, \cdots, \varphi_{k V}\right)\)</span>, 其中 <span class="arithmatex">\(\varphi_{k v}\)</span> 表示话题 <span class="arithmatex">\(z_k\)</span> 生成单词 <span class="arithmatex">\(w_v\)</span> 的概率。所有话题的参数向量构成一个 <span class="arithmatex">\(K \times V\)</span> 矩阵 <span class="arithmatex">\(\varphi=\left\{\varphi_k\right\}_{k=1}^K\)</span> 。超参数 <span class="arithmatex">\(\beta\)</span> 也是一个 <span class="arithmatex">\(V\)</span> 维向量 <span class="arithmatex">\(\beta=\left(\beta_1, \beta_2, \cdots, \beta_V\right)_{\text {。 }}\)</span>(对于话题<span class="arithmatex">\(z_k\)</span>其生成单词<span class="arithmatex">\(w_v\)</span>先验服从狄利克雷分布，因此是一个V维向量)</p>
<p>每一个文本 <span class="arithmatex">\(\mathbf{w}_m\)</span> 由一个话题的条件概率分布 <span class="arithmatex">\(p\left(z \mid \mathbf{w}_m\right)\)</span> 决定, <span class="arithmatex">\(z \in Z_{\text {。 }}\)</span> 分布 <span class="arithmatex">\(p\left(z \mid \mathbf{w}_m\right)\)</span> 服从多项分布 (严格意义上类别分布), 其参数为 <span class="arithmatex">\(\theta_m\)</span> 。参数 <span class="arithmatex">\(\theta_m\)</span> 服从狄利克雷分布 (先验分布), 其超参数为 <span class="arithmatex">\(\alpha\)</span> , 参数 <span class="arithmatex">\(\theta_m\)</span> 是一个 <span class="arithmatex">\(K\)</span> 维向量 <span class="arithmatex">\(\theta_m=\left(\theta_{m 1}, \theta_{m 2}, \cdots, \theta_{m K}\right)\)</span>, 其中 <span class="arithmatex">\(\theta_{m k}\)</span> 表示文本 <span class="arithmatex">\(\mathrm{w}_m\)</span> 生成话题 <span class="arithmatex">\(z_k\)</span> 的概率。所有文本的参数向量构成一个 <span class="arithmatex">\(M \times K\)</span> 矩阵 <span class="arithmatex">\(\theta=\left\{\theta_m\right\}_{m=1}^M\)</span> 。超参数 <span class="arithmatex">\(\alpha\)</span> 也是一个 <span class="arithmatex">\(K\)</span> 维向量 <span class="arithmatex">\(\alpha=\left(\alpha_1, \alpha_2, \cdots, \alpha_K\right)\)</span> 。</p>
<p>每一个文本 <span class="arithmatex">\(\mathbf{w}_m\)</span> 中的每一个单词 <span class="arithmatex">\(w_{m n}\)</span> 由该文本的话题分布 <span class="arithmatex">\(p\left(z \mid \mathbf{w}_m\right)\)</span> 以及所有话 题的单词分布 <span class="arithmatex">\(p\left(w \mid z_k\right)\)</span> 决定。</p>
<h4 id="生成过程">生成过程<a class="headerlink" href="#生成过程" title="Permanent link">&para;</a></h4>
<p>LDA 文本集合的生成过程如下:
给定单词集合 <span class="arithmatex">\(W\)</span>, 文本集合 <span class="arithmatex">\(D\)</span>, 话题集合 <span class="arithmatex">\(Z\)</span>, 狄利克雷分布的超参数 <span class="arithmatex">\(\alpha\)</span> 和 <span class="arithmatex">\(\beta\)</span> 。
（1）生成单词分布
随机生成 <span class="arithmatex">\(K\)</span> 个话题的单词分布。具体过程如下, 按照狄利克雷分布 <span class="arithmatex">\(\operatorname{Dir}(\beta)\)</span> 随机 生成一个参数向量 <span class="arithmatex">\(\varphi_k, \varphi_k \sim \operatorname{Dir}(\beta)\)</span>, 作为话题 <span class="arithmatex">\(z_k\)</span> 的单词分布 <span class="arithmatex">\(p\left(w \mid z_k\right), w \in W, k=\)</span> <span class="arithmatex">\(1,2, \cdots, K\)</span> 。</p>
<p>（2）生成主题分布
随机生成 <span class="arithmatex">\(M\)</span> 个文本的主题分布。具体过程如下: 按照狄利克雷分布 <span class="arithmatex">\(\operatorname{Dir}(\alpha)\)</span> 随 机生成一个参数向量 <span class="arithmatex">\(\theta_m, \theta_m \sim \operatorname{Dir}(\alpha)\)</span>, 作为文本 <span class="arithmatex">\(\mathbf{w}_m\)</span> 的主题分布 <span class="arithmatex">\(p\left(z \mid \mathbf{w}_m\right), m=\)</span> <span class="arithmatex">\(1,2, \cdots, M_{}\)</span> 。</p>
<p>（3）生成文本的单词序列
随机生成 <span class="arithmatex">\(M\)</span> 个文本的 <span class="arithmatex">\(N_m\)</span> 个单词。文本 <span class="arithmatex">\(\mathbf{w}_m(m=1,2, \cdots, M)\)</span> 的单词 <span class="arithmatex">\(w_{m n}(n=\)</span> <span class="arithmatex">\(\left.1,2, \cdots, N_m\right)\)</span> 的生成过程如下:</p>
<p>(3-1) 首先按照多项分布 <span class="arithmatex">\(\operatorname{Mult}\left(\theta_m\right)\)</span> 随机生成一个话题 <span class="arithmatex">\(z_{m n}, z_{m n} \sim \operatorname{Mult}\left(\theta_m\right)\)</span>
<span class="arithmatex">\((3-2)\)</span> 然后按照多项分布 <span class="arithmatex">\(\operatorname{Mult}\left(\varphi_{z_{m n}}\right)\)</span> 随机生成一个单词 <span class="arithmatex">\(w_{m n}, w_{m n} \sim \operatorname{Mult}\left(\varphi_{z_{m n}}\right)_{\text {。 }}\)</span>
文本 <span class="arithmatex">\(\mathbf{w}_m\)</span> 本身是单词序列 <span class="arithmatex">\(\mathbf{w}_m=\left(w_{m 1}, w_{m 2}, \cdots, w_{m N_m}\right)\)</span>, 对应着隐式的话题序列 <span class="arithmatex">\(\mathbf{z}_m=\left(z_{m 1}, z_{m 2}, \cdots, z_{m N_m}\right) 。\)</span></p>
<p>引用一下LDA数学八卦的图：
<img alt="" src="../image/Pasted%20image%2020221019104516.png" /></p>
<ul>
<li><span class="arithmatex">\(\vec{\alpha} \rightarrow \vec{\theta}_m \rightarrow z_{m, n}\)</span>, 这个过程表示在生成第 <span class="arithmatex">\(m\)</span> 篇文档的时候，先从第一个坛子中抽了一个doc-topic 骰子 <span class="arithmatex">\(\vec{\theta}_m\)</span>,然后投这个骰子生成了文档<span class="arithmatex">\(m\)</span>中第 <span class="arithmatex">\(n\)</span> 个词的topic编号 <span class="arithmatex">\(z_{m, n}\)</span> ；</li>
<li><span class="arithmatex">\(\vec{\beta} \rightarrow \vec{\varphi}_k \rightarrow w_{m, n} \mid k=z_{m, n}\)</span>, 这个过程表示用如下动作生成语料中第 <span class="arithmatex">\(m\)</span> 篇文档的第 <span class="arithmatex">\(n\)</span> 个词: 在上帝手头的 <span class="arithmatex">\(K\)</span> 个topic-word 骰子 <span class="arithmatex">\(\vec{\varphi}_k\)</span> 中，挑选编号为 <span class="arithmatex">\(k=z_{m, n}\)</span> 的那个骰子进行投掷，然后生成 word <span class="arithmatex">\(w_{m, n}\)</span> ;</li>
</ul>
<p>理解 LDA最重要的就是理解这两个物理过程。LDA 模型在基于 <span class="arithmatex">\(K\)</span> 个 topic 生成语料中的 <span class="arithmatex">\(M\)</span> 篇文档的过程中， 由于是 bag-of-words 模型，有一些物理过程是相互独立可交换的。由此，LDA生成模型中， <span class="arithmatex">\(M\)</span> 篇文档会对应 于 <span class="arithmatex">\(M\)</span> 个独立的 Dirichlet-Multinomial 共轭结构；K个 个 topic 会对应于 <span class="arithmatex">\(K\)</span> 个独立的 Dirichlet-Multinomial 共轭结 构。所以理解 LDA 所需要的所有数学就是理解 Dirichlet-Multiomail 共轭，其它都就是理解物理过程。</p>
<h4 id="总结">总结<a class="headerlink" href="#总结" title="Permanent link">&para;</a></h4>
<p>(1) 对于话题 <span class="arithmatex">\(z_k(k=1,2, \cdots, K)\)</span> :
    生成多项分布参数 <span class="arithmatex">\(\varphi_k \sim \operatorname{Dir}(\beta)\)</span>, 作为话题的单词分布 <span class="arithmatex">\(p\left(w \mid z_k\right)\)</span>;
(2) 对于文本 <span class="arithmatex">\(\mathbf{w}_m(m=1,2, \cdots, M)\)</span>;
生成多项分布参数 <span class="arithmatex">\(\theta_m \sim \operatorname{Dir}(\alpha)\)</span>, 作为文本的话题分布 <span class="arithmatex">\(p\left(z \mid \mathbf{w}_m\right)\)</span>;
(3) 对于文本 <span class="arithmatex">\(\mathbf{w}_m\)</span> 的单词 <span class="arithmatex">\(w_{m n}\left(m=1,2, \cdots, M, n=1,2, \cdots, N_m\right)\)</span> :
    (a) 生成话题 <span class="arithmatex">\(z_{m n} \sim \operatorname{Mult}\left(\theta_m\right)\)</span>, 作为单词对应的话题;
    (b) 生成单词 <span class="arithmatex">\(w_{m n} \sim \operatorname{Mult}\left(\varphi_{z_{m n}}\right)\)</span> 。</p>
<p>LDA 的文本生成过程中, 假定话题个数 <span class="arithmatex">\(K\)</span> 给定, 实际通常通过实验选定。狄利 克雷分布的超参数 <span class="arithmatex">\(\alpha\)</span> 和 <span class="arithmatex">\(\beta\)</span> 通常也是事先给定的。在没有其他先验知识的情况下, 可以 假设向量 <span class="arithmatex">\(\alpha\)</span> 和 <span class="arithmatex">\(\beta\)</span> 的所有分量均为 1 , 这时的文本的话题分布 <span class="arithmatex">\(\theta_m\)</span> 是对称的, 话题的单 词分布 <span class="arithmatex">\(\varphi_k\)</span> 也是对称的。</p>
<h3 id="概率计算">概率计算<a class="headerlink" href="#概率计算" title="Permanent link">&para;</a></h3>
<p>LDA 模型整体是由观测变量和隐变量组成的联合概率分布, 可以表为</p>
<div class="arithmatex">\[
p(\mathbf{w}, \mathbf{z}, \theta, \varphi \mid \alpha, \beta)=\prod_{k=1}^K p\left(\varphi_k \mid \beta\right) \prod_{m=1}^M p\left(\theta_m \mid \alpha\right) \prod_{n=1}^{N_m} p\left(z_{m n} \mid \theta_m\right) p\left(w_{m n} \mid z_{m n}, \varphi\right)
\]</div>
<p>(其中M为文本数，<span class="arithmatex">\(N_m\)</span>为文档m的长度，K为主题数)
其中观测变量 <span class="arithmatex">\(\mathrm{w}\)</span> 表示所有文本中的单词序列, 隐变量 <span class="arithmatex">\(\mathrm{z}\)</span> 表示所有文本中的话题序列, 隐变量 <span class="arithmatex">\(\theta\)</span> 表示所有文本的话题分布的参数, 隐变量 <span class="arithmatex">\(\varphi\)</span> 表示所有话题的单词分布的参 数, <span class="arithmatex">\(\alpha\)</span> 和 <span class="arithmatex">\(\beta\)</span> 是超参数。</p>
<ul>
<li><span class="arithmatex">\(p\left(\varphi_k \mid \beta\right)\)</span> 表示超参数 <span class="arithmatex">\(\beta\)</span> 给定条件下第 <span class="arithmatex">\(k\)</span> 个话题的单词分布的参数 <span class="arithmatex">\(\varphi_k\)</span> 的生成概率;</li>
<li><span class="arithmatex">\(p\left(\theta_m \mid \alpha\right)\)</span> 表示超参数 <span class="arithmatex">\(\alpha\)</span> 给定条件下第 <span class="arithmatex">\(m\)</span> 个文本的话题分布的 参数 <span class="arithmatex">\(\theta_m\)</span> 的生成概率;</li>
<li><span class="arithmatex">\(p\left(z_{m n} \mid \theta_m\right)\)</span> 表示第 <span class="arithmatex">\(m\)</span> 个文本的话题分布 <span class="arithmatex">\(\theta_m\)</span> 给定条件下文本的 第 <span class="arithmatex">\(n\)</span> 个位置的话题 <span class="arithmatex">\(z_{m n}\)</span> 的生成概率;</li>
<li><span class="arithmatex">\(p\left(w_{m n} \mid z_{m n}, \varphi\right)\)</span> 表示在第 <span class="arithmatex">\(m\)</span> 个文本的第 <span class="arithmatex">\(n\)</span> 个位 置的话题 <span class="arithmatex">\(z_{m n}\)</span> 及所有话题的单词分布的参数 <span class="arithmatex">\(\varphi\)</span> 给定条件下第 <span class="arithmatex">\(m\)</span> 个文本的第 <span class="arithmatex">\(n\)</span> 个位 置的单词 <span class="arithmatex">\(w_{m n}\)</span> 的生成概率。</li>
</ul>
<p>第 <span class="arithmatex">\(m\)</span> 个文本的联合概率分布可以表为</p>
<div class="arithmatex">\[
p\left(\mathbf{w}_m, \mathbf{z}_m, \theta_m, \varphi \mid \alpha, \beta\right)=\prod_{k=1}^K p\left(\varphi_k \mid \beta\right) p\left(\theta_m \mid \alpha\right) \prod_{n=1}^{N_m} p\left(z_{m n} \mid \theta_m\right) p\left(w_{m n} \mid z_{m n}, \varphi\right)
\]</div>
<p>其中 <span class="arithmatex">\(\mathbf{w}_m\)</span> 表示该文本中的单词序列, <span class="arithmatex">\(\mathbf{z}_m\)</span> 表示该文本的话题序列, <span class="arithmatex">\(\theta_m\)</span> 表示该文本的话 题分布参数。
LDA 模型的联合分布含有隐变量, 对隐变量进行积分得到边缘分布。
参数 <span class="arithmatex">\(\theta_m\)</span> 和 <span class="arithmatex">\(\varphi\)</span> 给定条件下第 <span class="arithmatex">\(m\)</span> 个文本的生成概率是</p>
<div class="arithmatex">\[
p\left(\mathbf{w}_m \mid \theta_m, \varphi\right)=\prod_{n=1}^{N_m}\left[\sum_{k=1}^K p\left(z_{m n}=k \mid \theta_m\right) p\left(w_{m n} \mid \varphi_k\right)\right]
\]</div>
<p>超参数 <span class="arithmatex">\(\alpha\)</span> 和 <span class="arithmatex">\(\beta\)</span> 给定条件下第 <span class="arithmatex">\(m\)</span> 个文本的生成概率是</p>
<div class="arithmatex">\[
p\left(\mathbf{w}_m \mid \alpha, \beta\right)=\prod_{k=1}^K \int p\left(\varphi_k \mid \beta\right)\left[\int p\left(\theta_m \mid \alpha\right) \prod_{n=1}^{N_m}\left[\sum_{l=1}^K p\left(z_{m n}=l \mid \theta_m\right) p\left(w_{m n} \mid \varphi_l\right)\right] \mathrm{d} \theta_m\right] \mathrm{d} \varphi_k
\]</div>
<p>超参数 <span class="arithmatex">\(\alpha\)</span> 和 <span class="arithmatex">\(\beta\)</span> 给定条件下所有文本的生成概率是</p>
<div class="arithmatex">\[
p(\mathbf{w} \mid \alpha, \beta)=\prod_{k=1}^K \int p\left(\varphi_k \mid \beta\right)\left[\prod_{m=1}^M \int p\left(\theta_m \mid \alpha\right) \prod_{n=1}^{N_m}\left[\sum_{l=1}^K p\left(z_{m n}=l \mid \theta_m\right) p\left(w_{m n} \mid \varphi_l\right)\right] \mathrm{d} \theta_m\right] \mathrm{d} \varphi_k
\]</div>
<h3 id="吉布斯抽样">吉布斯抽样<a class="headerlink" href="#吉布斯抽样" title="Permanent link">&para;</a></h3>
<h4 id="基本思想">基本思想<a class="headerlink" href="#基本思想" title="Permanent link">&para;</a></h4>
<p>有三个主要目标：
- 话题序列的集合<span class="arithmatex">\(z=(z_1, z_2, \cdots, z_M)\)</span>的后验概率分布，其中<span class="arithmatex">\(z_m\)</span>是第m个文本的主题序列，<span class="arithmatex">\(z_m=(z_{m1}, \cdots, z_{mN_{m}})\)</span>;
- 参数<span class="arithmatex">\(\theta=(\theta_1, \cdots, \theta_{M})\)</span>，其中<span class="arithmatex">\(\theta_m\)</span>是第m个文本的主题分布的参数；
- 参数<span class="arithmatex">\(\varphi=(\varphi_1, \cdots, \varphi_K)\)</span>，其中<span class="arithmatex">\(\varphi_k\)</span>是第k个主题的单词分布的参数。</p>
<p>对<span class="arithmatex">\(p(\mathbf{w}, \mathbf{z}, \theta, \varphi \mid \alpha, \beta)\)</span>进行估计</p>
<p>吉布斯抽样, 这是一种常用的马尔可夫链蒙特卡罗法。为了估计 多元随机变量 <span class="arithmatex">\(x\)</span> 的联合分布 <span class="arithmatex">\(p(x)\)</span>, 吉布斯抽样法选择 <span class="arithmatex">\(x\)</span> 的一个分量, 固定其他分量, 按照其条件概率分布进行随机抽样, 依次循环对每一个分量执行这个操作, 得到联合 分布 <span class="arithmatex">\(p(x)\)</span> 的一个随机样本, 重复这个过程, 在燃烧期之后, 得到联合概率分布 <span class="arithmatex">\(p(x)\)</span> 的 样本集合。</p>
<p>LDA 模型的学习通常采用收缩的吉布斯抽样 (collapsed Gibbs sampling) , 基本想法是, 通过对隐变量 <span class="arithmatex">\(\theta\)</span> 和 <span class="arithmatex">\(\varphi\)</span> 积分, 得到边缘概率分布 <span class="arithmatex">\(p(\mathbf{w}, \mathbf{z} \mid \alpha, \beta)\)</span> (也是联合分 布), 其中变量 <span class="arithmatex">\(\mathbf{w}\)</span> 是可观测的, 变量 <span class="arithmatex">\(\mathbf{z}\)</span> 是不可观测的; 对后验概率分布 <span class="arithmatex">\(p(\mathbf{z} \mid \mathbf{w}, \alpha, \beta)\)</span> 进 行吉布斯抽样, 得到分布 <span class="arithmatex">\(p(\mathbf{z} \mid \mathbf{w}, \alpha, \beta)\)</span> 的样本集合; 再利用这个样本集合对参数 <span class="arithmatex">\(\theta\)</span> 和 <span class="arithmatex">\(\varphi\)</span> 进行估计, 最终得到 LDA 模型 <span class="arithmatex">\(p(\mathbf{w}, \mathbf{z}, \theta, \varphi \mid \alpha, \beta)\)</span> 的所有参数估计。</p>
<h4 id="算法流程">算法流程<a class="headerlink" href="#算法流程" title="Permanent link">&para;</a></h4>
<p>输入: 文本的单词序列 <span class="arithmatex">\(\mathbf{w}=\left\{\mathbf{w}_1, \cdots, \mathbf{w}_m, \cdots, \mathbf{w}_M\right\}, \mathbf{w}_m=\left(w_{m 1}, \cdots, w_{m n}, \cdots\right.\)</span>, <span class="arithmatex">\(\left.w_{m_{N_m}}\right)\)</span>;</p>
<p>输出: 文本的话题序列 <span class="arithmatex">\(\mathrm{z}=\left\{\mathbf{z}_1, \cdots, \mathbf{z}_m, \cdots, \mathbf{z}_M\right\}, \mathbf{z}_m=\left(z_{m 1}, \cdots, z_{m n}, \cdots, z_{m_{N_m}}\right)\)</span> 的后验概率分布 <span class="arithmatex">\(p(\mathbf{z} \mid \mathbf{w}, \alpha, \beta)\)</span> 的样本计数, 模型的参数 <span class="arithmatex">\(\varphi\)</span> 和 <span class="arithmatex">\(\theta\)</span> 的估计值;
参数: 超参数 <span class="arithmatex">\(\alpha\)</span> 和 <span class="arithmatex">\(\beta\)</span>, 话题个数 <span class="arithmatex">\(K\)</span> 。</p>
<p>(1) 设所有计数矩阵的元素 <span class="arithmatex">\(n_{m k}, n_{k v}\)</span>, 计数向量的元素 <span class="arithmatex">\(n_m, n_k\)</span> 初值为 0 ;</p>
<p>(2) 对所有文本 <span class="arithmatex">\(\mathbf{w}_m, m=1,2, \cdots, M\)</span>
对第 <span class="arithmatex">\(m\)</span> 个文本中的所有单词 <span class="arithmatex">\(w_{m n}, n=1,2, \cdots, N_m\)</span>
(a) 抽样话题 <span class="arithmatex">\(z_{m n}=z_k \sim \operatorname{Mult}\left(\frac{1}{K}\right)\)</span>;(对于文本m，其多项分布的参数为<span class="arithmatex">\(\frac{1}{K}\)</span>，由<span class="arithmatex">\(\alpha\)</span>生成，即<span class="arithmatex">\(\theta_m \sim Dir(\alpha)\)</span>，<span class="arithmatex">\(\theta_m\)</span>为长度为K的向量，此处说明所有主题的生成概率都为<span class="arithmatex">\(\frac{1}{K}\)</span>)
增加文本-话题计数 <span class="arithmatex">\(n_{m k}=n_{m k}+1\)</span>,
增加文本-话题和计数 <span class="arithmatex">\(n_m=n_m+1\)</span>,
增加话题-单词计数 <span class="arithmatex">\(n_{k v}=n_{k v}+1\)</span>,
增加话题-单词和计数 <span class="arithmatex">\(n_k=n_k+1\)</span>;</p>
<p>（3）循环执行以下操作, 直到进入燃烧期
对所有文本 <span class="arithmatex">\(\mathbf{w}_m, m=1,2, \cdots, M\)</span>
对第 <span class="arithmatex">\(m\)</span> 个文本中的所有单词 <span class="arithmatex">\(w_{m n}, n=1,2, \cdots, N_m\)</span>
(a) 当前的单词 <span class="arithmatex">\(w_{m n}\)</span> 是第 <span class="arithmatex">\(v\)</span> 个单词, 话题指派 <span class="arithmatex">\(z_{m n}\)</span> 是第 <span class="arithmatex">\(k\)</span> 个话题;
减少计数 <span class="arithmatex">\(n_{m k}=n_{m k}-1, n_m=n_m-1, n_{k v}=n_{k v}-1, n_k=n_k-1\)</span>;
(b) 按照满条件分布进行抽样</p>
<div class="arithmatex">\[
p\left(z_i \mid \mathbf{z}_{-i}, \mathbf{w}, \alpha, \beta\right) \propto \frac{n_{k v}+\beta_v}{\sum_{v=1}^V\left(n_{k v}+\beta_v\right)} \cdot \frac{n_{m k}+\alpha_k}{\sum_{k=1}^K\left(n_{m k}+\alpha_k\right)}
\]</div>
<p>得到新的第 <span class="arithmatex">\(k^{\prime}\)</span> 个话题, 分配给 <span class="arithmatex">\(z_{m n}\)</span>;
&copy; 增加计数 <span class="arithmatex">\(n_{m k^{\prime}}=n_{m k^{\prime}}+1, n_m=n_m+1, n_{k^{\prime} v}=n_{k^{\prime} v}+1, n_{k^{\prime}}=n_{k^{\prime}}+1\)</span>;
(d) 得到更新的两个计数矩阵 <span class="arithmatex">\(N_{K \times V}=\left[n_{k v}\right]\)</span> 和 <span class="arithmatex">\(N_{M \times K}=\left[n_{m k}\right]\)</span>, 表示后验 概率分布 <span class="arithmatex">\(p(\mathbf{z} \mid \mathbf{w}, \alpha, \beta)\)</span> 的样本计数;</p>
<p>(4) 利用得到的样本计数, 计算模型参数</p>
<div class="arithmatex">\[
\begin{aligned}
\theta_{m k} &amp;=\frac{n_{m k}+\alpha_k}{\sum_{k=1}^K\left(n_{m k}+\alpha_k\right)} \\
\varphi_{k v} &amp;=\frac{n_{k v}+\beta_v}{\sum_{v=1}^V\left(n_{k v}+\beta_v\right)}
\end{aligned}
\]</div>
<h3 id="训练与推断">训练与推断<a class="headerlink" href="#训练与推断" title="Permanent link">&para;</a></h3>
<p>有了LDA模型，我们的目标有两个：</p>
<ul>
<li>估计模型中的参数<span class="arithmatex">\(\varphi_1, \cdots, \varphi_K\)</span>和<span class="arithmatex">\(\theta_1, \cdots, \theta_M\)</span>;</li>
<li>对于新来的一篇doc，我们能够计算这篇文档的topic分布<span class="arithmatex">\(\theta_{new}\)</span>。</li>
</ul>
<p>有了吉布斯采样公式就可以基于语料训练LDA模型，并应用训练得到的模型对新的文档进行topic语义分析，训练的过程就是通过Gibbs Samping获取语料中的（z,w）样本，而模型中的所有参数可以基于采样的样本进行估计。</p>
<p>训练流程如下：</p>
<ul>
<li>随机初始化：对语料中的每篇文档的每个词w，随机赋一个topic编号z。</li>
<li>重新扫描语料库，对每个词按照吉布斯采样公式重新采样它的topic，在语料中进行更新。</li>
<li>重复以上语料库的重新采样过程直到吉布斯采样收敛。</li>
<li>统计语料库的topic-word共现频率矩阵，就是LDA的模型</li>
</ul>
<p>由这个矩阵我们可以计算每一个<span class="arithmatex">\(p(word\mid topic)\)</span>概率，从而计算出模型参数<span class="arithmatex">\(\varphi_1, \cdots, \varphi_K\)</span>，也可以计算另一个参数<span class="arithmatex">\(\theta_1, \cdots, \theta_M\)</span>，只要在吉布斯抽样收敛后统计每篇文章的topic频率分布，就可以计算每一个<span class="arithmatex">\(p(topic\mid doc)\)</span>概率，由于它是和训练语料的每篇文章相关的，对于我们理解新的文档毫无用处，所以一般没有必要保留这个概率。</p>
<p>如何对新的文档进行推断呢？其实和训练过程完全相似，对于新的文档，认为<span class="arithmatex">\(\varphi_{kt}\)</span>是稳定不变的，是由训练语料得到的模型提供的。采样过程只估计该文档的topic分布<span class="arithmatex">\(\theta_{new}\)</span>就好了。</p>
<p>推断过程如下：</p>
<ul>
<li>随机初始化：对当前文档的每个词w，随机的赋一个topic编号z；</li>
<li>重新扫描当前文档，按照吉布斯抽样公式，对每个词w，重新采样它的topic；</li>
<li>重复以上过程直到吉布斯采样收敛</li>
<li>统计文档中的topic分布，该分布就是<span class="arithmatex">\(\theta_{new}\)</span></li>
</ul>
<h3 id="代码">代码<a class="headerlink" href="#代码" title="Permanent link">&para;</a></h3>
<p>实现了吉布斯推断的python代码：
<div class="highlight"><pre><span></span><code><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">LDA implementation in Python</span>



<span class="sd">@author: Michael Zhang</span>

<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">scipy</span>



<span class="k">class</span> <span class="nc">LDA</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tdm</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">iteration</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        tdm: the copus, of (D, Num_words_in_corpus),</span>

<span class="sd">            the value of each entry is the counts of corresponding words in this the corresponding document.</span>

<span class="sd">            e.g.</span>

<span class="sd">            tdm[d, w] = number of word w appears in document d.</span>

<span class="sd">        T: the number of topics</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">tdm</span> <span class="o">=</span> <span class="n">tdm</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tdm</span><span class="o">.</span><span class="n">shape</span>            

        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="o">=</span> <span class="n">alpha</span> <span class="c1"># count for expected value for hyper parameter alpha of theta, i.e. document-topic distribution.</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span> <span class="c1"># count for expected value for hyper parameter beta topic-word distribution.</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="o">=</span> <span class="n">T</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">=</span> <span class="n">iteration</span>

        <span class="c1"># z must take in (d,w,i) as input, corresponding to</span>

        <span class="c1"># topic indicator for i-th obserevation of word w in doc d</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">z</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">topic_word_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">))</span> <span class="c1"># initialize the topic-word matrix.</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">doc_topic_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">))</span> <span class="c1"># initialize the documnet-topic matrix.</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">topic_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="c1"># initialize the topic counter for after sampling process, should be sum of value in self.topic_word_matrix</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">doc_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="p">)</span> <span class="c1"># initialize the doc counter for after sampling process, should be sum of value in self.doc_topic_matrix</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">log_likelihood</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">iteration</span><span class="p">)</span> <span class="c1"># store the value of log likelihood at each iteration</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_init_matrix</span><span class="p">()</span>

    <span class="c1"># @pysnooper.snoop(&#39;init.log&#39;)    </span>

    <span class="k">def</span> <span class="nf">_init_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        for all words</span>

<span class="sd">        1. sample a topic randomly from T topics for each word</span>

<span class="sd">        2. increment topic word count, self.topic_word_matrix</span>

<span class="sd">        3. increment document topic count,  self.doc_topic_matrix</span>

<span class="sd">        4. update the topic indicator z.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="p">):</span>

            <span class="n">doc</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">coo_matrix</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tdm</span><span class="p">[</span><span class="n">d</span><span class="p">])</span>

            <span class="n">word_freq_topic</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">col</span><span class="p">,</span> <span class="n">doc</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">frequency</span> <span class="ow">in</span> <span class="n">word_freq_topic</span><span class="p">:</span> <span class="c1"># (word, freq)</span>

                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">frequency</span><span class="p">):</span>

                    <span class="c1">############ Finish the following initialization steps #############</span>

                    <span class="c1"># 1. sample a topic randomly from T topics for each word</span>

                    <span class="n">topic</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

                    <span class="c1"># 2. increment topic word count, self.topic_word_matrix</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">topic_word_matrix</span><span class="p">[</span><span class="n">topic</span><span class="p">,</span> <span class="n">w</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

                    <span class="c1"># 3. increment document topic count,  self.doc_topic_matrix</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">doc_topic_matrix</span><span class="p">[</span><span class="n">d</span><span class="p">,</span> <span class="n">topic</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

                    <span class="c1"># 4. update the topic indicator z.</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">z</span><span class="p">[(</span><span class="n">d</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="n">topic</span> <span class="c1"># d: document ID; w: word ID: i: instance ID，即在d中第几个w</span>



        <span class="bp">self</span><span class="o">.</span><span class="n">topic_counts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">topic_word_matrix</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">doc_counts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">doc_topic_matrix</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>



    <span class="c1"># @pysnooper.snoop(&#39;fit.log&#39;)    </span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">iteration</span><span class="p">):</span>

            <span class="c1"># iterate over all the documents</span>

            <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="p">):</span>

            <span class="c1"># iterate over all the words in d</span>

                <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tdm</span><span class="p">[</span><span class="n">d</span><span class="p">]</span><span class="o">.</span><span class="n">indices</span><span class="p">:</span>

                    <span class="c1"># iterate over number of times observed word w in doc d</span>

                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tdm</span><span class="p">[</span><span class="n">d</span><span class="p">,</span> <span class="n">w</span><span class="p">]):</span>

                        <span class="c1"># we apply the hidden-varible method of Gibbs sampler, the hidden variable is z[(d,w,i)]</span>

                        <span class="bp">self</span><span class="o">.</span><span class="n">doc_topic_matrix</span><span class="p">[</span><span class="n">d</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">z</span><span class="p">[(</span><span class="n">d</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">i</span><span class="p">)]]</span> <span class="o">-=</span> <span class="mi">1</span>

                        <span class="bp">self</span><span class="o">.</span><span class="n">doc_counts</span><span class="p">[</span><span class="n">d</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">1</span>

                        <span class="bp">self</span><span class="o">.</span><span class="n">topic_word_matrix</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">z</span><span class="p">[(</span><span class="n">d</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">i</span><span class="p">)],</span><span class="n">w</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">1</span>

                        <span class="bp">self</span><span class="o">.</span><span class="n">topic_counts</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">z</span><span class="p">[(</span><span class="n">d</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">i</span><span class="p">)]]</span> <span class="o">-=</span> <span class="mi">1</span>



                        <span class="c1"># estimation of phi and theta for the current corpus</span>

                        <span class="n">phi_hat</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">topic_word_matrix</span><span class="p">[:,</span><span class="n">w</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">topic_counts</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)</span>

                        <span class="n">theta_hat</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">doc_topic_matrix</span><span class="p">[</span><span class="n">d</span><span class="p">,:]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">doc_counts</span><span class="p">[</span><span class="n">d</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>



                        <span class="c1"># calculate the full conditional distribution</span>

                        <span class="n">full_conditional</span> <span class="o">=</span> <span class="n">phi_hat</span> <span class="o">*</span> <span class="n">theta_hat</span>

                        <span class="c1"># normalize full_conditional such that it summation equals to 1.</span>

                        <span class="n">full_conditional</span> <span class="o">=</span> <span class="n">full_conditional</span> <span class="o">/</span> <span class="n">full_conditional</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

                        <span class="c1"># sample a topic for i-th obserevation of word w in doc d based on full_conditional</span>

                        <span class="n">new_topic</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">full_conditional</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span>

                        <span class="c1"># update z, doc_topic_matrix, doc_counts, topic_word_matrix, topic_counts here.</span>

                        <span class="bp">self</span><span class="o">.</span><span class="n">z</span><span class="p">[(</span><span class="n">d</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="n">new_topic</span>



                        <span class="bp">self</span><span class="o">.</span><span class="n">doc_topic_matrix</span><span class="p">[</span><span class="n">d</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">z</span><span class="p">[(</span><span class="n">d</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">i</span><span class="p">)]]</span> <span class="o">+=</span> <span class="mi">1</span>

                        <span class="bp">self</span><span class="o">.</span><span class="n">topic_word_matrix</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">z</span><span class="p">[(</span><span class="n">d</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">i</span><span class="p">)],</span><span class="n">w</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

                        <span class="bp">self</span><span class="o">.</span><span class="n">doc_counts</span><span class="p">[</span><span class="n">d</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

                        <span class="bp">self</span><span class="o">.</span><span class="n">topic_counts</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">z</span><span class="p">[(</span><span class="n">d</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">i</span><span class="p">)]]</span> <span class="o">+=</span> <span class="mi">1</span>

                        <span class="c1">############################################################</span>




            <span class="c1"># Equation 2  log P(w|z)  for each iteration based on Equation [2]</span>

            <span class="c1">## +++++++++ insert code below ++++++++++++++++++++++++###</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">log_likelihood</span><span class="p">[</span><span class="n">it</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">):</span>

                <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">):</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">log_likelihood</span><span class="p">[</span><span class="n">it</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">topic_word_matrix</span><span class="p">[</span><span class="n">k</span><span class="p">,</span><span class="n">w</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">topic_word_matrix</span><span class="p">[</span><span class="n">k</span><span class="p">,</span><span class="n">w</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">topic_counts</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">))</span>

            <span class="c1">############################################################</span>

            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Iteration </span><span class="si">%i</span><span class="se">\t</span><span class="s1"> LL: </span><span class="si">%.2f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">it</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">log_likelihood</span><span class="p">[</span><span class="n">it</span><span class="p">]))</span>
</code></pre></div></p>
<h3 id="本质与使用条件">本质与使用条件<a class="headerlink" href="#本质与使用条件" title="Permanent link">&para;</a></h3>
<p>本质上说，主题模型根本上是实现文本数据的结构化，结构化的文档可以彼此比较和查询，实现传统的任务。
LDA主题模型本质上解决了两类问题：
- 文档聚类
- 词汇聚类</p>
<p>主要价值在于：
1）文档的结构化，相比于传统的词袋模型达到了降维的效果
2）完成了文档的聚类和词汇的聚类，实现文本信息的抽象化分析，帮助分析者探索隐含的语义内容。</p>
<p>实践中数据要有以下性质才会有较好的结果：</p>
<ol>
<li>文档足够多</li>
<li>文档足够长</li>
<li>词汇特征够多</li>
<li>词频足够大</li>
</ol>
<h2 id="总结_1">总结<a class="headerlink" href="#总结_1" title="Permanent link">&para;</a></h2>
<p>历时好几周，终于完结了主题模型，主要是概率论没有学好，跟着推导的过程过于痛苦，不过也算是稍微理解了一点LDA，复述一下：
LDA理解可以类比于PLSA，大体的思想都是根据文档生成主题分布，再根据主题分布和单词分布得到文档中的各个单词。不同的是LDA是贝叶斯派的思想，对于两种分布加入了狄利克雷先验概率。LDA的生成过程可以看成上帝掷骰子，从M个骰子中选取一个作为文本m的主题分布，从K个骰子中选取一个作为主题k的单词分布，（注意这里的多项分布的参数就是多项分布中的概率p，其服从狄利克雷分布，比如对于<span class="arithmatex">\(\theta_m\)</span>，它其实就是文本m生成不同主题k的概率，是个K维的向量。对于<span class="arithmatex">\(\varphi_k\)</span>，是由主题k生成不同单词v的概率，是个V维的向量。也就是根据狄利克雷分布采样得到的是一些概率，这些概率作为多项分布的参数再生成主题或者单词，写这些是便于理解）。</p>
<p>由主题分布可以对文本的每个位置赋值一个主题，再根据主题-单词分布可以生成整个文本。一切的一切都是和PLSA一样，求两个分布，以至于可以生成我们的文档。LDA也可以得到文档的主题分布，得到了主题分布和单词分布可以应用于各种任务当中。具体可以参考《LDA漫游指南》。</p>
<p>现在知道了LDA是怎么一回事了，但还是感觉模模糊糊的，经过代码的洗礼，又理解深入了一些，但感觉还没有掌握的很好，可能需要消化消化，那就先告一段落了。以后常看看就行。</p>
<h2 id="参考">参考<a class="headerlink" href="#参考" title="Permanent link">&para;</a></h2>
<p><a href="https://zhuanlan.zhihu.com/p/374924140">https://zhuanlan.zhihu.com/p/374924140</a>
<a href="https://www.cnblogs.com/gasongjian/p/7631978.html">https://www.cnblogs.com/gasongjian/p/7631978.html</a></p>
                
              
              
                


              
            </article>
          </div>
        </div>
        
      </main>
      
        
<footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../PPMI/" class="md-footer__link md-footer__link--prev" aria-label="Previous: PPMI" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              PPMI
            </div>
          </div>
        </a>
      
      
        
        <a href="../BM25/" class="md-footer__link md-footer__link--next" aria-label="Next: BM25" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              BM25
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        
          Made with
          <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
            Material for MkDocs
          </a>
        
        
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../..", "features": [], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../../assets/javascripts/workers/search.fcfe8b6d.min.js", "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.b1047164.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>