<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>所有文章 - vllbc02&#39;s blogs</title>
        <link>https://blog.vllbc.top/posts/</link>
        <description>所有文章 | vllbc02&#39;s blogs</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Thu, 05 Jun 2025 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://blog.vllbc.top/posts/" rel="self" type="application/rss+xml" /><item>
    <title>shortcode(置顶)</title>
    <link>https://blog.vllbc.top/shortcode%E7%BD%AE%E9%A1%B6/</link>
    <pubDate>Tue, 07 Mar 2023 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/shortcode%E7%BD%AE%E9%A1%B6/</guid>
    <description><![CDATA[<p>贴一下可以玩的shortcode。</p>
<h2 id="音乐播放">音乐播放</h2>
<h3 id="播放列表">播放列表</h3>
<p>夏日口袋专辑： <meting-js auto="https://music.163.com/album?id=73470837&amp;uct2=U2FsdGVkX18gTMY/Tb1&#43;2PmOZr2G/Q7mOdM/mANJ8xY=" theme="#448aff"></meting-js></p>
<h3 id="播放单曲">播放单曲</h3>
<p>最爱的一首（我是紬厨）： <meting-js server="netease" type="song" id="1311346841" theme="#448aff"></meting-js></p>
<h2 id="视频播放">视频播放</h2>
<h3 id="bilibili">bilibili</h3>
<p><div class="bilibili"><iframe src="//player.bilibili.com/player.html?bvid=BV1ptXPYREe7&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe></div>
 有多P可以选择集数</p>
<h2 id="admonition">admonition</h2>
<p>类型有：note、abstract、info、tip、success、question、warning、failure、danger、bug、example、quote。
<div class="details admonition tip open">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-lightbulb fa-fw" aria-hidden="true"></i>技巧<i class="details-icon fas fa-angle-right fa-fw" aria-hidden="true"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content">一个 <strong>技巧</strong> 横幅</div>
        </div>
    </div></p>]]></description>
</item>
<item>
    <title>verl总体概览</title>
    <link>https://blog.vllbc.top/verl%E6%80%BB%E4%BD%93%E6%A6%82%E8%A7%88/</link>
    <pubDate>Thu, 05 Jun 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/verl%E6%80%BB%E4%BD%93%E6%A6%82%E8%A7%88/</guid>
    <description><![CDATA[
]]></description>
</item>
<item>
    <title>reward_mananger</title>
    <link>https://blog.vllbc.top/reward_mananger/</link>
    <pubDate>Mon, 02 Jun 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/reward_mananger/</guid>
    <description><![CDATA[<p>最原生的reward_mananger:</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NaiveRewardManager:</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;The reward manager.&quot;&quot;&quot;</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, tokenizer, num_examine, compute_score<span class="op">=</span><span class="va">None</span>, reward_fn_key<span class="op">=</span><span class="st">&quot;data_source&quot;</span>) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tokenizer <span class="op">=</span> tokenizer</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_examine <span class="op">=</span> num_examine  <span class="co"># the number of batches of decoded responses to print to the console</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.compute_score <span class="op">=</span> compute_score <span class="kw">or</span> default_compute_score</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.reward_fn_key <span class="op">=</span> reward_fn_key</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, data: DataProto, return_dict<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;We will expand this function gradually based on the available datasets&quot;&quot;&quot;</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If there is rm score, we directly return rm score. Otherwise, we compute via rm_score_fn</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">&quot;rm_scores&quot;</span> <span class="kw">in</span> data.batch.keys():</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> return_dict:</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> {<span class="st">&quot;reward_tensor&quot;</span>: data.batch[<span class="st">&quot;rm_scores&quot;</span>]}</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> data.batch[<span class="st">&quot;rm_scores&quot;</span>]</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>        reward_tensor <span class="op">=</span> torch.zeros_like(data.batch[<span class="st">&quot;responses&quot;</span>], dtype<span class="op">=</span>torch.float32)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>        reward_extra_info <span class="op">=</span> defaultdict(<span class="bu">list</span>)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>        already_print_data_sources <span class="op">=</span> {}</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(data)):</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>            data_item <span class="op">=</span> data[i]  <span class="co"># DataProtoItem</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>            prompt_ids <span class="op">=</span> data_item.batch[<span class="st">&quot;prompts&quot;</span>]</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>            prompt_length <span class="op">=</span> prompt_ids.shape[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>            valid_prompt_length <span class="op">=</span> data_item.batch[<span class="st">&quot;attention_mask&quot;</span>][:prompt_length].<span class="bu">sum</span>()</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>            valid_prompt_ids <span class="op">=</span> prompt_ids[<span class="op">-</span>valid_prompt_length:]</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>            response_ids <span class="op">=</span> data_item.batch[<span class="st">&quot;responses&quot;</span>]</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>            valid_response_length <span class="op">=</span> data_item.batch[<span class="st">&quot;attention_mask&quot;</span>][prompt_length:].<span class="bu">sum</span>()</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>            valid_response_ids <span class="op">=</span> response_ids[:valid_response_length]</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>            <span class="co"># decode</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>            prompt_str <span class="op">=</span> <span class="va">self</span>.tokenizer.decode(valid_prompt_ids, skip_special_tokens<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>            response_str <span class="op">=</span> <span class="va">self</span>.tokenizer.decode(valid_response_ids, skip_special_tokens<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>            ground_truth <span class="op">=</span> data_item.non_tensor_batch[<span class="st">&quot;reward_model&quot;</span>][<span class="st">&quot;ground_truth&quot;</span>]</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>            data_source <span class="op">=</span> data_item.non_tensor_batch[<span class="va">self</span>.reward_fn_key]</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>            extra_info <span class="op">=</span> data_item.non_tensor_batch.get(<span class="st">&quot;extra_info&quot;</span>, <span class="va">None</span>)</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>            score <span class="op">=</span> <span class="va">self</span>.compute_score(</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>                data_source<span class="op">=</span>data_source,</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>                solution_str<span class="op">=</span>response_str,</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>                ground_truth<span class="op">=</span>ground_truth,</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>                extra_info<span class="op">=</span>extra_info,</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(score, <span class="bu">dict</span>):</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>                reward <span class="op">=</span> score[<span class="st">&quot;score&quot;</span>]</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Store the information including original reward</span></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> key, value <span class="kw">in</span> score.items():</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>                    reward_extra_info[key].append(value)</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>                reward <span class="op">=</span> score</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>            reward_tensor[i, valid_response_length <span class="op">-</span> <span class="dv">1</span>] <span class="op">=</span> reward</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> data_source <span class="kw">not</span> <span class="kw">in</span> already_print_data_sources:</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>                already_print_data_sources[data_source] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> already_print_data_sources[data_source] <span class="op">&lt;</span> <span class="va">self</span>.num_examine:</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>                already_print_data_sources[data_source] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="st">&quot;[prompt]&quot;</span>, prompt_str)</span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="st">&quot;[response]&quot;</span>, response_str)</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="st">&quot;[ground_truth]&quot;</span>, ground_truth)</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> <span class="bu">isinstance</span>(score, <span class="bu">dict</span>):</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">for</span> key, value <span class="kw">in</span> score.items():</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>                        <span class="bu">print</span>(<span class="ss">f&quot;[</span><span class="sc">{</span>key<span class="sc">}</span><span class="ss">]&quot;</span>, value)</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">print</span>(<span class="st">&quot;[score]&quot;</span>, score)</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> return_dict:</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> {</span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;reward_tensor&quot;</span>: reward_tensor,</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;reward_extra_info&quot;</span>: reward_extra_info,</span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> reward_tensor</span></code></pre></div>
<p>逻辑很简单，就是通过compute_score函数来计算score。</p>]]></description>
</item>
<item>
    <title>basic</title>
    <link>https://blog.vllbc.top/basic/</link>
    <pubDate>Sun, 18 May 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/basic/</guid>
    <description><![CDATA[<h2 id="example">example</h2>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> hydra</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> omegaconf <span class="im">import</span> DictConfig, OmegaConf</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="at">@hydra.main</span>(version_base<span class="op">=</span><span class="va">None</span>, config_path<span class="op">=</span><span class="st">&quot;conf&quot;</span>, config_name<span class="op">=</span><span class="st">&quot;config.yaml&quot;</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> main(cfg: DictConfig):</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(OmegaConf.to_yaml(cfg))</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&quot;__main__&quot;</span>:</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    main()</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>]]></description>
</item>
<item>
    <title>PPO</title>
    <link>https://blog.vllbc.top/rlhf/</link>
    <pubDate>Sun, 18 May 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/rlhf/</guid>
    <description><![CDATA[<p>基础部分看猛猿大佬的<a
href="https://zhuanlan.zhihu.com/p/7461863937">人人都能看懂的RL-PPO理论知识</a>即可，通俗易懂，我写不出来比这个更好的了。本文是各RL算法笔记。</p>
<h1 id="ppo-openrlhf库">PPO (openrlhf库)</h1>
<p>重点记录一下experience的采集过程。训练其实很简单。actor 在 RLHF
会进行 auto-regressive decoding，而 critic, reward 和 reference 则只会
prefill，不会 decode。所以，我们将 actor 的推理特定称为
rollout，而其他模型的推理称为 inference。 </p>]]></description>
</item>
<item>
    <title>MCTS和PRM</title>
    <link>https://blog.vllbc.top/mcts%E5%92%8Cprm/</link>
    <pubDate>Fri, 04 Apr 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/mcts%E5%92%8Cprm/</guid>
    <description><![CDATA[<h2 id="核心总结">核心总结</h2>
<ul>
<li><strong>PRM和MCTS实际上是两种可以独立使用的技术，只不过，往往它们组合使用时往往能产生1+1&gt;2的效果</strong>。例如，
<ul>
<li>单独使用PRM：我们可以让模型对同一个prompt采样多个不同solution，无需MCTS，只需利用模型的temperature等随机参数让每次生成结果不同，然后用PRM对每个solution的每一步打分，最终选择分数最高的路径返回。</li>
<li>单独使用MCTS：使用MCTS生成多个解题路径时，不一定要用PRM来决定哪个节点值得扩展，可以用外部大模型（如GPT-4）来选择，也可以用模型自身的perplexity来判断。本质上，我们需要的是找到最值得扩展的节点，PRM只是挑选的众多方法之一。</li>
</ul></li>
<li><strong>PRM 和 MCTS
既可以应用于优化训练数据，也可以用来预测用</strong>
<ul>
<li>用于得到高质量训练数据：如rStar论文中，可以用PRM和MCTS的方式来迭代地筛选得到质量更好的思维链SFT数据或者RLHF数据，还可以生成更精确的reward
model训练数据。</li>
<li>用于推理：很简单，推理用MCTS的方式把 test-scaling
做上来，再结合PRM的方式从众多路径中挑选最佳答案。</li>
</ul></li>
<li><strong>PRM和MCTS的缺点</strong><br />
这方面 DeepSeek-R1和 kimi1.5的论文已经说得很情况了。</li>
<li>Process Reward Model(PRM) 在实际应用中有三大局限：
<ul>
<li>第一，难以清晰界定一般推理中的细粒度步骤，说白了，怎么定义什么为一个步骤。</li>
<li>第二，判断当前步骤的正误难度大，模型自动化标注不如人意，人工标注又难以拓展。</li>
<li>第三，引入基于模型的PRM易致reward hacking，有时为了训练 policy
model，但反而更多时间去优化 reward model 去了。</li>
</ul></li>
<li>对MCTS的看法：
<ul>
<li>文本的生成搜索空间指数级增长，为应对，给节点设扩展上限，却容易让模型陷入局部最优解困境。</li>
<li>MCTS往往要结合一个精确的PRM来用才能发挥最大效果，但PRM又有上述的问题，陷入一个死循环。</li>
</ul></li>
</ul>
<h2 id="参考">参考</h2>
<p>https://zhuanlan.zhihu.com/p/27278317894 rStar-Math: Small LLMs Can
Master Math Reasoning with Self-Evolved Deep Thinking</p>]]></description>
</item>
<item>
    <title>LEGB</title>
    <link>https://blog.vllbc.top/legb/</link>
    <pubDate>Mon, 24 Mar 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/legb/</guid>
    <description><![CDATA[<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> <span class="st">&#39;global&#39;</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> outer():</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># def len(in_var):</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     print(&#39;called my len() function: &#39;, end=&quot;&quot;)</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     l = 0</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     for i in in_var:</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">#         l += 1</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     return l</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> <span class="st">&#39;local&#39;</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> inner():</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>        <span class="kw">nonlocal</span> a</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>        a <span class="op">+=</span> <span class="st">&#39; variable&#39;</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    inner()</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&#39;a is&#39;</span>, a)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># print(len(a))</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>outer()</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="co"># print(len(a))</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;a is&#39;</span>, a)</span></code></pre></div>
<p>此时为nonlocal
a，会按照local-闭包-global的顺序找到闭包变量a。a的值为local variable</p>]]></description>
</item>
<item>
    <title>debugger</title>
    <link>https://blog.vllbc.top/debugger/</link>
    <pubDate>Sun, 23 Mar 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/debugger/</guid>
    <description><![CDATA[<p>python调试工具，类似于vscode的调试工具，使用命令行进行调试。</p>
<h2 id="使用方法">使用方法</h2>
<h3 id="插入式">插入式</h3>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pdb<span class="op">;</span> pdb.set_trace()</span></code></pre></div>
<p>或者</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="bu">breakpoint</span>()</span></code></pre></div>
<h3 id="非插入式">非插入式</h3>
<pre><code>python -m pdb [-c command] (-m module | pyfile) [args ...]</code></pre>
<h2 id="常用命令">常用命令</h2>
<h3 id="h">h</h3>
<p>即help，可用命令如下 </p>]]></description>
</item>
<item>
    <title>generate</title>
    <link>https://blog.vllbc.top/generate/</link>
    <pubDate>Sun, 09 Mar 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/generate/</guid>
    <description><![CDATA[<p>理论部分在这：<a
href="../../NLP/LLM/generate相关.md">generate相关</a> ##
generate参数</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> generate(</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>        inputs: Optional[torch.Tensor] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>        generation_config: Optional[GenerationConfig] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>        logits_processor: Optional[LogitsProcessorList] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>        stopping_criteria: Optional[StoppingCriteriaList] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>        prefix_allowed_tokens_fn: Optional[Callable[[<span class="bu">int</span>, torch.Tensor], List[<span class="bu">int</span>]]] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>        synced_gpus: Optional[<span class="bu">bool</span>] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>        assistant_model: Optional[<span class="st">&quot;PreTrainedModel&quot;</span>] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>        streamer: Optional[<span class="st">&quot;BaseStreamer&quot;</span>] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>        negative_prompt_ids: Optional[torch.Tensor] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>        negative_prompt_attention_mask: Optional[torch.Tensor] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>        <span class="op">**</span>kwargs,</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    ) <span class="op">-&gt;</span> Union[GenerateOutput, torch.LongTensor]:</span></code></pre></div>
<p>在代码中可以看到在函数入口显式的定义了很多参数。他们的具体含义如下</p>]]></description>
</item>
<item>
    <title>einsum</title>
    <link>https://blog.vllbc.top/einsum/</link>
    <pubDate>Sat, 11 Jan 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/einsum/</guid>
    <description><![CDATA[<blockquote>
<p>einops.einsum calls einsum operations with einops-style named axes
indexing, computing tensor products with an arbitrary number of tensors.
Unlike typical einsum syntax, here you must pass tensors first, and then
the pattern.</p>
</blockquote>
<blockquote>
<p>Also, note that rearrange operations such
as <code>"(batch chan) out"</code>, or singleton axes <code>()</code>,
are not currently supported.</p>
</blockquote>
<p>爱因斯坦求和</p>
<p> </p>]]></description>
</item>
</channel>
</rss>
