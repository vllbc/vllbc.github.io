<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>vllbc02&#39;s blogs</title>
        <link>https://blog.vllbc.top/</link>
        <description>vllbc&#39;s blog</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Wed, 16 Jul 2025 00:00:00 &#43;0000</lastBuildDate>
            <atom:link href="https://blog.vllbc.top/index.xml" rel="self" type="application/rss+xml" />
        <item>
    <title>shortcode(置顶)</title>
    <link>https://blog.vllbc.top/shortcode%E7%BD%AE%E9%A1%B6/</link>
    <pubDate>Tue, 07 Mar 2023 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/shortcode%E7%BD%AE%E9%A1%B6/</guid>
    <description><![CDATA[<p>贴一下可以玩的shortcode。</p>
<h2 id="音乐播放">音乐播放</h2>
<h3 id="播放列表">播放列表</h3>
<p>夏日口袋专辑： <meting-js auto="https://music.163.com/album?id=73470837&amp;uct2=U2FsdGVkX18gTMY/Tb1&#43;2PmOZr2G/Q7mOdM/mANJ8xY=" theme="#448aff"></meting-js></p>
<h3 id="播放单曲">播放单曲</h3>
<p>最爱的一首（我是紬厨）： <meting-js server="netease" type="song" id="1311346841" theme="#448aff"></meting-js></p>
<h2 id="视频播放">视频播放</h2>
<h3 id="bilibili">bilibili</h3>
<p><div class="bilibili"><iframe src="//player.bilibili.com/player.html?bvid=BV1ptXPYREe7&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe></div>
 有多P可以选择集数</p>
<h2 id="admonition">admonition</h2>
<p>类型有：note、abstract、info、tip、success、question、warning、failure、danger、bug、example、quote。
<div class="details admonition tip open">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-lightbulb fa-fw" aria-hidden="true"></i>技巧<i class="details-icon fas fa-angle-right fa-fw" aria-hidden="true"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content">一个 <strong>技巧</strong> 横幅</div>
        </div>
    </div></p>]]></description>
</item>
<item>
    <title>batch_size解释</title>
    <link>https://blog.vllbc.top/batch_size%E8%A7%A3%E9%87%8A/</link>
    <pubDate>Wed, 16 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/batch_size%E8%A7%A3%E9%87%8A/</guid>
    <description><![CDATA[
]]></description>
</item>
<item>
    <title>BRiTE：Bootstrapping Reinforced Thinking Process to Enhance Language Model Reasoning</title>
    <link>https://blog.vllbc.top/britebootstrapping-reinforced-thinking-process-to-enhance-language-model-reasoning/</link>
    <pubDate>Wed, 16 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/britebootstrapping-reinforced-thinking-process-to-enhance-language-model-reasoning/</guid>
    <description><![CDATA[<p>好的，非常荣幸能以领域专家的身份，与您一同深入探讨这篇富有洞见的论文《BRITE:
Bootstrapping Reinforced Thinking Process to Enhance Language Model
Reasoning》。这篇论文确实触及了当前大模型领域一个核心且棘手的问题：如何让模型不仅能生成流畅的文本，更能进行可靠、严谨的逻辑推理。</p>]]></description>
</item>
<item>
    <title>MHA</title>
    <link>https://blog.vllbc.top/mha/</link>
    <pubDate>Wed, 16 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/mha/</guid>
    <description><![CDATA[<h2 id="self-attention">Self-attention</h2>
<p>首先介绍一下最主要的 self-attention，可以说是 self-attention
实现了上述的 token 之间交互的功能。</p>
<p>自注意力是模型的关键组成部分之一。注意和自注意之间的区别在于，自注意在相同性质的表示之间运行：例如，某个层中的所有编码器状态。</p>]]></description>
</item>
<item>
    <title>MQA</title>
    <link>https://blog.vllbc.top/mqa/</link>
    <pubDate>Wed, 16 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/mqa/</guid>
    <description><![CDATA[<figure>

<figcaption aria-hidden="true">image.png</figcaption>
</figure>
<p>标准的 mha 中，KV heads 的数量和 Query heads 的数量相同，每一个 q
head 对应一个独立的 kv head，但这样的开销比较大。 <strong>MQA (Multi
Queries Attention): MQA 比较极端，只保留一个 KV Head，多个 Query Heads
共享相同的 KV Head</strong>。这相当于不同 Head 的 Attention
差异，全部都放在了 Query 上，需要模型仅从不同的 Query Heads
上就能够关注到输入 hidden states
不同方面的信息。这样做的好处是，极大地降低了 KV Cache
的需求，但是会导致模型效果有所下降。（层内共享）</p>]]></description>
</item>
<item>
    <title>PROCESS REINFORCEMENT THROUGH IMPLICIT REWARDS</title>
    <link>https://blog.vllbc.top/process-reinforcement-through-implicit-rewards/</link>
    <pubDate>Wed, 16 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/process-reinforcement-through-implicit-rewards/</guid>
    <description><![CDATA[<h3 id="论文深入解读">论文深入解读</h3>
<p>这篇名为《Process Reinforcement through Implicit
Rewards》(通过隐式奖励进行过程强化)
的论文，由来自清华大学、上海人工智能实验室、UIUC
等顶尖机构的研究者共同完成，为大语言模型（LLM）的强化学习（RL）领域带来了一个极具价值和创新性的解决方案——<strong>PRIME</strong>
框架。其核心贡献在于，它成功地将<strong>过程监督 (Process
Supervision)</strong> 的高效率与<strong>结果监督 (Outcome
Supervision)</strong>
的低成本相结合，解决了在复杂推理任务（如数学和编程）中应用强化学习时面临的关键瓶颈。</p>]]></description>
</item>
<item>
    <title>Search-R1：Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning</title>
    <link>https://blog.vllbc.top/search-r1training-llms-to-reason-and-leverage-search-engines-with-reinforcement-learning/</link>
    <pubDate>Wed, 16 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/search-r1training-llms-to-reason-and-leverage-search-engines-with-reinforcement-learning/</guid>
    <description><![CDATA[<p>好的，作为大模型领域的学术专家，我非常乐于为您深入解读这篇具有重要意义的论文《SEARCH-R
1: Training LLMs to Reason and Leverage Search Engines with
Reinforcement Learning》。</p>
<p>这篇论文的核心，是探索如何让大型语言模型（LLM）<strong>学会</strong>像人类专家一样，在解决复杂问题时，<strong>主动、智能、且迭代地使用搜索引擎</strong>。它不仅仅是简单地把搜索结果“喂”给模型，而是通过<strong>强化学习（Reinforcement
Learning,
RL）</strong>，训练模型形成一种内在的“研究”能力——知道<strong>什么时候</strong>需要信息，需要<strong>什么</strong>信息，以及如何<strong>整合</strong>这些信息来形成最终答案。</p>]]></description>
</item>
<item>
    <title>WebThinker：Empowering Large Reasoning Models with Deep Research Capability</title>
    <link>https://blog.vllbc.top/webthinkerempowering-large-reasoning-models-with-deep-research-capability/</link>
    <pubDate>Wed, 16 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/webthinkerempowering-large-reasoning-models-with-deep-research-capability/</guid>
    <description><![CDATA[<p>好的，作为大模型领域的专家，我很乐意为您深入解读这篇富有洞见的论文《WebThinker:
Empowering Large Reasoning Models with Deep Research
Capability》。这篇论文确实触及了当前大模型研究的前沿核心——如何让模型从一个静态的“知识库”转变为一个动态的“研究员”。</p>]]></description>
</item>
<item>
    <title>dapo</title>
    <link>https://blog.vllbc.top/dapo/</link>
    <pubDate>Tue, 15 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/dapo/</guid>
    <description><![CDATA[
]]></description>
</item>
<item>
    <title>First Return, Entropy-Eliciting Explore</title>
    <link>https://blog.vllbc.top/first-return-entropy-eliciting-explore/</link>
    <pubDate>Tue, 15 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/first-return-entropy-eliciting-explore/</guid>
    <description><![CDATA[<p>好的，作为大模型领域的学术专家，非常荣幸能与您一同深入探讨这篇富有启发性的论文——《First
Return, Entropy-Eliciting Explore》。这篇由字节跳动、M-A-P
及曼彻斯特大学的研究者们共同完成的工作，直面了当前大模型在复杂推理任务中通过强化学习进行优化时的一个核心痛点。</p>]]></description>
</item>
</channel>
</rss>
