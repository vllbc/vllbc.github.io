<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>vllbc02</title>
        <link>https://blog.vllbc.top/</link>
        <description>vllbc&#39;s blog</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>vllbc02@163.com (vllbc)</managingEditor>
            <webMaster>vllbc02@163.com (vllbc)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 &#43;0000</lastBuildDate>
            <atom:link href="https://blog.vllbc.top/index.xml" rel="self" type="application/rss+xml" />
        <item>
    <title>shortcode(ç½®é¡¶)</title>
    <link>https://blog.vllbc.top/shortcode%E7%BD%AE%E9%A1%B6/</link>
    <pubDate>Tue, 07 Mar 2023 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/shortcode%E7%BD%AE%E9%A1%B6/</guid>
    <description><![CDATA[è´´ä¸€ä¸‹å¯ä»¥çŽ©çš„shortcodeã€‚ éŸ³ä¹æ’­æ”¾ æ’­æ”¾åˆ—è¡¨ æ’­æ”¾å•æ›² è§†é¢‘æ’­æ”¾ bilibili æœ‰å¤šPå¯ä»¥é€‰æ‹©é›†æ•° youtube admonition ç±»åž‹æœ‰ï¼šnoteã€abstractã€infoã€ti]]></description>
</item>
<item>
    <title>llamaç³»åˆ—</title>
    <link>https://blog.vllbc.top/llama%E7%B3%BB%E5%88%97/</link>
    <pubDate>Thu, 26 Sep 2024 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/llama%E7%B3%BB%E5%88%97/</guid>
    <description><![CDATA[llamaç³»åˆ—çš„ä¸»è¦å·®åˆ«åœ¨è®­ç»ƒä¸Šä¸‹æ–‡é•¿åº¦ã€è¯è¡¨å¤§å°ã€è®­ç»ƒtokenæ•°ã€æ³¨æ„åŠ›æœºåˆ¶ä»¥åŠå¯¹é½æ–¹æ³•ä¸Šï¼Œç”±äºŽå¼ºåŒ–å­¦ä¹ è¿˜æ²¡æ·±å…¥å­¦ä¹ ï¼Œå› æ­¤è·³è¿‡å¼ºåŒ–å­¦ä¹ éƒ¨]]></description>
</item>
<item>
    <title>frequency_penalty&amp;presence_penalty</title>
    <link>https://blog.vllbc.top/generate%E7%9B%B8%E5%85%B3/</link>
    <pubDate>Thu, 05 Sep 2024 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/generate%E7%9B%B8%E5%85%B3/</guid>
    <description><![CDATA[LLMè§£ç æ—¶é‡‡ç”¨çš„è‡ªå›žå½’é‡‡æ ·ï¼Œå…¶è¿‡ç¨‹å¦‚ä¸‹ï¼š å°æ¨¡åž‹ä½¿ç”¨å‰ç¼€ä½œä¸ºè¾“å…¥ï¼Œå°†è¾“å‡ºç»“æžœå¤„ç†+å½’ä¸€åŒ–æˆæ¦‚çŽ‡åˆ†å¸ƒåŽï¼Œé‡‡æ ·ç”Ÿæˆä¸‹ä¸€ä¸ªtokenã€‚ å°†ç”Ÿæˆçš„to]]></description>
</item>
<item>
    <title>rwkv</title>
    <link>https://blog.vllbc.top/rwkv/</link>
    <pubDate>Wed, 04 Sep 2024 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/rwkv/</guid>
    <description><![CDATA[çº¿æ€§Transformer \[V_i&#39;=\frac{\sum_{j=1}^N sim(Q_i,K_j)V_j}{\sum_{j=1}^N sim(Q_i,K_j)}\] æ³¨æ„ä¸‹æ ‡iã€‚ å…¶ä¸­ \[sim(Q_{i},K_{j})=\phi(Q_{i},K_{j})\] æ­¤æ—¶æœ‰ï¼š \[V_{i}^{\prime}=\frac{\phi(Q_{i})\sum_{j=1}^{i}\phi(K_{j})^{T}V_{j}}{\phi(Q_{i})\sum_{j=1}^{i}\phi(K_{j})^{T}}\] æ³¨æ„å¯ä»¥å°†\(\phi(Q_{i})\)æå‡ºæ¥ã€‚ åŽŸå§‹Transformerçš„è®¡ç®—]]></description>
</item>
<item>
    <title>rope</title>
    <link>https://blog.vllbc.top/rope/</link>
    <pubDate>Sat, 31 Aug 2024 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/rope/</guid>
    <description><![CDATA[è¯æ˜Ž æ ¸å¿ƒæ€æƒ³å°±æ˜¯æ‰¾åˆ°ä¸€ä¸ªè½¬æ¢ï¼Œå¯ä»¥é€šè¿‡ç‚¹ç§¯æ“ä½œå°†ä½ç½®ä¿¡æ¯æ³¨å…¥ï¼Œå³ï¼š \[&lt;f_q\left(x_m,m\right),f_k\left(x_n,n\right)&gt;=g\left(x_m,x_n,m-n\right)\] è€Œé€šè¿‡å¤æ•°çš„ä¸€äº›æ€§è´¨ï¼Œæ‰¾åˆ°äº†æ»¡è¶³ä¸Šè¿°æ“ä½œçš„è½¬æ¢ï¼š \[\begin{aligned} &amp;f_{q}\left(\boldsymbol{x}_{m},m\right)=\left(\boldsymbol{W}_{q}\boldsymbol{x}_{m}\right)e^{im\theta} \\ &amp;f_{k}\left(\boldsymbol{x}_{n},n\right)=\left(\boldsymbol{W}_{k}\boldsymbol{x}_{n}\right)e^{in\theta} \\ &amp;g\left(\boldsymbol{x}_{m},\boldsymbol{x}_{n},m-n\right)=\mathrm{Re}\left[\left(\boldsymbol{W}_{q}\boldsymbol{x}_{m}\right)\left(\boldsymbol{W}_{k}\boldsymbol{x}_{n}\right)^{*}e^{i(m-n)\theta}\right] \end{aligned}\] å¯ä»¥å‘çŽ°g]]></description>
</item>
<item>
    <title>Data Engineering for Scaling Language Models to 128K Context</title>
    <link>https://blog.vllbc.top/data-engineering-for-scaling-language-models-to-128k-context/</link>
    <pubDate>Thu, 08 Aug 2024 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/data-engineering-for-scaling-language-models-to-128k-context/</guid>
    <description><![CDATA[Data Engineering for Scaling Language Models to 128K Context ðŸ’¡ Meta Data Title Data Engineering for Scaling Language Models to 128K Context Journal Authors Yao Fu; Rameswar Panda; Xinyao Niu; Xiang Yue; Hannaneh Hajishirzi; Yoon Kim; Hao Peng Pub. date 2024-02-15 æœŸåˆŠæ ‡ç­¾ DOI 10.48550/arXiv.2402.10171 é™„ä»¶ Fu et al_2024_Data Engineering for Scaling Language Models to 128K Context.pdf ðŸ“œ ç ”ç©¶èƒŒæ™¯ &amp; åŸºç¡€ &amp; ç›®]]></description>
</item>
<item>
    <title>KV cache</title>
    <link>https://blog.vllbc.top/kv-cache/</link>
    <pubDate>Wed, 07 Aug 2024 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/kv-cache/</guid>
    <description><![CDATA[KV cache LLMæŽ¨ç†è¿‡ç¨‹åˆ†ä¸ºPrefillå’ŒDecodeä¸¤ä¸ªé˜¶æ®µï¼Œå…¶ä¸­Prefillé˜¶æ®µä¼šå¯¹Promptä¸­æ‰€æœ‰çš„tokenåšå¹¶è¡Œè®¡ç®—ï¼Œå¾—åˆ°Prom]]></description>
</item>
<item>
    <title>Loraå¾®è°ƒ</title>
    <link>https://blog.vllbc.top/lora%E5%BE%AE%E8%B0%83/</link>
    <pubDate>Wed, 07 Aug 2024 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/lora%E5%BE%AE%E8%B0%83/</guid>
    <description><![CDATA[]]></description>
</item>
<item>
    <title>Moe</title>
    <link>https://blog.vllbc.top/moe/</link>
    <pubDate>Wed, 07 Aug 2024 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/moe/</guid>
    <description><![CDATA[]]></description>
</item>
<item>
    <title>Transformer Feed-Forward Layers Are Key-Value Memories</title>
    <link>https://blog.vllbc.top/transformer-feed-forward-layers-are-key-value-memories/</link>
    <pubDate>Wed, 07 Aug 2024 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/transformer-feed-forward-layers-are-key-value-memories/</guid>
    <description><![CDATA[Transformer Feed-Forward Layers Are Key-Value Memories ðŸ’¡ Meta Data Title Transformer Feed-Forward Layers Are Key-Value Memories Journal Authors Mor Geva; Roei Schuster; Jonathan Berant; Omer Levy Pub. date 2021-09-05 æœŸåˆŠæ ‡ç­¾ DOI 10.48550/arXiv.2012.14913 é™„ä»¶ Geva et al_2021_Transformer Feed-Forward Layers Are Key-Value Memories.pdf ðŸ“œ ç ”ç©¶èƒŒæ™¯ &amp; åŸºç¡€ &amp; ç›®çš„ å‰é¦ˆå±‚å æ®äº† Transformer æ¨¡åž‹å‚æ•°çš„ä¸‰åˆ†]]></description>
</item>
</channel>
</rss>
