<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>vllbc02&#39;s blogs</title>
        <link>https://blog.vllbc.top/</link>
        <description>vllbc&#39;s blog</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Fri, 08 Aug 2025 00:00:00 &#43;0000</lastBuildDate>
            <atom:link href="https://blog.vllbc.top/index.xml" rel="self" type="application/rss+xml" />
        <item>
    <title>shortcode(置顶)</title>
    <link>https://blog.vllbc.top/shortcode%E7%BD%AE%E9%A1%B6/</link>
    <pubDate>Tue, 07 Mar 2023 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/shortcode%E7%BD%AE%E9%A1%B6/</guid>
    <description><![CDATA[<p>贴一下可以玩的shortcode。</p>
<h2 id="音乐播放">音乐播放</h2>
<h3 id="播放列表">播放列表</h3>
<p>夏日口袋专辑： <meting-js auto="https://music.163.com/album?id=73470837&amp;uct2=U2FsdGVkX18gTMY/Tb1&#43;2PmOZr2G/Q7mOdM/mANJ8xY=" theme="#448aff"></meting-js></p>
<h3 id="播放单曲">播放单曲</h3>
<p>最爱的一首（我是紬厨）： <meting-js server="netease" type="song" id="1311346841" theme="#448aff"></meting-js></p>
<h2 id="视频播放">视频播放</h2>
<h3 id="bilibili">bilibili</h3>
<p><div class="bilibili"><iframe src="//player.bilibili.com/player.html?bvid=BV1ptXPYREe7&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe></div>
 有多P可以选择集数</p>
<h2 id="admonition">admonition</h2>
<p>类型有：note、abstract、info、tip、success、question、warning、failure、danger、bug、example、quote。
<div class="details admonition tip open">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-lightbulb fa-fw" aria-hidden="true"></i>技巧<i class="details-icon fas fa-angle-right fa-fw" aria-hidden="true"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content">一个 <strong>技巧</strong> 横幅</div>
        </div>
    </div></p>]]></description>
</item>
<item>
    <title>qwen</title>
    <link>https://blog.vllbc.top/qwen/</link>
    <pubDate>Fri, 08 Aug 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/qwen/</guid>
    <description><![CDATA[<pre class="python3"><code>------------------------------------------------------------------------------------------------------
# Qwen-1
+ Embedding and output projection. (Untied embedding for input embedding and output projection)
+ ROPE
+ QKV bias required
+ Pre-Norm &amp; RMSNorm
+ SwiGLU

------------------------------------------------------------------------------------------------------
# Qwen-2
- Multi-Head Attention

+ MoE
+ Grouped Query Attention
+ Dual Chunk Attention
+ YARN
+ Expert Granularity
+ Expert Routing
+ Expert Initialization
+ Shared Experts

------------------------------------------------------------------------------------------------------
# Qwen-2.5
+ More control tokens. 3 -&gt; 22

------------------------------------------------------------------------------------------------------
# Qwen-3
- QKV bias
- Shared experts

+ QK-Norm
------------------------------------------------------------------------------------------------------</code></pre>
<h2 id="参考">参考</h2>
<p><a href="https://zhuanlan.zhihu.com/p/1933558376689804480">Qwen
各版本主要结构变化</a></p>]]></description>
</item>
<item>
    <title>信用分配</title>
    <link>https://blog.vllbc.top/%E4%BF%A1%E7%94%A8%E5%88%86%E9%85%8D/</link>
    <pubDate>Tue, 05 Aug 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/%E4%BF%A1%E7%94%A8%E5%88%86%E9%85%8D/</guid>
    <description><![CDATA[<p>最近涌现了很多关于信用分配的论文，因此整理一下</p>
<h2 id="first-return-entropy-eliciting-explore"><a
href="../../reading/Reasoning/First%20Return,%20Entropy-Eliciting%20Explore.md">First
Return, Entropy-Eliciting Explore</a></h2>
<h2
id="good-learners-think-their-thinkinggenerative-prm-makes-large-reasoning-model-more-efficient-math-learne"><a
href="../../reading/Reasoning/Good%20Learners%20Think%20Their%20Thinking：Generative%20PRM%20Makes%20Large%20Reasoning%20Model%20More%20Efficient%20Math%20Learne.md">Good
Learners Think Their Thinking：Generative PRM Makes Large Reasoning
Model More Efficient Math Learne</a></h2>
<h2 id="group-sequence-policy-optimization"><a
href="../../reading/LLM-RL/Group%20Sequence%20Policy%20Optimization.md">Group
Sequence Policy Optimization</a></h2>
<h2 id="process-reinforcement-through-implicit-rewards"><a
href="../../reading/Reasoning/PROCESS%20REINFORCEMENT%20THROUGH%20IMPLICIT%20REWARDS.md">PROCESS
REINFORCEMENT THROUGH IMPLICIT REWARDS</a></h2>
<h2
id="rlvmrreinforcement-learning-with-verifiable-meta-reasoning-rewards-for-robust-long-horizon-agents"><a
href="../../reading/Planning/RLVMR：Reinforcement%20Learning%20with%20Verifiable%20Meta-Reasoning%20Rewards%20for%20Robust%20Long-Horizon%20Agents.md">RLVMR：Reinforcement
Learning with Verifiable Meta-Reasoning Rewards for Robust Long-Horizon
Agents</a></h2>
<h2
id="vapoefficient-and-reliable-reinforcement-learning-for-advanced-reasoning-tasks"><a
href="../../reading/LLM-RL/VAPO：Efficient%20and%20Reliable%20Reinforcement%20Learning%20for%20Advanced%20Reasoning%20Tasks.md">VAPO：Efficient
and Reliable Reinforcement Learning for Advanced Reasoning
Tasks</a></h2>
<h2 id="group-in-group-policy-optimization-for-llm-agent-training"><a
href="../../reading/Planning/Group-in-Group%20Policy%20Optimization%20for%20LLM%20Agent%20Training.md">Group-in-Group
Policy Optimization for LLM Agent Training</a></h2>
<h2
id="capotowards-enhancing-llm-reasoning-through-verifiable-generative-credit-assignment"><a
href="../../reading/Reasoning/CAPO：Towards%20Enhancing%20LLM%20Reasoning%20through%20Verifiable%20Generative%20Credit%20Assignment.md">CAPO：Towards
Enhancing LLM Reasoning through Verifiable Generative Credit
Assignment</a></h2>
<h2
id="beyond-policy-optimizationa-data-curation-flywheel-for-sparse-reward-long-horizon-planning"><a
href="../../reading/Planning/Beyond%20Policy%20Optimization：A%20Data%20Curation%20Flywheel%20for%20Sparse-Reward%20Long-Horizon%20Planning.md">Beyond
Policy Optimization：A Data Curation Flywheel for Sparse-Reward
Long-Horizon Planning</a></h2>
<h2
id="gtpo-and-grpo-stoken-and-sequence-level-reward-shaping-with-policy-entropy"><a
href="../../reading/Reasoning/GTPO%20and%20GRPO-S：Token%20and%20Sequence-Level%20Reward%20Shaping%20with%20Policy%20Entropy.md">GTPO
and GRPO-S：Token and Sequence-Level Reward Shaping with Policy
Entropy</a></h2>
<h2
id="gtpotrajectory-based-policy-optimization-in-large-language-models"><a
href="../../reading/Reasoning/GTPO：Trajectory-Based%20Policy%20Optimization%20in%20Large%20Language%20Models.md">GTPO：Trajectory-Based
Policy Optimization in Large Language Models</a></h2>]]></description>
</item>
<item>
    <title>K2</title>
    <link>https://blog.vllbc.top/k2/</link>
    <pubDate>Wed, 30 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/k2/</guid>
    <description><![CDATA[<h2 id="预训练">预训练</h2>
<h3 id="muon-clip">Muon-clip</h3>
<p>详见<a href="../../Deep%20Learning/优化器/Muon.md">Muon</a></p>
<p>通过裁剪权重解决Max-Logit问题，实现稳定训练。</p>
<h3 id="数据增强">数据增强</h3>
<p>通过改写句子来提高token效率，避免重复使用token造成的过拟合，改写方法如下：</p>]]></description>
</item>
<item>
    <title>ALiBi</title>
    <link>https://blog.vllbc.top/alibi/</link>
    <pubDate>Tue, 29 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/alibi/</guid>
    <description><![CDATA[<p>在softmax的结果后添加一个静态的不可学习的偏置项。  q1和k1之间的距离是0，所以对应位置就是0<br />
 q2和k1之间的距离是「相对位置偏移为“<strong>k的索引</strong>”1」 -
「q的索引2」，得到1-2 = -1，就对应到了中间矩阵的取值为-1了<br />
以此类推，相对距离矩阵的中间对角线上都是0，然后左下角的取值都是对应的「k的索引」-「q的索引」了</p>]]></description>
</item>
<item>
    <title>Gemma</title>
    <link>https://blog.vllbc.top/gemma/</link>
    <pubDate>Tue, 29 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/gemma/</guid>
    <description><![CDATA[<h2 id="gemma-3">Gemma 3</h2>
<h3 id="qk-norm">QK-Norm</h3>
<p>简单来说就是在Q和K矩阵上进行RMSNorm，即：</p>
<p><span class="math display">\[
\begin{aligned}
O &amp;= softmax(\bar{Q}\bar{K}^T)V \\
\bar{Q} &amp;=RMSNorm(Q) \\
\bar{K} &amp;=RMSNorm(V)
\end{aligned}\
\]</span></p>
<p>但这种方法的问题是不适用MLA的推理阶段，因为推理阶段的MLA将Wk吸取到了Q中，具体见<a
href="../Attention/MLA.md">MLA</a></p>]]></description>
</item>
<item>
    <title>dynamic_bsz</title>
    <link>https://blog.vllbc.top/dynamic_bsz/</link>
    <pubDate>Sun, 27 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/dynamic_bsz/</guid>
    <description><![CDATA[
]]></description>
</item>
<item>
    <title>Dataset</title>
    <link>https://blog.vllbc.top/dataset/</link>
    <pubDate>Sat, 26 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/dataset/</guid>
    <description><![CDATA[<p>详细讲解一下verl中的RLHFDataset，它继承自torch的Dataset，需要实现__getitem__来返回数据。</p>
<h2 id="初始化">初始化</h2>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RLHFDataset(Dataset):</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Load and preprocess RLHF data from Parquet files.</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co">    - Caches files locally.</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">    - Reads into a HuggingFace Dataset and tokenizes prompts.</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">    - Optionally handles images/videos via a ProcessorMixin.</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">    - Filters prompts over a max length.</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co">    - Supports resuming from checkpoints.</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co">        data_files (str or list): Path(s) to Parquet file(s).</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co">        tokenizer (PreTrainedTokenizer): For the tokenization of text to token IDs.</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co">        config (DictConfig): Options like cache_dir, prompt_key, max_prompt_length, truncation, etc.</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co">        processor (ProcessorMixin, optional): Multimodal preprocessor for images/videos.</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>        data_files: <span class="bu">str</span> <span class="op">|</span> <span class="bu">list</span>[<span class="bu">str</span>],</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>        tokenizer: PreTrainedTokenizer,</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>        config: DictConfig,</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>        processor: Optional[ProcessorMixin] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(data_files, <span class="bu">list</span> <span class="op">|</span> ListConfig):</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>            data_files <span class="op">=</span> [data_files]</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.data_files <span class="op">=</span> copy.deepcopy(data_files)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.original_data_files <span class="op">=</span> copy.deepcopy(data_files)  <span class="co"># use for resume</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tokenizer <span class="op">=</span> tokenizer</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.processor <span class="op">=</span> processor</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.config <span class="op">=</span> config</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.cache_dir <span class="op">=</span> os.path.expanduser(config.get(<span class="st">&quot;cache_dir&quot;</span>, <span class="st">&quot;~/.cache/verl/rlhf&quot;</span>))</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.prompt_key <span class="op">=</span> config.get(<span class="st">&quot;prompt_key&quot;</span>, <span class="st">&quot;prompt&quot;</span>)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_key <span class="op">=</span> config.get(<span class="st">&quot;image_key&quot;</span>, <span class="st">&quot;images&quot;</span>)</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.video_key <span class="op">=</span> config.get(<span class="st">&quot;video_key&quot;</span>, <span class="st">&quot;videos&quot;</span>)</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.max_prompt_length <span class="op">=</span> config.get(<span class="st">&quot;max_prompt_length&quot;</span>, <span class="dv">1024</span>)</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.return_raw_chat <span class="op">=</span> config.get(<span class="st">&quot;return_raw_chat&quot;</span>, <span class="va">False</span>)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.return_full_prompt <span class="op">=</span> config.get(<span class="st">&quot;return_full_prompt&quot;</span>, <span class="va">False</span>)</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.truncation <span class="op">=</span> config.get(<span class="st">&quot;truncation&quot;</span>, <span class="st">&quot;error&quot;</span>)</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.filter_overlong_prompts <span class="op">=</span> config.get(<span class="st">&quot;filter_overlong_prompts&quot;</span>, <span class="va">True</span>)</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_workers <span class="op">=</span> config.get(<span class="st">&quot;filter_overlong_prompts_workers&quot;</span>, <span class="bu">max</span>(<span class="dv">1</span>, os.cpu_count() <span class="op">//</span> <span class="dv">4</span>))</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_workers <span class="op">=</span> <span class="bu">min</span>(<span class="va">self</span>.num_workers, os.cpu_count())</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.use_shm <span class="op">=</span> config.get(<span class="st">&quot;use_shm&quot;</span>, <span class="va">False</span>)</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.chat_template_func <span class="op">=</span> config.get(<span class="st">&quot;chat_template_func&quot;</span>, <span class="va">None</span>)</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.need_tools_kwargs <span class="op">=</span> config.get(<span class="st">&quot;need_tools_kwargs&quot;</span>, <span class="va">False</span>)</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.filter_prompts <span class="op">=</span> config.get(<span class="st">&quot;filter_prompts&quot;</span>, <span class="va">True</span>)</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.serialize_dataset <span class="op">=</span> <span class="va">False</span></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.return_multi_modal_inputs <span class="op">=</span> config.get(<span class="st">&quot;return_multi_modal_inputs&quot;</span>, <span class="va">True</span>)</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._download()</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._read_files_and_tokenize()</span></code></pre></div>
<p> （来自deepwiki）</p>]]></description>
</item>
<item>
    <title>device_mesh</title>
    <link>https://blog.vllbc.top/device_mesh/</link>
    <pubDate>Sat, 26 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/device_mesh/</guid>
    <description><![CDATA[<h2 id="verl中的device_mesh">verl中的device_mesh</h2>
<p>verl中有3个device_mesh，分别是： - 训练用的FSDP mesh（通常是一维） -
推理用的rollout mesh（包含tp维度） - Ulysses序列并行的mesh（dp×sp）</p>]]></description>
</item>
<item>
    <title>agent_loop</title>
    <link>https://blog.vllbc.top/agent_loop/</link>
    <pubDate>Thu, 24 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/agent_loop/</guid>
    <description><![CDATA[<p>Verl 最近实现了 agent loop 功能，也就是多轮工具调用 RL ，弥补了 verl
中 vllm 无法使用多轮 rollout 的不足。整体流程大致如下（来自
https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/rlhf/verl/multi-turn/imgs/Multi-Turn_Rollout_Workflow.png）</p>
<figure>

<figcaption aria-hidden="true">image.png</figcaption>
</figure>
<p>在官方实现中（目前在 verl/experimental/agent_loop
目录下），核心代码在
agent_loop.py中，single_turn_agent_loop.py和tool_agent_loop对应两种agent_loop，tool_parser.py定义了hermes工具解析类。所以重点就是在agent_loop.py中，各个类的协作流程如下图：</p>]]></description>
</item>
</channel>
</rss>
