<!DOCTYPE html>
<html lang="zh-CN">
    <head>
	<meta name="generator" content="Hugo 0.145.0">
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title>vllbc02&#39;s blogs</title><meta name="Description" content="vllbc&#39;s blog"><meta property="og:url" content="https://blog.vllbc.top/">
  <meta property="og:site_name" content="vllbc02&#39;s blogs">
  <meta property="og:title" content="vllbc02&#39;s blogs">
  <meta property="og:description" content="vllbc&#39;s blog">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="website">
    <meta property="og:image" content="https://blog.vllbc.top/images/logo.png">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="https://blog.vllbc.top/images/logo.png">
  <meta name="twitter:title" content="vllbc02&#39;s blogs">
  <meta name="twitter:description" content="vllbc&#39;s blog">
<meta name="application-name" content="vllbc02">
<meta name="apple-mobile-web-app-title" content="vllbc02">
<meta name="referrer" content="no-referrer" /><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://blog.vllbc.top/" /><link rel="alternate" href="/index.xml" type="application/rss+xml" title="vllbc02&#39;s blogs">
    <link rel="feed" href="/index.xml" type="application/rss+xml" title="vllbc02&#39;s blogs"><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.2/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.2/css/all.min.css"></noscript><link rel="preload" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "WebSite",
        "url": "https:\/\/blog.vllbc.top\/","inLanguage": "zh-CN","description": "vllbc's blog","image": {
                "@type": "ImageObject",
                "url": "https:\/\/blog.vllbc.top\/images\/Apple-Devices-Preview.png",
                "width":  3200 ,
                "height":  2048 
            },"thumbnailUrl": "https:\/\/blog.vllbc.top\/images\/screenshot.png","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","name": "vllbc02's blogs"
    }
    </script></head>
    <body data-header-desktop="fixed" data-header-mobile="auto"><script>(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper">
<header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="vllbc02&#39;s blogs"><img
        class="lazyload logo"
        src="/svg/loading.min.svg"
        data-src="/images/logo.png"
        data-srcset="/images/logo.png, /images/logo.png 1.5x, /images/logo.png 2x"
        data-sizes="auto"
        alt="/images/logo.png"
        title="/images/logo.png" width="32" height="32" />vllbc02</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> 所有文章 </a><a class="menu-item" href="/tags/"> 标签 </a><a class="menu-item" href="/categories/"> 分类 </a><a class="menu-item" href="/about/"> 关于 </a><a class="menu-item" href="https://github.com/vllbc/vllbc.github.io" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw' aria-hidden='true'></i>  </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="vllbc02&#39;s blogs"><img
        class="lazyload logo"
        src="/svg/loading.min.svg"
        data-src="/images/logo.png"
        data-srcset="/images/logo.png, /images/logo.png 1.5x, /images/logo.png 2x"
        data-sizes="auto"
        alt="/images/logo.png"
        title="/images/logo.png" width="32" height="32" />vllbc02</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        取消
                    </a>
                </div><a class="menu-item" href="/posts/" title="">所有文章</a><a class="menu-item" href="/tags/" title="">标签</a><a class="menu-item" href="/categories/" title="">分类</a><a class="menu-item" href="/about/" title="">关于</a><a class="menu-item" href="https://github.com/vllbc/vllbc.github.io" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw' aria-hidden='true'></i></a><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a></div>
    </div>
</header><div class="search-dropdown desktop">
        <div id="search-dropdown-desktop"></div>
    </div>
    <div class="search-dropdown mobile">
        <div id="search-dropdown-mobile"></div>
    </div>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/base16/darcula.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script><main class="main">
                <div class="container"><div class="page home" data-home="posts"><div class="home-profile"><div class="home-avatar"><a href="/posts/" title="所有文章"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="/images/avatar.png"
        data-srcset="/images/avatar.png, /images/avatar.png 1.5x, /images/avatar.png 2x"
        data-sizes="auto"
        alt="/images/avatar.png"
        title="/images/avatar.png" width="512" height="512" /></a></div><h1 class="home-title">vllbc</h1><div class="home-subtitle"><div id="id-1" class="typeit"></div></div><div class="links"><a href="https://github.com/vllbc" title="GitHub" target="_blank" rel="noopener noreffer me"><i class="fab fa-github fa-fw" aria-hidden="true"></i></a><a href="https://steamcommunity.com/id/vllbc" title="Steam" target="_blank" rel="noopener noreffer me"><i class="fab fa-steam fa-fw" aria-hidden="true"></i></a><a href="tel:18265090197" title="Phone" rel="me"><i class="fas fa-phone fa-fw" aria-hidden="true"></i></a><a href="mailto:vllbc02@163.com" title="Email" rel="me"><i class="far fa-envelope fa-fw" aria-hidden="true"></i></a><a href="/index.xml" title="RSS" target="_blank" rel="noopener noreffer me"><i class="fas fa-rss fa-fw" aria-hidden="true"></i></a></div></div>
<article class="single summary" itemscope itemtype="http://schema.org/Article"><h1 class="single-title" itemprop="name headline">
        <a href="/parse_shape/">parse_shape</a>
    </h1><div class="post-meta"><span class="post-author"><a href="/" title="Author" rel="author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>vllbc</a></span>&nbsp;<span class="post-publish">发布于 <time datetime="2025-01-08">2025-01-08</time></span>&nbsp;<span class="post-category">收录于 <a href="/categories/einops/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Einops</a></span></div><div class="content"><blockquote>
<p>Parse a tensor shape to dictionary mapping axes names to their
lengths.</p>
</blockquote>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use underscore to skip the dimension in parsing. </span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> x <span class="op">=</span> np.zeros([<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">7</span>]) <span class="op">&gt;&gt;&gt;</span> parse_shape(x, <span class="st">&#39;batch _ h w&#39;</span>) {<span class="st">&#39;batch&#39;</span>: <span class="dv">2</span>, <span class="st">&#39;h&#39;</span>: <span class="dv">5</span>, <span class="st">&#39;w&#39;</span>: <span class="dv">7</span>} </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># `parse_shape` output can be used to specify axes_lengths for other operations: </span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> y <span class="op">=</span> np.zeros([<span class="dv">700</span>]) </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> rearrange(y, <span class="st">&#39;(b c h w) -&gt; b c h w&#39;</span>, <span class="op">**</span>parse_shape(x, <span class="st">&#39;b _ h w&#39;</span>)).shape </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>(<span class="dv">2</span>, <span class="dv">10</span>, <span class="dv">5</span>, <span class="dv">7</span>)</span></code></pre></div>
<p>也就是把维度的维数映射到对应的命名。与数据无关，只看得到维度。</p></div><div class="post-footer">
        <a href="/parse_shape/">阅读全文</a><div class="post-tags">
                <i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/einops/">Einops</a></div></div>
</article><article class="single summary" itemscope itemtype="http://schema.org/Article"><h1 class="single-title" itemprop="name headline">
        <a href="/agent-planning%E7%BB%BC%E8%BF%B0/">agent planning综述</a>
    </h1><div class="post-meta"><span class="post-author"><a href="/" title="Author" rel="author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>vllbc</a></span>&nbsp;<span class="post-publish">发布于 <time datetime="2024-12-20">2024-12-20</time></span>&nbsp;<span class="post-category">收录于 <a href="/categories/survey/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Survey</a>&nbsp;<a href="/categories/reading/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Reading</a>&nbsp;<a href="/categories/planning/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Planning</a></span></div><div class="content"><p>该工作主要梳理了LLM-based Agent
中的规划（planning）能力，原文链接：</p>
<p><a href="​arxiv.org/abs/2402.02716">Understanding the planning of LLM
agents: A survey</a></p>
<p>文章中，作者将planning能力进一步细分为了五个维度：</p></div><div class="post-footer">
        <a href="/agent-planning%E7%BB%BC%E8%BF%B0/">阅读全文</a><div class="post-tags">
                <i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/task_planning/">Task_planning</a>,&nbsp;<a href="/tags/survey/">Survey</a></div></div>
</article><article class="single summary" itemscope itemtype="http://schema.org/Article"><h1 class="single-title" itemprop="name headline">
        <a href="/gather%E5%92%8Cscatter/">gather和scatter</a>
    </h1><div class="post-meta"><span class="post-author"><a href="/" title="Author" rel="author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>vllbc</a></span>&nbsp;<span class="post-publish">发布于 <time datetime="2024-12-20">2024-12-20</time></span>&nbsp;<span class="post-category">收录于 <a href="/categories/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Categories</a>&nbsp;<a href="/categories/coding/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Coding</a>&nbsp;<a href="/categories/torch/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Torch</a></span></div><div class="content"><h2 id="gather">gather</h2>
<p>参数：</p>
<ul>
<li><strong>input</strong> (<a
href="https://link.zhihu.com/?target=https%3A//pytorch.org/docs/stable/tensors.html%23torch.Tensor">Tensor</a>)
– the source tensor</li>
<li><strong>dim</strong> (<a
href="https://link.zhihu.com/?target=https%3A//docs.python.org/3/library/functions.html%23int">int</a>)
– the axis along which to index</li>
<li><strong>index</strong> (<em>LongTensor</em>) – the indices of
elements to gather</li>
<li><strong>out</strong> (<a
href="https://link.zhihu.com/?target=https%3A//pytorch.org/docs/stable/tensors.html%23torch.Tensor">Tensor</a>_,__optional_)
– the destination tensor</li>
<li><strong>sparse_grad</strong> (<a
href="https://link.zhihu.com/?target=https%3A//docs.python.org/3/library/functions.html%23bool">bool</a><em>,optional</em>)
– If <code>True</code>, gradient w.r.t. <code>input</code> will be a
sparse tensor. &gt;
gather操作是scatter操作的<strong>逆操作</strong>，如果说scatter是根据index和src求self(<em>input</em>)，那么gather操作是根据self(input)和index求src。具体来说gather操作是根据index指出的索引，沿dim指定的轴收集input的值。</li>
</ul>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>out[i][j][k] <span class="op">=</span> <span class="bu">input</span>[index[i][j][k]][j][k]  <span class="co"># if dim == 0</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>out[i][j][k] <span class="op">=</span> <span class="bu">input</span>[i][index[i][j][k]][k]  <span class="co"># if dim == 1</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>out[i][j][k] <span class="op">=</span> <span class="bu">input</span>[i][j][index[i][j][k]]  <span class="co"># if dim == 2</span></span></code></pre></div>
<p>对于gather操作来说，有三个约束需要满足：</p></div><div class="post-footer">
        <a href="/gather%E5%92%8Cscatter/">阅读全文</a><div class="post-tags">
                <i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/coding/">Coding</a>,&nbsp;<a href="/tags/gather/">Gather</a>,&nbsp;<a href="/tags/scatter/">Scatter</a></div></div>
</article><article class="single summary" itemscope itemtype="http://schema.org/Article"><h1 class="single-title" itemprop="name headline">
        <a href="/llama%E7%B3%BB%E5%88%97/">llama系列</a>
    </h1><div class="post-meta"><span class="post-author"><a href="/" title="Author" rel="author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>vllbc</a></span>&nbsp;<span class="post-publish">发布于 <time datetime="2024-09-26">2024-09-26</time></span>&nbsp;<span class="post-category">收录于 <a href="/categories/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Categories</a>&nbsp;<a href="/categories/llm/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>LLM</a>&nbsp;<a href="/categories/nlp/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>NLP</a></span></div><div class="content"><h1 id="llama介绍">LLaMA介绍</h1>
<p>LLaMA 是目前为止，效果最好的开源 LLM 之一。</p>
<blockquote>
<p><strong>论文的核心思想：相比于GPT，更小的模型+更多的训练数据</strong>**也可以获得可比的效果</p>
</blockquote>
<p>基于更多 tokens
的训练集，在各种推理预算下，训练出性能最佳的一系列语言模型，称为
<code>LLaMA</code>，参数范围从 7B 到 65B 不等，与现有最佳 LLM
相比，其性能是有竞争力的。比如，LLaMA-13B 在大多数基准测试中优于
GPT-3，尽管其尺寸只有 GPT-3 的十分之一。作者相信，LLaMA 将有助于使 LLM
的使用和研究平民化，因为它可以在单个 GPU
上运行！在规模较大的情况下，LLaMA-65B 也具有与最佳大型语言模型（如
Chinchilla 或 PaLM-540B）相竞争的能力。</p></div><div class="post-footer">
        <a href="/llama%E7%B3%BB%E5%88%97/">阅读全文</a><div class="post-tags">
                <i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/llm/">LLM</a>,&nbsp;<a href="/tags/nlp/">NLP</a>,&nbsp;<a href="/tags/llama/">Llama</a></div></div>
</article><article class="single summary" itemscope itemtype="http://schema.org/Article"><h1 class="single-title" itemprop="name headline">
        <a href="/generate%E7%9B%B8%E5%85%B3/">frequency_penalty&presence_penalty</a>
    </h1><div class="post-meta"><span class="post-author"><a href="/" title="Author" rel="author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>vllbc</a></span>&nbsp;<span class="post-publish">发布于 <time datetime="2024-09-05">2024-09-05</time></span>&nbsp;<span class="post-category">收录于 <a href="/categories/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Categories</a>&nbsp;<a href="/categories/llm/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>LLM</a>&nbsp;<a href="/categories/generate/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Generate</a></span></div><div class="content"><p>wLLM解码时采用的自回归采样，其过程如下：</p>
<ol type="1">
<li>小模型使用前缀作为输入，将输出结果处理+归一化成<a
href="https://zhida.zhihu.com/search?content_id=232876036&amp;content_type=Article&amp;match_order=1&amp;q=%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83&amp;zhida_source=entity">概率分布</a>后，采样生成下一个token。</li>
<li>将生成的token和前缀拼接成新的前缀，重复执行1，直到生成EOS或者达到最大token数目。</li>
</ol>
<p>将模型输出logits的转换成概率，有几种常用的采样方法，包括argmax、<a
href="https://zhida.zhihu.com/search?content_id=232876036&amp;content_type=Article&amp;match_order=1&amp;q=top-k&amp;zhida_source=entity">top-k</a>和top-n等
# 贪心搜索
直接选择概率最高的单词。这种方法简单高效，但是可能会导致生成的文本过于单调和重复
# 随机采样
按照概率分布随机选择一个单词。这种方法可以增加生成的多样性，但是可能会导致生成的文本不连贯和无意义。
# beam search 维护一个大小为 k
的候选序列集合，每一步从每个候选序列的概率分布中选择概率最高的 k
个单词，然后保留总概率最高的 k
个候选序列。这种方法可以平衡生成的质量和多样性，但是可能会导致生成的文本过于保守和不自然。
# top-k <img
src="https://cdn.jsdelivr.net/gh/vllbc/img4blog//image/20240927155937.png"
alt="image.png" /></p></div><div class="post-footer">
        <a href="/generate%E7%9B%B8%E5%85%B3/">阅读全文</a><div class="post-tags">
                <i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/llm/">LLM</a>,&nbsp;<a href="/tags/generate/">Generate</a></div></div>
</article><article class="single summary" itemscope itemtype="http://schema.org/Article"><h1 class="single-title" itemprop="name headline">
        <a href="/rwkv/">rwkv</a>
    </h1><div class="post-meta"><span class="post-author"><a href="/" title="Author" rel="author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>vllbc</a></span>&nbsp;<span class="post-publish">发布于 <time datetime="2024-09-04">2024-09-04</time></span>&nbsp;<span class="post-category">收录于 <a href="/categories/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Categories</a>&nbsp;<a href="/categories/llm/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>LLM</a></span></div><div class="content"><h1 id="线性transformer">线性Transformer</h1>
<p><span class="math display">\[V_i&#39;=\frac{\sum_{j=1}^N
sim(Q_i,K_j)V_j}{\sum_{j=1}^N sim(Q_i,K_j)}\]</span> 注意下标i。
其中</p>
<p><span
class="math display">\[sim(Q_{i},K_{j})=\phi(Q_{i},K_{j})\]</span></p>
<p>此时有：</p>
<p><span
class="math display">\[V_{i}^{\prime}=\frac{\phi(Q_{i})\sum_{j=1}^{i}\phi(K_{j})^{T}V_{j}}{\phi(Q_{i})\sum_{j=1}^{i}\phi(K_{j})^{T}}\]</span></p>
<p>注意可以将<span
class="math inline">\(\phi(Q_{i})\)</span>提出来。</p>
<p>原始Transformer的计算复杂度随序列长N呈二次方增长，这是因为attention的计算包含两层for循环，外层是对于每一个Query，我们需要计算它对应token的新表征；内层for循环是为了计算每一个Query对应的新表征，需要让该Query与每一个Key进行计算。
所以外层是 for q in Queries，内层是 for k in
Keys。Queries数量和Keys数量都是N，所以复杂度是 O(N^2) 。而Linear
Transformer，它只有外层for q in
Queries这个循环了。因为求和项的计算与i无关，所以所有的 Qi
可以共享求和项的值。换言之，求和项的值可以只计算一次，然后存在内存中供所有
Qi 去使用。所以Linear Transformer的计算复杂度是O(N) 。</p></div><div class="post-footer">
        <a href="/rwkv/">阅读全文</a><div class="post-tags">
                <i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/llm/">LLM</a>,&nbsp;<a href="/tags/rwkv/">Rwkv</a></div></div>
</article><article class="single summary" itemscope itemtype="http://schema.org/Article"><h1 class="single-title" itemprop="name headline">
        <a href="/rope/">rope</a>
    </h1><div class="post-meta"><span class="post-author"><a href="/" title="Author" rel="author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>vllbc</a></span>&nbsp;<span class="post-publish">发布于 <time datetime="2024-08-31">2024-08-31</time></span>&nbsp;<span class="post-category">收录于 <a href="/categories/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Categories</a>&nbsp;<a href="/categories/llm/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>LLM</a></span></div><div class="content"><h1 id="证明">证明</h1>
<p>核心思想就是找到一个转换，可以通过点积操作将位置信息注入，即： <span
class="math display">\[&lt;f_q\left(x_m,m\right),f_k\left(x_n,n\right)&gt;=g\left(x_m,x_n,m-n\right)\]</span>
而通过复数的一些性质，找到了满足上述操作的转换：</p>
<p><span class="math display">\[\begin{aligned}
&amp;f_{q}\left(\boldsymbol{x}_{m},m\right)=\left(\boldsymbol{W}_{q}\boldsymbol{x}_{m}\right)e^{im\theta}
\\
&amp;f_{k}\left(\boldsymbol{x}_{n},n\right)=\left(\boldsymbol{W}_{k}\boldsymbol{x}_{n}\right)e^{in\theta}
\\
&amp;g\left(\boldsymbol{x}_{m},\boldsymbol{x}_{n},m-n\right)=\mathrm{Re}\left[\left(\boldsymbol{W}_{q}\boldsymbol{x}_{m}\right)\left(\boldsymbol{W}_{k}\boldsymbol{x}_{n}\right)^{*}e^{i(m-n)\theta}\right]
\end{aligned}\]</span> 可以发现g函数中存在相对位置信息。 欧拉公式：<span
class="math inline">\(e^{ix}=\cos x+i\sin x\)</span></p></div><div class="post-footer">
        <a href="/rope/">阅读全文</a><div class="post-tags">
                <i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/llm/">LLM</a></div></div>
</article><article class="single summary" itemscope itemtype="http://schema.org/Article"><h1 class="single-title" itemprop="name headline">
        <a href="/data-engineering-for-scaling-language-models-to-128k-context/">Data Engineering for Scaling Language Models to 128K Context</a>
    </h1><div class="post-meta"><span class="post-author"><a href="/" title="Author" rel="author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>vllbc</a></span>&nbsp;<span class="post-publish">发布于 <time datetime="2024-08-08">2024-08-08</time></span>&nbsp;<span class="post-category">收录于 <a href="/categories/reading/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Reading</a></span></div><div class="content"><p>好的，非常荣幸能以专家的身份，与您一同深入探讨这篇在长上下文（Long
Context）领域具有重要影响力的论文——《Data Engineering for Scaling
Language Models to 128K Context》。</p></div><div class="post-footer">
        <a href="/data-engineering-for-scaling-language-models-to-128k-context/">阅读全文</a><div class="post-tags">
                <i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/%E6%96%87%E7%8C%AE/">文献</a>,&nbsp;<a href="/tags/llm/">LLM</a></div></div>
</article><article class="single summary" itemscope itemtype="http://schema.org/Article"><h1 class="single-title" itemprop="name headline">
        <a href="/kv-cache/">KV cache</a>
    </h1><div class="post-meta"><span class="post-author"><a href="/" title="Author" rel="author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>vllbc</a></span>&nbsp;<span class="post-publish">发布于 <time datetime="2024-08-07">2024-08-07</time></span>&nbsp;<span class="post-category">收录于 <a href="/categories/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Categories</a></span></div><div class="content"><h1 id="kv-cache">KV cache</h1>
<p><img
src="https://cdn.jsdelivr.net/gh/vllbc/img4blog//image/20240916121501.png"
alt="image.png" /> <img
src="https://cdn.jsdelivr.net/gh/vllbc/img4blog//image/20240916121505.png"
alt="image.png" /> <img
src="https://cdn.jsdelivr.net/gh/vllbc/img4blog//image/20240916121510.png"
alt="image.png" /></p>
<p>LLM推理过程分为Prefill和Decode两个阶段，其中Prefill阶段会对Prompt中所有的token做<a
href="https://zhida.zhihu.com/search?q=%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97&amp;zhida_source=entity&amp;is_preview=1">并行计算</a>，得到Prompt中所有Tokens的KV
Cache以及计算得到首Token。Prompt阶段Token计算得到的KV
Cache会保存下来，留给Decode阶段复用，Decode阶段是一个自回归过程，每decode一个新的Token，都需要用到所有之前计算得到的KV
Cache来计算当前query
token的Attention。因此，当输出长度越来越大或者context很长时，KV
Cache将会占用大量的显存。<strong>如何优化KV
Cache的显存占用，一直都是LLM推理的核心主题之一。</strong></p></div><div class="post-footer">
        <a href="/kv-cache/">阅读全文</a></div>
</article><article class="single summary" itemscope itemtype="http://schema.org/Article"><h1 class="single-title" itemprop="name headline">
        <a href="/lora%E5%BE%AE%E8%B0%83/">Lora微调</a>
    </h1><div class="post-meta"><span class="post-author"><a href="/" title="Author" rel="author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>vllbc</a></span>&nbsp;<span class="post-publish">发布于 <time datetime="2024-08-07">2024-08-07</time></span>&nbsp;<span class="post-category">收录于 <a href="/categories/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Categories</a></span></div><div class="content"><p><a href="https://arxiv.org/abs/2106.09685">Low-Rank Adaption
(LoRA)</a>，即“低秩适配”，实现了预训练模型的参数高效微调，且不会增加模型的推理延迟。
## 内在维度 2020年，A.
Aghajanyan等人研究了这一现象，发现预训练模型存在一个较低的”内在维度”,使用少量样本微调时，实际上是在更新低维空间中的参数。把预训练模型的全部参数看成一个D维参数向量，记为<span
class="math inline">\(\Theta^\mathrm{(D)}\)</span>,模型的原始参数为<span
class="math inline">\(\Theta_0^\mathrm{(D)}\)</span>,设<span
class="math inline">\(\Theta^{(d)}\)</span>是d维子空间中的一个向量，d&lt;D,利用一个固定的D*d映射矩阵P
把d维空间中的向量映射到D维空间，<span
class="math inline">\(\Theta^{(\mathrm{D})}\)</span>可写为：</p></div><div class="post-footer">
        <a href="/lora%E5%BE%AE%E8%B0%83/">阅读全文</a></div>
</article><ul class="pagination"><li class="page-item ">
                    <span class="page-link">
                        <a href="/">1</a>
                    </span>
                </li><li class="page-item ">
                    <span class="page-link" aria-hidden="true">&hellip;</span>
                </li><li class="page-item ">
                    <span class="page-link">
                        <a href="/page/7/">7</a>
                    </span>
                </li><li class="page-item ">
                    <span class="page-link">
                        <a href="/page/8/">8</a>
                    </span>
                </li><li class="page-item active">
                    <span class="page-link">
                        <a href="/page/9/">9</a>
                    </span>
                </li><li class="page-item ">
                    <span class="page-link">
                        <a href="/page/10/">10</a>
                    </span>
                </li><li class="page-item ">
                    <span class="page-link">
                        <a href="/page/11/">11</a>
                    </span>
                </li><li class="page-item ">
                    <span class="page-link" aria-hidden="true">&hellip;</span>
                </li><li class="page-item ">
                    <span class="page-link">
                        <a href="/page/25/">25</a>
                    </span>
                </li></ul></div></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line" itemscope itemtype="http://schema.org/CreativeWork"><i class="far fa-copyright fa-fw" aria-hidden="true"></i><span itemprop="copyrightYear">2020 - 2025</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank"></a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="回到顶部">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a>
        </div>

        <div id="fixed-buttons-hidden"><a href="#" id="view-comments" class="fixed-button" title="查看评论">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/css/lightgallery-bundle.min.css"><script src="https://cdn.jsdelivr.net/npm/autocomplete.js@0.38.1/dist/autocomplete.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lunr@2.3.9/lunr.min.js"></script><script src="/lib/lunr/lunr.stemmer.support.min.js"></script><script src="/lib/lunr/lunr.zh.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/plugins/thumbnail/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/plugins/zoom/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js"></script><script src="https://cdn.jsdelivr.net/npm/sharer.js@0.5.2/sharer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/typeit@8.6.0/dist/index.umd.js"></script><script>window.config={"data":{"id-1":"NLP、任务规划、世界模型"},"lightgallery":true,"search":{"highlightTag":"em","lunrIndexURL":"/index.json","lunrLanguageCode":"zh","lunrSegmentitURL":"/lib/lunr/lunr.segmentit.js","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"lunr"},"typeit":{"cursorChar":"|","cursorSpeed":1000,"data":{"id-1":["id-1"]},"duration":-1,"speed":100}};</script><script src="/js/theme.min.js"></script></body>
</html>
