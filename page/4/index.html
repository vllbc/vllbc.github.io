<!DOCTYPE html>
<html lang="zh-CN">
    <head>
	<meta name="generator" content="Hugo 0.105.0">
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title>vllbc02</title><meta name="Description" content="vllbc&#39;s blog"><meta property="og:title" content="vllbc02" />
<meta property="og:description" content="vllbc&#39;s blog" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://vllbc.top/" /><meta property="og:image" content="https://vllbc.top/logo.png"/><meta property="og:site_name" content="vllbc02" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://vllbc.top/logo.png"/>

<meta name="twitter:title" content="vllbc02"/>
<meta name="twitter:description" content="vllbc&#39;s blog"/>
<meta name="application-name" content="vllbc02">
<meta name="apple-mobile-web-app-title" content="vllbc02"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://vllbc.top/" /><link rel="alternate" href="/index.xml" type="application/rss+xml" title="vllbc02">
    <link rel="feed" href="/index.xml" type="application/rss+xml" title="vllbc02"><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css"></noscript><link rel="preload" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "WebSite",
        "url": "https:\/\/vllbc.top\/","inLanguage": "zh-CN","author": {
                "@type": "Person",
                "name": "vllbc"
            },"description": "vllbc's blog","image": {
                "@type": "ImageObject",
                "url": "https:\/\/vllbc.top\/images\/Apple-Devices-Preview.png",
                "width":  3200 ,
                "height":  2048 
            },"thumbnailUrl": "https:\/\/vllbc.top\/images\/screenshot.png","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","name": "vllbc02"
    }
    </script></head>
    <body data-header-desktop="fixed" data-header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="vllbc02"><img
        class="lazyload logo"
        src="/svg/loading.min.svg"
        data-src="/images/logo.png"
        data-srcset="/images/logo.png, /images/logo.png 1.5x, /images/logo.png 2x"
        data-sizes="auto"
        alt="/images/logo.png"
        title="/images/logo.png" />vllbc02</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> 所有文章 </a><a class="menu-item" href="/tags/"> 标签 </a><a class="menu-item" href="/categories/"> 分类 </a><a class="menu-item" href="/about/"> 关于 </a><a class="menu-item" href="https://github.com/dillonzq/LoveIt" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw' aria-hidden='true'></i>  </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="vllbc02"><img
        class="lazyload logo"
        src="/svg/loading.min.svg"
        data-src="/images/logo.png"
        data-srcset="/images/logo.png, /images/logo.png 1.5x, /images/logo.png 2x"
        data-sizes="auto"
        alt="/images/logo.png"
        title="/images/logo.png" />vllbc02</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        取消
                    </a>
                </div><a class="menu-item" href="/posts/" title="">所有文章</a><a class="menu-item" href="/tags/" title="">标签</a><a class="menu-item" href="/categories/" title="">分类</a><a class="menu-item" href="/about/" title="">关于</a><a class="menu-item" href="https://github.com/dillonzq/LoveIt" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw' aria-hidden='true'></i></a><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a></div>
    </div>
</header><div class="search-dropdown desktop">
        <div id="search-dropdown-desktop"></div>
    </div>
    <div class="search-dropdown mobile">
        <div id="search-dropdown-mobile"></div>
    </div><main class="main">
                <div class="container"><div class="page home" data-home="posts"><div class="home-profile"><div class="home-avatar"><a href="/posts/" title="所有文章"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="/images/avatar.png"
        data-srcset="/images/avatar.png, /images/avatar.png 1.5x, /images/avatar.png 2x"
        data-sizes="auto"
        alt="/images/avatar.png"
        title="/images/avatar.png" width="1080" height="1080" /></a></div><h1 class="home-title">vllbc</h1><div class="home-subtitle"><div id="id-1" class="typeit"></div></div><div class="links"><a href="https://github.com/vllbc" title="GitHub" target="_blank" rel="noopener noreffer me"><i class="fab fa-github fa-fw" aria-hidden="true"></i></a><a href="https://steamcommunity.com/id/vllbc" title="Steam" target="_blank" rel="noopener noreffer me"><i class="fab fa-steam fa-fw" aria-hidden="true"></i></a><a href="tel:18265090197" title="Phone" rel="me"><i class="fas fa-phone fa-fw" aria-hidden="true"></i></a><a href="mailto:m18265090197@163.com" title="Email" rel="me"><i class="far fa-envelope fa-fw" aria-hidden="true"></i></a><a href="/index.xml" title="RSS" target="_blank" rel="noopener noreffer me"><i class="fas fa-rss fa-fw" aria-hidden="true"></i></a></div></div>
<article class="single summary" itemscope itemtype="http://schema.org/Article"><h1 class="single-title" itemprop="name headline">
        <a href="/adam%E7%AE%97%E6%B3%95/">Adam算法</a>
    </h1><div class="post-meta"><span class="post-author"><a href="https://vllbc.top" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>vllbc</a></span>&nbsp;<span class="post-publish">发布于 <time datetime="2022-07-31">2022-07-31</time></span>&nbsp;<span class="post-category">收录于 <a href="/categories/deep-learning/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Deep Learning</a>&nbsp;<a href="/categories/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>优化算法</a></span></div><div class="content">Adam算法 背景 作为机器学习的初学者必然会接触梯度下降算法以及SGD，基本上形式如下： $$ \theta_t = \theta_{t-1} - \alpha ;g(\theta) $$ 其中$\alpha$为学习率，$g(\</div><div class="post-footer">
        <a href="/adam%E7%AE%97%E6%B3%95/">阅读全文</a><div class="post-tags">
                <i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/deep-learning/">Deep Learning</a>,&nbsp;<a href="/tags/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/">优化算法</a></div></div>
</article><article class="single summary" itemscope itemtype="http://schema.org/Article"><h1 class="single-title" itemprop="name headline">
        <a href="/bm25/">BM25</a>
    </h1><div class="post-meta"><span class="post-author"><a href="https://vllbc.top" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>vllbc</a></span>&nbsp;<span class="post-publish">发布于 <time datetime="2022-07-30">2022-07-30</time></span>&nbsp;<span class="post-category">收录于 <a href="/categories/nlp/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>NLP</a></span></div><div class="content">BM25算法 BM25算法，通常用来作搜索相关性平分。一句话概况其主要思想：对Query进行语素解析，生成语素qi；然后，对于每个搜索结果D，</div><div class="post-footer">
        <a href="/bm25/">阅读全文</a><div class="post-tags">
                <i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/nlp/">NLP</a></div></div>
</article><article class="single summary" itemscope itemtype="http://schema.org/Article"><h1 class="single-title" itemprop="name headline">
        <a href="/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/">梯度下降法</a>
    </h1><div class="post-meta"><span class="post-author"><a href="https://vllbc.top" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>vllbc</a></span>&nbsp;<span class="post-publish">发布于 <time datetime="2022-07-30">2022-07-30</time></span>&nbsp;<span class="post-category">收录于 <a href="/categories/deep-learning/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Deep Learning</a>&nbsp;<a href="/categories/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>优化算法</a></span></div><div class="content">梯度下降法 简介 批度梯度下降 其实就是一次将整个数据集进行梯度下降的迭代 随机梯度下降 就是对样本进行循环，每循环一个样本就更新一次参数，但是不容易</div><div class="post-footer">
        <a href="/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/">阅读全文</a><div class="post-tags">
                <i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/deep-learning/">Deep Learning</a>,&nbsp;<a href="/tags/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/">优化算法</a></div></div>
</article><article class="single summary" itemscope itemtype="http://schema.org/Article"><h1 class="single-title" itemprop="name headline">
        <a href="/bert/">BERT</a>
    </h1><div class="post-meta"><span class="post-author"><a href="https://vllbc.top" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>vllbc</a></span>&nbsp;<span class="post-publish">发布于 <time datetime="2022-07-29">2022-07-29</time></span>&nbsp;<span class="post-category">收录于 <a href="/categories/nlp/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>NLP</a></span></div><div class="content">Bert BERT 的模型架构非常简单，你已经知道它是如何工作的：它只是 Transformer 的编码器。新的是训练目标和 BERT 用于下游任务的方式。 我们如何使用纯文本训练（双向）编码</div><div class="post-footer">
        <a href="/bert/">阅读全文</a><div class="post-tags">
                <i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/nlp/">NLP</a></div></div>
</article><article class="single summary" itemscope itemtype="http://schema.org/Article"><h1 class="single-title" itemprop="name headline">
        <a href="/cove/">CoVe</a>
    </h1><div class="post-meta"><span class="post-author"><a href="https://vllbc.top" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>vllbc</a></span>&nbsp;<span class="post-publish">发布于 <time datetime="2022-07-29">2022-07-29</time></span>&nbsp;<span class="post-category">收录于 <a href="/categories/nlp/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>NLP</a></span></div><div class="content">CoVe Cove代表上下文向量，它是一种有监督的预训练模型，其主要思想就是训练了一个NMT系统，并使用它的编码器， 模型训练 主要假设是，为了翻译一个</div><div class="post-footer">
        <a href="/cove/">阅读全文</a><div class="post-tags">
                <i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/nlp/">NLP</a></div></div>
</article><article class="single summary" itemscope itemtype="http://schema.org/Article"><h1 class="single-title" itemprop="name headline">
        <a href="/elmo/">ELMo</a>
    </h1><div class="post-meta"><span class="post-author"><a href="https://vllbc.top" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>vllbc</a></span>&nbsp;<span class="post-publish">发布于 <time datetime="2022-07-29">2022-07-29</time></span>&nbsp;<span class="post-category">收录于 <a href="/categories/nlp/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>NLP</a></span></div><div class="content">ELMo 在Transformer中提到了ELMo解决了word2vec中存在的多义词问题，其使用双向的LSTM作为特征提取器，考虑了上下文的语义，</div><div class="post-footer">
        <a href="/elmo/">阅读全文</a><div class="post-tags">
                <i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/nlp/">NLP</a></div></div>
</article><article class="single summary" itemscope itemtype="http://schema.org/Article"><h1 class="single-title" itemprop="name headline">
        <a href="/gpt/">GPT</a>
    </h1><div class="post-meta"><span class="post-author"><a href="https://vllbc.top" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>vllbc</a></span>&nbsp;<span class="post-publish">发布于 <time datetime="2022-07-29">2022-07-29</time></span>&nbsp;<span class="post-category">收录于 <a href="/categories/nlp/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>NLP</a></span></div><div class="content">GPT 预训练(从左到右的 Transformer 语言模型) GPT 是一种基于 Transformer 的从左到右的语言模型。该架构是一个 12 层的 Transformer 解码器（没有解码器-编码器）。 模型架构 就是12层的t</div><div class="post-footer">
        <a href="/gpt/">阅读全文</a><div class="post-tags">
                <i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/nlp/">NLP</a></div></div>
</article><article class="single summary" itemscope itemtype="http://schema.org/Article"><h1 class="single-title" itemprop="name headline">
        <a href="/svm/">SVM</a>
    </h1><div class="post-meta"><span class="post-author"><a href="https://vllbc.top" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>vllbc</a></span>&nbsp;<span class="post-publish">发布于 <time datetime="2022-07-29">2022-07-29</time></span>&nbsp;<span class="post-category">收录于 <a href="/categories/machine-learning/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Machine Learning</a>&nbsp;<a href="/categories/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>分类算法</a></span></div><div class="content">SVM kernel 介绍 其实核函数和映射关系并不大，kernel可以看作是一个运算技巧。 一般认为，原本在低维线性不可分的数据集在足够高的维度存在线性可分的超</div><div class="post-footer">
        <a href="/svm/">阅读全文</a><div class="post-tags">
                <i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/machine-learning/">Machine Learning</a>,&nbsp;<a href="/tags/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/">分类算法</a></div></div>
</article><article class="single summary" itemscope itemtype="http://schema.org/Article"><h1 class="single-title" itemprop="name headline">
        <a href="/%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90/">线性判别分析</a>
    </h1><div class="post-meta"><span class="post-author"><a href="https://vllbc.top" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>vllbc</a></span>&nbsp;<span class="post-publish">发布于 <time datetime="2022-07-29">2022-07-29</time></span>&nbsp;<span class="post-category">收录于 <a href="/categories/machine-learning/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Machine Learning</a>&nbsp;<a href="/categories/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>分类算法</a></span></div><div class="content">线性判别分析(LDA) 线性判别分析，也就是LDA（与主题模型中的LDA区分开），现在常常用于数据的降维中，但从它的名字中可以看出来它也是一个</div><div class="post-footer">
        <a href="/%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90/">阅读全文</a><div class="post-tags">
                <i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/machine-learning/">Machine Learning</a>,&nbsp;<a href="/tags/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/">分类算法</a></div></div>
</article><article class="single summary" itemscope itemtype="http://schema.org/Article"><h1 class="single-title" itemprop="name headline">
        <a href="/%E5%89%8D%E7%BC%80%E6%A0%91/">前缀树</a>
    </h1><div class="post-meta"><span class="post-author"><a href="https://vllbc.top" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>vllbc</a></span>&nbsp;<span class="post-publish">发布于 <time datetime="2022-07-27">2022-07-27</time></span>&nbsp;<span class="post-category">收录于 <a href="/categories/%E9%9D%A2%E7%BB%8F/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>面经</a></span></div><div class="content">什么是前缀树？ 前缀树是N叉树的一种特殊形式。通常来说，一个前缀树是用来存储字符串的。前缀树的每一个节点代表一个字符串（前缀）。每一个节点会有</div><div class="post-footer">
        <a href="/%E5%89%8D%E7%BC%80%E6%A0%91/">阅读全文</a><div class="post-tags">
                <i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/%E9%9D%A2%E7%BB%8F/">面经</a></div></div>
</article><article class="single summary" itemscope itemtype="http://schema.org/Article"><h1 class="single-title" itemprop="name headline">
        <a href="/lr%E4%B8%BA%E4%BB%80%E4%B9%88%E7%94%A8%E4%BA%A4%E5%8F%89%E7%86%B5/">LR为什么用交叉熵</a>
    </h1><div class="post-meta"><span class="post-author"><a href="https://vllbc.top" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>vllbc</a></span>&nbsp;<span class="post-publish">发布于 <time datetime="2022-07-26">2022-07-26</time></span>&nbsp;<span class="post-category">收录于 <a href="/categories/%E9%9D%A2%E7%BB%8F/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>面经</a></span></div><div class="content">关于损失函数的问题，之前也有很多疑惑。看了网上的很多博客，有从很多角度出发来讲解的，看的也是云里雾里。现在大致做一下整理。 对于最小二乘，为什</div><div class="post-footer">
        <a href="/lr%E4%B8%BA%E4%BB%80%E4%B9%88%E7%94%A8%E4%BA%A4%E5%8F%89%E7%86%B5/">阅读全文</a><div class="post-tags">
                <i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/%E9%9D%A2%E7%BB%8F/">面经</a></div></div>
</article><article class="single summary" itemscope itemtype="http://schema.org/Article"><h1 class="single-title" itemprop="name headline">
        <a href="/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0/">分类算法概述</a>
    </h1><div class="post-meta"><span class="post-author"><a href="https://vllbc.top" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>vllbc</a></span>&nbsp;<span class="post-publish">发布于 <time datetime="2022-07-21">2022-07-21</time></span>&nbsp;<span class="post-category">收录于 <a href="/categories/machine-learning/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Machine Learning</a>&nbsp;<a href="/categories/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>分类算法</a></span></div><div class="content">分类算法 主要区分一下生成模型和判别模型，首先要知道生成模型和判别模型都属于监督学习，即样本有其对应的标签的。还有一个概念就是硬分类和软分类，</div><div class="post-footer">
        <a href="/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0/">阅读全文</a><div class="post-tags">
                <i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/machine-learning/">Machine Learning</a>,&nbsp;<a href="/tags/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/">分类算法</a></div></div>
</article><ul class="pagination"><li class="page-item ">
                    <span class="page-link">
                        <a href="/">1</a>
                    </span>
                </li><li class="page-item ">
                    <span class="page-link">
                        <a href="/page/2/">2</a>
                    </span>
                </li><li class="page-item ">
                    <span class="page-link">
                        <a href="/page/3/">3</a>
                    </span>
                </li><li class="page-item active">
                    <span class="page-link">
                        <a href="/page/4/">4</a>
                    </span>
                </li><li class="page-item ">
                    <span class="page-link">
                        <a href="/page/5/">5</a>
                    </span>
                </li><li class="page-item ">
                    <span class="page-link">
                        <a href="/page/6/">6</a>
                    </span>
                </li><li class="page-item ">
                    <span class="page-link" aria-hidden="true">&hellip;</span>
                </li><li class="page-item ">
                    <span class="page-link">
                        <a href="/page/16/">16</a>
                    </span>
                </li></ul></div></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line" itemscope itemtype="http://schema.org/CreativeWork"><i class="far fa-copyright fa-fw" aria-hidden="true"></i><span itemprop="copyrightYear">2020 - 2022</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="https://vllbc.top" target="_blank">vllbc</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="回到顶部">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="查看评论">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css"><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/autocomplete.js@0.38.1/dist/autocomplete.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/algoliasearch@4.13.1/dist/algoliasearch-lite.umd.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/sharer.js@0.5.1/sharer.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/typeit@8.6.0/dist/index.umd.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/copy-tex.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/mhchem.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"复制到剪贴板","maxShownLines":50},"data":{"id-1":"NLP、信息检索、机器学习"},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"algoliaAppID":"PASDMWALPK","algoliaIndex":"index.zh-cn","algoliaSearchKey":"b42948e51daaa93df92381c8e2ac0f93","highlightTag":"em","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"algolia"},"typeit":{"cursorChar":"|","cursorSpeed":1000,"data":{"id-1":["id-1"]},"duration":-1,"speed":100}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
