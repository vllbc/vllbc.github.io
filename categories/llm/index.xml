<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>LLM - 分类 - vllbc02&#39;s blogs</title>
        <link>https://blog.vllbc.top/categories/llm/</link>
        <description>LLM - 分类 - vllbc02&#39;s blogs</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Fri, 08 Aug 2025 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://blog.vllbc.top/categories/llm/" rel="self" type="application/rss+xml" /><item>
    <title>qwen</title>
    <link>https://blog.vllbc.top/qwen/</link>
    <pubDate>Fri, 08 Aug 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/qwen/</guid>
    <description><![CDATA[<pre class="python3"><code>------------------------------------------------------------------------------------------------------
# Qwen-1
+ Embedding and output projection. (Untied embedding for input embedding and output projection)
+ ROPE
+ QKV bias required
+ Pre-Norm &amp; RMSNorm
+ SwiGLU

------------------------------------------------------------------------------------------------------
# Qwen-2
- Multi-Head Attention

+ MoE
+ Grouped Query Attention
+ Dual Chunk Attention
+ YARN
+ Expert Granularity
+ Expert Routing
+ Expert Initialization
+ Shared Experts

------------------------------------------------------------------------------------------------------
# Qwen-2.5
+ More control tokens. 3 -&gt; 22

------------------------------------------------------------------------------------------------------
# Qwen-3
- QKV bias
- Shared experts

+ QK-Norm
------------------------------------------------------------------------------------------------------</code></pre>
<h2 id="参考">参考</h2>
<p><a href="https://zhuanlan.zhihu.com/p/1933558376689804480">Qwen
各版本主要结构变化</a></p>]]></description>
</item>
<item>
    <title>信用分配</title>
    <link>https://blog.vllbc.top/%E4%BF%A1%E7%94%A8%E5%88%86%E9%85%8D/</link>
    <pubDate>Tue, 05 Aug 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/%E4%BF%A1%E7%94%A8%E5%88%86%E9%85%8D/</guid>
    <description><![CDATA[<p>最近涌现了很多关于信用分配的论文，因此整理一下</p>
<h2 id="first-return-entropy-eliciting-explore"><a
href="../../reading/Reasoning/First%20Return,%20Entropy-Eliciting%20Explore.md">First
Return, Entropy-Eliciting Explore</a></h2>
<h2
id="good-learners-think-their-thinkinggenerative-prm-makes-large-reasoning-model-more-efficient-math-learne"><a
href="../../reading/Reasoning/Good%20Learners%20Think%20Their%20Thinking：Generative%20PRM%20Makes%20Large%20Reasoning%20Model%20More%20Efficient%20Math%20Learne.md">Good
Learners Think Their Thinking：Generative PRM Makes Large Reasoning
Model More Efficient Math Learne</a></h2>
<h2 id="group-sequence-policy-optimization"><a
href="../../reading/LLM-RL/Group%20Sequence%20Policy%20Optimization.md">Group
Sequence Policy Optimization</a></h2>
<h2 id="process-reinforcement-through-implicit-rewards"><a
href="../../reading/Reasoning/PROCESS%20REINFORCEMENT%20THROUGH%20IMPLICIT%20REWARDS.md">PROCESS
REINFORCEMENT THROUGH IMPLICIT REWARDS</a></h2>
<h2
id="rlvmrreinforcement-learning-with-verifiable-meta-reasoning-rewards-for-robust-long-horizon-agents"><a
href="../../reading/Planning/RLVMR：Reinforcement%20Learning%20with%20Verifiable%20Meta-Reasoning%20Rewards%20for%20Robust%20Long-Horizon%20Agents.md">RLVMR：Reinforcement
Learning with Verifiable Meta-Reasoning Rewards for Robust Long-Horizon
Agents</a></h2>
<h2
id="vapoefficient-and-reliable-reinforcement-learning-for-advanced-reasoning-tasks"><a
href="../../reading/LLM-RL/VAPO：Efficient%20and%20Reliable%20Reinforcement%20Learning%20for%20Advanced%20Reasoning%20Tasks.md">VAPO：Efficient
and Reliable Reinforcement Learning for Advanced Reasoning
Tasks</a></h2>
<h2 id="group-in-group-policy-optimization-for-llm-agent-training"><a
href="../../reading/Planning/Group-in-Group%20Policy%20Optimization%20for%20LLM%20Agent%20Training.md">Group-in-Group
Policy Optimization for LLM Agent Training</a></h2>
<h2
id="capotowards-enhancing-llm-reasoning-through-verifiable-generative-credit-assignment"><a
href="../../reading/Reasoning/CAPO：Towards%20Enhancing%20LLM%20Reasoning%20through%20Verifiable%20Generative%20Credit%20Assignment.md">CAPO：Towards
Enhancing LLM Reasoning through Verifiable Generative Credit
Assignment</a></h2>
<h2
id="beyond-policy-optimizationa-data-curation-flywheel-for-sparse-reward-long-horizon-planning"><a
href="../../reading/Planning/Beyond%20Policy%20Optimization：A%20Data%20Curation%20Flywheel%20for%20Sparse-Reward%20Long-Horizon%20Planning.md">Beyond
Policy Optimization：A Data Curation Flywheel for Sparse-Reward
Long-Horizon Planning</a></h2>
<h2
id="gtpo-and-grpo-stoken-and-sequence-level-reward-shaping-with-policy-entropy"><a
href="../../reading/Reasoning/GTPO%20and%20GRPO-S：Token%20and%20Sequence-Level%20Reward%20Shaping%20with%20Policy%20Entropy.md">GTPO
and GRPO-S：Token and Sequence-Level Reward Shaping with Policy
Entropy</a></h2>
<h2
id="gtpotrajectory-based-policy-optimization-in-large-language-models"><a
href="../../reading/Reasoning/GTPO：Trajectory-Based%20Policy%20Optimization%20in%20Large%20Language%20Models.md">GTPO：Trajectory-Based
Policy Optimization in Large Language Models</a></h2>]]></description>
</item>
<item>
    <title>K2</title>
    <link>https://blog.vllbc.top/k2/</link>
    <pubDate>Wed, 30 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/k2/</guid>
    <description><![CDATA[<h2 id="预训练">预训练</h2>
<h3 id="muon-clip">Muon-clip</h3>
<p>详见<a href="../../Deep%20Learning/优化器/Muon.md">Muon</a></p>
<p>通过裁剪权重解决Max-Logit问题，实现稳定训练。</p>
<h3 id="数据增强">数据增强</h3>
<p>通过改写句子来提高token效率，避免重复使用token造成的过拟合，改写方法如下：</p>]]></description>
</item>
<item>
    <title>ALiBi</title>
    <link>https://blog.vllbc.top/alibi/</link>
    <pubDate>Tue, 29 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/alibi/</guid>
    <description><![CDATA[<p>在softmax的结果后添加一个静态的不可学习的偏置项。  q1和k1之间的距离是0，所以对应位置就是0<br />
 q2和k1之间的距离是「相对位置偏移为“<strong>k的索引</strong>”1」 -
「q的索引2」，得到1-2 = -1，就对应到了中间矩阵的取值为-1了<br />
以此类推，相对距离矩阵的中间对角线上都是0，然后左下角的取值都是对应的「k的索引」-「q的索引」了</p>]]></description>
</item>
<item>
    <title>Gemma</title>
    <link>https://blog.vllbc.top/gemma/</link>
    <pubDate>Tue, 29 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/gemma/</guid>
    <description><![CDATA[<h2 id="gemma-3">Gemma 3</h2>
<h3 id="qk-norm">QK-Norm</h3>
<p>简单来说就是在Q和K矩阵上进行RMSNorm，即：</p>
<p><span class="math display">\[
\begin{aligned}
O &amp;= softmax(\bar{Q}\bar{K}^T)V \\
\bar{Q} &amp;=RMSNorm(Q) \\
\bar{K} &amp;=RMSNorm(V)
\end{aligned}\
\]</span></p>
<p>但这种方法的问题是不适用MLA的推理阶段，因为推理阶段的MLA将Wk吸取到了Q中，具体见<a
href="../Attention/MLA.md">MLA</a></p>]]></description>
</item>
<item>
    <title>device_mesh</title>
    <link>https://blog.vllbc.top/device_mesh/</link>
    <pubDate>Sat, 26 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/device_mesh/</guid>
    <description><![CDATA[<h2 id="verl中的device_mesh">verl中的device_mesh</h2>
<p>verl中有3个device_mesh，分别是： - 训练用的FSDP mesh（通常是一维） -
推理用的rollout mesh（包含tp维度） - Ulysses序列并行的mesh（dp×sp）</p>]]></description>
</item>
<item>
    <title>data_parallel</title>
    <link>https://blog.vllbc.top/data_parallel/</link>
    <pubDate>Wed, 23 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/data_parallel/</guid>
    <description><![CDATA[<p>如果想将模型训练扩展到大的批次，则很快就会达到在单个 GPU
上可以做的极限。具体来说，会发生
<code>RuntimeError: CUDA out of memory</code>。 <a
href="梯度累计.md">梯度累计</a>、<a
href="Activation%20checkpointing.md">Activation checkpointing</a> 和 <a
href="CPU%20offloading.md">CPU offloading</a>
都可以一定程度上减少显存的占用，为了_有效地_扩展到更大的模型大小和不断增长的数据集，同时仍然在合理的时间内训练模型，我们需要将计算<strong>分布在</strong>一组机器上。</p>]]></description>
</item>
<item>
    <title>pipeline parallelism</title>
    <link>https://blog.vllbc.top/pipeline-parallelism/</link>
    <pubDate>Wed, 23 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/pipeline-parallelism/</guid>
    <description><![CDATA[<h2 id="参考">参考</h2>
<ul>
<li><a
href="https://cdn-lfs-us-1.hf.co/repos/e7/07/e7077a163ab0f314cedbb8ddd44667d765205ee536e8b4785fdd0872534107db/274a19a2577ed220cd3a102b4469c44310e4a7c8e8f8ebc36842d907cb51e127?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27The_Ultra-Scale_Playbook_Training_LLMs_on_GPU_Clusters.pdf%3B+filename%3D%22The_Ultra-Scale_Playbook_Training_LLMs_on_GPU_Clusters.pdf%22%3B&amp;response-content-type=application%2Fpdf&amp;Expires=1751735939&amp;Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MTczNTkzOX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2U3LzA3L2U3MDc3YTE2M2FiMGYzMTRjZWRiYjhkZGQ0NDY2N2Q3NjUyMDVlZTUzNmU4YjQ3ODVmZGQwODcyNTM0MTA3ZGIvMjc0YTE5YTI1NzdlZDIyMGNkM2ExMDJiNDQ2OWM0NDMxMGU0YTdjOGU4ZjhlYmMzNjg0MmQ5MDdjYjUxZTEyNz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&amp;Signature=jer8tObN1q6%7Eij8fX2vLIiox2VNNX0yAD9hjDxq9JXGDmzou6ONo7lnwIlrn%7ECbbaP-BXm80YdFMAgI2SbINgrxMfxLHTkp5IVwqppQ1INlC8K6JrZS3T8QlL4aY5jY7wX7SCUvweSuxEWA2QXMYwHWWV2Iy-OQAMkcdvvxDvjIZZwlYZqJ0tccDbpSYrOhNfkMcGYyxhp3HPgcEd6gVPydQE6g2wM8ErR04u-9dzwkJrIBowWrr8OSD9HJraRyr5XObTaBx3NEADn9De8Zyo%7EknwQs4MDxWSueQCYTlCfFElMF0%7EVMXYh%7EVfDSV5lZZiuxCFfke43Z12VSK5cMV%7EA__&amp;Key-Pair-Id=K24J24Z295AEI9">The
Ultra-Scale Playbook: Training LLMs on GPU Clusters</a></li>
<li><a
href="https://medium.com/huggingface/training-larger-batches-practical-tips-on-1-gpu-multi-gpu-distributed-setups-ec88c3e51255">💥
Training Neural Nets on Larger Batches: Practical Tips for 1-GPU,
Multi-GPU &amp; Distributed setups | by Thomas Wolf | HuggingFace |
Medium</a></li>
<li><a href="https://www.jeremyjordan.me/distributed-training/">Training
extremely large neural networks across thousands of GPUs.</a></li>
</ul>]]></description>
</item>
<item>
    <title>tensor_parallel</title>
    <link>https://blog.vllbc.top/tensor_parallel/</link>
    <pubDate>Wed, 23 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/tensor_parallel/</guid>
    <description><![CDATA[<h2 id="参考">参考</h2>
<ul>
<li><a
href="https://cdn-lfs-us-1.hf.co/repos/e7/07/e7077a163ab0f314cedbb8ddd44667d765205ee536e8b4785fdd0872534107db/274a19a2577ed220cd3a102b4469c44310e4a7c8e8f8ebc36842d907cb51e127?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27The_Ultra-Scale_Playbook_Training_LLMs_on_GPU_Clusters.pdf%3B+filename%3D%22The_Ultra-Scale_Playbook_Training_LLMs_on_GPU_Clusters.pdf%22%3B&amp;response-content-type=application%2Fpdf&amp;Expires=1751735939&amp;Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MTczNTkzOX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2U3LzA3L2U3MDc3YTE2M2FiMGYzMTRjZWRiYjhkZGQ0NDY2N2Q3NjUyMDVlZTUzNmU4YjQ3ODVmZGQwODcyNTM0MTA3ZGIvMjc0YTE5YTI1NzdlZDIyMGNkM2ExMDJiNDQ2OWM0NDMxMGU0YTdjOGU4ZjhlYmMzNjg0MmQ5MDdjYjUxZTEyNz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&amp;Signature=jer8tObN1q6%7Eij8fX2vLIiox2VNNX0yAD9hjDxq9JXGDmzou6ONo7lnwIlrn%7ECbbaP-BXm80YdFMAgI2SbINgrxMfxLHTkp5IVwqppQ1INlC8K6JrZS3T8QlL4aY5jY7wX7SCUvweSuxEWA2QXMYwHWWV2Iy-OQAMkcdvvxDvjIZZwlYZqJ0tccDbpSYrOhNfkMcGYyxhp3HPgcEd6gVPydQE6g2wM8ErR04u-9dzwkJrIBowWrr8OSD9HJraRyr5XObTaBx3NEADn9De8Zyo%7EknwQs4MDxWSueQCYTlCfFElMF0%7EVMXYh%7EVfDSV5lZZiuxCFfke43Z12VSK5cMV%7EA__&amp;Key-Pair-Id=K24J24Z295AEI9">The
Ultra-Scale Playbook: Training LLMs on GPU Clusters</a></li>
<li><a
href="https://medium.com/huggingface/training-larger-batches-practical-tips-on-1-gpu-multi-gpu-distributed-setups-ec88c3e51255">💥
Training Neural Nets on Larger Batches: Practical Tips for 1-GPU,
Multi-GPU &amp; Distributed setups | by Thomas Wolf | HuggingFace |
Medium</a></li>
<li><a href="https://www.jeremyjordan.me/distributed-training/">Training
extremely large neural networks across thousands of GPUs.</a></li>
</ul>]]></description>
</item>
<item>
    <title>zero</title>
    <link>https://blog.vllbc.top/zero/</link>
    <pubDate>Tue, 22 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/zero/</guid>
    <description><![CDATA[<p>分为zero1、zero2、zero3，虽然zero3对模型进行了分割，但是本质上还是属于数据并行，因为在前向传播和反向传播需要all-gather模型参数，需要完整的模型权重。</p>]]></description>
</item>
</channel>
</rss>
