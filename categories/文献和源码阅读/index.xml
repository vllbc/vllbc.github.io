<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>æ–‡çŒ®å’Œæºç é˜…è¯» - åˆ†ç±» - vllbc02&#39;s blogs</title>
        <link>http://localhost:1313/categories/%E6%96%87%E7%8C%AE%E5%92%8C%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</link>
        <description>æ–‡çŒ®å’Œæºç é˜…è¯» - åˆ†ç±» - vllbc02&#39;s blogs</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Thu, 08 Aug 2024 00:00:00 &#43;0000</lastBuildDate><atom:link href="http://localhost:1313/categories/%E6%96%87%E7%8C%AE%E5%92%8C%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/" rel="self" type="application/rss+xml" /><item>
    <title>Data Engineering for Scaling Language Models to 128K Context</title>
    <link>http://localhost:1313/data-engineering-for-scaling-language-models-to-128k-context/</link>
    <pubDate>Thu, 08 Aug 2024 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>http://localhost:1313/data-engineering-for-scaling-language-models-to-128k-context/</guid>
    <description><![CDATA[<h1
id="data-engineering-for-scaling-language-models-to-128k-context">Data
Engineering for Scaling Language Models to 128K Context</h1>
<hr />
<h2 id="meta-data"><span style="color: #1B5E20"><span
style="background-color: #f1f8e9">ğŸ’¡ Meta Data</span></span></h2>
<table>
<colgroup>
<col style="width: 21%" />
<col style="width: 78%" />
</colgroup>
<thead>
<tr>
<th><span style="background-color: #dbeedd">Title</span></th>
<th><span style="background-color: #dbeedd">Data Engineering for Scaling
Language Models to 128K Context</span></th>
</tr>
</thead>
<tbody>
<tr>
<td><span style="background-color: #f3faf4">Journal</span></td>
<td></td>
</tr>
<tr>
<td><span style="background-color: #dbeedd">Authors</span></td>
<td><span style="background-color: #dbeedd">Yao Fu; Rameswar Panda;
Xinyao Niu; Xiang Yue; Hannaneh Hajishirzi; Yoon Kim; Hao
Peng</span></td>
</tr>
<tr>
<td><span style="background-color: #f3faf4">Pub. date</span></td>
<td><span style="background-color: #f3faf4">2024-02-15</span></td>
</tr>
<tr>
<td><span style="background-color: #dbeedd">æœŸåˆŠæ ‡ç­¾</span></td>
<td></td>
</tr>
<tr>
<td><span style="background-color: #f3faf4">DOI</span></td>
<td><span
style="background-color: #f3faf4"><a href="https://doi.org/10.48550/arXiv.2402.10171" rel="noopener noreferrer nofollow">10.48550/arXiv.2402.10171</a></span></td>
</tr>
<tr>
<td><span style="background-color: #dbeedd">é™„ä»¶</span></td>
<td><span
style="background-color: #dbeedd"><a href="zotero://open-pdf/0_Z5AQISDH" rel="noopener noreferrer nofollow">Fu
et al_2024_Data Engineering for Scaling Language Models to 128K
Context.pdf</a></span></td>
</tr>
</tbody>
</table>
<h2 id="ç ”ç©¶èƒŒæ™¯-åŸºç¡€-ç›®çš„"><span style="color: #E65100"><span
style="background-color: #fff8e1">ğŸ“œ ç ”ç©¶èƒŒæ™¯ &amp; åŸºç¡€ &amp;
ç›®çš„</span></span></h2>
<hr />
<p><span style="color: rgb(6, 6, 7)"><span
style="background-color: rgb(255, 255, 255)">è®ºæ–‡ä¸»è¦ç ”ç©¶äº†å¦‚ä½•é€šè¿‡æ•°æ®å·¥ç¨‹çš„æ–¹æ³•ï¼Œå°†è¯­è¨€æ¨¡å‹çš„ä¸Šä¸‹æ–‡é•¿åº¦æ‰©å±•åˆ°128Kä¸ªtokenã€‚è¿™é¡¹ç ”ç©¶çš„é‡ç‚¹åœ¨äºæ•°æ®å·¥ç¨‹ï¼Œä½œè€…ä»¬æå‡ºäº†ä¸€ä¸ªå‡è®¾ï¼šé•¿ä¸Šä¸‹æ–‡å»ºæ¨¡çš„èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åˆ©ç”¨ä»»æ„è¾“å…¥ä½ç½®ä¿¡æ¯çš„èƒ½åŠ›ï¼Œä¸»è¦æ˜¯é€šè¿‡å¤§è§„æ¨¡é¢„è®­ç»ƒè·å¾—çš„ï¼Œå¹¶ä¸”è¿™ç§èƒ½åŠ›å¯ä»¥é€šè¿‡è½»é‡çº§çš„æŒç»­é¢„è®­ç»ƒåœ¨é€‚å½“çš„æ•°æ®æ··åˆä¸Šæ‰©å±•åˆ°è®­ç»ƒæœŸé—´æœªè§è¿‡çš„æ›´é•¿ä¸Šä¸‹æ–‡ï¼ˆä¾‹å¦‚ï¼Œä»4Kæ‰©å±•åˆ°128Kï¼‰ã€‚</span></span></p>]]></description>
</item>
<item>
    <title>Data Engineering for Scaling Language Models to 128K Context</title>
    <link>http://localhost:1313/data-engineering-for-scaling-language-models-to-128k-context/</link>
    <pubDate>Thu, 08 Aug 2024 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>http://localhost:1313/data-engineering-for-scaling-language-models-to-128k-context/</guid>
    <description><![CDATA[<p>å¥½çš„ï¼Œéå¸¸è£å¹¸èƒ½ä»¥ä¸“å®¶çš„èº«ä»½ï¼Œä¸æ‚¨ä¸€åŒæ·±å…¥æ¢è®¨è¿™ç¯‡åœ¨é•¿ä¸Šä¸‹æ–‡ï¼ˆLong
Contextï¼‰é¢†åŸŸå…·æœ‰é‡è¦å½±å“åŠ›çš„è®ºæ–‡â€”â€”ã€ŠData Engineering for Scaling
Language Models to 128K Contextã€‹ã€‚</p>]]></description>
</item>
<item>
    <title>Transformer Feed-Forward Layers Are Key-Value Memories</title>
    <link>http://localhost:1313/transformer-feed-forward-layers-are-key-value-memories/</link>
    <pubDate>Wed, 07 Aug 2024 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>http://localhost:1313/transformer-feed-forward-layers-are-key-value-memories/</guid>
    <description><![CDATA[<h1
id="transformer-feed-forward-layers-are-key-value-memories">Transformer
Feed-Forward Layers Are Key-Value Memories</h1>
<hr />
<h2 id="meta-data"><span style="color: #1B5E20"><span
style="background-color: #f1f8e9">ğŸ’¡ Meta Data</span></span></h2>
<table>
<colgroup>
<col style="width: 21%" />
<col style="width: 78%" />
</colgroup>
<thead>
<tr>
<th><span style="background-color: #dbeedd">Title</span></th>
<th><span style="background-color: #dbeedd">Transformer Feed-Forward
Layers Are Key-Value Memories</span></th>
</tr>
</thead>
<tbody>
<tr>
<td><span style="background-color: #f3faf4">Journal</span></td>
<td></td>
</tr>
<tr>
<td><span style="background-color: #dbeedd">Authors</span></td>
<td><span style="background-color: #dbeedd">Mor Geva; Roei Schuster;
Jonathan Berant; Omer Levy</span></td>
</tr>
<tr>
<td><span style="background-color: #f3faf4">Pub. date</span></td>
<td><span style="background-color: #f3faf4">2021-09-05</span></td>
</tr>
<tr>
<td><span style="background-color: #dbeedd">æœŸåˆŠæ ‡ç­¾</span></td>
<td></td>
</tr>
<tr>
<td><span style="background-color: #f3faf4">DOI</span></td>
<td><span
style="background-color: #f3faf4"><a href="https://doi.org/10.48550/arXiv.2012.14913" rel="noopener noreferrer nofollow">10.48550/arXiv.2012.14913</a></span></td>
</tr>
<tr>
<td><span style="background-color: #dbeedd">é™„ä»¶</span></td>
<td><span
style="background-color: #dbeedd"><a href="zotero://open-pdf/0_NUWXXUEK" rel="noopener noreferrer nofollow">Geva
et al_2021_Transformer Feed-Forward Layers Are Key-Value
Memories.pdf</a></span></td>
</tr>
</tbody>
</table>
<h2 id="ç ”ç©¶èƒŒæ™¯-åŸºç¡€-ç›®çš„"><span style="color: #E65100"><span
style="background-color: #fff8e1">ğŸ“œ ç ”ç©¶èƒŒæ™¯ &amp; åŸºç¡€ &amp;
ç›®çš„</span></span></h2>
<hr />
<p><span style="color: rgb(6, 6, 7)"><span
style="background-color: rgb(255, 255, 255)">å‰é¦ˆå±‚å æ®äº† Transformer
æ¨¡å‹å‚æ•°çš„ä¸‰åˆ†ä¹‹äºŒï¼Œä½†å…¶åœ¨ç½‘ç»œä¸­çš„ä½œç”¨å°šæœªè¢«å……åˆ†æ¢ç´¢ã€‚ä½œè€…å‘ç°
Transformer è¯­è¨€æ¨¡å‹ä¸­çš„å‰é¦ˆå±‚å¯ä»¥ä½œä¸ºé”®å€¼è®°å¿†ï¼ˆkey-value
memoriesï¼‰æ¥æ“ä½œã€‚æ¯ä¸ªé”®ï¼ˆkeyï¼‰ä¸è®­ç»ƒç¤ºä¾‹ä¸­çš„æ–‡æœ¬æ¨¡å¼ç›¸å…³è”ï¼Œæ¯ä¸ªå€¼ï¼ˆvalueï¼‰åˆ™è¯±å¯¼è¾“å‡ºè¯æ±‡è¡¨ä¸Šçš„æ¦‚ç‡åˆ†å¸ƒã€‚ä½œè€…å‘ç°
Transformer è¯­è¨€æ¨¡å‹ä¸­çš„å‰é¦ˆå±‚å¯ä»¥ä½œä¸ºé”®å€¼è®°å¿†ï¼ˆkey-value
memoriesï¼‰æ¥æ“ä½œã€‚æ¯ä¸ªé”®ï¼ˆkeyï¼‰ä¸è®­ç»ƒç¤ºä¾‹ä¸­çš„æ–‡æœ¬æ¨¡å¼ç›¸å…³è”ï¼Œæ¯ä¸ªå€¼ï¼ˆvalueï¼‰åˆ™è¯±å¯¼è¾“å‡ºè¯æ±‡è¡¨ä¸Šçš„æ¦‚ç‡åˆ†å¸ƒã€‚å‰é¦ˆå±‚çš„è¾“å‡ºæ˜¯å…¶è®°å¿†çš„ç»„åˆï¼Œå¹¶é€šè¿‡æ¨¡å‹å±‚çš„æ®‹å·®è¿æ¥é€æ­¥ç»†åŒ–ï¼Œä»¥äº§ç”Ÿæœ€ç»ˆçš„è¾“å‡ºåˆ†å¸ƒã€‚</span></span></p>]]></description>
</item>
<item>
    <title>Transformer Feed-Forward Layers Are Key-Value Memories</title>
    <link>http://localhost:1313/transformer-feed-forward-layers-are-key-value-memories/</link>
    <pubDate>Wed, 07 Aug 2024 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>http://localhost:1313/transformer-feed-forward-layers-are-key-value-memories/</guid>
    <description><![CDATA[<p>è¿™ç¯‡è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®ï¼Œåœ¨äºå®ƒä¸ºTransformeræ¨¡å‹ä¸­å æ®äº†çº¦ä¸‰åˆ†ä¹‹äºŒå‚æ•°é‡ã€ä½†é•¿æœŸä»¥æ¥å…¶åŠŸèƒ½è¢«ä¸¥é‡å¿½è§†çš„å‰é¦ˆç¥ç»ç½‘ç»œï¼ˆFeed-Forward
Network,
FFNï¼‰å±‚ï¼Œæä¾›äº†ä¸€ä¸ªç®€æ´è€Œæ·±åˆ»çš„è§£é‡Šæ¡†æ¶ã€‚åœ¨æ­¤ä¹‹å‰ï¼Œå­¦æœ¯ç•Œçš„ç›®å…‰å¤§å¤šèšç„¦äºè‡ªæ³¨æ„åŠ›ï¼ˆSelf-Attentionï¼‰æœºåˆ¶ï¼Œè€ŒFFNå±‚åˆ™åƒä¸€ä¸ªç¥ç§˜çš„â€œé»‘ç®±â€ã€‚Gevaç­‰äººçš„è¿™é¡¹å·¥ä½œï¼Œé€šè¿‡ä¸€ç³»åˆ—ç²¾å·§çš„å®éªŒï¼Œä»¤äººä¿¡æœåœ°è®ºè¯äº†ï¼š<strong>FFNå±‚åœ¨åŠŸèƒ½ä¸Šç­‰åŒäºä¸€ä¸ªé”®å€¼è®°å¿†ï¼ˆKey-Value
Memoryï¼‰ç³»ç»Ÿ</strong>ã€‚</p>]]></description>
</item>
</channel>
</rss>
