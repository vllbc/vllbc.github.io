<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>优化算法 - 分类 - vllbc02&#39;s blogs</title>
        <link>https://blog.vllbc.top/categories/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/</link>
        <description>优化算法 - 分类 - vllbc02&#39;s blogs</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Sat, 12 Jul 2025 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://blog.vllbc.top/categories/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/" rel="self" type="application/rss+xml" /><item>
    <title>AdamW</title>
    <link>https://blog.vllbc.top/adamw/</link>
    <pubDate>Sat, 12 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/adamw/</guid>
    <description><![CDATA[<p>AdamW相对与Adam的改动十分简单，其将权重衰减项从梯度的计算中拿出来直接加在了最后的权重更新步骤上（图1，式12）。其提出的动机在于：原先Adam的实现中如果采用了
<a
href="https://zhida.zhihu.com/search?content_id=231119964&amp;content_type=Article&amp;match_order=1&amp;q=L2%E6%9D%83%E9%87%8D%E8%A1%B0%E5%87%8F&amp;zhida_source=entity">L2权重衰减</a>，则相应的权重衰减项会被直接加在loss里，从而导致动量的一阶与二阶滑动平均均考虑了该权重衰减项，而这影响了Adam的优化效果，而将权重衰减与梯度的计算进行解耦能够显著提升Adam的效果。目前，AdamW现在已经成为<a
href="https://zhida.zhihu.com/search?content_id=231119964&amp;content_type=Article&amp;match_order=1&amp;q=transformer&amp;zhida_source=entity">transformer</a>训练中的默认优化器了。</p>]]></description>
</item>
<item>
    <title>Muon</title>
    <link>https://blog.vllbc.top/muon/</link>
    <pubDate>Fri, 11 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/muon/</guid>
    <description><![CDATA[<p>Muon 算法流程如下图所示：</p>
<figure>

<figcaption aria-hidden="true">image.png</figcaption>
</figure>
<p>其中最主要的部分是 NewtonSchulz 5 算法，流程如下：</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> newtonschulz5(G, steps<span class="op">=</span><span class="dv">5</span>, eps<span class="op">=</span><span class="fl">1e-7</span>):</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> G.ndim <span class="op">==</span> <span class="dv">2</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    a, b, c <span class="op">=</span> (<span class="fl">3.4445</span>, <span class="op">-</span><span class="fl">4.7750</span>, <span class="fl">2.0315</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> G.bfloat16()</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    X <span class="op">/=</span> (X.norm() <span class="op">+</span> eps)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> G.size(<span class="dv">0</span>) <span class="op">&gt;</span> G.size(<span class="dv">1</span>):</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> X.T</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(steps):</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    A <span class="op">=</span> X <span class="op">@</span> X.T</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    B <span class="op">=</span> b <span class="op">*</span> A <span class="op">+</span> c <span class="op">*</span> A <span class="op">@</span> A</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> a <span class="op">*</span> X <span class="op">+</span> B <span class="op">@</span> X</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> G.size(<span class="dv">0</span>) <span class="op">&gt;</span> G.size(<span class="dv">1</span>):</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> X.T</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X</span></code></pre></div>
<p>这个算法的作用是将 G 近似为一个最接近他的半正交矩阵，即：</p>]]></description>
</item>
<item>
    <title>Adam算法</title>
    <link>https://blog.vllbc.top/adam/</link>
    <pubDate>Sun, 11 Sep 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/adam/</guid>
    <description><![CDATA[<h2 id="moment矩">moment(矩)</h2>
<p>矩在数学中的定义，一阶矩(first moment)就是样本的均值(mean),
二阶矩就是方差（variance）。 ## 滑动平均 滑动平均(exponential moving
average)，或者叫做指数加权平均(exponentially weighted moving
average)，可以用来估计变量的局部均值，使得变量的更新与一段时间内的历史取值有关。在时间序列预测中也常用。</p>]]></description>
</item>
</channel>
</rss>
