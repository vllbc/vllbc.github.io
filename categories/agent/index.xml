<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Agent - 分类 - vllbc02&#39;s blogs</title>
        <link>https://blog.vllbc.top/categories/agent/</link>
        <description>Agent - 分类 - vllbc02&#39;s blogs</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Sun, 20 Jul 2025 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://blog.vllbc.top/categories/agent/" rel="self" type="application/rss+xml" /><item>
    <title>Search and Refine During Think：Autonomous Retrieval - Augmented Reasoning of LLMs</title>
    <link>https://blog.vllbc.top/search-and-refine-during-thinkautonomous-retrieval-augmented-reasoning-of-llms/</link>
    <pubDate>Sun, 20 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/search-and-refine-during-thinkautonomous-retrieval-augmented-reasoning-of-llms/</guid>
    <description><![CDATA[<h3
id="论文深度解读从思考时搜索到思考时搜索并提炼的范式革命">论文深度解读：从“思考时搜索”到“思考时搜索并提炼”的范式革命</h3>
<p>这篇论文的核心贡献在于，它挑战了传统检索增强生成（RAG）系统中一个根深蒂固的、看似理所当然的流程，并提出了一种更为精细、鲁棒和智能的替代范式。传统的
RAG
模型通常遵循一种“<strong>思考时搜索</strong>”（search-during-think）的模式：当模型在生成答案的过程中意识到知识不足时，它会触发一次或多次搜索，获取外部文档，然后直接基于这些（可能混杂着大量噪声的）文档来生成最终答案。这种方法的致命弱点在于，它假设模型能够自行从混杂、冗长甚至可能错误的信息中精准地“淘金”，而现实是，这种“信息投喂”常常导致“<strong>垃圾进，垃圾出</strong>”（garbage
in, garbage out）的困境。</p>]]></description>
</item>
<item>
    <title>ZEROSEARCH：Incentivize the Search Capability of LLMs without Searching</title>
    <link>https://blog.vllbc.top/zerosearchincentivize-the-search-capability-of-llms-without-searching/</link>
    <pubDate>Fri, 18 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/zerosearchincentivize-the-search-capability-of-llms-without-searching/</guid>
    <description><![CDATA[<p>好的，作为大模型领域的学术专家，我非常乐意为您深入解读这篇富有启发性的论文《ZEROSEARCH:
Incentivize the Search Capability of LLMs without Searching》。</p>
<p>这篇论文的核心思想极其巧妙，它直击了当前训练“搜索智能体（Search
Agent）”LLM 时最头疼的两个问题：高昂的 API
调用成本和不可控的搜索结果质量。传统的做法是让 LLM
在训练时与真实的搜索引擎（如谷歌）进行交互，通过强化学习（RL）来学习何时搜索、搜索什么以及如何利用搜索结果。但这就像让一个新手司机直接在高峰期的纽约街头学开车，不仅成本高昂（每次“练习”都要花钱），而且路况复杂多变（搜索结果时好时坏），很容易让模型“学坏”或者干脆放弃学习。</p>]]></description>
</item>
<item>
    <title>Search-R1：Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning</title>
    <link>https://blog.vllbc.top/search-r1training-llms-to-reason-and-leverage-search-engines-with-reinforcement-learning/</link>
    <pubDate>Wed, 16 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/search-r1training-llms-to-reason-and-leverage-search-engines-with-reinforcement-learning/</guid>
    <description><![CDATA[<p>好的，作为大模型领域的学术专家，我非常乐于为您深入解读这篇具有重要意义的论文《SEARCH-R
1: Training LLMs to Reason and Leverage Search Engines with
Reinforcement Learning》。</p>
<p>这篇论文的核心，是探索如何让大型语言模型（LLM）<strong>学会</strong>像人类专家一样，在解决复杂问题时，<strong>主动、智能、且迭代地使用搜索引擎</strong>。它不仅仅是简单地把搜索结果“喂”给模型，而是通过<strong>强化学习（Reinforcement
Learning,
RL）</strong>，训练模型形成一种内在的“研究”能力——知道<strong>什么时候</strong>需要信息，需要<strong>什么</strong>信息，以及如何<strong>整合</strong>这些信息来形成最终答案。</p>]]></description>
</item>
<item>
    <title>WebThinker：Empowering Large Reasoning Models with Deep Research Capability</title>
    <link>https://blog.vllbc.top/webthinkerempowering-large-reasoning-models-with-deep-research-capability/</link>
    <pubDate>Wed, 16 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/webthinkerempowering-large-reasoning-models-with-deep-research-capability/</guid>
    <description><![CDATA[<p>好的，作为大模型领域的专家，我很乐意为您深入解读这篇富有洞见的论文《WebThinker:
Empowering Large Reasoning Models with Deep Research
Capability》。这篇论文确实触及了当前大模型研究的前沿核心——如何让模型从一个静态的“知识库”转变为一个动态的“研究员”。</p>]]></description>
</item>
<item>
    <title>world_model</title>
    <link>https://blog.vllbc.top/world_model/</link>
    <pubDate>Mon, 30 Jun 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/world_model/</guid>
    <description><![CDATA[<p>我理解的agent中的world
model即可以预测采取某个action之后state的变化，这样做的好处是可以降低试错带来的时间成本或者是其它潜在的成本、风险。</p>]]></description>
</item>
<item>
    <title>agent概览</title>
    <link>https://blog.vllbc.top/agent%E6%A6%82%E8%A7%88/</link>
    <pubDate>Sat, 14 Jun 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/agent%E6%A6%82%E8%A7%88/</guid>
    <description><![CDATA[<p>根据Anthropic的定义，agent定义如下：</p>
<blockquote>
<p>At Anthropic, we categorize all these variations as <strong>agentic
systems</strong>, but draw an important architectural distinction
between <strong>workflows</strong> and <strong>agents</strong>:
<strong>Workflows</strong> are systems where LLMs and tools are
orchestrated through predefined code paths. <strong>Agents</strong>, on
the other hand, are systems where LLMs dynamically direct their own
processes and tool usage, maintaining control over how they accomplish
tasks.</p>]]></description>
</item>
</channel>
</rss>
