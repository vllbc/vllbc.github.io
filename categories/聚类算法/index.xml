<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>聚类算法 - 分类 - vllbc02&#39;s blogs</title>
        <link>https://blog.vllbc.top/categories/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/</link>
        <description>聚类算法 - 分类 - vllbc02&#39;s blogs</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Thu, 03 Nov 2022 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://blog.vllbc.top/categories/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/" rel="self" type="application/rss+xml" /><item>
    <title>DBSCAN</title>
    <link>https://blog.vllbc.top/dbscan/</link>
    <pubDate>Thu, 03 Nov 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/dbscan/</guid>
    <description><![CDATA[<p>DBSCAN属于密度聚类的一种。通常情形下，密度聚类算法从样
本密度的角度来考察样本之间的可连接性，并基于可连接样本不断扩展聚类簇
以获得最终的聚类结果。</p>]]></description>
</item>
<item>
    <title>高斯混合聚类</title>
    <link>https://blog.vllbc.top/%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E8%81%9A%E7%B1%BB/</link>
    <pubDate>Tue, 25 Oct 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E8%81%9A%E7%B1%BB/</guid>
    <description><![CDATA[<p>基础就是高斯混合模型，假设我们熟知的高斯分布的概率密度函数为<span
class="math inline">\(p(x\mid \mu,
\Sigma)\)</span>。则高斯混合分布为：</p>
<p><span class="math display">\[
p_{\mathcal{M}}(\boldsymbol{x})=\sum_{i=1}^k \alpha_i \cdot
p\left(\boldsymbol{x} \mid \boldsymbol{\mu}_i,
\boldsymbol{\Sigma}_i\right)
\]</span></p>
<p>分布共由 <span class="math inline">\(k\)</span> 个混合成分组成,
每个混合成分对应一个高斯分布. 其中 <span
class="math inline">\(\mu_i\)</span> 与 <span
class="math inline">\(\Sigma_i\)</span> 是第 <span
class="math inline">\(i\)</span> 个高斯混合成分的参数, 而 <span
class="math inline">\(\alpha_i&gt;0\)</span> 为相应的 “混合系数”
(mixture coefficient), <span class="math inline">\(\sum_{i=1}^k
\alpha_i=1\)</span>。 假设样本的生成过程由高斯混合分布给出: 首先, 根据
<span class="math inline">\(\alpha_1, \alpha_2, \ldots,
\alpha_k\)</span> 定义 的先验分布选择高斯混合成分, 其中 <span
class="math inline">\(\alpha_i\)</span> 为选择第 <span
class="math inline">\(i\)</span> 个混合成分的概率; 然后, 根
据被选择的混合成分的概率密度函数进行采样, 从而生成相应的样本。</p>]]></description>
</item>
<item>
    <title>谱聚类</title>
    <link>https://blog.vllbc.top/%E8%B0%B1%E8%81%9A%E7%B1%BB/</link>
    <pubDate>Fri, 13 Aug 2021 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/%E8%B0%B1%E8%81%9A%E7%B1%BB/</guid>
    <description><![CDATA[
]]></description>
</item>
<item>
    <title>层次聚类</title>
    <link>https://blog.vllbc.top/%E5%B1%82%E6%AC%A1%E8%81%9A%E7%B1%BB/</link>
    <pubDate>Tue, 29 Jun 2021 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/%E5%B1%82%E6%AC%A1%E8%81%9A%E7%B1%BB/</guid>
    <description><![CDATA[
]]></description>
</item>
<item>
    <title>kmeans</title>
    <link>https://blog.vllbc.top/kmeans/</link>
    <pubDate>Sun, 28 Mar 2021 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/kmeans/</guid>
    <description><![CDATA[<h2 id="通过sklearn模块实现">通过sklearn模块实现</h2>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> metrics</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_blobs</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_iris</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>X,y <span class="op">=</span> make_blobs(n_samples<span class="op">=</span><span class="dv">100</span>,n_features<span class="op">=</span><span class="dv">2</span>,centers<span class="op">=</span>[[<span class="op">-</span><span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>],[<span class="dv">0</span>,<span class="dv">0</span>],[<span class="dv">1</span>,<span class="dv">1</span>],[<span class="dv">2</span>,<span class="dv">2</span>]],cluster_std<span class="op">=</span>[<span class="fl">0.4</span>,<span class="fl">0.2</span>,<span class="fl">0.2</span>,<span class="fl">0.2</span>])<span class="co">#使用make_blobs生成训练数据,生成100个样本,每个样本2个特征,共4个聚类,聚类中心分别为[-1,-1],[0,0],[1,1],[2,2],聚类方差分别为0.4,0.2,0.2,0.2</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[:,<span class="dv">0</span>],X[:,<span class="dv">1</span>])<span class="co">#画出训练样本的散点图,散点图的横坐标为样本的第一维特征,纵坐标为样本的第二维特征</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<p></p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">3</span>)<span class="co">#生成kmeans分类器,聚类数量为3,其余参数使用默认值。</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> kmeans.fit_predict(X)<span class="co">#使用fit_predict方法计算聚类中心并且预测每个样本的聚类索引。</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[:,<span class="dv">0</span>],X[:,<span class="dv">1</span>],c<span class="op">=</span>y_pred)<span class="co">#画出训练样本的散点图,散点图的横坐标为样本的第一维特征,纵坐标为样本的第二维特征,将各聚类结果显示为不同的颜色</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<p></p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">4</span>)<span class="co">#生成kmeans分类器,聚类数量为4,其余参数使用默认值。</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> kmeans.fit_predict(X)<span class="co">#使用fit_predict方法计算聚类中心并且预测每个样本的聚类索引。</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[:,<span class="dv">0</span>],X[:,<span class="dv">1</span>],c<span class="op">=</span>y_pred)<span class="co">#画出训练样本的散点图,散点图的横坐标为样本的第一维特征,纵坐标为样本的第二维特征,将各聚类结果显示为不同的颜色</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<p></p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>iris <span class="op">=</span> load_iris()     <span class="co">#导入iris数据集,iris数据集包含了150个样本,分别属于3类,每个样本包含4个特征</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>data_train<span class="op">=</span>iris.data   <span class="co">#iris样本集的样本特征</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>label_train<span class="op">=</span>iris.target <span class="co">#iris样本集的样本标签</span></span></code></pre></div>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">3</span>)<span class="co">#生成kmeans分类器,聚类数量为3,其余参数使用默认值。</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>y_predict <span class="op">=</span> kmeans.fit_predict(data_train)<span class="co">#使用fit_predict方法计算聚类中心并且预测每个样本的聚类索引。</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>plt.scatter(data_train[:,<span class="dv">0</span>],data_train[:,<span class="dv">2</span>],c<span class="op">=</span>y_predict)<span class="co">#画出训练样本的散点图,散点图的横坐标为样本的第一维特征,纵坐标为样本的第三维特征,将各聚类结果显示为不同的颜色</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<p></p>]]></description>
</item>
</channel>
</rss>
