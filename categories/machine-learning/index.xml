<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Machine Learning - 分类 - vllbc02</title>
        <link>https://vllbc.top/categories/machine-learning/</link>
        <description>Machine Learning - 分类 - vllbc02</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>m18265090197@163.com (vllbc)</managingEditor>
            <webMaster>m18265090197@163.com (vllbc)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Tue, 01 Nov 2022 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://vllbc.top/categories/machine-learning/" rel="self" type="application/rss+xml" /><item>
    <title>Adaboost</title>
    <link>https://vllbc.top/adaboost/</link>
    <pubDate>Tue, 01 Nov 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/adaboost/</guid>
    <description><![CDATA[Boosting算法的工作机制是首先从训练集用初始权重训练出一个弱学习器1，根据弱学习的学习误差率表现来更新训练样本的权重，使得之前弱学习器]]></description>
</item>
<item>
    <title>高斯混合聚类</title>
    <link>https://vllbc.top/%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E8%81%9A%E7%B1%BB/</link>
    <pubDate>Tue, 25 Oct 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E8%81%9A%E7%B1%BB/</guid>
    <description><![CDATA[基础就是高斯混合模型，假设我们熟知的高斯分布的概率密度函数为$p(x\mid \mu, \Sigma)$。则高斯混合分布为： $$ p_{\mathcal{M}}(\boldsymbol{x})=\sum_{i=1}^k \alpha_i \cdot p\left(\boldsymbol{x} \mid \boldsymbol{\mu}_i, \boldsymbol{\Sigma}_i\right) $$ 分布共由]]></description>
</item>
<item>
    <title>随机森林</title>
    <link>https://vllbc.top/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/</link>
    <pubDate>Wed, 19 Oct 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/</guid>
    <description><![CDATA[]]></description>
</item>
<item>
    <title>感知机算法</title>
    <link>https://vllbc.top/%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%AE%97%E6%B3%95/</link>
    <pubDate>Tue, 04 Oct 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%AE%97%E6%B3%95/</guid>
    <description><![CDATA[感知机算法 感知机印象中没有系统学习过但是是一个很简单的算法，最近看了一下李航老师的统计学习方法，发现感知机的思想和svm十分类似，并且比sv]]></description>
</item>
<item>
    <title>谱聚类</title>
    <link>https://vllbc.top/%E8%B0%B1%E8%81%9A%E7%B1%BB/</link>
    <pubDate>Tue, 20 Sep 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/%E8%B0%B1%E8%81%9A%E7%B1%BB/</guid>
    <description><![CDATA[]]></description>
</item>
<item>
    <title>Stacking</title>
    <link>https://vllbc.top/stacking/</link>
    <pubDate>Fri, 26 Aug 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/stacking/</guid>
    <description><![CDATA[Stacking 思想简介 简单得理解，就是对于多个学习器，分别对结果进行预测，然后将预测的结果作为特征，再对结果进行预测。 上一张经典的图： 以这个5折stac]]></description>
</item>
<item>
    <title>SVM</title>
    <link>https://vllbc.top/svm/</link>
    <pubDate>Fri, 29 Jul 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/svm/</guid>
    <description><![CDATA[SVM kernel 介绍 其实核函数和映射关系并不大，kernel可以看作是一个运算技巧。 一般认为，原本在低维线性不可分的数据集在足够高的维度存在线性可分的超]]></description>
</item>
<item>
    <title>线性判别分析</title>
    <link>https://vllbc.top/%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90/</link>
    <pubDate>Fri, 29 Jul 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90/</guid>
    <description><![CDATA[线性判别分析(LDA) 线性判别分析，也就是LDA（与主题模型中的LDA区分开），现在常常用于数据的降维中，但从它的名字中可以看出来它也是一个]]></description>
</item>
<item>
    <title>分类算法概述</title>
    <link>https://vllbc.top/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0/</link>
    <pubDate>Thu, 21 Jul 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0/</guid>
    <description><![CDATA[分类算法 主要区分一下生成模型和判别模型，首先要知道生成模型和判别模型都属于监督学习，即样本有其对应的标签的。还有一个概念就是硬分类和软分类，]]></description>
</item>
<item>
    <title>精确率和召回率</title>
    <link>https://vllbc.top/%E7%B2%BE%E7%A1%AE%E7%8E%87%E5%92%8C%E5%8F%AC%E5%9B%9E%E7%8E%87/</link>
    <pubDate>Wed, 29 Jun 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/%E7%B2%BE%E7%A1%AE%E7%8E%87%E5%92%8C%E5%8F%AC%E5%9B%9E%E7%8E%87/</guid>
    <description><![CDATA[精确率和召回率 混淆矩阵 True Positive(真正, TP)：将正类预测为正类数. True Negative(真负 , TN)：将负类预测为负类数. False Posi]]></description>
</item>
</channel>
</rss>
