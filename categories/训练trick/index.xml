<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>训练trick - 分类 - vllbc02</title>
        <link>https://vllbc.top/categories/%E8%AE%AD%E7%BB%83trick/</link>
        <description>训练trick - 分类 - vllbc02</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>m18265090197@163.com (vllbc)</managingEditor>
            <webMaster>m18265090197@163.com (vllbc)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Sun, 14 Jan 2024 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://vllbc.top/categories/%E8%AE%AD%E7%BB%83trick/" rel="self" type="application/rss+xml" /><item>
    <title>温度超参数</title>
    <link>https://vllbc.top/%E6%B8%A9%E5%BA%A6%E8%B6%85%E5%8F%82%E6%95%B0/</link>
    <pubDate>Sun, 14 Jan 2024 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/%E6%B8%A9%E5%BA%A6%E8%B6%85%E5%8F%82%E6%95%B0/</guid>
    <description><![CDATA[温度超参数t，一般为softmax结果除以该参数，或者在对比学习中，相似度除以参数t。 如图： 上图为无监督simcse中的损失函数。 t越大，结]]></description>
</item>
<item>
    <title>early-stopping</title>
    <link>https://vllbc.top/early-stopping/</link>
    <pubDate>Mon, 06 Mar 2023 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/early-stopping/</guid>
    <description><![CDATA[介绍 早停止（Early Stopping）是 当达到某种或某些条件时，认为模型已经收敛，结束模型训练，保存现有模型的一种手段。 如何判断已经收敛？]]></description>
</item>
<item>
    <title>warmup</title>
    <link>https://vllbc.top/warmup/</link>
    <pubDate>Sun, 05 Mar 2023 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/warmup/</guid>
    <description><![CDATA[在训练开始的时候，如果学习率太高的话，可能会导致loss来回跳动，会导致无法收敛，因此在训练开始的时候就可以设置一个很小的learning r]]></description>
</item>
<item>
    <title>标签平滑</title>
    <link>https://vllbc.top/%E6%A0%87%E7%AD%BE%E5%B9%B3%E6%BB%91/</link>
    <pubDate>Sun, 05 Mar 2023 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/%E6%A0%87%E7%AD%BE%E5%B9%B3%E6%BB%91/</guid>
    <description><![CDATA[神经网络会促使自身往正确标签和错误标签差值最大的方向学习，在训练数据较少，不足以表征所有的样本特征的情况下，会导致网络过拟合。因为oneho]]></description>
</item>
<item>
    <title>调参技巧</title>
    <link>https://vllbc.top/%E8%B0%83%E5%8F%82%E6%8A%80%E5%B7%A7/</link>
    <pubDate>Thu, 02 Mar 2023 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/%E8%B0%83%E5%8F%82%E6%8A%80%E5%B7%A7/</guid>
    <description><![CDATA[基本原则：快速试错。 小步试错，快速迭代 可以试试无脑的配置 实时打印一些结果 自动调参：网格搜索、random search、贝叶斯优化、 参数初始化]]></description>
</item>
<item>
    <title>对抗训练</title>
    <link>https://vllbc.top/%E5%AF%B9%E6%8A%97%E8%AE%AD%E7%BB%83/</link>
    <pubDate>Thu, 02 Mar 2023 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/%E5%AF%B9%E6%8A%97%E8%AE%AD%E7%BB%83/</guid>
    <description><![CDATA[Min-Max公式 $$ {} {(x,y) }U[{r{adv}}L(,x+r_{adv},y)] $$ 内部max是为了找到worst-case的扰动，也就是攻击，其中， \(L\)为损失函数， \(\mathbb{S}\) 为扰动的范围空间。 外部]]></description>
</item>
<item>
    <title>数据不平衡</title>
    <link>https://vllbc.top/%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1/</link>
    <pubDate>Thu, 02 Mar 2023 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1/</guid>
    <description><![CDATA[数据不均衡 所谓的不平衡指的是不同类别的样本量差异非常大，或者少数样本代表了业务的关键数据（少量样本更重要），需要对少量样本的模式有很好的学习]]></description>
</item>
</channel>
</rss>
