<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Coding - 分类 - vllbc02&#39;s blogs</title>
        <link>https://blog.vllbc.top/categories/coding/</link>
        <description>Coding - 分类 - vllbc02&#39;s blogs</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Sun, 27 Jul 2025 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://blog.vllbc.top/categories/coding/" rel="self" type="application/rss+xml" /><item>
    <title>dynamic_bsz</title>
    <link>https://blog.vllbc.top/dynamic_bsz/</link>
    <pubDate>Sun, 27 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/dynamic_bsz/</guid>
    <description><![CDATA[
]]></description>
</item>
<item>
    <title>Dataset</title>
    <link>https://blog.vllbc.top/dataset/</link>
    <pubDate>Sat, 26 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/dataset/</guid>
    <description><![CDATA[<p>详细讲解一下verl中的RLHFDataset，它继承自torch的Dataset，需要实现__getitem__来返回数据。</p>
<h2 id="初始化">初始化</h2>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RLHFDataset(Dataset):</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Load and preprocess RLHF data from Parquet files.</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co">    - Caches files locally.</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">    - Reads into a HuggingFace Dataset and tokenizes prompts.</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">    - Optionally handles images/videos via a ProcessorMixin.</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">    - Filters prompts over a max length.</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co">    - Supports resuming from checkpoints.</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co">        data_files (str or list): Path(s) to Parquet file(s).</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co">        tokenizer (PreTrainedTokenizer): For the tokenization of text to token IDs.</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co">        config (DictConfig): Options like cache_dir, prompt_key, max_prompt_length, truncation, etc.</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co">        processor (ProcessorMixin, optional): Multimodal preprocessor for images/videos.</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>        data_files: <span class="bu">str</span> <span class="op">|</span> <span class="bu">list</span>[<span class="bu">str</span>],</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>        tokenizer: PreTrainedTokenizer,</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>        config: DictConfig,</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>        processor: Optional[ProcessorMixin] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(data_files, <span class="bu">list</span> <span class="op">|</span> ListConfig):</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>            data_files <span class="op">=</span> [data_files]</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.data_files <span class="op">=</span> copy.deepcopy(data_files)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.original_data_files <span class="op">=</span> copy.deepcopy(data_files)  <span class="co"># use for resume</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tokenizer <span class="op">=</span> tokenizer</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.processor <span class="op">=</span> processor</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.config <span class="op">=</span> config</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.cache_dir <span class="op">=</span> os.path.expanduser(config.get(<span class="st">&quot;cache_dir&quot;</span>, <span class="st">&quot;~/.cache/verl/rlhf&quot;</span>))</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.prompt_key <span class="op">=</span> config.get(<span class="st">&quot;prompt_key&quot;</span>, <span class="st">&quot;prompt&quot;</span>)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_key <span class="op">=</span> config.get(<span class="st">&quot;image_key&quot;</span>, <span class="st">&quot;images&quot;</span>)</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.video_key <span class="op">=</span> config.get(<span class="st">&quot;video_key&quot;</span>, <span class="st">&quot;videos&quot;</span>)</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.max_prompt_length <span class="op">=</span> config.get(<span class="st">&quot;max_prompt_length&quot;</span>, <span class="dv">1024</span>)</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.return_raw_chat <span class="op">=</span> config.get(<span class="st">&quot;return_raw_chat&quot;</span>, <span class="va">False</span>)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.return_full_prompt <span class="op">=</span> config.get(<span class="st">&quot;return_full_prompt&quot;</span>, <span class="va">False</span>)</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.truncation <span class="op">=</span> config.get(<span class="st">&quot;truncation&quot;</span>, <span class="st">&quot;error&quot;</span>)</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.filter_overlong_prompts <span class="op">=</span> config.get(<span class="st">&quot;filter_overlong_prompts&quot;</span>, <span class="va">True</span>)</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_workers <span class="op">=</span> config.get(<span class="st">&quot;filter_overlong_prompts_workers&quot;</span>, <span class="bu">max</span>(<span class="dv">1</span>, os.cpu_count() <span class="op">//</span> <span class="dv">4</span>))</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_workers <span class="op">=</span> <span class="bu">min</span>(<span class="va">self</span>.num_workers, os.cpu_count())</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.use_shm <span class="op">=</span> config.get(<span class="st">&quot;use_shm&quot;</span>, <span class="va">False</span>)</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.chat_template_func <span class="op">=</span> config.get(<span class="st">&quot;chat_template_func&quot;</span>, <span class="va">None</span>)</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.need_tools_kwargs <span class="op">=</span> config.get(<span class="st">&quot;need_tools_kwargs&quot;</span>, <span class="va">False</span>)</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.filter_prompts <span class="op">=</span> config.get(<span class="st">&quot;filter_prompts&quot;</span>, <span class="va">True</span>)</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.serialize_dataset <span class="op">=</span> <span class="va">False</span></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.return_multi_modal_inputs <span class="op">=</span> config.get(<span class="st">&quot;return_multi_modal_inputs&quot;</span>, <span class="va">True</span>)</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._download()</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._read_files_and_tokenize()</span></code></pre></div>
<p> （来自deepwiki）</p>]]></description>
</item>
<item>
    <title>agent_loop</title>
    <link>https://blog.vllbc.top/agent_loop/</link>
    <pubDate>Thu, 24 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/agent_loop/</guid>
    <description><![CDATA[<p>Verl 最近实现了 agent loop 功能，也就是多轮工具调用 RL ，弥补了 verl
中 vllm 无法使用多轮 rollout 的不足。整体流程大致如下（来自
https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/rlhf/verl/multi-turn/imgs/Multi-Turn_Rollout_Workflow.png）</p>
<figure>

<figcaption aria-hidden="true">image.png</figcaption>
</figure>
<p>在官方实现中（目前在 verl/experimental/agent_loop
目录下），核心代码在
agent_loop.py中，single_turn_agent_loop.py和tool_agent_loop对应两种agent_loop，tool_parser.py定义了hermes工具解析类。所以重点就是在agent_loop.py中，各个类的协作流程如下图：</p>]]></description>
</item>
<item>
    <title>batch_size解释</title>
    <link>https://blog.vllbc.top/batch_size%E8%A7%A3%E9%87%8A/</link>
    <pubDate>Wed, 16 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/batch_size%E8%A7%A3%E9%87%8A/</guid>
    <description><![CDATA[<p>batch_size的复杂性来自于tp、dp、sp，引用一下<a
href="https://zhuanlan.zhihu.com/p/1925295185891430869">浅入理解verl中的batch_size</a>的解释：</p>
<blockquote>
<p>vllm + fsdp 训推时，如果每张卡都是一个 DP，事情会简单很多。但 verl
中有两个功能不满足这一条件，一是 rollout 时让 vllm 开启 TP，二是在 fsdp
中使用 ulysses（SP）。verl 中数据分发使用的是 dispatch mode
这一机制，比如 fsdp workers
主要使用 <code>Dispatch.DP_COMPUTE_PROTO</code>这个 mode，它是在 worker
group 的层次上进行数据分发以及结果收集的。由于这个层次是没有 TP/SP
概念的，所以它仅在 one GPU one DP 时才是正确的。那么为了正确支持
TP/SP，就需要对数据做一些前后处理。</p>]]></description>
</item>
<item>
    <title>DataProto</title>
    <link>https://blog.vllbc.top/dataproto/</link>
    <pubDate>Wed, 09 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/dataproto/</guid>
    <description><![CDATA[<figure>

<figcaption aria-hidden="true">image.png</figcaption>
</figure>
<p>从上图中可以看到DataProto可以分为3个部分： - non_tensor_batch - batch
- meta_info
其中non_tensor_batch和meta_info都是个字典，而batch是TensorDict类型的变量。</p>]]></description>
</item>
<item>
    <title>init_workers详解</title>
    <link>https://blog.vllbc.top/init_workers%E8%AF%A6%E8%A7%A3/</link>
    <pubDate>Thu, 26 Jun 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/init_workers%E8%AF%A6%E8%A7%A3/</guid>
    <description><![CDATA[<p>前置知识，<a href="ray前置知识.md">ray前置知识</a>
我将用此文来详细介绍veRL中有关single_controller和SPMD的相关内容。本文不涉及ppo训练相关，只是记录一下理解veRL架构实现的核心。</p>]]></description>
</item>
<item>
    <title>ray前置知识</title>
    <link>https://blog.vllbc.top/ray%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86/</link>
    <pubDate>Thu, 26 Jun 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/ray%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86/</guid>
    <description><![CDATA[<h2 id="原生ray">原生Ray</h2>
<p>代码改编自<a
href="https://zhuanlan.zhihu.com/p/1918280771946382774"># verl 解读 -
ray 相关前置知识 (part1)</a>
ray分配资源的单位是bundle，一个bundle一般由1个cpu和1个gpu构成。
而一个placement_group由多个bundle组成，当参数设置为<code>pack</code>通常为同1个node上的bundle构成的。参数设置为<code>spread</code>为不同node的bundle组成。如下图所示：
</p>]]></description>
</item>
<item>
    <title>verl总体概览</title>
    <link>https://blog.vllbc.top/verl%E6%80%BB%E4%BD%93%E6%A6%82%E8%A7%88/</link>
    <pubDate>Thu, 05 Jun 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/verl%E6%80%BB%E4%BD%93%E6%A6%82%E8%A7%88/</guid>
    <description><![CDATA[<h2 id="hybrid-engine">Hybrid Engine</h2>
<blockquote>
<p>在 RLHF 流程中，<a
href="https://zhida.zhihu.com/search?content_id=253958539&amp;content_type=Article&amp;match_order=1&amp;q=actor+model&amp;zhida_source=entity">actor
model</a> 的 generation 和 rollout 占据了绝大多数运行时间（在 veRL 是
58.9%）。并且，由于 PPO 是 online 算法，经验（experiences）必须来自于被
train 的模型本身，因此，rollout 和 training
是必须串行的。如果这两者使用不同的资源组，比如 rollout 用 2 张卡，而
training 用 4 张卡，rollout 的时候 training 的资源闲置，training 的时候
rollout 的资源闲置，无论如何都会浪费大量的计算资源。由此，veRL 将
training 和 rollout engine 放置在同一个资源组中串行执行。training 时，将
rollout engine 的显存回收（offload 到 CPU 上 或者直接析构掉），rollout
时，再将 training engine 的显存释放掉。这种将 actor model 的不同 engine
放置在同一个资源组上的方案，就称为 hybrid engine。</p>]]></description>
</item>
<item>
    <title>reward_mananger</title>
    <link>https://blog.vllbc.top/reward_mananger/</link>
    <pubDate>Mon, 02 Jun 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/reward_mananger/</guid>
    <description><![CDATA[<p>最原生的reward_mananger:</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NaiveRewardManager:</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;The reward manager.&quot;&quot;&quot;</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, tokenizer, num_examine, compute_score<span class="op">=</span><span class="va">None</span>, reward_fn_key<span class="op">=</span><span class="st">&quot;data_source&quot;</span>) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tokenizer <span class="op">=</span> tokenizer</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_examine <span class="op">=</span> num_examine  <span class="co"># the number of batches of decoded responses to print to the console</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.compute_score <span class="op">=</span> compute_score <span class="kw">or</span> default_compute_score</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.reward_fn_key <span class="op">=</span> reward_fn_key</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, data: DataProto, return_dict<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;We will expand this function gradually based on the available datasets&quot;&quot;&quot;</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If there is rm score, we directly return rm score. Otherwise, we compute via rm_score_fn</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">&quot;rm_scores&quot;</span> <span class="kw">in</span> data.batch.keys():</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> return_dict:</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> {<span class="st">&quot;reward_tensor&quot;</span>: data.batch[<span class="st">&quot;rm_scores&quot;</span>]}</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> data.batch[<span class="st">&quot;rm_scores&quot;</span>]</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>        reward_tensor <span class="op">=</span> torch.zeros_like(data.batch[<span class="st">&quot;responses&quot;</span>], dtype<span class="op">=</span>torch.float32)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>        reward_extra_info <span class="op">=</span> defaultdict(<span class="bu">list</span>)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>        already_print_data_sources <span class="op">=</span> {}</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(data)):</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>            data_item <span class="op">=</span> data[i]  <span class="co"># DataProtoItem</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>            prompt_ids <span class="op">=</span> data_item.batch[<span class="st">&quot;prompts&quot;</span>]</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>            prompt_length <span class="op">=</span> prompt_ids.shape[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>            valid_prompt_length <span class="op">=</span> data_item.batch[<span class="st">&quot;attention_mask&quot;</span>][:prompt_length].<span class="bu">sum</span>()</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>            valid_prompt_ids <span class="op">=</span> prompt_ids[<span class="op">-</span>valid_prompt_length:]</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>            response_ids <span class="op">=</span> data_item.batch[<span class="st">&quot;responses&quot;</span>]</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>            valid_response_length <span class="op">=</span> data_item.batch[<span class="st">&quot;attention_mask&quot;</span>][prompt_length:].<span class="bu">sum</span>()</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>            valid_response_ids <span class="op">=</span> response_ids[:valid_response_length]</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>            <span class="co"># decode</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>            prompt_str <span class="op">=</span> <span class="va">self</span>.tokenizer.decode(valid_prompt_ids, skip_special_tokens<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>            response_str <span class="op">=</span> <span class="va">self</span>.tokenizer.decode(valid_response_ids, skip_special_tokens<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>            ground_truth <span class="op">=</span> data_item.non_tensor_batch[<span class="st">&quot;reward_model&quot;</span>][<span class="st">&quot;ground_truth&quot;</span>]</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>            data_source <span class="op">=</span> data_item.non_tensor_batch[<span class="va">self</span>.reward_fn_key]</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>            extra_info <span class="op">=</span> data_item.non_tensor_batch.get(<span class="st">&quot;extra_info&quot;</span>, <span class="va">None</span>)</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>            score <span class="op">=</span> <span class="va">self</span>.compute_score(</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>                data_source<span class="op">=</span>data_source,</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>                solution_str<span class="op">=</span>response_str,</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>                ground_truth<span class="op">=</span>ground_truth,</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>                extra_info<span class="op">=</span>extra_info,</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(score, <span class="bu">dict</span>):</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>                reward <span class="op">=</span> score[<span class="st">&quot;score&quot;</span>]</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Store the information including original reward</span></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> key, value <span class="kw">in</span> score.items():</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>                    reward_extra_info[key].append(value)</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>                reward <span class="op">=</span> score</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>            reward_tensor[i, valid_response_length <span class="op">-</span> <span class="dv">1</span>] <span class="op">=</span> reward</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> data_source <span class="kw">not</span> <span class="kw">in</span> already_print_data_sources:</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>                already_print_data_sources[data_source] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> already_print_data_sources[data_source] <span class="op">&lt;</span> <span class="va">self</span>.num_examine:</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>                already_print_data_sources[data_source] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="st">&quot;[prompt]&quot;</span>, prompt_str)</span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="st">&quot;[response]&quot;</span>, response_str)</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="st">&quot;[ground_truth]&quot;</span>, ground_truth)</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> <span class="bu">isinstance</span>(score, <span class="bu">dict</span>):</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">for</span> key, value <span class="kw">in</span> score.items():</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>                        <span class="bu">print</span>(<span class="ss">f&quot;[</span><span class="sc">{</span>key<span class="sc">}</span><span class="ss">]&quot;</span>, value)</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">print</span>(<span class="st">&quot;[score]&quot;</span>, score)</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> return_dict:</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> {</span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;reward_tensor&quot;</span>: reward_tensor,</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;reward_extra_info&quot;</span>: reward_extra_info,</span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> reward_tensor</span></code></pre></div>
<p>逻辑很简单，就是通过compute_score函数来计算score。</p>]]></description>
</item>
<item>
    <title>LEGB</title>
    <link>https://blog.vllbc.top/legb/</link>
    <pubDate>Mon, 24 Mar 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/legb/</guid>
    <description><![CDATA[<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> <span class="st">&#39;global&#39;</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> outer():</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># def len(in_var):</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     print(&#39;called my len() function: &#39;, end=&quot;&quot;)</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     l = 0</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     for i in in_var:</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">#         l += 1</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     return l</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> <span class="st">&#39;local&#39;</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> inner():</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>        <span class="kw">nonlocal</span> a</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>        a <span class="op">+=</span> <span class="st">&#39; variable&#39;</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    inner()</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&#39;a is&#39;</span>, a)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># print(len(a))</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>outer()</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="co"># print(len(a))</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;a is&#39;</span>, a)</span></code></pre></div>
<p>此时为nonlocal
a，会按照local-闭包-global的顺序找到闭包变量a。a的值为local variable</p>]]></description>
</item>
</channel>
</rss>
