<!DOCTYPE html>
<html lang="zh-CN">
    <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title>LDA - vllbc02&#39;s blogs</title><meta name="Description" content="vllbc&#39;s blog"><meta property="og:title" content="LDA" />
<meta property="og:description" content="线性判别分析LDA(Linear Discriminant Analysis) 线性判别分析，也就是LDA（与主题模型中的LDA区分开），现在常常用于数据的降维中，但从它的名字中可以看" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/lda/" /><meta property="og:image" content="http://localhost:1313/logo.png" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-12-21T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-03-24T00:00:00+00:00" /><meta property="og:site_name" content="vllbc02" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="http://localhost:1313/logo.png" /><meta name="twitter:title" content="LDA"/>
<meta name="twitter:description" content="线性判别分析LDA(Linear Discriminant Analysis) 线性判别分析，也就是LDA（与主题模型中的LDA区分开），现在常常用于数据的降维中，但从它的名字中可以看"/>
<meta name="application-name" content="vllbc02">
<meta name="apple-mobile-web-app-title" content="vllbc02"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="http://localhost:1313/lda/" /><link rel="prev" href="http://localhost:1313/selectfrommodel/" /><link rel="next" href="http://localhost:1313/gan/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="/lib/fontawesome-free/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"></noscript><link rel="preload" href="/lib/animate/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="/lib/animate/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "LDA",
        "inLanguage": "zh-CN",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "http:\/\/localhost:1313\/lda\/"
        },"image": [{
                            "@type": "ImageObject",
                            "url": "http:\/\/localhost:1313\/images\/Apple-Devices-Preview.png",
                            "width":  3200 ,
                            "height":  2048 
                        }],"genre": "posts","keywords": "Machine Learning, 降维算法, LDA","wordcount":  1602 ,
        "url": "http:\/\/localhost:1313\/lda\/","datePublished": "2022-12-21T00:00:00+00:00","dateModified": "2023-03-24T00:00:00+00:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
            "@type": "Organization",
            "name": "xxxx","logo": {
                    "@type": "ImageObject",
                    "url": "http:\/\/localhost:1313\/images\/avatar.png",
                    "width":  512 ,
                    "height":  512 
                }},"author": {
                "@type": "Person",
                "name": "vllbc"
            },"description": ""
    }
    </script></head>
    <body data-header-desktop="fixed" data-header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };

  window.addEventListener('load', (event) => {
      document.querySelectorAll("mjx-container").forEach(function(x){
        x.parentElement.classList += 'has-jax'})
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="vllbc02&#39;s blogs"><img
        class="lazyload logo"
        src="/svg/loading.min.svg"
        data-src="/images/logo.png"
        data-srcset="/images/logo.png, /images/logo.png 1.5x, /images/logo.png 2x"
        data-sizes="auto"
        alt="/images/logo.png"
        title="/images/logo.png" width="32" height="32" />vllbc02</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> 所有文章 </a><a class="menu-item" href="/tags/"> 标签 </a><a class="menu-item" href="/categories/"> 分类 </a><a class="menu-item" href="/about/"> 关于 </a><a class="menu-item" href="https://github.com/vllbc/vllbc.github.io" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw' aria-hidden='true'></i>  </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="vllbc02&#39;s blogs"><img
        class="lazyload logo"
        src="/svg/loading.min.svg"
        data-src="/images/logo.png"
        data-srcset="/images/logo.png, /images/logo.png 1.5x, /images/logo.png 2x"
        data-sizes="auto"
        alt="/images/logo.png"
        title="/images/logo.png" width="32" height="32" />vllbc02</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        取消
                    </a>
                </div><a class="menu-item" href="/posts/" title="">所有文章</a><a class="menu-item" href="/tags/" title="">标签</a><a class="menu-item" href="/categories/" title="">分类</a><a class="menu-item" href="/about/" title="">关于</a><a class="menu-item" href="https://github.com/vllbc/vllbc.github.io" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw' aria-hidden='true'></i></a><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a></div>
    </div>
</header><div class="search-dropdown desktop">
        <div id="search-dropdown-desktop"></div>
    </div>
    <div class="search-dropdown mobile">
        <div id="search-dropdown-mobile"></div>
    </div>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/base16/darcula.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script><main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">目录</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">LDA</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="https://blog.vllbc.top" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>vllbc</a></span>&nbsp;<span class="post-category">收录于 <a href="/categories/machine-learning/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Machine Learning</a>&nbsp;<a href="/categories/%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>降维算法</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;<time datetime="2022-12-21">2022-12-21</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden="true"></i>&nbsp;约 1602 字&nbsp;
                <i class="far fa-clock fa-fw" aria-hidden="true"></i>&nbsp;预计阅读 4 分钟&nbsp;</div>
        </div><div class="details toc" id="toc-static"  data-kept="">
                <div class="details-summary toc-title">
                    <span>目录</span>
                    <span><i class="details-icon fas fa-angle-right" aria-hidden="true"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"></div>
            </div><div class="content" id="content"><h1
id="线性判别分析ldalinear-discriminant-analysis">线性判别分析LDA(Linear
Discriminant Analysis)</h1>
<p>线性判别分析，也就是LDA（与主题模型中的LDA区分开），现在常常用于数据的降维中，但从它的名字中可以看出来它也是一个分类的算法，而且属于硬分类，也就是结果不是概率，是具体的类别，一起学习一下吧。</p>
<h2 id="主要思想">主要思想</h2>
<ol type="1">
<li>类内方差小</li>
<li>类间方差大</li>
</ol>
<h2 id="推导">推导</h2>
<p>这里以二类为例，即只有两个类别。</p>
<p>首先是投影，我们假定原来的数据是向量 <span
class="math inline">\(x\)</span>，那么顺着 $ w$ 方向的投影就是标量：
<span class="math display">\[
z=w^T\cdot x(=|w|\cdot|x|\cos\theta)
\]</span>
对第一点，相同类内部的样本更为接近，我们假设属于两类的试验样本数量分别是
<span class="math inline">\(N_1\)</span>和 <span
class="math inline">\(N_2\)</span>，那么我们采用方差矩阵来表征每一个类内的总体分布，这里我们使用了协方差的定义，用
<span class="math inline">\(S\)</span> 表示原数据的协方差：</p>
<p><span class="math display">\[
\begin{aligned}
C_1:Var_z[C_1]&amp;=\frac{1}{N_1}\sum\limits_{i=1}^{N_1}(z_i-\bar{z_{c1}})(z_i-\bar{z_{c1}})^T\nonumber\\\\\\\\
&amp;=\frac{1}{N_1}\sum\limits_{i=1}^{N_1}(w^Tx_i-\frac{1}{N_1}\sum\limits_{j=1}^{N_1}w^Tx_j)(w^Tx_i-\frac{1}{N_1}\sum\limits_{j=1}^{N_1}w^Tx_j)^T\nonumber\\\\\\\\
&amp;=w^T\frac{1}{N_1}\sum\limits_{i=1}^{N_1}(x_i-\bar{x_{c1}})(x_i-\bar{x_{c1}})^Tw\nonumber\\\\
=w^TS_1w\\\\\\\\
C_2:Var_z[C_2]&amp;=\frac{1}{N_2}\sum\limits_{i=1}^{N_2}(z_i-\bar{z_{c2}})(z_i-\bar{z_{c2}})^T\nonumber\\\\
=w^TS_2w
\end{aligned}
\]</span></p>
<p>所以类内距离为：</p>
<p><span class="math display">\[
\begin{align}
Var_z[C_1]+Var_z[C_2]=w^T(S_1+S_2)w
\end{align}
\]</span></p>
<p>对于第二点，我们可以用两类的均值表示这个距离：</p>
<p><span class="math display">\[
\begin{align}
(\bar{z_{c1}}-\bar{z_{c2}})^2&amp;=(\frac{1}{N_1}\sum\limits_{i=1}^{N_1}w^Tx_i-\frac{1}{N_2}\sum\limits_{i=1}^{N_2}w^Tx_i)^2\nonumber\\\\
&amp;=(w^T(\bar{x_{c1}}-\bar{x_{c2}}))^2\nonumber\\\\
&amp;=w^T(\bar{x_{c1}}-\bar{x_{c2}})(\bar{x_{c1}}-\bar{x_{c2}})^Tw
\end{align}
\]</span></p>
<p>合这两点，由于协方差是一个矩阵，于是我们用将这两个值相除来得到我们的损失函数，并最大化这个值：</p>
<p><span class="math display">\[
\begin{align}
\hat{w}=\mathop{argmax}\limits_wJ(w)&amp;=\mathop{argmax}\limits_w\frac{(\bar{z_{c1}}-\bar{z_{c2}})^2}{Var_z[C_1]+Var_z[C_2]}\nonumber\\\\
&amp;=\mathop{argmax}\limits_w\frac{w^T(\bar{x_{c1}}-\bar{x_{c2}})(\bar{x_{c1}}-\bar{x_{c2}})^Tw}{w^T(S_1+S_2)w}\nonumber\\\\\\\\
&amp;=\mathop{argmax}\limits_w\frac{w^TS_bw}{w^TS_ww}
\end{align}
\]</span></p>
<p>这样，我们就把损失函数和原数据集以及参数结合起来了。下面对这个损失函数求偏导，注意我们其实对w的绝对值没有任何要求，只对方向有要求，因此只要一个方程就可以求解了：</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\frac{\partial}{\partial
w}J(w)=2S_bw(w^TS_ww)^{-1}-2w^TS_bw(w^TS_ww)^{-2}S_ww=0\nonumber\\\\\\\\
&amp;\Longrightarrow S_bw(w^TS_ww)=(w^TS_bw)S_ww\nonumber\\\\\\\\
&amp;\Longrightarrow w\propto
S_w^{-1}S_bw=S_w^{-1}(\bar{x_{c1}}-\bar{x_{c2}})(\bar{x_{c1}}-\bar{x_{c2}})^Tw\propto
S_w^{-1}(\bar{x_{c1}}-\bar{x_{c2}})
\end{aligned}
\]</span></p>
<p>也就是说最后我们的结果就是<span
class="math inline">\(w=S_w^{-1}(\bar{x_{c1}}-\bar{x_{c2}})\)</span>
可以归一化求得单位的w值。</p>
<h2 id="多类情况">多类情况</h2>
<p>前面的很容易类比二类的情况，现在的目标函数变成了：</p>
<p><span class="math display">\[
\frac{W^TS_bW}{W^TS_wW}
\]</span>
现在的问题就是这些都是矩阵，不能像上面那样直接优化，需要替换优化目标。</p>
<p><span class="math display">\[
\underbrace{arg\;max}_W\;\;J(W) =
\frac{\prod\limits_{diag}W^TS_bW}{\prod\limits_{diag}W^TS_wW}
\]</span> 其中 <span
class="math inline">\(\prod_{diag}A\)</span>为A的主对角线元素的乘积,W为<span
class="math inline">\(n \times
d\)</span>的矩阵，n为原来的维度，d为映射到超平面的维度，则最终的目标就变成了：</p>
<p><span class="math display">\[
J(W)
= \frac{\prod\limits_{i=1}^dw_i^TS_bw_i}{\prod\limits_{i=1}^dw_i^TS_ww_i}
= \prod\limits_{i=1}^d\frac{w_i^TS_bw_i}{w_i^TS_ww_i}
\]</span> 根据广式瑞利商，最大值是矩阵<span
class="math inline">\(S_w^{-1}S_b\)</span>的最大特征值,最大的d个值的乘积就是矩阵的<span
class="math inline">\(S_w^{-1}S_b\)</span>最大的d个特征值的乘积,此时对应的矩阵<span
class="math inline">\(W\)</span>为这最大的d个特征值对应的特征向量张成的矩阵。</p>
<h2 id="总结">总结</h2>
<p>LDA是一种监督学习的降维技术，也就是说它的数据集的每个样本是有类别输出的。这点和PCA不同。PCA是不考虑样本类别输出的无监督降维技术。LDA的思想可以用一句话概括，就是“投影后类内方差最小，类间方差最大”。什么意思呢？
我们要将数据在低维度上进行投影，投影后希望每一种类别数据的投影点尽可能的接近，而不同类别的数据的类别中心之间的距离尽可能的大。</p>
<p>实际上LDA除了可以用于降维以外，还可以用于分类。一个常见的LDA分类基本思想是假设各个类别的样本数据符合高斯分布，这样利用LDA进行投影后，可以利用极大似然估计计算各个类别投影数据的均值和方差，进而得到该类别高斯分布的概率密度函数。当一个新的样本到来后，我们可以将它投影，然后将投影后的样本特征分别带入各个类别的高斯分布概率密度函数，计算它属于这个类别的概率，最大的概率对应的类别即为预测类别。</p>
<p>LDA用于降维，和PCA有很多相同，也有很多不同的地方，因此值得好好的比较一下两者的降维异同点。</p>
<p>首先我们看看相同点：</p>
<p>1）两者均可以对数据进行降维。</p>
<p>2）两者在降维时均使用了矩阵特征分解的思想。</p>
<p>3）两者都假设数据符合高斯分布。</p>
<p>我们接着看看不同点：</p>
<p>1）LDA是有监督的降维方法，而PCA是无监督的降维方法</p>
<p>2）LDA降维最多降到类别数k-1的维数，而PCA没有这个限制。</p>
<p>3）LDA除了可以用于降维，还可以用于分类。</p>
<p>4）LDA选择分类性能最好的投影方向，而PCA选择样本点投影具有最大方差的方向。</p>
<h2 id="代码">代码</h2>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>mean_list <span class="op">=</span> []</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>):</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    mean_list.append(np.mean(X_train[y_train<span class="op">==</span>i], axis<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>mean_list <span class="op">=</span> np.array(mean_list)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>S_W <span class="op">=</span> np.zeros((X_train.shape[<span class="dv">1</span>], X_train.shape[<span class="dv">1</span>])) <span class="co"># 类内散度矩阵</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> c, mv <span class="kw">in</span> <span class="bu">zip</span>(<span class="bu">range</span>(<span class="dv">2</span>), mean_list):</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    class_scatter <span class="op">=</span> np.zeros((X_train.shape[<span class="dv">1</span>], X_train.shape[<span class="dv">1</span>]))</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> row <span class="kw">in</span> X_train[y_train<span class="op">==</span>c]:</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>        row, mv <span class="op">=</span> row.reshape(X_train.shape[<span class="dv">1</span>], <span class="op">-</span><span class="dv">1</span>), mv.reshape(X_train.shape[<span class="dv">1</span>], <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>        class_scatter <span class="op">+=</span> (row<span class="op">-</span>mv).dot((row<span class="op">-</span>mv).T)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    S_W <span class="op">+=</span> class_scatter</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>over_all_mean <span class="op">=</span> np.mean(X_train, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>S_B <span class="op">=</span> np.zeros((X_train.shape[<span class="dv">1</span>], X_train.shape[<span class="dv">1</span>])) <span class="co"># 类间散度矩阵</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, mean_vec <span class="kw">in</span> <span class="bu">enumerate</span>(mean_list):</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> X_train[y_train<span class="op">==</span>i, :].shape[<span class="dv">0</span>]</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    mean_list_temp <span class="op">=</span> mean_list[i, :].reshape(<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    over_all_mean <span class="op">=</span> over_all_mean.reshape(X_train.shape[<span class="dv">1</span>], <span class="dv">1</span>)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    S_B <span class="op">+=</span> n<span class="op">*</span>(mean_vec<span class="op">-</span>over_all_mean).dot((mean_vec<span class="op">-</span>over_all_mean).T)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>eig_vals, eig_vecs <span class="op">=</span> np.linalg.eig(np.linalg.inv(S_W).dot(S_B))</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>eig_pairs <span class="op">=</span> [(np.<span class="bu">abs</span>(eig_vals[i]), eig_vecs[:, i]) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(eig_vals))]</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>eig_pairs <span class="op">=</span> <span class="bu">sorted</span>(eig_pairs, key<span class="op">=</span><span class="kw">lambda</span> k: k[<span class="dv">0</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="co"># eigv_sum = sum(eig_vals)</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="co"># for i, j in enumerate(eig_pairs):</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="co">#     print(&#39;eigenvalue {0:}: {1:.2%}&#39;.format(i + 1, (j[0] / eigv_sum).real)) # 根据百分比显示特征值，从而选取最大的n个特征值</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>W <span class="op">=</span> np.hstack((eig_pairs[<span class="dv">0</span>][<span class="dv">1</span>].reshape(X_train.shape[<span class="dv">1</span>], <span class="dv">1</span>), eig_pairs[<span class="dv">1</span>][<span class="dv">1</span>].reshape(X_train.shape[<span class="dv">1</span>], <span class="dv">1</span>)))</span></code></pre></div>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>更新于 2023-03-24</span>
            </div></div>
        <div class="post-info-line">
            <div class="post-info-md"><span>
                            <a class="link-to-markdown" href="/lda/index.md" target="_blank">阅读原始文档</a>
                        </span></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="分享到 Twitter" data-sharer="twitter" data-url="http://localhost:1313/lda/" data-title="LDA" data-hashtags="Machine Learning,降维算法,LDA"><i class="fab fa-twitter fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="分享到 Facebook" data-sharer="facebook" data-url="http://localhost:1313/lda/" data-hashtag="Machine Learning"><i class="fab fa-facebook-square fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="分享到 Hacker News" data-sharer="hackernews" data-url="http://localhost:1313/lda/" data-title="LDA"><i class="fab fa-hacker-news fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="分享到 Line" data-sharer="line" data-url="http://localhost:1313/lda/" data-title="LDA"><i data-svg-src="/lib/simple-icons/icons/line.min.svg" aria-hidden="true"></i></a><a href="javascript:void(0);" title="分享到 微博" data-sharer="weibo" data-url="http://localhost:1313/lda/" data-title="LDA"><i class="fab fa-weibo fa-fw" aria-hidden="true"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/machine-learning/">Machine Learning</a>,&nbsp;<a href="/tags/%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95/">降维算法</a>,&nbsp;<a href="/tags/lda/">LDA</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="/">主页</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/selectfrommodel/" class="prev" rel="prev" title="SelectFromModel"><i class="fas fa-angle-left fa-fw" aria-hidden="true"></i>SelectFromModel</a>
            <a href="/gan/" class="next" rel="next" title="GAN">GAN<i class="fas fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
</article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line" itemscope itemtype="http://schema.org/CreativeWork"><i class="far fa-copyright fa-fw" aria-hidden="true"></i><span itemprop="copyrightYear">2020 - 2025</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="https://blog.vllbc.top" target="_blank">vllbc</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="回到顶部">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="查看评论">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><script type="text/javascript" src="/lib/autocomplete/autocomplete.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.stemmer.support.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.zh.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/sharer/sharer.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"复制到剪贴板","maxShownLines":50},"comment":{},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","lunrLanguageCode":"zh","lunrSegmentitURL":"/lib/lunr/lunr.segmentit.js","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"lunr"}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
