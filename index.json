[{"categories":["工具"],"content":"贴一下可以玩的shortcode。 ","date":"2023-03-07","objectID":"/shortcode%E7%BD%AE%E9%A1%B6/:0:0","tags":["工具"],"title":"shortcode(置顶)","uri":"/shortcode%E7%BD%AE%E9%A1%B6/"},{"categories":["工具"],"content":"音乐播放 ","date":"2023-03-07","objectID":"/shortcode%E7%BD%AE%E9%A1%B6/:1:0","tags":["工具"],"title":"shortcode(置顶)","uri":"/shortcode%E7%BD%AE%E9%A1%B6/"},{"categories":["工具"],"content":"播放列表 夏日口袋专辑： ","date":"2023-03-07","objectID":"/shortcode%E7%BD%AE%E9%A1%B6/:1:1","tags":["工具"],"title":"shortcode(置顶)","uri":"/shortcode%E7%BD%AE%E9%A1%B6/"},{"categories":["工具"],"content":"播放单曲 最爱的一首（我是紬厨）： ","date":"2023-03-07","objectID":"/shortcode%E7%BD%AE%E9%A1%B6/:1:2","tags":["工具"],"title":"shortcode(置顶)","uri":"/shortcode%E7%BD%AE%E9%A1%B6/"},{"categories":["工具"],"content":"视频播放 ","date":"2023-03-07","objectID":"/shortcode%E7%BD%AE%E9%A1%B6/:2:0","tags":["工具"],"title":"shortcode(置顶)","uri":"/shortcode%E7%BD%AE%E9%A1%B6/"},{"categories":["工具"],"content":"bilibili 有多P可以选择集数 ","date":"2023-03-07","objectID":"/shortcode%E7%BD%AE%E9%A1%B6/:2:1","tags":["工具"],"title":"shortcode(置顶)","uri":"/shortcode%E7%BD%AE%E9%A1%B6/"},{"categories":["工具"],"content":"admonition 类型有：note、abstract、info、tip、success、question、warning、failure、danger、bug、example、quote。 技巧 一个 技巧 横幅 ","date":"2023-03-07","objectID":"/shortcode%E7%BD%AE%E9%A1%B6/:3:0","tags":["工具"],"title":"shortcode(置顶)","uri":"/shortcode%E7%BD%AE%E9%A1%B6/"},{"categories":["工具"],"content":"mapbox ","date":"2023-03-07","objectID":"/shortcode%E7%BD%AE%E9%A1%B6/:4:0","tags":["工具"],"title":"shortcode(置顶)","uri":"/shortcode%E7%BD%AE%E9%A1%B6/"},{"categories":["model","LLM"],"content":"------------------------------------------------------------------------------------------------------ # Qwen-1 + Embedding and output projection. (Untied embedding for input embedding and output projection) + ROPE + QKV bias required + Pre-Norm \u0026 RMSNorm + SwiGLU ------------------------------------------------------------------------------------------------------ # Qwen-2 - Multi-Head Attention + MoE + Grouped Query Attention + Dual Chunk Attention + YARN + Expert Granularity + Expert Routing + Expert Initialization + Shared Experts ------------------------------------------------------------------------------------------------------ # Qwen-2.5 + More control tokens. 3 -\u003e 22 ------------------------------------------------------------------------------------------------------ # Qwen-3 - QKV bias - Shared experts + QK-Norm ------------------------------------------------------------------------------------------------------ ","date":"2025-08-08","objectID":"/qwen/:0:0","tags":["LLM","model"],"title":"qwen","uri":"/qwen/"},{"categories":["model","LLM"],"content":"参考 Qwen 各版本主要结构变化 ","date":"2025-08-08","objectID":"/qwen/:1:0","tags":["LLM","model"],"title":"qwen","uri":"/qwen/"},{"categories":["reasoning","LLM"],"content":"最近涌现了很多关于信用分配的论文，因此整理一下 ","date":"2025-08-05","objectID":"/%E4%BF%A1%E7%94%A8%E5%88%86%E9%85%8D/:0:0","tags":["LLM","reasoning"],"title":"信用分配","uri":"/%E4%BF%A1%E7%94%A8%E5%88%86%E9%85%8D/"},{"categories":["reasoning","LLM"],"content":"First Return, Entropy-Eliciting Explore Good Learners Think Their Thinking：Generative PRM Makes Large Reasoning Model More Efficient Math Learne ","date":"2025-08-05","objectID":"/%E4%BF%A1%E7%94%A8%E5%88%86%E9%85%8D/:1:0","tags":["LLM","reasoning"],"title":"信用分配","uri":"/%E4%BF%A1%E7%94%A8%E5%88%86%E9%85%8D/"},{"categories":["reasoning","LLM"],"content":"Group Sequence Policy Optimization ","date":"2025-08-05","objectID":"/%E4%BF%A1%E7%94%A8%E5%88%86%E9%85%8D/:2:0","tags":["LLM","reasoning"],"title":"信用分配","uri":"/%E4%BF%A1%E7%94%A8%E5%88%86%E9%85%8D/"},{"categories":["reasoning","LLM"],"content":"PROCESS REINFORCEMENT THROUGH IMPLICIT REWARDS RLVMR：Reinforcement Learning with Verifiable Meta-Reasoning Rewards for Robust Long-Horizon Agents VAPO：Efficient and Reliable Reinforcement Learning for Advanced Reasoning Tasks ","date":"2025-08-05","objectID":"/%E4%BF%A1%E7%94%A8%E5%88%86%E9%85%8D/:3:0","tags":["LLM","reasoning"],"title":"信用分配","uri":"/%E4%BF%A1%E7%94%A8%E5%88%86%E9%85%8D/"},{"categories":["reasoning","LLM"],"content":"Group-in-Group Policy Optimization for LLM Agent Training CAPO：Towards Enhancing LLM Reasoning through Verifiable Generative Credit Assignment Beyond Policy Optimization：A Data Curation Flywheel for Sparse-Reward Long-Horizon Planning GTPO and GRPO-S：Token and Sequence-Level Reward Shaping with Policy Entropy GTPO：Trajectory-Based Policy Optimization in Large Language Models ","date":"2025-08-05","objectID":"/%E4%BF%A1%E7%94%A8%E5%88%86%E9%85%8D/:4:0","tags":["LLM","reasoning"],"title":"信用分配","uri":"/%E4%BF%A1%E7%94%A8%E5%88%86%E9%85%8D/"},{"categories":["model","LLM"],"content":"预训练 ","date":"2025-07-30","objectID":"/k2/:1:0","tags":["LLM","model"],"title":"K2","uri":"/k2/"},{"categories":["model","LLM"],"content":"Muon-clip 详见Muon 通过裁剪权重解决Max-Logit问题，实现稳定训练。 ","date":"2025-07-30","objectID":"/k2/:1:1","tags":["LLM","model"],"title":"K2","uri":"/k2/"},{"categories":["model","LLM"],"content":"数据增强 通过改写句子来提高token效率，避免重复使用token造成的过拟合，改写方法如下： 多样化风格和视角的提示词：为在保持事实完整性的同时增强语言多样性，研究团队应用了一系列精心构建的提示词。这些提示词引导大语言模型从不同风格和视角生成原始文本的忠实改写版本。 分块式自回归生成：为保持全局连贯性并避免长文档信息丢失，研究团队采用了基于分块的自回归重写策略。文本被划分为若干段落，分别进行改写，然后重新组合形成完整文章。这种方法缓解了大语言模型通常存在的隐式输出长度限制问题，如图4所示。 保真度验证：为确保原始内容与改写内容的一致性，研究团队执行保真度检查，比较每个改写段落与原文的语义对齐程度。这作为训练前的初步质量控制环节。 ","date":"2025-07-30","objectID":"/k2/:1:2","tags":["LLM","model"],"title":"K2","uri":"/k2/"},{"categories":["model","LLM"],"content":"模型架构 k2通过实验发现了稀疏性扩展法则（稀疏性定义为专家总数与激活专家数量的比值）。 以及注意力头的数量多只能提升少量性能，但带来了大量的计算量。 ","date":"2025-07-30","objectID":"/k2/:1:3","tags":["LLM","model"],"title":"K2","uri":"/k2/"},{"categories":["model","LLM"],"content":"infra 分为并行化策略和激活值压缩 并行化策略：EP通信与交错1F1B的重叠与更小的EP规模 激活值压缩： 选择性重计算 对计算成本低但内存占用高的操作进行重计算，包括LayerNorm、SwiGLU和MLA上投影。此外，训练过程中还对MoE下投影进行重计算以进一步降低激活值内存需求。虽然这种重计算是可选的，但它能够维持充足的GPU内存，防止早期训练阶段因专家负载不均衡导致的系统崩溃。 不敏感激活值的FP8存储 将MoE上投影和SwiGLU的输入压缩为1×128数据块中的FP8-E4M3格式，配合FP32缩放因子。小规模实验表明这种压缩不会导致可测量的损失增加。由于初步研究中观察到潜在的性能下降风险，研究团队未在计算过程中采用FP8格式。 激活值CPU卸载 将所有剩余激活值卸载至CPU内存。数据传输引擎负责流式卸载和加载，与计算和通信核心实现重叠处理。在1F1B阶段，系统在预取下一个微批次的反向激活值的同时卸载前一个微批次的前向激活值。 ","date":"2025-07-30","objectID":"/k2/:1:4","tags":["LLM","model"],"title":"K2","uri":"/k2/"},{"categories":["model","LLM"],"content":"Post-training ","date":"2025-07-30","objectID":"/k2/:2:0","tags":["LLM","model"],"title":"K2","uri":"/k2/"},{"categories":["model","LLM"],"content":"工具能力增强 合成了大量工具来进行微调。 - 工具规范生成：首先从现实世界工具和LLM合成工具中构建大型工具规范库 - 智能体和任务生成：针对从工具库中采样的每个工具集，生成使用该工具集的智能体和相应任务 - 轨迹生成：为每个智能体和任务生成智能体通过工具调用完成任务的轨迹 image.png 智能体的多样化 团队通过合成各种系统提示词并为其配备来自资源库的不同工具组合，生成了数千个不同的智能体。这创建了具有不同能力、专业领域和行为模式的多样化智能体群体，确保了潜在用例的广泛覆盖。 基于评价标准的任务生成 针对每个智能体配置，团队生成从简单到复杂的各种操作任务。每个任务都配备明确的评价标准，规定成功标准、期望的工具使用模式和评估检查点。这种基于评价标准的方法确保了智能体性能评估的一致性和客观性。 多轮轨迹生成 团队通过以下组件模拟真实的工具使用场景： 用户模拟：LLM生成具有不同沟通风格和偏好的用户角色，与智能体进行多轮对话，创建自然的交互模式。 工具执行环境：复杂的工具模拟器（功能等同于世界模型）执行工具调用并提供真实反馈。模拟器在每次工具执行后维护和更新状态，支持具有持续效果的复杂多步交互。它引入受控随机性，产生包括成功、部分失败和边缘情况在内的各种结果。 质量评估和筛选 基于LLM的评判者根据任务评价标准评估每个轨迹。只有满足成功标准的轨迹被保留用于训练，确保数据质量的同时允许任务完成策略的自然变化。 与真实执行环境的混合方法 虽然模拟提供了可扩展性，但团队认识到模拟保真度的固有局限性。为解决这一问题，团队在真实性至关重要的场景（特别是编程和软件工程任务）中，使用真实执行沙盒来补充模拟环境。这些真实沙盒执行实际代码，与真正的开发环境交互，并通过测试套件通过率等客观指标提供真实反馈。这种组合确保模型能够从模拟场景的多样性和真实执行的准确性中学习，显著增强实际智能体能力。 ","date":"2025-07-30","objectID":"/k2/:2:1","tags":["LLM","model"],"title":"K2","uri":"/k2/"},{"categories":["model","LLM"],"content":"参考 [2507.20534] Kimi K2: Open Agentic Intelligence https://zhuanlan.zhihu.com/p/1933619657589384402 ","date":"2025-07-30","objectID":"/k2/:3:0","tags":["LLM","model"],"title":"K2","uri":"/k2/"},{"categories":["basic","LLM"],"content":"在softmax的结果后添加一个静态的不可学习的偏置项。 q1和k1之间的距离是0，所以对应位置就是0 q2和k1之间的距离是「相对位置偏移为“k的索引”1」 - 「q的索引2」，得到1-2 = -1，就对应到了中间矩阵的取值为-1了 以此类推，相对距离矩阵的中间对角线上都是0，然后左下角的取值都是对应的「k的索引」-「q的索引」了 ","date":"2025-07-29","objectID":"/alibi/:0:0","tags":["LLM","basic"],"title":"ALiBi","uri":"/alibi/"},{"categories":["model","LLM"],"content":"Gemma 3 ","date":"2025-07-29","objectID":"/gemma/:1:0","tags":["LLM","model"],"title":"Gemma","uri":"/gemma/"},{"categories":["model","LLM"],"content":"QK-Norm 简单来说就是在Q和K矩阵上进行RMSNorm，即： \\[ \\begin{aligned} O \u0026= softmax(\\bar{Q}\\bar{K}^T)V \\\\ \\bar{Q} \u0026=RMSNorm(Q) \\\\ \\bar{K} \u0026=RMSNorm(V) \\end{aligned}\\ \\] 但这种方法的问题是不适用MLA的推理阶段，因为推理阶段的MLA将Wk吸取到了Q中，具体见MLA ","date":"2025-07-29","objectID":"/gemma/:1:1","tags":["LLM","model"],"title":"Gemma","uri":"/gemma/"},{"categories":["verl","coding"],"content":"详细讲解一下verl中的RLHFDataset，它继承自torch的Dataset，需要实现__getitem__来返回数据。 ","date":"2025-07-26","objectID":"/dataset/:0:0","tags":["coding","verl"],"title":"Dataset","uri":"/dataset/"},{"categories":["verl","coding"],"content":"初始化 class RLHFDataset(Dataset): \"\"\" Load and preprocess RLHF data from Parquet files. - Caches files locally. - Reads into a HuggingFace Dataset and tokenizes prompts. - Optionally handles images/videos via a ProcessorMixin. - Filters prompts over a max length. - Supports resuming from checkpoints. Args: data_files (str or list): Path(s) to Parquet file(s). tokenizer (PreTrainedTokenizer): For the tokenization of text to token IDs. config (DictConfig): Options like cache_dir, prompt_key, max_prompt_length, truncation, etc. processor (ProcessorMixin, optional): Multimodal preprocessor for images/videos. \"\"\" def __init__( self, data_files: str | list[str], tokenizer: PreTrainedTokenizer, config: DictConfig, processor: Optional[ProcessorMixin] = None, ): if not isinstance(data_files, list | ListConfig): data_files = [data_files] self.data_files = copy.deepcopy(data_files) self.original_data_files = copy.deepcopy(data_files) # use for resume self.tokenizer = tokenizer self.processor = processor self.config = config self.cache_dir = os.path.expanduser(config.get(\"cache_dir\", \"~/.cache/verl/rlhf\")) self.prompt_key = config.get(\"prompt_key\", \"prompt\") self.image_key = config.get(\"image_key\", \"images\") self.video_key = config.get(\"video_key\", \"videos\") self.max_prompt_length = config.get(\"max_prompt_length\", 1024) self.return_raw_chat = config.get(\"return_raw_chat\", False) self.return_full_prompt = config.get(\"return_full_prompt\", False) self.truncation = config.get(\"truncation\", \"error\") self.filter_overlong_prompts = config.get(\"filter_overlong_prompts\", True) self.num_workers = config.get(\"filter_overlong_prompts_workers\", max(1, os.cpu_count() // 4)) self.num_workers = min(self.num_workers, os.cpu_count()) self.use_shm = config.get(\"use_shm\", False) self.chat_template_func = config.get(\"chat_template_func\", None) self.need_tools_kwargs = config.get(\"need_tools_kwargs\", False) self.filter_prompts = config.get(\"filter_prompts\", True) self.serialize_dataset = False self.return_multi_modal_inputs = config.get(\"return_multi_modal_inputs\", True) self._download() self._read_files_and_tokenize() （来自deepwiki） download方法就是把hdfs文件或者本地文件缓存到缓存路径下。 接下来重点看一下read_files_and_tokenize方法： def _read_files_and_tokenize(self): dataframes = [] for parquet_file in self.data_files: # read parquet files and cache dataframe = datasets.load_dataset(\"parquet\", data_files=parquet_file)[\"train\"] dataframes.append(dataframe) self.dataframe: datasets.Dataset = datasets.concatenate_datasets(dataframes) print(f\"dataset len: {len(self.dataframe)}\") self.dataframe = self.maybe_filter_out_long_prompts(self.dataframe) def maybe_filter_out_long_prompts(self, dataframe: datasets.Dataset = None): # filter out too long prompts if self.filter_overlong_prompts: tokenizer = self.tokenizer processor = self.processor prompt_key = self.prompt_key image_key = self.image_key video_key = self.video_key if processor is not None: from verl.utils.dataset.vision_utils import process_image, process_video def doc2len(doc) -\u003e int: messages = self._build_messages(doc) raw_prompt = self.processor.apply_chat_template( messages, add_generation_prompt=True, tokenize=False ) images = [process_image(image) for image in doc[image_key]] if image_key in doc else None videos = [process_video(video) for video in doc[video_key]] if video_key in doc else None return len(processor(text=[raw_prompt], images=images, videos=videos)[\"input_ids\"][0]) else: def doc2len(doc) -\u003e int: return len(tokenizer.apply_chat_template(doc[prompt_key], add_generation_prompt=True)) dataframe = dataframe.filter( lambda doc: doc2len(doc) \u003c= self.max_prompt_length, num_proc=self.num_workers, desc=f\"Filtering prompts longer than {self.max_prompt_length} tokens\", ) print(f\"filter dataset len: {len(dataframe)}\") return dataframe 实现了读取parquet文件，然后再根据传入的prompt_length筛选掉prompt长度超过length的样本。返回的是dataframe。 然后就到了最重要的__getitem__方法，来构造我们需要的数据： def __getitem__(self, item): \"\"\" Note that we also return the raw_input_ids so that it can be co","date":"2025-07-26","objectID":"/dataset/:1:0","tags":["coding","verl"],"title":"Dataset","uri":"/dataset/"},{"categories":["大模型分布式","LLM"],"content":"verl中的device_mesh verl中有3个device_mesh，分别是： - 训练用的FSDP mesh（通常是一维） - 推理用的rollout mesh（包含tp维度） - Ulysses序列并行的mesh（dp×sp） ","date":"2025-07-26","objectID":"/device_mesh/:1:0","tags":["LLM","大模型分布式"],"title":"device_mesh","uri":"/device_mesh/"},{"categories":["大模型分布式","LLM"],"content":"fsdp mesh ","date":"2025-07-26","objectID":"/device_mesh/:2:0","tags":["LLM","大模型分布式"],"title":"device_mesh","uri":"/device_mesh/"},{"categories":["大模型分布式","LLM"],"content":"rollout mesh ","date":"2025-07-26","objectID":"/device_mesh/:3:0","tags":["LLM","大模型分布式"],"title":"device_mesh","uri":"/device_mesh/"},{"categories":["大模型分布式","LLM"],"content":"ulysses mesh ","date":"2025-07-26","objectID":"/device_mesh/:4:0","tags":["LLM","大模型分布式"],"title":"device_mesh","uri":"/device_mesh/"},{"categories":["verl","coding"],"content":"Verl 最近实现了 agent loop 功能，也就是多轮工具调用 RL ，弥补了 verl 中 vllm 无法使用多轮 rollout 的不足。整体流程大致如下（来自 https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/rlhf/verl/multi-turn/imgs/Multi-Turn_Rollout_Workflow.png） image.png 在官方实现中（目前在 verl/experimental/agent_loop 目录下），核心代码在 agent_loop.py中，single_turn_agent_loop.py和tool_agent_loop对应两种agent_loop，tool_parser.py定义了hermes工具解析类。所以重点就是在agent_loop.py中，各个类的协作流程如下图： image.png verl官网图如下（Agent Loop — verl documentation）： 按照上面的流程图进行逐步讲解。 ","date":"2025-07-24","objectID":"/agent_loop/:0:0","tags":["coding","verl"],"title":"agent_loop","uri":"/agent_loop/"},{"categories":["verl","coding"],"content":"AgentLoopManager AgentLoopManager是入口处，在ray_trainer.py中由actor_rollout_wg初始化： if self.config.actor_rollout_ref.rollout.mode == \"async\": from verl.experimental.agent_loop import AgentLoopManager self.async_rollout_mode = True self.async_rollout_manager = AgentLoopManager( config=self.config, worker_group=self.actor_rollout_wg, ) AgentLoopManager需要先启动多个推理引擎服务器，数量为dp_size（world_size/tp_size）。代码： class AgentLoopManager: \"\"\"Agent loop manager that manages a group of agent loop workers.\"\"\" def __init__(self, config: DictConfig, worker_group: RayWorkerGroup): \"\"\"Initialize agent loop manager. Args: config (DictConfig): trainer config. worker_group (RayWorkerGroup): ActorRolloutRef worker group. \"\"\" self.config = config self.worker_group = worker_group self._initialize_llm_servers() self._init_agent_loop_workers() def _initialize_llm_servers(self): # 这里也对应了一开始图中的最下面的部分 self.rollout_tp_size = self.config.actor_rollout_ref.rollout.tensor_model_parallel_size self.rollout_dp_size = self.worker_group.world_size // self.rollout_tp_size ... unready_dp_ranks = set(range(self.rollout_dp_size)) while len(unready_dp_ranks) \u003e 0: servers = { rollout_dp_rank: server_class.options( # make sure AsyncvLLMServer colocates with its corresponding workers scheduling_strategy=ray.util.scheduling_strategies.NodeAffinitySchedulingStrategy( node_id=workers_info[rollout_dp_rank * self.rollout_tp_size], soft=False, ), name=f\"async_llm_server_{rollout_dp_rank}\", ).remote(self.config, self.rollout_dp_size, rollout_dp_rank, self.worker_group.name_prefix) for rollout_dp_rank in unready_dp_ranks } for rollout_dp_rank, server in servers.items(): try: address = ray.get(server.get_server_address.remote()) self.server_addresses[rollout_dp_rank] = address self.async_llm_servers[rollout_dp_rank] = server unready_dp_ranks.remove(rollout_dp_rank) except Exception: ray.kill(server) print(f\"rollout server {rollout_dp_rank} failed, maybe address already in use, restarting...\") # All server instances are ready, init AsyncLLM engine. ray.get([server.init_engine.remote() for server in self.async_llm_servers]) AgentLoopManager负责管理多个AgentLoopWorker，个数由参数rollout.agent.num_workers确定。然后将prompt切分成num_worker个，让各个worker分别进行推理，这部分的代码如下： ## 初始化各个worker def _init_agent_loop_workers(self): self.agent_loop_workers = [] for i in range(self.config.actor_rollout_ref.rollout.agent.num_workers): self.agent_loop_workers.append( AgentLoopWorker.options( name=f\"agent_loop_worker_{i}\", ).remote(self.config, self.async_llm_servers) ) ... ## 根据worker的数量切分prompts，推理后再合并起来 def generate_sequences(self, prompts: DataProto) -\u003e DataProto: if self.config.actor_rollout_ref.rollout.free_cache_engine: self.wake_up() chunkes = prompts.chunk(len(self.agent_loop_workers)) outputs = ray.get( [ worker.generate_sequences.remote(chunk) for worker, chunk in zip(self.agent_loop_workers, chunkes, strict=True) ] ) output = DataProto.concat(outputs) 从初始化也说明了，我们在RayPPOTrainer中init_workers方法里面初始化好AgentLoopManager，同时也初始化好了推理服务器和各个workers。 ## AsyncLLMServerManager 在上面的代码中，可以看到我们在创建各个worker的时候传入了初始化好的servers，需要一个类来对这些server进行管理，即AsyncLLMServerManager类。具体的作用就是针对不同的request，来选择哪一个server进行推理，使用LRU算法来进行管理，具体如下： def __init__(self, config: DictConfig, server_handles: list[ray.actor.ActorHandle], max_cache_size: int = 10000): \"\"\"Initialize the AsyncLLMServerManager. Args: config (DictConfig): YAML config. server_handles (List[ray.actor.ActorHandle]): OpenAI compatible LLM server actor handles. max_cache_size (int, optional): max cache size for request_id to server mapping. Defaults to 10000. \"\"\" self.config = config self.server_handles = server_handles random.shuffle(self.server_handles) # Least requests load balancing self.weighted_serveres = [[0, (hash(server), server)] for server in server_handles] heapq.heapify(self.weighted_serveres) # LRU cache to map request_id to server self.request_id_to_server = LRUCache(maxsize=max_cache_size) def _choose_server(self, request_id: str) -\u003e ray.actor.ActorHandle: # TODO: implement server pressure a","date":"2025-07-24","objectID":"/agent_loop/:1:0","tags":["coding","verl"],"title":"agent_loop","uri":"/agent_loop/"},{"categories":["verl","coding"],"content":"AgentLoopWorker 现在回到AgentLoopWorker中，前面已经提到了，我们用AgentLoopManager管理多个Worker，每一个Worker都可以用所有创建的server进行推理，接下来就看worker的generate_sequcences方法做了什么： async def generate_sequences(self, batch: DataProto) -\u003e DataProto: \"\"\"Generate sequences from agent loop. Args: batch (DataProto): Input batch. Returns: DataProto: Output batch. - prompts: [bsz, prompt_length], prompt token ids from dataset. - responses: [bsz, response_length], output token ids include response tokens from LLM generation and observation tokens from tool_calls. - response_mask: [bsz, response_length], 1 for LLM generated tokens, 0 for observation/padding tokens. - input_ids: [bsz, prompt_length + response_length], whole sequence token ids, including prompt tokens and response tokens. - attention_mask: [bsz, prompt_length + response_length], 0 for padding tokens, 1 for other tokens. - position_ids: [bsz, prompt_length + response_length], incremental position ids. For multi-turn conversations: responses: |\u003c- LLM generation -\u003e|\u003c- tool_calls -\u003e|\u003c- LLM generation -\u003e|\u003c- padding -\u003e| response_mask: | 1, 1, 1, ..., 1, 1 | 0, 0, .., 0, 0 | 1, 1, 1, ..., 1, 1 | 0, 0, ..., 0| \"\"\" config = self.config.actor_rollout_ref.rollout sampling_params = dict( temperature=config.temperature, top_p=config.top_p, repetition_penalty=1.0, ) # override sampling params for validation if batch.meta_info.get(\"validate\", False): sampling_params[\"top_p\"] = config.val_kwargs.top_p sampling_params[\"temperature\"] = config.val_kwargs.temperature # by default, we assume it's a single turn agent if \"agent_name\" not in batch.non_tensor_batch: batch.non_tensor_batch[\"agent_name\"] = np.array([\"single_turn_agent\"] * len(batch), dtype=object) tasks = [] agent_names = batch.non_tensor_batch[\"agent_name\"] raw_prompts = batch.non_tensor_batch[\"raw_prompt\"] if \"index\" in batch.non_tensor_batch: index = batch.non_tensor_batch[\"index\"] else: index = np.arange(len(raw_prompts)) trajectory_info = await get_trajectory_info( batch.meta_info.get(\"global_steps\", -1), index, batch.meta_info.get(\"validate\", False) ) for agent_name, messages, trajectory in zip(agent_names, raw_prompts, trajectory_info, strict=True): tasks.append( asyncio.create_task(self._run_agent_loop(agent_name, messages.tolist(), sampling_params, trajectory)) ) outputs = await asyncio.gather(*tasks) output = self._postprocess(outputs) return output 根据注释的信息，输入为batch数据，输出为推理后的prompt、response、mask等。这里需要先判断使用的agent_loop的类型，前面提到这里实现了single_turn和tool两种agent_loop，此外用户可以根据AgentLoopBase抽象类来自定义agent_loop（init_class和run两个方法）。 这里先是有一个判断，如果数据集中没有agent_name字段，则默认就是single_turn类型，因此如果你想使用agent_loop，必须在数据预处理的时候加入agent_name字段为tool_agent。这里创建了一个叫trajectory_info的变量，目的是为了rollout_trace，来区分保存到文件中的各个prompt生成的response。接下来进入到_run_agent_loop方法中： async def _run_agent_loop( self, agent_name: str, messages: list[dict[str, Any]], sampling_params: dict[str, Any], trajectory: dict[str, Any], ) -\u003e AgentLoopOutput: with rollout_trace_attr( step=trajectory[\"step\"], sample_index=trajectory[\"sample_index\"], rollout_n=trajectory[\"rollout_n\"], validate=trajectory[\"validate\"], name=\"agent_loop\", ): assert agent_name in _agent_loop_registry, ( f\"Agent loop {agent_name} not registered, registered agent loops: {_agent_loop_registry.keys()}\" ) agent_loop_config = _agent_loop_registry[agent_name] agent_loop = hydra.utils.instantiate( config=agent_loop_config, trainer_config=_DummyConfig(config=self.config), server_manager=self.server_manager, tokenizer=self.tokenizer, ) output = await agent_loop.run(messages, sampling_params) return output 对于定义的不同的agent_loop，需要用register装饰器进行注册（设计模式中的工厂模式），register装饰器如下： def register(agent_name: str): \"\"\"Register agent loop class.\"\"\" def decorator(subclass: type[AgentLoopBase]) -\u003e type[AgentLoopBase]: fqdn = f\"{subclass.__module__}.{subclass.__qualname__}\" _agent_loop_registry[agent_name] = {\"_target_\": fqdn} return subclass return decorator 对于装饰的类，将这个信息存入一个名为 _agent_loop_registry 的全局字典中。 - 键 (Key)：在装饰器中提供的 agent_name 字符串 (e.g., “my_agent”)。 值 (Value)：一个特殊格式的字典 {“target”","date":"2025-07-24","objectID":"/agent_loop/:2:0","tags":["coding","verl"],"title":"agent_loop","uri":"/agent_loop/"},{"categories":["verl","coding"],"content":"ToolAgentLoop 首先看初始化： @register(\"tool_agent\") class ToolAgentLoop(AgentLoopBase): @classmethod def init_class(cls, config, tokenizer, **kwargs): if cls._class_initialized: return cls._class_initialized = True print(\"Performing class-level ToolAgentLoop initialization\") # Initialize tools from config file cls.tokenizer = tokenizer cls.max_user_turns = config.actor_rollout_ref.rollout.multi_turn.max_user_turns cls.max_assistant_turns = config.actor_rollout_ref.rollout.multi_turn.max_assistant_turns cls.max_parallel_calls = config.actor_rollout_ref.rollout.multi_turn.max_parallel_calls cls.max_tool_response_length = config.actor_rollout_ref.rollout.multi_turn.max_tool_response_length cls.tool_response_truncate_side = config.actor_rollout_ref.rollout.multi_turn.tool_response_truncate_side tool_config_path = config.actor_rollout_ref.rollout.multi_turn.tool_config_path tool_list = initialize_tools_from_config(tool_config_path) if tool_config_path else [] cls.tools = {tool.name: tool for tool in tool_list} cls.tool_schemas = [tool.tool_schema.model_dump(exclude_unset=True, exclude_none=True) for tool in tool_list] cls.tool_parser = ToolParser.get_tool_parser(config.actor_rollout_ref.rollout.multi_turn.format, cls.tokenizer) print(f\"Initialized tools: {cls.tools}\") cls.prompt_length = config.actor_rollout_ref.rollout.prompt_length cls.response_length = config.actor_rollout_ref.rollout.response_length cls.system_prompt = tokenizer.apply_chat_template([{}], add_generation_prompt=False, tokenize=True) 关于工具的初始化，来自于sglang团队，详细可以看博客：Awesome-ML-SYS-Tutorial/rlhf/verl/multi-turn/release_log/verl-multiturn-rollout-Release_ZH.md at main · zhaochenyang20/Awesome-ML-SYS-Tutorial · GitHub 简单来说就是将工具的信息定义在一个yaml文件中，将文件路径传入到actor_rollout_ref.rollout.multi_turn.tool_config_path参数，然后获取tool_schemas用于后续传入到chat_template中，此外在tool_parser.py中定义了tool_parser。 这里还有一个值得注意的是system_prompt，这是因为进行chat_template的时候如果没有role为system的会自动加上，而在后面对工具返回结果进行单独chat_template的时候需要将自动添加的system prompt给删除，所以这里预存了一个system_prompt。 下面我们来看最核心的多轮rollout代码： @rollout_trace_op async def run(self, messages: list[dict[str, Any]], sampling_params: dict[str, Any]) -\u003e AgentLoopOutput: metrics = {} request_id = uuid4().hex prompt_ids = await self.loop.run_in_executor( None, lambda: self.tokenizer.apply_chat_template( messages, tools=self.tool_schemas, add_generation_prompt=True, tokenize=True ), ) response_mask = [] user_turns, assistant_turns = 0, 0 while True: with simple_timer(\"generate_sequences\", metrics): response_ids = await self.server_manager.generate( request_id=request_id, prompt_ids=prompt_ids, sampling_params=sampling_params ) prompt_ids += response_ids response_mask += [1] * len(response_ids) assistant_turns += 1 # reach max response length if len(response_mask) \u003e= self.response_length: break # reach max assistant turns if self.max_assistant_turns and assistant_turns \u003e= self.max_assistant_turns: break # reach max user turns if self.max_user_turns and user_turns \u003e= self.max_user_turns: break # no tool calls _, tool_calls = await self.tool_parser.extract_tool_calls(response_ids) if not tool_calls: break # call tools tasks = [] for tool_call in tool_calls[: self.max_parallel_calls]: tasks.append(self._call_tool(tool_call)) with simple_timer(\"tool_calls\", metrics): tool_responses = await asyncio.gather(*tasks) if any(isinstance(item, Exception) for item in tool_responses): break # append tool_response_ids tool_response_ids = await self.loop.run_in_executor( None, lambda messages=tool_responses: self.tokenizer.apply_chat_template( messages, add_generation_prompt=True, tokenize=True ), ) tool_response_ids = tool_response_ids[len(self.system_prompt) :] # NOTE: last turn should not be user turn, or the EOS token reward # can't be propagated to previous token in GAE. if len(response_mask) + len(tool_response_ids) \u003e= self.response_length: break prompt_ids += tool_response_ids response_mask += [0] * len(tool_response_ids) user_turns += 1 response_ids = prompt_ids[-len(response_mask) :] prompt_","date":"2025-07-24","objectID":"/agent_loop/:3:0","tags":["coding","verl"],"title":"agent_loop","uri":"/agent_loop/"},{"categories":["verl","coding"],"content":"返回 返回后，我们回到AgentLoopWorker的generate_sequences方法中，可以看到我们将返回的结果都放入了outputs变量中，而在最终输出前，需要进行后处理，也就是_postprocess方法。需要对prompt进行左pad，对response进行右pad，最后整合成DataProto返回。 def generate_sequences(self, prompts: DataProto) -\u003e DataProto: \"\"\"Split input batch and dispatch to agent loop workers. Args: prompts (DataProto): Input batch. Returns: DataProto: Output batch. \"\"\" if self.config.actor_rollout_ref.rollout.free_cache_engine: self.wake_up() chunkes = prompts.chunk(len(self.agent_loop_workers)) outputs = ray.get( [ worker.generate_sequences.remote(chunk) for worker, chunk in zip(self.agent_loop_workers, chunkes, strict=True) ] ) output = DataProto.concat(outputs) if self.config.actor_rollout_ref.rollout.free_cache_engine: self.sleep() # calculate performance metrics metrics = [output.meta_info[\"metrics\"] for output in outputs] # List[List[Dict[str, str]]] timing = self._performance_metrics(metrics, output) output.meta_info = {\"timing\": timing} return output 然后回到AgentLoopWorker的generate_sequences方法中，将各个worker推理的结果concat起来。并将一些metric放入meta_info来logger。 ","date":"2025-07-24","objectID":"/agent_loop/:4:0","tags":["coding","verl"],"title":"agent_loop","uri":"/agent_loop/"},{"categories":["大模型分布式","LLM"],"content":"如果想将模型训练扩展到大的批次，则很快就会达到在单个 GPU 上可以做的极限。具体来说，会发生 RuntimeError: CUDA out of memory。 梯度累计、Activation checkpointing 和 CPU offloading 都可以一定程度上减少显存的占用，为了_有效地_扩展到更大的模型大小和不断增长的数据集，同时仍然在合理的时间内训练模型，我们需要将计算分布在一组机器上。 3 D 并行即：数据并行、张量并行、流水线并行 后两者可以统一划分到模型并行，区别是一个是层内并行，一个是层间并行。 这里介绍数据并行。 ","date":"2025-07-23","objectID":"/data_parallel/:0:0","tags":["LLM","大模型分布式"],"title":"data_parallel","uri":"/data_parallel/"},{"categories":["大模型分布式","LLM"],"content":"Naive data parallel 一个很直觉的做法就是在 batch 维度上进行划分，各个卡上初始化完整的模型，然后将将划分的不同的 batch 发送到各个卡上进行前向传播和反向传播，再由一个卡整合梯度再下发给各 GPU，然后各 GPU 更新自己维护的模型参数。 image.png 但这种做法显然有很多问题，需要有一个 gpu 担任梯度聚合和下发的角色，如果这个 gpu 出问题了怎么办？每一个 gpu 都需要维护完整的模型参数、梯度和优化器，这部分的显存没有得到减少；此外这种方式通讯量很大，详见显存占用计算 ","date":"2025-07-23","objectID":"/data_parallel/:1:0","tags":["LLM","大模型分布式"],"title":"data_parallel","uri":"/data_parallel/"},{"categories":["大模型分布式","LLM"],"content":"DDP DDP 解决的问题就是将 Server 上的通讯压力均衡转移到各个 worker 上（Server 即担任梯度聚合和下发的角色，而 worker 就是各个 gpu），因此引入了 ring-all-reduce 算法来解决这个问题。需要把反向传播后的梯度切分成 N（world_size）份来进行 ring-all-reduce 算法。 ","date":"2025-07-23","objectID":"/data_parallel/:2:0","tags":["LLM","大模型分布式"],"title":"data_parallel","uri":"/data_parallel/"},{"categories":["大模型分布式","LLM"],"content":"zero zero ## fsdp fsdp ## 参考 The Ultra-Scale Playbook: Training LLMs on GPU Clusters 💥 Training Neural Nets on Larger Batches: Practical Tips for 1-GPU, Multi-GPU \u0026 Distributed setups | by Thomas Wolf | HuggingFace | Medium Training extremely large neural networks across thousands of GPUs. # 图解大模型训练之：数据并行上篇(DP, DDP与ZeRO) ","date":"2025-07-23","objectID":"/data_parallel/:3:0","tags":["LLM","大模型分布式"],"title":"data_parallel","uri":"/data_parallel/"},{"categories":["大模型分布式","LLM"],"content":"参考 The Ultra-Scale Playbook: Training LLMs on GPU Clusters 💥 Training Neural Nets on Larger Batches: Practical Tips for 1-GPU, Multi-GPU \u0026 Distributed setups | by Thomas Wolf | HuggingFace | Medium Training extremely large neural networks across thousands of GPUs. ","date":"2025-07-23","objectID":"/pipeline-parallelism/:1:0","tags":["LLM","大模型分布式"],"title":"pipeline parallelism","uri":"/pipeline-parallelism/"},{"categories":["大模型分布式","LLM"],"content":"参考 The Ultra-Scale Playbook: Training LLMs on GPU Clusters 💥 Training Neural Nets on Larger Batches: Practical Tips for 1-GPU, Multi-GPU \u0026 Distributed setups | by Thomas Wolf | HuggingFace | Medium Training extremely large neural networks across thousands of GPUs. ","date":"2025-07-23","objectID":"/tensor_parallel/:1:0","tags":["LLM","大模型分布式"],"title":"tensor_parallel","uri":"/tensor_parallel/"},{"categories":["大模型分布式","LLM"],"content":"分为zero1、zero2、zero3，虽然zero3对模型进行了分割，但是本质上还是属于数据并行，因为在前向传播和反向传播需要all-gather模型参数，需要完整的模型权重。 先来一张经典的图片： image.png 这里的K具体是多少可以看显存占用计算 接下来逐个介绍各个stage zero。随着zero优化的深入，越来越节省显存，但通讯时间也大大增加，导致训练时间增加。 ## zero1 针对优化器状态进行分割。 ","date":"2025-07-22","objectID":"/zero/:0:0","tags":["LLM","大模型分布式"],"title":"zero","uri":"/zero/"},{"categories":["大模型分布式","LLM"],"content":"zero2 针对优化器状态和梯度进行分割。 ","date":"2025-07-22","objectID":"/zero/:1:0","tags":["LLM","大模型分布式"],"title":"zero","uri":"/zero/"},{"categories":["大模型分布式","LLM"],"content":"zero3 针对优化器状态、梯度和模型参数进行分割。 ","date":"2025-07-22","objectID":"/zero/:2:0","tags":["LLM","大模型分布式"],"title":"zero","uri":"/zero/"},{"categories":["infra","LLM"],"content":" FLOPs, floating point operations, 表示浮点数运算次数，衡量了计算量的大小。 如何计算矩阵乘法的 FLOPs 呢？ 对于 \\(A\\in R^{1\\times n},B\\in R^{n\\times1}\\) ,计算 \\(AB\\) 需要进行 \\(n\\) 次乘法运算和 \\(n\\) 次加法运算，共计 \\(2n\\) 次浮点数运算，需要 \\(2n\\) 的 FLOPs。对于 \\(A\\in R^{m\\times n},B\\in R^{n\\times p}\\) ,计算 \\(AB\\) 需要的浮点数运算次数为 \\(2mnp\\) 。 在一次训练迭代中，假设输入数据的形状为 \\([b,s]\\) 。我们先分析 self-attention 块的计算，计 算公式如下： \\[Q=xW_Q,K=xW_K,V=xW_V\\] \\[x_{out}=softmax(\\frac{QK^T}{\\sqrt{h}})\\cdot V\\cdot W_o+x\\] 计算 \\(Q,K,V:\\) 矩阵乘法的输入和输出形状为 \\([b,s,h]\\times[h,h]\\to[b,s,h]\\) 。计算量为 \\(3*2bsh^2=6bsh^2\\) 。 \\(2.QK^T\\) 矩阵乘法的输入和输出形状为 \\([b,head\\_num,s,per\\_head\\_hidden\\_size]\\) \\(\\times[b,head\\_num,per\\_head\\_hidden\\_size,s]\\rightarrow[b,head\\_num,s,s]\\) 。计算量为 \\(2bs^2h\\) 。 3. 计算在 \\(V\\) 上的加权 \\(score\\cdot V\\), 矩阵乘法的输入和输出形状为 \\([b,head\\_num,s,s]\\times[b,head\\_num,s,per\\_head\\_hidden\\_size]\\) 。计算量为 \\(2bs^2h\\) 。 4. Attention 后的线性映射，矩阵乘法的输入和输出形状为 \\([b,s,h]\\times[h,h]\\to[b,s,h]\\) 。计 算量为 \\(2bsh^2\\) 。 接下来分析 MLP 块的计算，计算公式如下： \\[x=f_{gelu}(x_{out}W_1)W_2+x_{out}\\] 第一个线性层，矩阵乘法的输入和输出形状为 \\([b,s,h]\\times[h,4h]\\to[b,s,4h]\\)。计算量 为 \\(8bsh^2\\) 。 第二个线性层，矩阵乘法的输入和输出形状为 \\([b,s,4h]\\times[4h,h]\\to[b,s,h]\\)。计算量 为 \\(8bsh^2\\) 。 将上述计算量相加，得到每个 transformer 层的计算量大约为 \\(24bsh^2+4bs^2h\\) 。 此外，另一个计算量的大头是 logits 的计算，将隐藏向量映射为词表大小。矩阵乘法的输入和 输出形状为 \\([b,s,h]\\times[h,V]\\to[b,s,V]\\) ,计算量为 \\(2bshV\\) 。 因此，对于一个 \\(l\\) 层的 transformer 模型，输入数据形状为 \\([b,s]\\) 的情况下，一次训练迭代的 计算量为 \\(l*(24bsh^2+4bs^2h)+2bshV\\) 。 ","date":"2025-07-19","objectID":"/flops%E5%88%86%E6%9E%90/:0:0","tags":["LLM","infra"],"title":"flops分析","uri":"/flops%E5%88%86%E6%9E%90/"},{"categories":["infra","LLM"],"content":"计算量与参数量的关联 当隐藏维度 \\(h\\) 比较大，且远大于序列长度 \\(s\\) 时，我们可以忽略一次项，计算量可以近似为 \\(24bsh^2*l\\) 。前面提到当模型参数量为 \\(12lh^2\\), 输入的 tokens 数为 \\(bs\\) ,存在等式 \\(\\frac{24bsh^2l}{12h^2\\times bs}=2\\)。我们可以近似认为：在一次前向传递中，对于每个 token，每个模型参数，需要进行 2 次浮点数运算，即一次乘法法运算和一次加法运算。 一次训练迭代包含了前向传递和后向传递，后向传递的计算量是前向传递的 2 倍。因此，前向传递+后向传递的系数=1+2=3 。一次训练迭代中，对于每个 token，每个模型参数，需要进行 2*3=6 次浮点数运算。 接下来，我们可以估计训练 GPT 3-175 B 所需要的计算量。对于 GPT 3，每个 token，每个参数进行了 6 次浮点数运算，再乘以参数量和总 tokens 数就得到了总的计算量。GPT 3 的模型参数量为 174600 \\(M\\) ,训练数据量为 \\(300B\\) tokens。 \\[6\\times174600\\times10^6\\times300\\times10^9=3.1428\\times10^{23}flops\\] ","date":"2025-07-19","objectID":"/flops%E5%88%86%E6%9E%90/:1:0","tags":["LLM","infra"],"title":"flops分析","uri":"/flops%E5%88%86%E6%9E%90/"},{"categories":["infra","LLM"],"content":"训练时间 \\[ 训练时间=\\frac{8 * tokens数 *模型参数量}{GPU数 * GPU峰值flops*GPU利用率} \\] 也就是训练时的 flops / gpu 的 flops。8 是前向传播、后向传播、Activation checkpointing 。前向传播系数为 1，后向传播是前向传播计算量的 2 倍，再加上在反向传播时需要前向传播一次，因此总系数为 4，1 个参数需要 2 次浮点数运算，这就是 8 怎么来的。 ","date":"2025-07-19","objectID":"/flops%E5%88%86%E6%9E%90/:2:0","tags":["LLM","infra"],"title":"flops分析","uri":"/flops%E5%88%86%E6%9E%90/"},{"categories":["大模型分布式","LLM"],"content":"All-reduced=all-gather+reduce-scatter All-Gather ：将分布式数据汇总到所有节点，适用于需要全局数据同步的场景。 Reduce-Scatter：将分布式数据进行规约并分散到所有节点，适用于需要局部结果分发的场景。 All-Reduce ： Reduce-Scatter 和 All-Gather 的组合。 ","date":"2025-07-17","objectID":"/ring-all-reduce/:0:0","tags":["LLM","大模型分布式"],"title":"ring-all-reduce","uri":"/ring-all-reduce/"},{"categories":["大模型分布式","LLM"],"content":"All-gather 核心功能：将每个节点的部分数据汇总到所有节点，最终所有节点拥有完整数据副本。 适用场景：模型并行中的参数同步、全局统计信息聚合。 image.png ","date":"2025-07-17","objectID":"/ring-all-reduce/:1:0","tags":["LLM","大模型分布式"],"title":"ring-all-reduce","uri":"/ring-all-reduce/"},{"categories":["大模型分布式","LLM"],"content":"Reduce-Scatter 核心功能：先对多节点数据进行规约（如求和），再将结果分散到各节点，使每个节点仅保留部分规约结果。 适用场景：ZeRO显存优化、梯度分片更新。 image.png ","date":"2025-07-17","objectID":"/ring-all-reduce/:2:0","tags":["LLM","大模型分布式"],"title":"ring-all-reduce","uri":"/ring-all-reduce/"},{"categories":["大模型分布式","LLM"],"content":"区别 All-Gather：只进行数据收集和分发，不进行任何计算或规约操作。每个节点拥有所有节点的数据副本。 Reduce-Scatter：先进行数据规约（reduce），然后再进行数据分散（scatter）。每个节点只拥有部分规约后的数据，而不是所有的数据 ","date":"2025-07-17","objectID":"/ring-all-reduce/:3:0","tags":["LLM","大模型分布式"],"title":"ring-all-reduce","uri":"/ring-all-reduce/"},{"categories":["大模型分布式","LLM"],"content":"例子 ","date":"2025-07-17","objectID":"/ring-all-reduce/:4:0","tags":["LLM","大模型分布式"],"title":"ring-all-reduce","uri":"/ring-all-reduce/"},{"categories":["大模型分布式","LLM"],"content":"通信量计算 假设模型参数大小为 \\(\\theta\\)，GPU 个数为 N，则每一个梯度块大小为 \\(\\frac{\\theta}{N}\\) 对于单卡而言： - Reduce-Scatter 阶段通讯量：\\((N-1) \\frac{\\theta}{N}\\) - All-Reduce 阶段通讯量：\\((N-1) \\frac{\\theta}{N}\\) 单卡通讯量为 \\(2(N-1) \\frac{\\theta}{N}\\)，所有卡的通讯量为 \\(2(N-1) \\theta\\) ","date":"2025-07-17","objectID":"/ring-all-reduce/:5:0","tags":["LLM","大模型分布式"],"title":"ring-all-reduce","uri":"/ring-all-reduce/"},{"categories":["大模型分布式","LLM"],"content":"参考 # 分布式训练中All-Reduce、All-Gather、Reduce-Scatter原理介绍 ","date":"2025-07-17","objectID":"/ring-all-reduce/:6:0","tags":["LLM","大模型分布式"],"title":"ring-all-reduce","uri":"/ring-all-reduce/"},{"categories":["verl","coding"],"content":"batch_size的复杂性来自于tp、dp、sp，引用一下浅入理解verl中的batch_size的解释： vllm + fsdp 训推时，如果每张卡都是一个 DP，事情会简单很多。但 verl 中有两个功能不满足这一条件，一是 rollout 时让 vllm 开启 TP，二是在 fsdp 中使用 ulysses（SP）。verl 中数据分发使用的是 dispatch mode 这一机制，比如 fsdp workers 主要使用 Dispatch.DP_COMPUTE_PROTO这个 mode，它是在 worker group 的层次上进行数据分发以及结果收集的。由于这个层次是没有 TP/SP 概念的，所以它仅在 one GPU one DP 时才是正确的。那么为了正确支持 TP/SP，就需要对数据做一些前后处理。 这一点在DataProto也有提到，具体的实现就是all_gather_data_proto函数。 TP需要在TP rank上all-gather来保证各个tp rank的输入相同，然后再将输出split返回当前rank的部分，保持和输入一致。 SP与 TP 一样，在 SP group 上进行 allgather 来保证各个 SP rank 的输入相同（ulysses 的需要）；对输出进行 split 并返回当前 rank 对应的部分。 在fsdp_worker中，初始化阶段对batch_size进行了处理： # normalize config if self._is_actor: self.config.actor.ppo_mini_batch_size *= self.config.rollout.n self.config.actor.ppo_mini_batch_size //= self.device_mesh.size() // self.ulysses_sequence_parallel_size assert self.config.actor.ppo_mini_batch_size \u003e 0, ( f\"ppo_mini_batch_size {self.config.actor.ppo_mini_batch_size} should be larger than 0 after \" f\"normalization\" ) # micro bsz if self.config.actor.ppo_micro_batch_size is not None: self.config.actor.ppo_micro_batch_size //= ( self.device_mesh.size() // self.ulysses_sequence_parallel_size ) self.config.actor.ppo_micro_batch_size_per_gpu = self.config.actor.ppo_micro_batch_size if self.config.actor.ppo_micro_batch_size_per_gpu is not None: assert self.config.actor.ppo_mini_batch_size % self.config.actor.ppo_micro_batch_size_per_gpu == 0, ( f\"normalized ppo_mini_batch_size {self.config.actor.ppo_mini_batch_size} should be divisible by \" f\"ppo_micro_batch_size_per_gpu {self.config.actor.ppo_micro_batch_size_per_gpu}\" ) assert self.config.actor.ppo_mini_batch_size // self.config.actor.ppo_micro_batch_size_per_gpu \u003e 0, ( f\"normalized ppo_mini_batch_size {self.config.actor.ppo_mini_batch_size} should be larger than \" f\"ppo_micro_batch_size_per_gpu {self.config.actor.ppo_micro_batch_size_per_gpu}\" ) # normalize rollout config if self._is_rollout and self.config.rollout.log_prob_micro_batch_size is not None: self.config.rollout.log_prob_micro_batch_size //= ( self.device_mesh.size() // self.ulysses_sequence_parallel_size ) self.config.rollout.log_prob_micro_batch_size_per_gpu = self.config.rollout.log_prob_micro_batch_size # normalize ref config if self._is_ref and self.config.ref.log_prob_micro_batch_size is not None: self.config.ref.log_prob_micro_batch_size //= self.device_mesh.size() // self.ulysses_sequence_parallel_size self.config.ref.log_prob_micro_batch_size_per_gpu = self.config.ref.log_prob_micro_batch_size 前面创建了fsdp_devicmesh（dp）、ulysses_device_mesh（dp和sp）以及在初始化rollout中创建了rollout_device_mesh（dp和tp）。具体可以查看device_mesh。 ","date":"2025-07-16","objectID":"/batch_size%E8%A7%A3%E9%87%8A/:0:0","tags":["coding","verl"],"title":"batch_size解释","uri":"/batch_size%E8%A7%A3%E9%87%8A/"},{"categories":["verl","coding"],"content":"Rollout 注意verl v0.5.0的实现中，所有的prompts直接由driver重复然后再dispatch，而不是先dispatch然后再交给Worker重复样本。这样做的目的是如果先分片的话，有可能batch_size小于world_size（对我来说基本不可能），导致不能正确切分，如果是先repeat的话就可以了。 因此对于Rollout： - 全局：train_batch_size * n个prompts，输出train_batch_size * n个prompts + responses。 - 单卡：输入train_batch_size * n / world_size个prompts，进行前处理为\\(\\frac{train\\_batch\\_size * n}{world\\_size} * tp\\_size\\)个prompts，然后进行推理，得到\\(\\frac{train\\_batch\\_size * n}{world\\_size} * tp\\_size\\)个prompts+responses，再进行后处理，输出train_batch_size * n / world_size个prompts+responses。 ","date":"2025-07-16","objectID":"/batch_size%E8%A7%A3%E9%87%8A/:1:0","tags":["coding","verl"],"title":"batch_size解释","uri":"/batch_size%E8%A7%A3%E9%87%8A/"},{"categories":["verl","coding"],"content":"Actor 与Actor有关的参数为ppo_mini_batch_size（决定一批experience的更新次数）、rollout.log_prob_micro_batch_size_per_gpu（计算old_logp）、ref.log_prob_micro_batch_size_per_gpu（计算ref_logp）、micro_batch_size_per_gpu（直接指定单卡上的batch_size）。 重点看ppo_mini_batch_size用于update_policy的处理，其它的都大同小异： 全局：train_batch_size * n大小的batch，包含了部分计算好的experience。 单卡：输入为train_batch_size * n / world_size，经过前处理为train_batch_size * rollout_n * sp_size / world_size。这和fsdp_worker初始化时的ppo_mini_batch_size一致，即 self.config.actor.ppo_mini_batch_size *= self.config.rollout.n self.config.actor.ppo_mini_batch_size //= self.device_mesh.size() // self.ulysses_sequence_parallel_size 这样的话对于一批experience的更新次数，就等于你传入的train_batch_size // mini_batch_size。对于micro_batch_size_per_gpu参数来说，可以直接指定单卡的bs。对于传入micro_batch_size再计算的方式，verl已经废弃了。 ","date":"2025-07-16","objectID":"/batch_size%E8%A7%A3%E9%87%8A/:2:0","tags":["coding","verl"],"title":"batch_size解释","uri":"/batch_size%E8%A7%A3%E9%87%8A/"},{"categories":["verl","coding"],"content":"ppo流程 从图中可以得到的是ppo_mini_batch_size是全局的prompt batch，而ppo_micro_batch_per_gpu是每一个gpu上的prompt+response batch，所以由此可以得到梯度累计的steps为 ppo_mini_batch_size * n * sp_size // world_size // micro_batch_per_gpu。即micro_batch_per_gpu代表梯度累计的bs。 ","date":"2025-07-16","objectID":"/batch_size%E8%A7%A3%E9%87%8A/:3:0","tags":["coding","verl"],"title":"batch_size解释","uri":"/batch_size%E8%A7%A3%E9%87%8A/"},{"categories":["verl","coding"],"content":"参考 浅入理解verl中的batch_size ","date":"2025-07-16","objectID":"/batch_size%E8%A7%A3%E9%87%8A/:4:0","tags":["coding","verl"],"title":"batch_size解释","uri":"/batch_size%E8%A7%A3%E9%87%8A/"},{"categories":["","LLM","attention","NLP"],"content":"Self-attention 首先介绍一下最主要的 self-attention，可以说是 self-attention 实现了上述的 token 之间交互的功能。 自注意力是模型的关键组成部分之一。注意和自注意之间的区别在于，自注意在相同性质的表示之间运行：例如，某个层中的所有编码器状态。 形式上，这种直觉是通过查询键值注意来实现的。Self-attention 中的每个输入标记都会收到三种表示，对应于它可以扮演的角色： Query Key Value 进入正题： 作为我们想要翻译的输入语句“The animal didn’t cross the street because it was too tired”。句子中”it”指的是什么呢？“it”指的是”street” 还是“animal”？对人来说很简单的问题，但是对算法而言并不简单。 当模型处理单词“it”时，self-attention 允许将“it”和“animal”联系起来。当模型处理每个位置的词时，self-attention 允许模型看到句子的其他位置信息作辅助线索来更好地编码当前词。如果你对 RNN 熟悉，就能想到 RNN 的隐状态是如何允许之前的词向量来解释合成当前词的解释向量。Transformer 使用 self-attention 来将相关词的理解编码到当前词中。 下面看一下 self-attention 是如何计算的： ","date":"2025-07-16","objectID":"/mha/:1:0","tags":["LLM","Attention","NLP"],"title":"MHA","uri":"/mha/"},{"categories":["","LLM","attention","NLP"],"content":"向量计算 第一步，根据编码器的输入向量，生成三个向量，比如，对每个词向量，生成 query-vec, key-vec, value-vec，生成方法为分别乘以三个矩阵，这些矩阵在训练过程中需要学习。【注意：不是每个词向量独享 3 个 matrix，而是所有输入共享 3 个转换矩阵；权重矩阵是基于输入位置的转换矩阵；有个可以尝试的点，如果每个词独享一个转换矩阵，会不会效果更厉害呢？】 注意到这些新向量的维度比输入词向量的维度要小（512–\u003e64），并不是必须要小的，是为了让多头 attention 的计算更稳定。 第二步，计算 attention 就是计算一个分值。对“Thinking Matchines”这句话，对“Thinking”（pos #1 ）计算 attention 分值。我们需要计算每个词与“Thinking”的评估分，这个分决定着编码“Thinking”时（某个固定位置时），每个输入词需要集中多少关注度。 这个分，通过“Thing”对应 query-vector 与所有词的 key-vec 依次做点积得到。所以当我们处理位置 #1时 ，第一个分值是 q 1 和 k 1 的点积，第二个分值是 q 1 和 k 2 的点积。这也就是所谓的注意力得分. 第三步和第四步，除以 8 (\\(=\\sqrt{dim_{key}}\\))，这样梯度会更稳定。然后加上 softmax 操作，归一化分值使得全为正数且加和为 1。 Softmax 分值决定着在这个位置，每个词的表达程度（关注度）。很明显，这个位置的词应该有最高的归一化分数，但大部分时候总是有助于关注该词的相关的词。 第五步，将 softmax 分值与 value-vec 按位相乘。保留关注词的 value 值，削弱非相关词的 value 值。 第六步，将所有加权向量加和，产生该位置的 self-attention 的输出结果。 上述就是 self-attention 的计算过程，生成的向量流入前向网络。在实际应用中，上述计算是以速度更快的矩阵形式进行的。下面我们看下在单词级别的矩阵计算。 ","date":"2025-07-16","objectID":"/mha/:1:1","tags":["LLM","Attention","NLP"],"title":"MHA","uri":"/mha/"},{"categories":["","LLM","attention","NLP"],"content":"矩阵计算 第一步，计算 query/key/value matrix，将所有输入词向量合并成输入矩阵 \\(X\\)，并且将其分别乘以权重矩阵 \\(W^q, W^k,W^v\\) 最后，鉴于我们使用矩阵处理，将步骤 2~6 合并成一个计算 self-attention 层输出的公式。 ","date":"2025-07-16","objectID":"/mha/:1:2","tags":["LLM","Attention","NLP"],"title":"MHA","uri":"/mha/"},{"categories":["","LLM","attention","NLP"],"content":"多头注意力机制 论文进一步增加了 multi-headed 的机制到 self-attention 上，在如下两个方面提高了 attention 层的效果： 多头机制扩展了模型集中于不同位置的能力。在上面的例子中，z 1 只包含了其他词的很少信息，仅由实际自己词决定。在其他情况下，比如翻译 “The animal didn’t cross the street because it was too tired”时，我们想知道单词”it”指的是什么。 多头机制赋予 attention 多种子表达方式。像下面的例子所示，在多头下有多组 query/key/value-matrix，而非仅仅一组（论文中使用 8-heads）。每一组都是随机初始化，经过训练之后，输入向量可以被映射到不同的子表达空间中。 如果我们计算 multi-headed self-attention 的，分别有八组不同的 Q/K/V matrix，我们得到八个不同的矩阵。 这会带来点麻烦，前向网络并不能接收八个矩阵，而是希望输入是一个矩阵，所以要有种方式处理下八个矩阵合并成一个矩阵。 上述就是多头自注意机制的内容，我认为还仅是一部分矩阵，下面尝试着将它们放到一个图上可视化如下。 #### 代码 下面实现一下多头注意力机制，在原论文中，实现的方法如下： 也就是对每个 W 进行多头的设置，即为原维度/head，然后拼接后，再经过 \\(hd_v\\times d_{model}\\) 的转换又得到原来的维度，代码的实现不太一样，代码是 W 还是 \\(d_{model}\\times d_{model}\\) 的矩阵然后得到 q, k, v 之后再进行截断，实现如下。 class MultiHeadedAttention(nn.Module): def __init__(self, h, d_model, dropout=0.1) -\u003e None: # h为head，这里为8，d_model为embedding的维度，这里为512 super().__init__() assert d_model % h == 0 self.d_k = d_model // h # 64 self.h = h self.Q_Linear = nn.Linear(d_model, d_model) self.K_Linear = nn.Linear(d_model, d_model) self.V_Linear = nn.Linear(d_model, d_model) self.res_Linear = nn.Linear(d_model, d_model) self.attn = None self.dropout = nn.Dropout(p=dropout) def forward(self, query, key, value, mask=None): if mask is not None: mask = mask.unsqueeze(1) batch_size = query.size(0) query = self.Q_Linear(query).view(batch_size, -1, self.h, self.d_k) # (batch_size, seq_len, h, d_k)即(batch_size, seq_len, 8, 64) query = query.transpose(1, 2) # (batch_size, h, seq_len, d_k)即(batch_size, 8, seq_len, 64) key = self.K_Linear(key).view(batch_size, -1, self.h, self.d_k).transpose(1, 2) value = self.V_Linear(value).view(batch_size, -1, self.h, self.d_k).transpose(1, 2) x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout) # x为(batch_size, h, seq_len, d_k) # attn为(batch_size, h, seq_len1, seq_len2) x = x.transpose(1, 2).contiguous().view(batch_size, -1, self.h * self.d_k) # (batch_size, h, seq_len, d_k) -\u003e (batch_size, seq_len, h, d_k) -\u003e (batch_size, seq_len, h * d_k) = (batch_size, seq_len, 512) return self.res_Linear(x) ","date":"2025-07-16","objectID":"/mha/:1:3","tags":["LLM","Attention","NLP"],"title":"MHA","uri":"/mha/"},{"categories":["","LLM","attention","NLP"],"content":"Masked self-attention 在训练的时候，主要是消除后面的信息对预测的影响，因为 decoder 输入的是整个句子，也就是我们所谓的参考答案，而实际预测的时候就是预测后面的 token，用不到后面的 token，如果不 mask 掉，当前的 token 将看到“未来”，这不是我们想要的，因此必须要 mask 掉。 其实 decoder 里的 sequence mask 与 encoder 里的 padding mask 异曲同工，padding mask 其实很简单，就是为了使句子长度一致进行了 padding，而为了避免关注 padding 的位置，进行了 mask，具体的做法就是将这些位置的值变成负无穷，这样 softmax 之后就接近于 0 了。 而 sequence mask 思想也差不多： 假设现在解码器的输入”\u003c s \u003e who am i \u003c e \u003e“在分别乘上一个矩阵进行线性变换后得到了 Q、K、V，且 Q 与 K 作用后得到了注意力权重矩阵（此时还未进行 softmax 操作），如图 17 所示。 此时已经计算得到了注意力权重矩阵。由第 1 行的权重向量可知，在解码第 1 个时刻时应该将 20%（严格来说应该是经过 softmax 后的值）的注意力放到’\u003c s \u003e’上，30%的注意力放到’who’上等等。不过此时有一个问题就是，模型在实际的预测过程中只是将当前时刻之前（包括当前时刻）的所有时刻作为输入来预测下一个时刻，也就是说模型在预测时是看不到当前时刻之后的信息。因此，Transformer 中的 Decoder 通过加入注意力掩码机制来解决了这一问题。 当然还要进行 softmax 等计算。 在网上查了很多资料，说法都很不一样，不过我更倾向于这样的看法。而在预测的时候是用前面的输出结果作为输入的。 几张图帮助理解： 后面还有 padding mask，所有的 self attention 都要用这个，因为 pad 的位置没有任何意义。 实践一下加深理解： 首先我们来定义模型： # 词典数为10， 词向量维度为8 embedding = nn.Embedding(10, 8) # 定义Transformer，注意一定要改成eval模型，否则每次输出结果不一样 transformer = nn.Transformer(d_model=8, batch_first=True).eval() 接下来定义我们的 src 和 tgt： # Encoder的输入 src = torch.LongTensor([[0, 1, 2, 3, 4]]) # Decoder的输入 tgt = torch.LongTensor([[4, 3, 2, 1, 0]]) 然后我们将 [4] 送给 Transformer 进行预测，模拟推理时的第一步： transformer(embedding(src), embedding(tgt[:, :1]), # 这个就是用来生成阶梯式的mask的 tgt_mask=nn.Transformer.generate_square_subsequent_mask(1)) tensor([[[ 1.4053, -0.4680, 0.8110, 0.1218, 0.9668, -1.4539, -1.4427, 0.0598]]], grad_fn=\u003cNativeLayerNormBackward0\u003e) 然后我们将 [4, 3] 送给 Transformer，模拟推理时的第二步： transformer(embedding(src), embedding(tgt[:, :2]), tgt_mask=nn.Transformer.generate_square_subsequent_mask(2)) tensor([[[ 1.4053, -0.4680, 0.8110, 0.1218, 0.9668, -1.4539, -1.4427, 0.0598], [ 1.2726, -0.3516, 0.6584, 0.3297, 1.1161, -1.4204, -1.5652, -0.0396]]], grad_fn=\u003cNativeLayerNormBackward0\u003e) 出的第一个向量和上面那个一模一样。 最后我们再将 tgt 一次性送给 transformer，模拟训练过程： transformer(embedding(src), embedding(tgt), tgt_mask=nn.Transformer.generate_square_subsequent_mask(5)) tensor([[[ 1.4053, -0.4680, 0.8110, 0.1218, 0.9668, -1.4539, -1.4427, 0.0598], [ 1.2726, -0.3516, 0.6584, 0.3297, 1.1161, -1.4204, -1.5652, -0.0396], [ 1.4799, -0.3575, 0.8310, 0.1642, 0.8811, -1.3140, -1.5643, -0.1204], [ 1.4359, -0.6524, 0.8377, 0.1742, 1.0521, -1.3222, -1.3799, -0.1454], [ 1.3465, -0.3771, 0.9107, 0.1636, 0.8627, -1.5061, -1.4732, 0.0729]]], grad_fn=\u003cNativeLayerNormBackward0\u003e) 可以看到使用 mask 后就可以保证前面的结果都是不变的，不然如果没有 mask 则计算 attention 时因为计算注意力变化所以结果都会变化，这就是 Mask self-attention 的意义。 到这里 self-attention 就介绍完了 ","date":"2025-07-16","objectID":"/mha/:1:4","tags":["LLM","Attention","NLP"],"title":"MHA","uri":"/mha/"},{"categories":[""],"content":" image.png 标准的 mha 中，KV heads 的数量和 Query heads 的数量相同，每一个 q head 对应一个独立的 kv head，但这样的开销比较大。 MQA (Multi Queries Attention): MQA 比较极端，只保留一个 KV Head，多个 Query Heads 共享相同的 KV Head。这相当于不同 Head 的 Attention 差异，全部都放在了 Query 上，需要模型仅从不同的 Query Heads 上就能够关注到输入 hidden states 不同方面的信息。这样做的好处是，极大地降低了 KV Cache 的需求，但是会导致模型效果有所下降。（层内共享） ","date":"2025-07-16","objectID":"/mqa/:0:0","tags":null,"title":"MQA","uri":"/mqa/"},{"categories":["RLHF","LLM"],"content":"DAPO 是对 GRPO 的改进。DAPO（Decoupled Clip and Dynamic sAmpling Policy Optimization，即解耦裁剪和动态采样策略优化）的优化点有四个（其中前 2 个是主要亮点，是命名的来源） image.png ","date":"2025-07-15","objectID":"/dapo/:0:0","tags":["LLM","RLHF"],"title":"dapo","uri":"/dapo/"},{"categories":["RLHF","LLM"],"content":"更高裁剪 clip的上边界可以放宽一些，即 clip_high 从 0.2 提高到了 0.28。 传统的PPO算法中，上限裁剪（upper clip）会限制策略的探索能力。这个问题在低概率的”探索型”token上特别明显，因为这些token的概率提升会被限制在一个严格的范围内。这导致了”熵坍塌”现象，也就是说策略的信息熵下降，采样的响应趋于几个相同的结果，限制了探索。DAPO通过调整上限ehigh裁剪范围来解决这个问题，特别是通过提高ehigh的值，为低概率token的概率提升留出更多空间。实验证明这种方法有效增强了策略的探索性，成功解决了熵坍塌问题。 ","date":"2025-07-15","objectID":"/dapo/:1:0","tags":["LLM","RLHF"],"title":"dapo","uri":"/dapo/"},{"categories":["RLHF","LLM"],"content":"动态采样（Dynamic Sampling） 在现有的RL算法中，如果某些提示的准确率达到1时，会遇到梯度下降的问题。比如在GRPO中，如果一个特定提示的所有输出都是正确的并获得相同的奖励，那么这组数据的优势（advantage）就会变为零。这种情况会导致策略梯度为零，缩小了批次梯度的幅度并增加了噪声敏感性，降低了采样效率。随着训练的进行，准确率为1的样本数量不断增加，这意味着每个批次中有效提示的数量不断减少，导致梯度方差增大并削弱了模型训练的梯度信号。同样地，准确率为0的样本也会导致零梯度问题。DAPO的解决方案是在训练前，采样并过滤准确率为1和0的提示，确保训练批次中有充满准确率既非0也非1的样本。这样可以确保批次中所有的提示都带有有效的梯度信号，保持了批次中有效提示数量的一致性，从而提高了训练效率和稳定性。 image.png image.png ","date":"2025-07-15","objectID":"/dapo/:2:0","tags":["LLM","RLHF"],"title":"dapo","uri":"/dapo/"},{"categories":["RLHF","LLM"],"content":"Token 级策略梯度损失（Token-Level Policy Gradient Loss） 这种策略可以使得response length稳步增长，而不是波动大。 image.png image.png ","date":"2025-07-15","objectID":"/dapo/:3:0","tags":["LLM","RLHF"],"title":"dapo","uri":"/dapo/"},{"categories":["RLHF","LLM"],"content":"超长奖励塑造（Overlong Reward Shaping） image.png image.png ","date":"2025-07-15","objectID":"/dapo/:4:0","tags":["LLM","RLHF"],"title":"dapo","uri":"/dapo/"},{"categories":["RLHF","LLM"],"content":"参考 # DAPO全是已有的小trick，为什么这么火? ","date":"2025-07-15","objectID":"/dapo/:5:0","tags":["LLM","RLHF"],"title":"dapo","uri":"/dapo/"},{"categories":["Attention","LLM"],"content":"Safe softmax 并没有 1-pass 算法，那么 Attention 会不会有呢？有！这就是 FlashAttention！ 在使用 online attention 的情况下，从头开始计算 attention score 的过程如下： \\(\\operatorname{NOTATIONS}\\) \\(Q[k,:]:\\) the \\(k\\) -th row vector of \\(Q\\) matrix. \\(\\begin{aligned}O[k,:]:\\mathrm{~the~}k\\text{-th row of output }O\\mathrm{~matrix.}\\\\\\mathbf{V}[i,i]:\\mathrm{~the~}k\\text{-th row of output }O\\mathrm{~matrix.}\\end{aligned}\\) \\(V[i,:]{:\\text{ the }i\\text{-th row of }V\\text{ matrix}}.\\) \\(\\{\\boldsymbol{o}_i\\}{:}\\sum_{j=1}^ia_jV[j,:]\\), a row vector storing partial aggregation result \\(A[k,:i]\\times V[:i,:]\\) BODY \\(\\textbf{for }i\\leftarrow 1, N\\textbf{ do}\\) \\[\\begin{aligned}x_i\u0026\\leftarrow\\quad Q[k,:]\\:K^T[:,i]\\\\m_i\u0026\\leftarrow\\quad\\max\\left(m_{i-1},x_i\\right)\\\\d_i'\u0026\\leftarrow\\quad d_{i-1}'e^{m_{i-1}-m_i}+e^{x_i-m_i}\\end{aligned}\\] \\(\\mathbf{end}\\) \\(\\textbf{for }i\\leftarrow 1, N\\textbf{ do}\\) \\[\\begin{aligned}\u0026a_i\\:\\leftarrow\\:\\frac{e^{x_i-m_N}}{d_N^{\\prime}}\\\\\u0026o_i\\:\\leftarrow\\:o_{i-1}+a_i\\:V[i,:\\:]\\end{aligned}\\] \\(\\mathbf{end}\\) \\[O[k,:]\\leftarrow\\boldsymbol{o}_N\\] 优化思路和 online attention 一样，将 \\(o_{i}\\) 的计算简化以便于可以写成迭代式。 原来的 \\(o_{i}\\) 使用以下方式计算，依赖于全局的 \\(m_{N}\\) 和 \\(d_{N}\\)。 \\[\\boldsymbol{o}_i:=\\sum_{j=1}^i\\left(\\frac{e^{x_j-m_N}}{d_N^{\\prime}}V[j,:]\\right)\\] 将其改写成如下形式： \\[\\boldsymbol{o}_i^{\\prime}:=\\left(\\sum_{j=1}^i\\frac{e^{x_j-m_i}}{d_i^{\\prime}}V[j,:]\\right)\\] 这样按照上面的方式拓展下去，可以找到一个循环迭代式。 \\[\\begin{aligned} \\mathbf{o}_i^{\\prime}\u0026 =\\sum_{j=1}^i\\frac{e^{x_j-m_i}}{d'}V[j,:] \\\\ \u0026= \\left(\\sum_{j=1}^{i-1}\\frac{e^{x_j-m_i}}{d_i^{\\prime}}V[j,:] \\right)+\\frac{e^{x_i-m_i}}{d_i^{\\prime}}V[i,:] \\\\ \u0026= \\left(\\sum_{j=1}^{i-1}\\frac{e^{x_j-m_{i-1}}}{d_{i-1}^{\\prime}}\\frac{e^{x_j-m_i}}{e^{x_j-m_{i-1}}}\\frac{d_{i-1}^{\\prime}}{d_i^{\\prime}}V[j,:]\\right)+\\frac{e^{x_i-m_i}}{d_i^{\\prime}}V[i,:] \\\\ \u0026= \\left(\\sum_{j=1}^{i-1}\\frac{e^{x_j-m_{i-1}}}{d_{i-1}^{\\prime}}V[j,.]\\right)\\frac{d_{i-1}^{\\prime}}{d_i^{\\prime}}e^{m_{i-1}-m_i}+\\frac{e^{x_i-m_i}}{d_i^{\\prime}}V[i,.] \\\\ \u0026= \\boldsymbol{o}_{i-1}'\\frac{d_{i-1}'e^{m_{i-1}-m_i}}{d_i'}+\\frac{e^{x_i-m_i}}{d_i'}V[i,:] \\end{aligned}\\] 这样就找到了 \\(o_{i}\\) 的递推表达式。 之后对 Q, K 进行 tiling 后计算，得到如下： \\[\\begin{aligned}\u0026\\textbf{for }i\\leftarrow1,\\#\\text{tiles do}\\\\\u0026\u0026\u0026\\boldsymbol{x}_i\\quad\\leftarrow\\quad Q[k;\\cdot] K^T[\\cdot,(i-1) b; i b]\\\\\u0026\u0026\u0026m_i^{(\\mathrm{local})}=\\begin{array}{c}\\overset{b}{\\operatorname*{max}}\\left(\\boldsymbol{x}_i[j]\\right)\\\\\\end{array}\\\\\u0026\u0026\u0026m_i \\leftarrow \\max\\left(m_{i-1},m_i^{(\\mathrm{local})}\\right)\\\\\u0026\u0026\u0026a_i^{\\prime} \\leftarrow d_{i-1}^{\\prime}e^{m_{i-1}-m_i}+\\sum_{j=1}^be^{\\boldsymbol{x}_i[j]-m_i}\\\\\u0026\u0026\u0026\\boldsymbol{o}_i^{\\prime} \\leftarrow \\boldsymbol{o}_{i-1}^{\\prime}\\frac{d_{i-1}^{\\prime}e^{m_{i-1}-m_i}}{d_i^{\\prime}}+\\sum_{j=1}^b\\frac{e^{\\boldsymbol{x}_i[j]-m_i}}{d_i^{\\prime}}V[(i-1) b+j,:]\\\\\u0026\\text{end}\\\\\u0026\u0026\u0026O[k,:]\\leftarrow\\boldsymbol{o}_{N/b}^{\\prime}\\end{aligned}\\] 对于 tiles，示意图如下： 可以理解成滑动窗口，\\(K^{T}\\) 从左向右滑动（按列读取），\\(V\\) 从上向下滑动（按行读取）。也可以直接理解成分块矩阵，具体为什么这么做，参考：Cuda 编程之 Tiling - 知乎 (zhihu.com) ","date":"2025-07-15","objectID":"/flash-attention/:0:0","tags":["Attention"],"title":"flash attention","uri":"/flash-attention/"},{"categories":["Attention","LLM"],"content":"参考 From Online Softmax to FlashAttention. ) ","date":"2025-07-15","objectID":"/flash-attention/:1:0","tags":["Attention"],"title":"flash attention","uri":"/flash-attention/"},{"categories":["Attention","LLM"],"content":" image.png 如上图所示，GQA 就是在 MHA 和 MQA 之间做了一个平衡。对 query heads 进行分组，分成几组就对应多少个 kv heads，然后每一组内的 query Heads 共享相同的 KV head。 GQA 可以在减少计算量和 KV Cache 同时确保模型效果不受到大的影响。 现在基本都使用 GQA，代码如下（核心是 repeat_kv 函数）： ```python def repeat_kv(x: torch.Tensor, n_rep: int) -\u003e torch.Tensor: “““torch.repeat_interleave(x, dim=2, repeats=n_rep)”“” bs, slen, n_kv_heads, head_dim = x.shape if n_rep == 1: return x return ( x[:, :, :, None, :] .expand(bs, slen, n_kv_heads, n_rep, head_dim) .reshape(bs, slen, n_kv_heads * n_rep, head_dim) ) class Attention(nn.Module): “““Multi-head attention module.”“” def __init__(self, args: ModelArgs): \"\"\" Initialize the Attention module. Args: args (ModelArgs): Model configuration parameters. Attributes: n_kv_heads (int): Number of key and value heads. n_local_heads (int): Number of local query heads. n_local_kv_heads (int): Number of local key and value heads. n_rep (int): Number of repetitions for local heads. head_dim (int): Dimension size of each attention head. wq (ColumnParallelLinear): Linear transformation for queries. wk (ColumnParallelLinear): Linear transformation for keys. wv (ColumnParallelLinear): Linear transformation for values. wo (RowParallelLinear): Linear transformation for output. cache_k (torch.Tensor): Cached keys for attention. cache_v (torch.Tensor): Cached values for attention. \"\"\" super().__init__() self.n_kv_heads = args.n_heads if args.n_kv_heads is None else args.n_kv_heads model_parallel_size = fs_init.get_model_parallel_world_size() self.n_local_heads = args.n_heads // model_parallel_size self.n_local_kv_heads = self.n_kv_heads // model_parallel_size self.n_rep = self.n_local_heads // self.n_local_kv_heads self.head_dim = args.dim // args.n_heads self.wq = ColumnParallelLinear( args.dim, args.n_heads * self.head_dim, bias=False, gather_output=False, init_method=lambda x: x, ) self.wk = ColumnParallelLinear( args.dim, self.n_kv_heads * self.head_dim, bias=False, gather_output=False, init_method=lambda x: x, ) self.wv = ColumnParallelLinear( args.dim, self.n_kv_heads * self.head_dim, bias=False, gather_output=False, init_method=lambda x: x, ) self.wo = RowParallelLinear( args.n_heads * self.head_dim, args.dim, bias=False, input_is_parallel=True, init_method=lambda x: x, ) # kv_cache是缓存键值对，在训练过程中，我们只保存最近n个键值对 self.cache_k = torch.zeros( ( args.max_batch_size, args.max_seq_len, self.n_local_kv_heads, self.head_dim, ) ).cuda() self.cache_v = torch.zeros( ( args.max_batch_size, args.max_seq_len, self.n_local_kv_heads, self.head_dim, ) ).cuda() def forward( self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor], ): \"\"\" Forward pass of the attention module. Args: x (torch.Tensor): Input tensor. start_pos (int): Starting position for caching. freqs_cis (torch.Tensor): Precomputed frequency tensor. mask (torch.Tensor, optional): Attention mask tensor. Returns: torch.Tensor: Output tensor after attention. \"\"\" # 假设当前x为(1, 1, dim)，也就是上一个预测的token # self-attention的输入，标准的(bs, seqlen, hidden_dim) bsz, seqlen, _ = x.shape # 计算当前token的qkv # q k v分别进行映射，注意这里key, value也需要先由输入进行映射再和kv_cache里面的key, value进行拼接 xq, xk, xv = self.wq(x), self.wk(x), self.wv(x) xq = xq.view(bsz, seqlen, self.n_local_heads, self.head_dim) xk = xk.view(bsz, seqlen, self.n_local_kv_heads, self.head_dim) xv = xv.view(bsz, seqlen, self.n_local_kv_heads, self.head_dim) # 对当前输入的query和key进行RoPE，注意kv_cache里面的key已经做过了RoPE xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis) # 缓存当前token的kv self.cache_k = self.cache_k.to(xq) self.cache_v = self.cache_v.to(xq) self.cache_k[:bsz, start_pos: start_pos + seqlen] = xk self.cache_v[:bsz, start_pos: start_pos + seqlen] = xv # 取出前seqlen个token的kv缓存 # 取出全部缓存的key和value（包括之前在cache里面的和本次输入的），作为最终的key和value keys = self.cache_k[:bsz, : start_pos + seqlen] values = self.cache_v[:bsz, : start_pos + seqlen] # 将kv重复填充，使kv和q的头数个数相同 # repeat k/v heads if n_kv_heads \u003c n_heads，对齐头的数量 keys = repeat_kv(keys, self.n_rep) # (bs, cache_len + seqlen, n_local_heads, head_dim) values = repea","date":"2025-07-15","objectID":"/gqa/:0:0","tags":["Attention"],"title":"GQA","uri":"/gqa/"},{"categories":["RLHF","LLM"],"content":"GRPO (trl 库) ","date":"2025-07-15","objectID":"/grpo/:0:0","tags":["LLM","RLHF"],"title":"grpo","uri":"/grpo/"},{"categories":["RLHF","LLM"],"content":"重要参数 Num_generations: Number of generations to sample. The effective batch size (num_processes * per_device_batch_size * gradient_accumulation_steps) must be evenly divisible by this value. generation_batch_size: Batch size to use for generation. If None, it defaults to the effective training batch size: per_device_train_batch_size * num_processes * steps_per_generation. steps_per_generation: Number of optimization steps per generation. If None, it defaults to gradient_accumulation_steps. Num_iterations: Number of iterations per batch (denoted as μ in the algorithm). Per_device_train_batch_size Num_processes (world_size) trl 库的重要参数比较少。其中根据官方文档，generation_batch_size = `per_device_train_batch_size * num_processes * steps_per_generation Gradient_accumulation_steps 一般就是 steps_per_generation (对应 verl 中的 mini_batch_size / n_gpus / ppo_micro_batch_size_per_gpu)，可以理解为 per_device_train_bs (对应 verl 中的 ppo_micro_batch_size_per_gpu) 是使用梯度累计后的 bs，乘 gpu 数，再乘梯度累计的 steps 就是总的 batch_size（对应 verl 中的 train_batch_size * rollout. N）。所以注意，总的 batch_size (generation_batch_size) 是已经 rollout 采样后的 bs，除以 num_generations 才是针对 prompts 的 bs（verl 中的 train_batch_size）。 下面是_get_train_sampler 方法的注释，对每一个 prompt 重复 num_generations 是该方法实现的。 if dataset is None: dataset = self.train_dataset return RepeatSampler( data_source=dataset, mini_repeat_count=self.num_generations, # 每个 prompt 生成 self.num_generations 个 completions # 例如，如果 per_device_train_batch_size=8, num_generations=2, steps_per_generation=4, # 则 generation_batch_size = 8 (per_device_train_batch_size) * 4 (steps_per_generation) = 32 # 这里的 batch_size = 32 / 2 = 16，表示一个 \"generation block\" 中有16个不同的prompt。 batch_size=self.args.generation_batch_size // self.num_generations, # 每个 \"generation block\" (包含16个不同prompt，每个prompt有2个completion) 会被用于 num_iterations * steps_per_generation 次更新 # 例如 num_iterations=1, steps_per_generation=4, 则这个 block 会被重复 1*4=4 次，每次取出一个 per_device_train_batch_size 的数据进行训练 repeat_count=self.num_iterations * self.args.steps_per_generation, shuffle=self.shuffle_dataset, seed=self.args.seed, ) 结合下面的例子帮助理解，例子中梯度累计 steps 不等于 steps_per_generation 在 GRPO_trainer 中，最重要的方法是 _generate_and_score_completions 方法，输入为 input，输出为计算得到的优势值和 old_logp 用于计算 ratio。一些核心的部分和注释如下： with unwrap_model_for_generation( self.model_wrapped, self.accelerator, gather_deepspeed3_params=self.args.ds3_gather_for_generation ) as unwrapped_model: with ( FSDP.summon_full_params(self.model_wrapped, recurse=False) if self.is_fsdp_enabled else nullcontext() ): # prompt_ids: (B_gen_local, P_max) # prompt_mask: (B_gen_local, P_max) # prompt_completion_ids: torch.Tensor (B_gen_local, P_max + C_new), C_new 是 HF generate 生成的新 token 数量 (最大为 max_completion_length) prompt_completion_ids = unwrapped_model.generate( prompt_ids, attention_mask=prompt_mask, generation_config=self.generation_config ) # Compute prompt length and extract completion ids prompt_length = prompt_ids.size(1) # P_max # prompt_ids 保持不变: (B_gen_local, P_max) prompt_ids = prompt_completion_ids[:, :prompt_length] # completion_ids: torch.Tensor (B_gen_local, C_new_hf) completion_ids = prompt_completion_ids[:, prompt_length:] 上面为 generate 的过程，不过现在基本上使用 vllm 或者 sglang 加速推理。为了逻辑简单，这里展示了 HF generate 的过程。Trl 实现的时候，将一个 prompt 采样多次的逻辑实现在了 get_train_dataloader 方法中，即一开始就使用 get_train_sampler 方法对同一个 prompt repeat 了多次。因此这里不需要再进行 repeat。 之后得到补充部分的 mask: # Mask everything after the first EOS token # is_eos: torch.Tensor (B_gen_local, C_new), C_new 是 completion 的实际长度 (C_max_vllm 或 C_new_hf) is_eos = completion_ids == self.processing_class.eos_token_id # eos_idx: torch.Tensor (B_gen_local,), 存储每个 completion 中第一个 EOS token 的索引，如果没有EOS则为序列长度 eos_idx = torch.full((is_eos.size(0),), is_eos.size(1), dtype=torch.long, device=device) eos_idx[is_eos.any(dim=1)] = is_eos.int().argmax(dim=1)[is_eos.any(dim=1)] sequence_indices = torch.arange(is_eos.size(1), device=device).expand(is_eos.size(0), -1) # completion_mask: torch.Tensor (B_gen_local, C_new), 标记有效 token (EOS之前及EOS本身) completion_mask = (sequence_","date":"2025-07-15","objectID":"/grpo/:1:0","tags":["LLM","RLHF"],"title":"grpo","uri":"/grpo/"},{"categories":["Attention","LLM"],"content":"3-pass \\(\\mathsf{NO}\\) TATIONS \\(\\{m_i\\}{:}\\max_{j=1}^i\\left\\{x_j\\right\\}\\), with initial value \\(m_0=-\\infty.\\) \\(\\{d_i\\}{:}\\sum_{j=1}^ie^{x_j-m_N}\\), with initial value \\(d_0=0,d_N\\) is the denominator of safe softmax. \\(\\{a_i\\}{:\\text{ the final softmax value}}.\\) BODY \\(\\textbf{for }i\\leftarrow 1, N\\textbf{ do}\\) \\[m_i\\leftarrow\\max\\left(m_{i-1},x_i\\right)\\] \\(\\mathbf{end}\\) \\(\\textbf{for }i\\leftarrow 1, N\\textbf{ do}\\) \\[d_i\\leftarrow d_{i-1}+e^{x_i-m_N}\\] \\(\\mathbf{end}\\) \\(\\textbf{for }i\\leftarrow 1, N\\textbf{ do}\\) \\[a_i\\leftarrow\\frac{e^{x_i-m_N}}{d_N}\\] \\(\\mathbf{end}\\) 这是 3 step 计算 attention 的方法，每一步都需要上一步的结果才可以继续计算。这样的话由于 sram 中没有足够的存储空间，因此需要多次访存。 ### Online attention \\[\\begin{aligned} d_i^{\\prime}\u0026 =\\sum_{j=1}^ie^{x_j-m_i} \\\\ \u0026= \\left(\\sum_{j=1}^{i-1} e^{x_j-m_i}\\right)+e^{x_i-m_i} \\\\ \u0026= \\left(\\sum_{j=1}^{i-1} e^{x_j-m_{i-1}}\\right)e^{m_{i-1}-m_i}+e^{x_i-m_i} \\\\ \u0026= d_{i-1}' e^{m_{i-1}-m_i}+e^{x_i-m_i} \\end{aligned}\\] 找到迭代式之后就可以从 3 step 降到 2 step \\[\\begin{aligned}\u0026\\mathbf{for~}i\\leftarrow1,N\\textbf{ do}\\\\\u0026\u0026\u0026m_i\u0026\u0026\\leftarrow\u0026\\max\\left(m_{i-1},x_i\\right)\\\\\u0026\u0026\u0026d_i^{\\prime}\u0026\u0026\\leftarrow\u0026d_{i-1}^{\\prime}e^{m_{i-1}-m_i}+e^{x_i-m_i}\\\\\u0026\\mathbf{end}\\\\\u0026\\mathbf{for~}i\\leftarrow1,N\\textbf{ do}\\\\\u0026\u0026\u0026a_i\\leftarrow\u0026\u0026\\frac{e^{x_i-m_N}}{d_N^{\\prime}}\\\\\u0026\\mathbf{end}\\end{aligned}\\] 好像 FLOPs 计算量并没有减少，甚至还略有增加，因为现在每次都需要计算额外的 scale X 值，也就是 pre-softmax logits，由于需要 O (N^2) 的显存无法放在 SRAM 中。因此： 1. 要么提前计算好 x，保存在全局显存中，需要 O (N^2) 的显存，容易爆显存。 2. 要么在算法中 online 计算，每次循环中去 load 一部分 Q，K 到片上内存，计算得到 x。 Attention 优化的目标就是避开第一种情况，尽可能节省显存，否则，LLM 根本无法处理类似 100 K 以上这种 long context 的情况。而对于第二种情况，我们不需要保存中间矩阵 x，节省了显存，但是计算没有节省，并且增加了 HBM IO Accesses（需要不断地 load Q, K）。此时，2-pass 算法相对于 3-pass 算法，可以减少一次整体的 load Q, K 以及减少一次对 xi 的 online recompute，因为在 2-pass 的第一个 pass 中， xi 是被两次计算共享的。类似 online-softmax 这种算法，对应到 Attention 中的应用，就是 Memory Efficient Attention（注意不是 FlashAttention）。 ","date":"2025-07-15","objectID":"/online-attention/:0:1","tags":["Attention"],"title":"online attention","uri":"/online-attention/"},{"categories":["Attention","LLM"],"content":"参考 # 图解大模型计算加速系列之：vLLM核心技术PagedAttention原理 ","date":"2025-07-15","objectID":"/paged-attention/:1:0","tags":["LLM","Attention"],"title":"paged attention","uri":"/paged-attention/"},{"categories":["RLHF","LLM"],"content":"PPO (openrlhf 库) 重点记录一下 experience 的采集过程。训练其实很简单。Actor 在 RLHF 会进行 auto-regressive decoding，而 critic, reward 和 reference 则只会 prefill，不会 decode。所以，我们将 actor 的推理特定称为 rollout，而其他模型的推理称为 inference。 获取 experience 的总体流程： #################### # 1. 调用Actor generate()方法获取Prompt的生成结果，把结果存储到Sample对象 #################### samples_list = self.generate_samples(all_prompts, **generate_kwargs) torch.distributed.barrier() #################### # 2. 调用make_experience 对每个Sample做处理，组装Experience部分字段（除了advantage和return） #################### experiences = [] for samples in samples_list: experiences.append(self.make_experience(samples).to_device(\"cpu\")) experiences, rewards = self.process_experiences(experiences) #################### # 3. 通过从后往前回溯计算的方式，获取advantage和return值 #################### for experience, reward in zip(experiences, rewards): num_actions = experience.info[\"num_actions\"] if self.advantage_estimator == \"gae\": experience.advantages, experience.returns = self.get_advantages_and_returns( experience.values, reward, experience.action_mask, generate_kwargs[\"gamma\"], generate_kwargs[\"lambd\"], ) if not getattr(self, \"packing_samples\", False): return_sums = reward.sum(dim=-1) else: return_sums = torch.tensor( [each_reward.sum() for each_reward in reward], device=torch.cuda.current_device() ) experience.info[\"return\"] = return_sums return experiences 关于句子序列中的 state 和 action 定义如下： ## Prompt -\u003e sample 首先对 batch 进行 pad, 注意推理时需要左 pad。 然后生成 sequences，attention_mask, action_mask： Sequences： Attention_mask： Action_mask： 至此 sample 数据就得到了。 ## Sample -\u003e experience 首先根据前面 generate 的 prompt+response 计算得到 response 部分的 logp： 同样的方式得到 reference_model 的 logp，然后就可以计算 kl 散度。 Critic 是预估状态的价值，看代码实现时，参考图 3，先理解 LLM 中状态的起始位置。最终状态序列长度是 num_actions (生成 token 的数量)，状态序列起始位置是 Prompt 的最后一个 token，结束位置是最后 eos token 前一个 token，所以计算出的 Critic 预估状态价值的数据为： 注意，图里 eos token 和 pad token 的位置输出应该并不是 0，是 regression head 的输出（小实数值），只是我们期望良好的价值函数在这些位置输出 0 在 RLHF 中，Reward Model 是一个 ORM（outcome Reward Model） 也就是对完整的生成 response 输出一个打分。代码实现上取每个 sequence eos token 位置的预估打分值。如图 11，图中”xx”也是会并行计算出的 Reward 值，单最终只取了序列最后 eos 位置的 score 作为完整序列的打分值。最后 reward 处理成[B, 1]格式，每个序列一个打分。 Gae (Generalized Advantage Estimation) 是 PPO 论文中实现的优势奖励值计算方法，可平衡优势预估的偏差和方差。结合公式和图片内容更容易理解： def get_advantages_and_returns(values: torch.Tensor, rewards: torch.Tensor,） Advantages looks like this: Adv1 = R1 + γ * λ * R2 + γ^2 * λ^2 * R3 + ... - V1 + γ * (1 - λ) V2 + γ^2 * λ * (1 - λ) V3 + ... Returns looks like this: Ret1 = R1 + γ * λ * R2 + γ^2 * λ^2 * R3 + ... + γ * (1 - λ) V2 + γ^2 * λ * (1 - λ) V3 + ... 计算 returns： image.png 此时我们就完成了 experience 的采集过程。 ","date":"2025-07-15","objectID":"/ppo/:1:0","tags":["LLM","RLHF"],"title":"ppo","uri":"/ppo/"},{"categories":["RLHF","LLM"],"content":"Clip 的一些细节 image.png image.png 上面这张图是很经典的一张图，来分析什么情况下 clip 项计算梯度。 ","date":"2025-07-15","objectID":"/ppo/:2:0","tags":["LLM","RLHF"],"title":"ppo","uri":"/ppo/"},{"categories":["RLHF","LLM"],"content":"例子 image.png state对于文本序列来说就是之前生成的所有tokens，V(s)就是当前所有tokens为状态下的回报。而reward是对于整个句子而言的，因此只有最后一个状态才有reward。 ","date":"2025-07-15","objectID":"/ppo/:3:0","tags":["LLM","RLHF"],"title":"ppo","uri":"/ppo/"},{"categories":["RLHF","LLM"],"content":"参考 如何理解Q值和V值 (https://zhuanlan.zhihu.com/p/14569025663) ","date":"2025-07-15","objectID":"/ppo/:4:0","tags":["LLM","RLHF"],"title":"ppo","uri":"/ppo/"},{"categories":["","优化器"],"content":" AdaGrad 直接暴力累加平方梯度，这种做法的缺点就是累加的和会持续增长，会导致学习率变小最终变得无穷小，最后将无法获得额外信息。 ","date":"2025-07-12","objectID":"/adagrad/:0:0","tags":["优化器"],"title":"AdaGrad","uri":"/adagrad/"},{"categories":["","优化器","优化算法"],"content":"AdamW相对与Adam的改动十分简单，其将权重衰减项从梯度的计算中拿出来直接加在了最后的权重更新步骤上（图1，式12）。其提出的动机在于：原先Adam的实现中如果采用了 L2权重衰减，则相应的权重衰减项会被直接加在loss里，从而导致动量的一阶与二阶滑动平均均考虑了该权重衰减项，而这影响了Adam的优化效果，而将权重衰减与梯度的计算进行解耦能够显著提升Adam的效果。目前，AdamW现在已经成为transformer训练中的默认优化器了。 image.png 参考：# Adam和AdamW ","date":"2025-07-12","objectID":"/adamw/:0:0","tags":["优化算法","优化器","AdamW"],"title":"AdamW","uri":"/adamw/"},{"categories":["","优化器"],"content":" RMSProp 和 Adagrad 算法的最大区别就是在于更新累积梯度值 r 的时候 RMSProp 考虑加入了一个权重系数 ρ 。 它使用了一个梯度平方的滑动平均。其主要思路就是考虑历史的梯度，对于离得近的梯度重点考虑，而距离比较远的梯度则逐渐忽略。注意图中的是内积。 ","date":"2025-07-12","objectID":"/rmsprop/:0:0","tags":["优化器"],"title":"RMSProp","uri":"/rmsprop/"},{"categories":["优化器"],"content":"作为机器学习的初学者必然会接触梯度下降算法以及 SGD，基本上形式如下： \\[ \\theta_t = \\theta_{t-1} - \\alpha \\;g(\\theta) \\] 其中 \\(\\alpha\\) 为学习率，\\(g(\\theta)\\) 为梯度。 ","date":"2025-07-12","objectID":"/sgd/:0:0","tags":["优化器"],"title":"SGD","uri":"/sgd/"},{"categories":["","优化器"],"content":"带动量的随机梯度下降方法 它的思路就是计算前面梯度的该变量，每次迭代会考虑前面的计算结果。这样如果在某个维度上波动厉害的特征，会由于“momentum”的影响，而抵消波动的方向（因为波动剧烈的维度每次更新的方向是相反的，momentum 能抵消这种波动）。使得梯度下降更加的平滑，得到更快的收敛效率。而后续提出的 Adagrad，RMSProp 以及结合两者优点的 Adam 算法都考虑了这种“momentum”的思想。 前面求梯度的过程省略了，后面可以这样写： \\[ \\begin{align} \u0026 v_t = \\beta v_{t-1} + (1-\\beta)g_t \\\\\\\\ \u0026 \\theta = \\theta - \\alpha v_t \\end{align} \\] 其中 \\(\\alpha\\) 为学习率，一般的 \\(\\beta\\) 为 0.9。V 就是动量。 所以，SGD + Momentum 可以理解为，利用历史权重梯度矩阵 \\(W_{i} l(i\u003ct)\\) 和当前权重梯度矩阵 \\(W_{t} l\\) 的加权平均和，来更新权重矩阵 \\(W\\) 。由于 \\(\\beta \\in(0,1)\\) ，所以随着 \\(t\\) 的增大和 \\(i\\) 的减小， \\(\\beta^{t-i}\\) 会减小，历史权重梯度矩阵 \\(W_{i} l(i\u003ct)\\) 会逐渐减小。通俗来讲，会逐渐遗忘越旧的权重梯度矩阵。 ","date":"2025-07-12","objectID":"/sgd-momentum/:0:0","tags":["优化器"],"title":"SGD-Momentum","uri":"/sgd-momentum/"},{"categories":["","LLM","attention"],"content":"前置阅读：MHA 、MQA、GQA 和 rope 在标准的 Transformer中，多头注意力（Multi-Head Attention, MHA）机制通过并行计算多个注意力头来捕捉输入序列中的不同特征。每个注意力头都有自己的查询（Query, Q）、键（Key, K）和值（Value, V）矩阵，计算过程如下： 查询矩阵 Q：用于计算输入序列中每个位置的注意力权重。 键矩阵 K：用于与查询矩阵 Q 计算注意力分数。 值矩阵 V：用于根据注意力分数加权求和，得到最终的输出。 MLA 的核心思想是通过低秩联合压缩技术，减少训练时的激活占用和推理时的 kv cache 的占用，从而节省显存。 ","date":"2025-07-11","objectID":"/mla/:0:0","tags":["LLM","Attention"],"title":"MLA","uri":"/mla/"},{"categories":["","LLM","attention"],"content":"核心思想 当前我要存的K cache是4个k_head，但如果我能从这4个k_head中抽取出1份共有的信息，然后在做attn计算时，每个head都用这1份共有的信息做计算，那么我也只需存这1份共有信息作为K cache了。这样我就把K cache从原来num_heads = 4变成num_heads = 1，这不就能节省K cache了吗？ 但是等等，现在共有的k_head信息是抽取出来了，那么相异的k_head信息呢？（简单来说，就是由 \\(W_{K}\\) 不同head部分学习到的相异信息）。我们当然是希望k_head间相异的信息也能保留下来，那么该把它们保留至哪里呢？当你回顾attn_weights的计算公式时，一个想法在你脑中闪现：q部分不是也有heads吗！我可以把每个k_head独有的信息转移到对应的q_head上吗！写成公式解释就是： 原来 \\(attention\\_weights=(W_{Q}h_{i})^T * (W_{k}h_{j})\\) ，括号表示运算顺序，即先各自算2个括号内的，再做 * 计算 现在 \\(attention\\_weights=(h_{i}^TW_{Q}W_{k})^T * h_{j}\\)，同理括号表示运算顺序。也就是说，这里我们通过矩阵乘法的交换律，巧妙地把1个token上k_heads独有的信息转移到了对应的q_head上来，这样1个token上k_heads间共享的相同信息就能被我们当作K cache存储下来。 （在这里，你可以抽象地把 \\(h_{j}\\) 理解成是4个k_heads共享的信息，但最终K cache的形式还会在这基础上有所变化。我知道此时你脑海中一定有很多疑惑。但我们先不要纠结细节的问题，因为在后文会展示全部细节，这里我们要做的是从宏观上理解MLA设计的核心思想。） 上述叙述来自再读MLA，还有多少细节是你不知道的 因此 MLA 的核心思想就是找到一个压缩的 \\(h_{j}\\) 来表示所有 head 的共有信息，而将 head 之间相异信息让 q 来吸收，这样就大大压缩了 k 的 head_num，v 也是同理，不同是 \\(W_{V}\\) 和 \\(W_{O}\\) 吸收。因此 MLA 并没有损失信息，而是将信息转移到了 q_head 上。总维度并没有减少。 ","date":"2025-07-11","objectID":"/mla/:1:0","tags":["LLM","Attention"],"title":"MLA","uri":"/mla/"},{"categories":["","LLM","attention"],"content":"苏神思路 我认为先看苏神的博客再去看猛猿大佬的博客是比较容易理解的。 苏神认为 MLA 是在 GQA 的基础上将简单的线性变换（分割、复制）换成一般的线性变换来增强模型的能力。GQA 也可以看作是一种低秩投影。原因见原文： 其中 g 是组数。这里的 c 只是简单的拼接，MLA 的初始想法就是使用一种线性转换代替拼接。这个线性转换也是一个可以学习的矩阵 \\(W\\)。因此一个自然的想法就出来了： 然而这种方法在推理阶段并不会减少 kv cache 的显存占用，我们还是需要存储 k 和 v 而不是 c，并且 kv cache 大小反而和 MHA 一样大了。这时引入一个恒等变换就可以解决问题： 这样就可以把 c 取代原来的 k，而把两个 W 当作新的 Q，同理后面可以把 Wv 和 Wo 合并，v 也可以用 c 取代。这个 c 就是上面说的所有 head 的共享信息。而相异信息放入了新的 Q 中来学习。这样在推理阶段就可以只保存 c 来作为 kv cache 了。所以可以降低 c 的维度来进一步降低显存占用。 现在成功降低了显存占用，但有了一个新问题，如何在这里引入 rope 呢，众所周知 rope 是在计算注意力分数时加入了位置信息。如果强行加入则会产生下面的问题： image.png 也就是新的 Q 矩阵与 i 有关，而不是固定的一个矩阵了。 解决的办法也简单粗暴，就是在 q 和 k 的维度上增加 rope 的维度。也就是： image.png 其中前半部分是 nope，后半部分是 rope，这个在后面猛猿大佬讲解的源码中会有体现。 最后为了降低激活值，又对 q 进行了低秩投影，最后变成了： 至于为什么 q 的 rope 项是 c，而 k 的 rope 项是 x，这个我也不清楚。在训练阶段，MLA 只是在 MHA 的基础上加了低秩投影，以及为了 rope 的计算在原本 dk 的维度上增加了 dr 维度。 区别在于解码阶段，MLA 可以像 MQA 一样简单： 在解码阶段，只需要保存 c（注意 c 是 k 和 v 的集合体），这大大降低了显存占用。苏神博客写 prefill 阶段使用 (10)，generation 阶段使用 (12)，因为 prefill 是 compute-bound，需要降低计算量，而 generation 阶段是 memory-bound，需要降低显存占用，这样结合完美符合我们的需求。 ","date":"2025-07-11","objectID":"/mla/:2:0","tags":["LLM","Attention"],"title":"MLA","uri":"/mla/"},{"categories":["","LLM","attention"],"content":"猛猿大佬思路 一切从下面这张图说起，这是对源码实现逻辑的抽离： (图中的 kv_b_proj 维度标注错误，应该为(nope+v_head_dim)，这里的 v_head_dim=nope) 从图中可以看到，此时 q_len 为 1，kv_len 为 1024，q_lora_rank 大小为 1536，而 kv_lora_rank 大小为 512，我们可以观察到左路和右路的计算流程不太一样，这是因为上面公式 (10) 中 q 和 k 的 rope 部分使用的不一样，q 使用的是压缩后的 c，而 k 使用的是原始 x, 因此在 x 为输入的时候 kv 部分就可以将 rope 部分算出来，而 q 部分需要将压缩后的 q 得到后才可以计算。q 是将 PE 和 NoPE split 开，而 kv 是将 NoPE 的 k 和 v split 开。 需要注意的是，在 nope 中，head_dim 为 128，而这大于 hsz // num_heads，猛猿大佬猜测这是为了提高模型的复杂度，因为推理的时候通过只保存压缩后的 kv 来减少了 kv cache 占用，那么训练的时候就可以稍微提高复杂度。 下面的代码是上图中的一些定义。结合苏神的推导过程相信可以理解 MLA。 class DeepseekV2Attention(nn.Module): \"\"\"Multi-headed attention from 'Attention Is All You Need' paper\"\"\" def __init__(self, config: DeepseekV2Config, layer_idx: Optional[int] = None): super().__init__() self.config = config self.layer_idx = layer_idx self.attention_dropout = config.attention_dropout self.hidden_size = config.hidden_size self.num_heads = config.num_attention_heads self.head_dim = config.head_dim self.max_position_embeddings = config.max_position_embeddings self.rope_theta = config.rope_theta self.q_lora_rank = config.q_lora_rank self.qk_rope_head_dim = config.qk_rope_head_dim self.kv_lora_rank = config.kv_lora_rank self.v_head_dim = config.v_head_dim self.qk_nope_head_dim = config.qk_nope_head_dim self.qk_head_dim = config.qk_nope_head_dim + config.qk_rope_head_dim self.num_key_value_groups = config.num_attention_heads // config.num_key_value_heads self.is_causal = True if self.q_lora_rank is None: self.q_proj = nn.Linear(self.hidden_size, self.num_heads * self.qk_head_dim, bias=False) else: self.q_a_proj = nn.Linear(self.hidden_size, config.q_lora_rank, bias=config.attention_bias) self.q_a_layernorm = DeepseekV2RMSNorm(config.q_lora_rank) self.q_b_proj = nn.Linear(config.q_lora_rank, self.num_heads * self.qk_head_dim, bias=False) self.kv_a_proj_with_mqa = nn.Linear( self.hidden_size, config.kv_lora_rank + config.qk_rope_head_dim, bias=config.attention_bias, ) self.kv_a_layernorm = DeepseekV2RMSNorm(config.kv_lora_rank) self.kv_b_proj = nn.Linear( config.kv_lora_rank, self.num_heads * (self.qk_head_dim - self.qk_rope_head_dim + self.v_head_dim), bias=False, ) self.o_proj = nn.Linear( self.num_heads * self.v_head_dim, self.hidden_size, bias=config.attention_bias, ) self.scaling = self.qk_head_dim ** (-0.5) ","date":"2025-07-11","objectID":"/mla/:3:0","tags":["LLM","Attention"],"title":"MLA","uri":"/mla/"},{"categories":["","LLM","attention"],"content":"参考 缓存与效果的极限拉扯：从MHA、MQA、GQA到MLA - 科学空间|Scientific Spaces # Multi-Head Latent Attention (MLA) 详细介绍（来自Deepseek V3的回答） 再读MLA，还有多少细节是你不知道的 modeling_deepseek.py · deepseek-ai/DeepSeek-V2 at main ","date":"2025-07-11","objectID":"/mla/:4:0","tags":["LLM","Attention"],"title":"MLA","uri":"/mla/"},{"categories":["","优化算法","优化器","Muon","LLM"],"content":"Muon 算法流程如下图所示： image.png 其中最主要的部分是 NewtonSchulz 5 算法，流程如下： def newtonschulz5(G, steps=5, eps=1e-7): assert G.ndim == 2 a, b, c = (3.4445, -4.7750, 2.0315) X = G.bfloat16() X /= (X.norm() + eps) if G.size(0) \u003e G.size(1): X = X.T for _ in range(steps): A = X @ X.T B = b * A + c * A @ A X = a * X + B @ X if G.size(0) \u003e G.size(1): X = X.T return X 这个算法的作用是将 G 近似为一个最接近他的半正交矩阵，即： image.png 对于经验动机，我们观察到，基于手动检查，SGD-momentum 和 Adam 对基于 Transformer 的神经网络中的 2D 参数产生的更新通常具有非常高的条件数。也就是说，它们几乎是低秩矩阵，所有神经元的更新仅由几个方向主导。我们推测正交化有效地增加了其他“罕见方向”的规模，这些方向在更新中幅度较小，但对学习仍然很重要。 ","date":"2025-07-11","objectID":"/muon/:0:0","tags":["优化算法","优化器","LLM"],"title":"Muon","uri":"/muon/"},{"categories":["","优化算法","优化器","Muon","LLM"],"content":"Muon in Moonlight 来自Muon续集：为什么我们选择尝试Muon？ - 科学空间|Scientific Spaces ### Weight Decay kimi团队研究发现如果不加上权重衰减收敛速度到后面会被adam追上，因此加上了权重衰减： \\[ \\Delta W =-\\eta[msign(M) + \\lambda W] \\] 总的来说，这种做法可以缓解MaxLogit爆炸的问题，因为qk相乘的结果和xq、xk以及Wq和Wk有关，x会经过rmsnorm，所以爆炸的原因来自于W的爆炸，所以权重衰减可以缓解这个问题。 ","date":"2025-07-11","objectID":"/muon/:1:0","tags":["优化算法","优化器","LLM"],"title":"Muon","uri":"/muon/"},{"categories":["","优化算法","优化器","Muon","LLM"],"content":"RMS对齐 我理解为这是一种将Adam调好的超参数用到其它优化器的方法。 ","date":"2025-07-11","objectID":"/muon/:1:1","tags":["优化算法","优化器","LLM"],"title":"Muon","uri":"/muon/"},{"categories":["","优化算法","优化器","Muon","LLM"],"content":"QK-clip QK-norm可以很好的压制MaxLogit，但它只适用于MHA、GQA，不适用于MLA的推理阶段。因为推理阶段的Wk被吸收到了Q中。 这时候就需要返璞归真，既然MaxLogit太大，那就设定一个阈值，当Logit的值超过阈值的时候，就 直接裁剪到这个阈值。 这就有了他们最初始的想法（因为Logit是\\(QK^T\\)，目的是在\\(QK^T\\)上进行裁剪，所以要对各自的参数矩阵裁剪sqrt。）： image.png 如果max_logit（在batch上也要找最大）大于阈值并且即将优化的参数是q或者k的线性矩阵参数，就将矩阵参数进行clip，来达到缩放max_logit的目的。 但后面他们发现这样一刀切很容易伤及无辜，因为多头注意力中，有可能只有1个头出现了max_logit超出阈值，但其它头的参数也会被裁减。 我们知道，不管哪种Attention变体都有多个Head，一开始我们是每一层Attention只监控一个MaxLogit指标，所有Head的Logit是放在一起取Max的，这导致QK-Clip也是所有Head一起Clip的。然而，当我们分别监控每个Head的MaxLogit后发现，实际上每层只有为数不多的Head会出现MaxLogit爆炸，如果所有Head按同一个比例来Clip，那么大部份Head都是被“无辜受累”的了，这就是过度裁剪的含义。 简单来说，QK-Clip的操作是乘以一个小于1的数，这个数对于MaxLogit爆炸的Head来说是刚刚好抵消增长趋势，但是对于其他head来说是单纯的缩小（它们没有增长趋势或者增长趋势很弱）。由于长期无端被乘一个小于1的数，那么很容易出现就趋于零的现象，这是“过度裁剪”的表现。 因此还需要监控各个头的max_logit，如果某个头出现了这个问题，那么就单独对这个头的参数矩阵进行裁剪。但这里有一个问题就是，对于MLA而言，并不是简单的存在Wq和Wk，而是Wqc、Wkc、Wqr、Wkr，而Wkr是所有的head共享的，如果裁剪Wkr也会导致出现无辜头，所以只需要裁剪Wqr。 所以最终版本如下： image.png 将QK-clip应用到Muon优化器就变成了Muon-Clip： image.png image.png 对比原生Muon可见改进了蛮多。 ","date":"2025-07-11","objectID":"/muon/:2:0","tags":["优化算法","优化器","LLM"],"title":"Muon","uri":"/muon/"},{"categories":["","LLM","infra"],"content":"为什么存储激活值？ 首先回顾为什么要存储激活值。 简单来说，模型参数是根据导数更新的。为了有效地计算这些导数，必须缓存某些张量。激活内存是这些缓存张量的内存成本。 具体来说，以 \\(f\\) 是矩阵乘法运算： \\[y=f(x)=W\\cdot x\\] \\(W\\)是一个可学习的权重矩阵。假设我们有关于 早期反向传播阶段的手头输出，\\(\\frac{\\partial L}{\\partial y}\\),我们 需要计算 两个额外的梯度： 1.关于\\(W\\),以便我们可以更新此权重。 2.关于\\(x\\),这样我们就可以继续反向传播算法 到产生的任何作\\(x\\) 前导数是 \\[\\frac{\\partial L}{\\partial W}=\\frac{\\partial L}{\\partial y}\\frac{\\partial y}{\\partial W}=\\frac{\\partial L}{\\partial y}\\times x\\] 而后者的导数是 \\[\\frac{\\partial L}{\\partial x}=\\frac{\\partial L}{\\partial y}\\cdot W\\] 因此，如下图所示，我们需要缓存输入张量 \\(x\\) 为了能够计算我们关心的导数。节省的成本 \\(x\\) 是激活 memory。 我们发现只需要保存 x，而对于 y 不需要保存，也就是说我们只保存反向传播时绝对需要的激活值，其它的临时变量要立即释放。 ","date":"2025-07-10","objectID":"/activation-checkpointing/:1:0","tags":["LLM","infra"],"title":"Activation checkpointing","uri":"/activation-checkpointing/"},{"categories":["","LLM","infra"],"content":"MLP class MLP(nn.Module): \"\"\" Basic MLP (multi-layer perceptron) layer with optional Dropout. \"\"\" def __init__( self, d_model: int, act_fn: nn.Module, dropout_prob: Optional[float] = None, device: Optional[Union[str, torch.device]] = None, dtype: Optional[torch.dtype] = None, ) -\u003e None: super().__init__() self.d_model = d_model self.act_fn = act_fn self.dropout_prob = dropout_prob factory_kwargs = {\"device\": device, \"dtype\": dtype} self.lin_0 = nn.Linear(self.d_model, 4 * self.d_model, **factory_kwargs) self.lin_1 = nn.Linear(4 * self.d_model, self.d_model, **factory_kwargs) self.dropout = nn.Dropout(self.dropout_prob) if self.dropout_prob else None def forward(self, inputs: torch.Tensor) -\u003e torch.Tensor: x = self.lin_0(inputs) x = self.act_fn(x) x = self.lin_1(x) if self.dropout is not None: x = self.dropout(x) return x image.png Maybe saved 的是否 是根据激活函数的类型来的： 如果是 GELU 激活函数 \\[y=\\frac x2\\times\\tanh\\left(\\sqrt{\\frac2\\pi}\\left(x+.044715x^3\\right)\\right)\\] 这时候计算梯度的话还是需要输入 x，这是需要存储的情况 而如果是一些特殊的激活函数的话，比如 ReLU \\[y=\\mathsf{ReLU}(x)=\\begin{cases}x\u0026\\mathrm{if~}x\u003e0\\\\0\u0026\\mathrm{if~}x\u003c0\u0026\\end{cases}\\] 梯度为： \\[\\frac{dy}{dx}=\\frac{d\\text{ ReLU}(x)}{dx}=\\begin{cases}1\u0026\\mathrm{if~}x\u003e0\\\\0\u0026\\mathrm{if~}x\u003c0\u0026\\end{cases}\\] 就不需要存储。 Tanh 也是同理： \\[ \\frac{dy}{dx} = \\frac{d\\tanh (x)}{dx} = 1-\\tanh(x)^2 = 1-y^2 \\] 如果想要性能，选择 GELU，想要低显存，使用 ReLU。 ","date":"2025-07-10","objectID":"/activation-checkpointing/:2:0","tags":["LLM","infra"],"title":"Activation checkpointing","uri":"/activation-checkpointing/"},{"categories":["","LLM","infra"],"content":"激活值计算 根据博客 # 分析transformer模型的参数量、计算量、中间激活、KV cache 内容来得到激活值的计算公式。 大模型在训练过程中通常采用混合精度训练，中间激活值一般是float16或者bfloat16数据类型的。在分析中间激活的显存占用时，假设中间激活值是以float16或bfloat16数据格式来保存的，每个元素占了2个bytes。唯一例外的是，dropout操作的mask矩阵，每个元素只占1个bytes。在下面的分析中，单位是bytes，而不是元素个数。 先分析 self-attention 块的中间激活。Self-attention 块的计算公式如下： \\[Q=xW_Q,K=xW_K,V=xW_V\\] \\[x_{out}=softmax(\\frac{QK^T}{\\sqrt{h}})\\cdot V\\cdot W_o+x\\] 对于 \\(Q,K,V\\) ,需要保存它们共同的输入 \\(x\\) ,这就是中间激活。输入 \\(x\\) 的形状为 \\([b,s,h]\\) ,元素个数为 bsh ,占用显存大小为 \\(2*bsh=2bsh\\) 。 对于 \\(QK^T\\) 矩阵乘法，需要保存中间激活 \\(Q,K\\) ,两个张量的形状都是 \\([b,s,h]\\) ,占用显 存大小合计为 \\(2*2*bsh=4bsh\\) 。 对于 \\(softmax()\\) 函数，需要保存函数的输入 \\(QK^T\\) ,占用显存大小为 \\(2bs^2a\\) ,这里的 \\(a\\) 表示注意力头数。 \\[score=softmax(\\frac{QK^T}{\\sqrt{d_k}})\\] \\(Q\\) 的形状为：\\([ b, head\\_ num, s, per\\_ head\\_ hidden\\_ size]\\) \\(K^T\\) 的形状为：\\([b,head\\_num,per\\_head\\_hidden\\_size,s]\\) \\(QK^T\\) 的形状为：\\([b,head\\_num,s,s]\\) ,元素个数为 \\(bs^2a\\) ,占用显存大小为 \\(2bs^2a\\) 。 4. 计算完 \\(softmax()\\) 函数后，会进行 dropout 操作。需要保存一个 mask 矩阵，mask 矩阵的形状与 \\(QK^T\\) 相同，占用显存大小为 \\(bs^2a\\) 。 5. 计算在 \\(V\\) 上的 attention，即 \\(score\\cdot V\\), 需要保存 score ,大小为 \\(2bs^2a\\) ;以及 \\(V\\) ,大小为 \\(2bsh\\) 。二者占用显存大小合计为 \\(2bs^2a+2bsh\\) 。 6. 计算输出映射以及一个 dropout 操作。输入映射需要保存其输入，大小为 \\(2bsh\\) ;dropout 需要保存 mask 矩阵，大小为 bsh 。二者占用显存大小合计为 \\(3bsh\\) 。 因此，将上述中间激活相加得到，self-attention 块的中间激活占用显存大小为 \\(11bsh+5bs^2a\\) 。 接下来看 MLP 块的中间激活。MLP 块的计算公式如下： \\[x=f_{gelu}(x_{out}W_1)W_2+x_{out}\\] 第一个线性层需要保存其输入，占用显存大小为 \\(2bsh\\) 。 激活函数需要保存其输入，占用显存大小为 \\(8bsh\\) 。 第二个线性层需要保存其输入，占用显存大小为 \\(8bsh\\) 。 最后有一个 dropout 操作，需要保存 mask 矩阵，占用显存大小为 bsh 。 对于 MLP 块，需要保存的中间激活值为 19 bsh 。 另外，self-attention 块和 MLP 块分别对应了一个 layer normalization。每个 layer norm 需要保存其输入，大小为 \\(2bsh\\) （忽略了均值和方差的2 bs，如果不忽略应当为 2 bsh+4 bs，这里的单位都是 bytes）。2 个 layer norm 需要保存的中间激活为 \\(4bsh\\) 。 综上，每个 transformer 层需要保存的中间激活占用显存大小为 \\(34bsh+5bs^2a\\)。对于 \\(l\\) 层 transformer 模型，还有 embedding 层、最后的输出层。Embedding 层不需要中间激活。总的而言，当隐藏维度 \\(h\\) 比较大，层数 \\(l\\) 较深时，这部分的中间激活是很少的，可以忽略。因 此，对于 \\(l\\) 层 transformer 模型，中间激活占用的显存大小可以近似为 \\((34bsh+5bs^2a)*l\\) ","date":"2025-07-10","objectID":"/activation-checkpointing/:3:0","tags":["LLM","infra"],"title":"Activation checkpointing","uri":"/activation-checkpointing/"},{"categories":["","LLM","infra"],"content":"Activation checkpointing 当使用该方法时，我们只需要保存一些关键的激活值，可以舍弃一些激活值从而在反向传播的过程中重新计算，通常有两种策略： Full：我们在 Transformer 模型每一层之间的过渡点检查激活值。这通常被称为“完整”策略，因为它需要每层都进行一次前向传播，即在反向传播过程中增加了一次完整的前向传播。这种策略节省的内存最多，但在计算方面成本最高。它通常会使计算成本和时间增加高达 30-40%，这一影响非常显著。 Select：总体而言，我们可以比全面优化做得更好。那篇关于重新计算的论文的作者进行了详细分析，研究了哪些激活值的增长最大，并且以每秒浮点运算次数（FLOPS）为标准，其重新计算成本最低。结果表明，注意力计算属于这一类别，因此我们通常可以丢弃它们，而专注于对昂贵的前馈计算进行检查点设置。对于 GPT-3（1750 亿参数）模型而言，这意味着在计算成本仅增加 2.7%的情况下，激活值内存减少了 70%。 如今，大多数训练框架都使用 FlashAttention，它通过在反向传播中重新计算注意力得分和矩阵，而不是存储它们，将激活重新计算集成到其优化策略中。因此，大多数使用 FlashAttention 的人已经在使用 AC。 由于重新计算，激活重新计算略微增加了 FLOPS 的数量，同时显著降低了内存访问开销。 这种权衡在 GPU 等高速内存有限的硬件上特别有利，因为访问内存通常比执行计算慢。尽管涉及额外的操作，但总体效果通常是计算速度更快，内存占用更少。 ","date":"2025-07-10","objectID":"/activation-checkpointing/:4:0","tags":["LLM","infra"],"title":"Activation checkpointing","uri":"/activation-checkpointing/"},{"categories":["","LLM","infra"],"content":"1. Full Activation Checkpointing (全量激活值检查点) 这是最经典、最直接的检查点方法。 工作原理： 分段: 将整个模型的计算图（所有层）在逻辑上划分为若干个段 (Segment)。 保存: 在前向传播时，只保存每个段的输入张量 (Input Tensor)。这些被保存的张量就是“检查点”。段内所有中间层的激活值都会在计算后被立即丢弃，不占用显存。 重算: 在反向传播时，当需要某个段内的激活值来计算梯度时，它会找到该段的检查点（即该段的输入），然后重新执行该段的前向传播，以恢复所需要的激活值。一旦这个激活值被使用完毕，它会再次被丢弃。 图解： 假设一个模型有16层，我们每4层设置一个检查点： 标准训练 (无Checkpointing): [Input] -\u003e L1 -\u003e L2 -\u003e ... -\u003e L16 -\u003e [Output] - 前向传播: 计算并存储 L1 到 L16 的所有激活值。 - 内存占用: 极高。 Full Activation Checkpointing: [Input] -\u003e [Segment 1: L1-L4] -\u003e [Segment 2: L5-L8] -\u003e [Segment 3: L9-L12] -\u003e [Segment 4: L13-L16] -\u003e [Output] - 前向传播: - 执行 Segment 1 (L1-L4)，只保存 L5 的输入（即L4的输出）作为检查点，丢弃 L1-L3 的激活值。 - 执行 Segment 2 (L5-L8)，只保存 L9 的输入作为检查点，丢弃 L5-L7 的激活值。 - …以此类推。 - 反向传播: - 当需要计算 L12 的梯度时，发现它的激活值没有被保存。 - 系统加载最近的检查点（L9的输入）。 - 重新计算 L9 -\u003e L10 -\u003e L11 -\u003e L12 的前向传播，得到 L12 的激活值。 - 使用该激活值计算梯度，然后丢弃它。 优缺点： 优点: 效果显著: 可以大幅度降低显存占用，内存占用量与模型的层数基本无关，只与最长的那个段的计算复杂度有关。 实现简单: 逻辑清晰，易于在各种框架中实现（例如 PyTorch 的 torch.utils.checkpoint）。 缺点: 计算开销大: 每个被 checkpoint 的段（除了最后一个）都会被重新计算一次。如果模型很大，这会带来大约 30%-50% 甚至更高的训练时间开销。 ","date":"2025-07-10","objectID":"/activation-checkpointing/:4:1","tags":["LLM","infra"],"title":"Activation checkpointing","uri":"/activation-checkpointing/"},{"categories":["","LLM","infra"],"content":"2. Selective Activation Checkpointing (选择性激活值检查点) 这是对全量检查点方法的智能化升级，也是目前更受关注的重点。它认识到“全量丢弃、全量重算”的策略过于粗暴和低效。 核心思想： 在同一个计算段内，不同的操作（Op）或激活值，其存储成本和重算成本是不同的。 有些激活值占用显存大，但重算很快（例如 ReLU, Dropout 等元素级操作）。 有些激活值占用显存小，但重算很慢（例如 MatMul, Convolution 的输出）。 Selective Checkpointing 的目标就是：在每个段内，不再丢弃所有激活值，而是有选择性地保存那些“重算成本高、存储成本低”的激活值，从而在反向传播时，避免代价高昂的重计算。 工作原理： 成本分析: 它需要对计算图中的每个操作进行成本分析。 存储成本: 该操作输出的激活值张量占用的显存大小。 重算成本: 重新计算出这个激活值所需要的时间（通常用 FLOPs 衡量）。 智能决策: 基于成本分析，算法（通常是动态规划或启发式搜索）会做出决策。对于段内的每一个激活值，它会判断： 是直接保存它更划算？ 还是丢弃它，之后再通过重计算恢复更划算？ 选择性保存与重算: 在前向传播时，除了保存每个段的输入（主检查点）外，还会额外保存段内那些被判定为“值得保存”的少量关键激活值。 在反向传播时，当需要一个激活值时，如果它被保存了，就直接使用。如果没被保存，系统会从最近的一个检查点（无论是主检查点还是段内保存的次级检查点）开始重算，而不是必须从段的开头开始。 图解（续上例）： 在 Segment 3 (L9-L12) 中： L9 (MatMul) -\u003e L10 (LayerNorm) -\u003e L11 (ReLU) -\u003e L12 (MatMul) Full Checkpointing 会丢弃 L9, L10, L11 的所有输出。重算 L12 时需要从 L9 的输入开始，重新执行 MatMul, LayerNorm, ReLU。 Selective Checkpointing 可能会做出如下决策： L9 (MatMul) 的输出：重算成本极高，但存储成本可能相对可控。决策：保存。 L11 (ReLU) 的输出：占用显存和 L10 一样大，但重算成本极低（只需对 L10 的输出再做一次 ReLU）。决策：丢弃。 在反向传播时： - 当需要 L11 的激活值时，发现它没被保存。但系统发现 L10 的激活值（或者 L9 的）被保存了。 - 它只需从 L10 开始重算 L10 -\u003e L11 (ReLU)，而无需重算昂贵的 L9 (MatMul)。 优缺点： 优点: 最佳平衡: 在实现与 Full Checkpointing 几乎相同显存节省效果的同时，显著降低了重计算的开销，从而缩短了训练时间。它在“时间”和“空间”之间找到了一个更优的平衡点。 高效: 相比 Full Checkpointing，训练速度更快。 缺点: 实现复杂: 需要对模型的计算图进行深入分析，并建立准确的成本模型。这通常需要深度学习框架或特定库（如 DeepSpeed）的底层支持。 模型依赖: 优化的效果依赖于模型结构。对于包含大量昂贵操作的模型，效果会更明显。 ","date":"2025-07-10","objectID":"/activation-checkpointing/:4:2","tags":["LLM","infra"],"title":"Activation checkpointing","uri":"/activation-checkpointing/"},{"categories":["","LLM","infra"],"content":"总结对比 特性 Full Activation Checkpointing Selective Activation Checkpointing 核心策略 以时间换空间 在时间和空间之间寻找最优平衡 粒度 粗粒度 (段级别) 细粒度 (操作级别) 保存内容 仅保存每个段的输入 保存每个段的输入 + 段内部分关键激活值 重算方式 总是从段的开头重算整个段 从最近的可用检查点开始重算，路径更短 计算开销 高 较低 显存节省 非常高 非常高 (与 Full 类似) 实现复杂度 低 高 总而言之，Selective Activation Checkpointing 是对传统检查点技术的一次重大优化。它通过更精细化的资源管理，在不牺牲太多内存节省的前提下，大幅减少了因重计算带来的时间惩罚，是目前训练超大规模模型时更为先进和高效的主流技术之一。 ## 参考 Activation Memory: A Deep Dive using PyTorch | Determined AI ","date":"2025-07-10","objectID":"/activation-checkpointing/:4:3","tags":["LLM","infra"],"title":"Activation checkpointing","uri":"/activation-checkpointing/"},{"categories":["","LLM","infra"],"content":"CPU 卸载允许我们将一些状态传输到 CPU，因此我们不必将所有内容都保存在 GPU RAM 中。虽然 CPU作比 GPU作慢，但将不常访问的数据移动到 CPU 内存可以帮助我们保持在 GPU 内存限制范围内。 ","date":"2025-07-10","objectID":"/cpu-offloading/:0:0","tags":["LLM","infra"],"title":"CPU offloading","uri":"/cpu-offloading/"},{"categories":["","LLM","infra"],"content":"梯度累积使我们能够通过按顺序处理较小的批次来扩展到更大的有效批次。我们不是一次计算整个批次的梯度（这需要将所有激活存储在内存中），而是在更新模型参数之前将每个小批次的梯度相加。这减少了内存使用量，但需要更多的向前/向后传递。 ","date":"2025-07-10","objectID":"/%E6%A2%AF%E5%BA%A6%E7%B4%AF%E8%AE%A1/:0:0","tags":["LLM","infra"],"title":"梯度累计","uri":"/%E6%A2%AF%E5%BA%A6%E7%B4%AF%E8%AE%A1/"},{"categories":["","LLM","infra"],"content":"代码 loss = loss / gradient_accumulation_stepsloss.backward() if step% gradient_accumulation_steps == 0: optimizer.step() optimizer.zero_grad() step+=1 gradient_accumulation_steps 是梯度累积次数，累积几次，原本的 loss 就要除以几，这是为了对多个批次的数据的梯度做累积。 有人说，应该有这一行代码才算累加 losses += loss 这样理解是错误的。 要明白最重要的一点是，梯度累加，累加的并不是损失，而是根据损失得到的梯度。 ","date":"2025-07-10","objectID":"/%E6%A2%AF%E5%BA%A6%E7%B4%AF%E8%AE%A1/:1:0","tags":["LLM","infra"],"title":"梯度累计","uri":"/%E6%A2%AF%E5%BA%A6%E7%B4%AF%E8%AE%A1/"},{"categories":["","LLM","infra"],"content":"梯度累计如何节省显存 减少瞬时激活值显存：每次仅处理小批量的数据，激活值显存占用降低为原来的 1/k（例如 k=4 时，显存占用降至 25%）。 复用显存：每次小批量计算完成后，释放当前激活值显存，供下一次计算使用（显存占用峰值始终为小批量对应的量）。 梯度显存不变：模型参数和梯度的显存占用与批量大小无关，因此不受影响（但需额外存储累积梯度的变量，这部分开销极小）。 梯度累积两次，跟 batch size 增大 2 倍，在多数情况下，效果一样吗？（loss 的 3 次平均） 理论上，梯度累计在数学上应该等同于全批量训练，但实际发现 loss 并不匹配。( Gradient accumulation yields worse results than the equivalent batch size · Issue #2175 · huggingface/trl) 一般情况下，loss 计算会经历三次平均 micro batch 维度，分母是这个 micro batch 中的所有 label 不是 -100 的 token 数（不同 token 之间 loss 的平均） DP 维度，分母是 DP size （和 GPU 数量相关，不同机器之间 loss 的平均） 梯度累加维度，分母是梯度累加数。（不同 batch 之间的 loss 的平均） image.png ","date":"2025-07-10","objectID":"/%E6%A2%AF%E5%BA%A6%E7%B4%AF%E8%AE%A1/:2:0","tags":["LLM","infra"],"title":"梯度累计","uri":"/%E6%A2%AF%E5%BA%A6%E7%B4%AF%E8%AE%A1/"},{"categories":["coding","verl"],"content":" image.png 从上图中可以看到DataProto可以分为3个部分： - non_tensor_batch - batch - meta_info 其中non_tensor_batch和meta_info都是个字典，而batch是TensorDict类型的变量。 image.png DataProto支持的一些操作如下： - concat: Combines multiple DataProto objects along the batch dimension - chunk: Splits a DataProto into equal chunks (requires batch size to be divisible by chunks) - split: Splits a DataProto into chunks of specified size (handles uneven splits) - repeat: Repeats the entire batch a specified number of times - sample_level_repeat: Repeats each sample a variable number of times - union: Merges two DataProto objects, combining their tensors and non-tensors - select/pop: Filter or remove specific keys from the batch - rename: Rename keys in the batch ","date":"2025-07-09","objectID":"/dataproto/:0:0","tags":["coding","verl"],"title":"DataProto","uri":"/dataproto/"},{"categories":["coding","verl"],"content":"DataProtoConfig 这个设置主要用于管理auto_padding配置，用在dp中，即如果数据批次 / world_size不能整除的话，就需要padding。这部分体现在： def _split_args_kwargs_data_proto_with_auto_padding(chunks, *args, **kwargs): from verl.protocol import DataProto, DataProtoFuture data_proto_len = None padding_size = None def _padding_and_split_data(obj, chunks): nonlocal data_proto_len, padding_size assert isinstance(obj, DataProto | DataProtoFuture) if isinstance(obj, DataProto) and obj.is_padding_enabled(): # for padding, we only support DataProto with same length if data_proto_len is None: data_proto_len = len(obj) padding_size = (chunks - (data_proto_len % chunks)) if (data_proto_len % chunks \u003e 0) else 0 else: assert data_proto_len == len(obj), ( f\"expecting all arg share same length of {data_proto_len}, but got {len(obj)}\" ) obj.padding(padding_size=padding_size) return obj.chunk(chunks=chunks) splitted_args = [_padding_and_split_data(arg, chunks) for arg in args] splitted_kwargs = {key: _padding_and_split_data(val, chunks) for key, val in kwargs.items()} if padding_size is not None: splitted_kwargs[_padding_size_key] = padding_size return splitted_args, splitted_kwargs 计算需要多少个额外的项目才能使批量大小能被目标除数整除 从批次的开头获取项以用作填充 将原始批次与填充项连接起来 跟踪填充大小以供以后删除 ","date":"2025-07-09","objectID":"/dataproto/:1:0","tags":["coding","verl"],"title":"DataProto","uri":"/dataproto/"},{"categories":["coding","verl"],"content":"DataProtoFuture DataProtoFuture类用于veRL中的分布式计算 image.png 关于collect_fn和dispatch_fn详见init_workers详解 接下来是分布式dataproto的工作流： image.png 其中all_gather_data_proto函数为： def all_gather_data_proto(data: DataProto, process_group): # Note that this is an inplace operator just like torch.distributed.all_gather group_size = torch.distributed.get_world_size(group=process_group) assert isinstance(data, DataProto) prev_device = data.batch.device data.batch = data.batch.to(get_device_id()) data.batch = allgather_dict_tensors(data.batch.contiguous(), size=group_size, group=process_group, dim=0) data.batch = data.batch.to(prev_device) # all gather non_tensor_batch all_non_tensor_batch = [None for _ in range(group_size)] torch.distributed.all_gather_object(all_non_tensor_batch, data.non_tensor_batch, group=process_group) data.non_tensor_batch = {k: np.concatenate([d[k] for d in all_non_tensor_batch]) for k in data.non_tensor_batch} 也就是all_gather操作来收集data，主要用于对tp分组上的数据all_gather，因为tp分组需要相同的输入。 \u003evllm + fsdp 训推时，如果每张卡都是一个 DP，事情会简单很多。但 verl 中有两个功能不满足这一条件，一是 rollout 时让 vllm 开启 TP，二是在 fsdp 中使用 ulysses（SP）。verl 中数据分发使用的是 dispatch mode 这一机制，比如 fsdp workers 主要使用 Dispatch.DP_COMPUTE_PROTO这个 mode，它是在 worker group 的层次上进行数据分发以及结果收集的。由于这个层次是没有 TP/SP 概念的，所以它仅在 one GPU one DP 时才是正确的。那么为了正确支持 TP/SP，就需要对数据做一些前后处理。 (上文引用自浅入理解verl中的batch_size) 体现在ShardingManager中，即： @GPUMemoryLogger(role=\"fsdp vllm sharding_manager\", logger=logger) def preprocess_data(self, data: DataProto) -\u003e DataProto: \"\"\"All gather across tp group to make each rank has identical input.\"\"\" if self.tp_size == 1: return data # TODO: Current impl doesn't consider FSDP with torch micro-dp group = vllm_ps.get_tensor_model_parallel_group().device_group all_gather_data_proto(data=data, process_group=group) return data 可见这里获取了tp group，然后在group中进行all_gather操作。post_process_data就是再将数据按照tp分组dispatch出去。在fsdp中需要sp，也有类似的操作。 with self.rollout_sharding_manager: log_gpu_memory_usage(\"After entering rollout sharding manager\", logger=logger) prompts = self.rollout_sharding_manager.preprocess_data(prompts) with simple_timer(\"generate_sequences\", timing_generate): output = self.rollout.generate_sequences(prompts=prompts) log_gpu_memory_usage(\"After rollout generation\", logger=logger) output = self.rollout_sharding_manager.postprocess_data(output) 总结：因为我们在进行dispatch的时候，是按照world_size进行的，但是对于tp分组需要相同的输入，所以要进行all_gather。 ## Sequence Balancing verl中对序列优化的做法有以下几点： - 序列长度平衡：在工作线程之间分配序列以平衡计算工作负载（本章节） - 动态批处理：按令牌计数而不是固定批次大小对序列进行分组（dynamic_bsz） - 序列打包：删除填充标记以提高内存效率remove_padding - 微批次优化：重新排列批次以实现最佳 GPU 利用率 image.png 平衡算法：对序列进行分组以最大限度地减少填充，同时尊重标记限制，从而减少填充标记上的计算浪费。 ","date":"2025-07-09","objectID":"/dataproto/:2:0","tags":["coding","verl"],"title":"DataProto","uri":"/dataproto/"},{"categories":["coding","verl"],"content":"数据处理流程 verl的数据处理流程大概如下图所示： image.png ","date":"2025-07-09","objectID":"/dataproto/:3:0","tags":["coding","verl"],"title":"DataProto","uri":"/dataproto/"},{"categories":["","infra","LLM"],"content":"即 packing，将不同长度的序列紧凑存储，避免填充，减少不必要的计算和存储，提升效率。 ","date":"2025-07-08","objectID":"/remove_padding/:0:0","tags":["LLM","infra"],"title":"remove_padding","uri":"/remove_padding/"},{"categories":["","infra","LLM"],"content":"动机 sft进行微调，因为gpu是并行计算的，所以如果一个batch里面的数据，每条数据长度不相等，就需要对数据进行truncation（截断）和padding（pad数据到相同的seq_length）。显然，如果使用了padding，那么一个batch里面，就会有很多的pad_token，这些pad_token输入进入到了模型，但是却没有样本训练，造成了计算量的浪费。 因此，对于这些长度不相等的样本，就可以使用packing（类似于打包），把这些样本拼接成长度相等的文本（比如20480, 4096, 8192）等长度。这样就能够是样本全部训练，增加了样本的计算效率。如图所示。每个样本之间不等长，但是可以使用eos_token进行拼接，达到加速训练的目的 image.png ","date":"2025-07-08","objectID":"/remove_padding/:1:0","tags":["LLM","infra"],"title":"remove_padding","uri":"/remove_padding/"},{"categories":["","infra","LLM"],"content":"带来的问题和解决方案（理论上） 如果使用了packing，需要考虑两个问题：attention和位置编码。相比于不使用packing，使用packing导致： atteniton有问题：本来我只需要和sample1的token计算attention，现在packing以后，我的attention不仅仅是sample1内部计算。现在是sample1，sample2，sample3，通通一起计算attention。这样是不是会有问题？ 位置编码：本来sample1的位置编码是从0开始的，现在我sample1,2,3一起packing，那sample2，3的位置编码就变了，无法和单条样本训练一致。 解决方案： - 将packing中的attention方式进行修改（每条样本只和自己内部做attention），如下图 - 将packing的位置编码，修改成和不使用packing一样的位置编码。 ","date":"2025-07-08","objectID":"/remove_padding/:2:0","tags":["LLM","infra"],"title":"remove_padding","uri":"/remove_padding/"},{"categories":["","infra","LLM"],"content":"代码做法 引用 verl 中 tests 的代码： def test_hf_casual_models(): batch_size = 4 seqlen = 128 response_length = 127 for config in test_configs: # config = AutoConfig.from_pretrained(test_case) with torch.device(\"cuda\"): model = AutoModelForCausalLM.from_config( config=config, torch_dtype=torch.bfloat16, attn_implementation=\"flash_attention_2\" ) model = model.to(device=\"cuda\") breakpoint() input_ids = torch.randint(low=0, high=config.vocab_size, size=(batch_size, seqlen), device=\"cuda\") attention_mask = create_random_mask( input_ids=input_ids, max_ratio_of_left_padding=0.1, max_ratio_of_valid_token=0.8, min_ratio_of_valid_token=0.5, ) position_ids = compute_position_id_with_mask( attention_mask ) # TODO(sgm): we can construct the position_ids_rmpad here input_ids_rmpad, indices, *_ = unpad_input( input_ids.unsqueeze(-1), attention_mask ) # input_ids_rmpad (total_nnz, ...) input_ids_rmpad = input_ids_rmpad.transpose(0, 1) # (1, total_nnz) # unpad the position_ids to align the rotary position_ids_rmpad = index_first_axis( rearrange(position_ids.unsqueeze(-1), \"b s ... -\u003e (b s) ...\"), indices ).transpose(0, 1) # input with input_ids_rmpad and postition_ids to enable flash attention varlen logits_rmpad = model( input_ids_rmpad, position_ids=position_ids_rmpad, use_cache=False ).logits # (1, total_nnz, vocab_size) origin_logits = model( input_ids=input_ids, attention_mask=attention_mask, position_ids=position_ids, use_cache=False ).logits origin_logits_rmpad, origin_logits_indices, *_ = unpad_input(origin_logits, attention_mask) logits_rmpad = logits_rmpad.squeeze(0) log_probs = log_probs_from_logits_all_rmpad( input_ids_rmpad=input_ids_rmpad, logits_rmpad=logits_rmpad, indices=indices, batch_size=batch_size, seqlen=seqlen, response_length=response_length, ) # (batch, seqlen) origin_log_probs = log_probs_from_logits_all_rmpad( input_ids_rmpad=input_ids_rmpad, logits_rmpad=origin_logits_rmpad, indices=origin_logits_indices, batch_size=batch_size, seqlen=seqlen, response_length=response_length, ) # (batch, seqlen) torch.testing.assert_close( masked_mean(log_probs, attention_mask[:, -response_length - 1 : -1]), masked_mean(origin_log_probs, attention_mask[:, -response_length - 1 : -1]), atol=1e-2, rtol=1e-5, ) print(\"Check pass\") 其中 unpad_input 函数简化逻辑的代码如下： def unpad_input(hidden_states, attention_mask): # 1. 找到所有有效 token 的位置 # seqlens_in_batch 是一个包含批次中每个序列实际长度的列表，例如 [3, 4] seqlens_in_batch = attention_mask.sum(dim=-1, dtype=torch.int32) # indices 是一个一维张量，包含了所有值为1的 mask 元素的展平后索引 indices = torch.nonzero(attention_mask.flatten(), as_tuple=False).flatten() # 2. 从 hidden_states 中提取出所有有效的 token # 首先将 hidden_states 展平成 (batch_size * sequence_length, ...) flat_hidden_states = hidden_states.reshape(-1, hidden_states.shape[-1]) # 然后使用 indices 来挑选出所有有效的 token hidden_states_unpadded = flat_hidden_states[indices] # 3. 计算累积序列长度 (cu_seqlens) # 例如，如果 seqlens_in_batch 是 [3, 4]，cu_seqlens 会是 [0, 3, 7] cu_seqlens = torch.cat( [torch.zeros(1, dtype=torch.int32), seqlens_in_batch.cumsum(dim=0)], dim=0 ) max_seqlen_in_batch = seqlens_in_batch.max().item() return hidden_states_unpadded, indices, cu_seqlens, max_seqlen_in_batch 这里的 cu_seqlens 就是不需要传入 attention_mask 的原因，相当于取代了 mask 的功能。 调试输出一些张量的 shape： (Pdb) input_ids.shape torch.Size([4, 128]) (Pdb) attention_mask.shape torch.Size([4, 128]) (Pdb) position_ids.shape torch.Size([4, 128]) (Pdb) input_ids_rmpad.shape torch.Size([1, 359]) # 也就是说去掉pad后4个sample在一起的有效长度为359 简单来说，indices 是一个“索引地图”。它的核心作用是记录在原始的、带填充的、被展平（flattened）的批次数据中，所有有效（非填充）词元的位置。 当 unpad_input 处理 input_ids 时，它会丢掉所有的填充词元，只保留有效词元，并生成这个 indices 地图。这个地图至关重要，因为批次中的数据往往不止 input_ids，还有与之严格对齐的 position_ids、token_type_ids 等。 indices 的主要用途是：确保其他辅助张量（如 position_ids）能够以与 input_ids 完全相同的方式被“解填充”（unpad），从而保持数据的一致性和对齐。 如果 position_ids 的解填充方式与 input_ids 不一致，那么旋转位置编码（Rotary Position Embedding, RoPE）等依赖位置信息的操作就会完全错乱。 ","date":"2025-07-08","objectID":"/remove_padding/:3:0","tags":["LLM","infra"],"title":"remove_padding","uri":"/remove_padding/"},{"categories":["大模型分布式","LLM"],"content":"一句话：在sequence维度上进行切分 将输入序列 X (长度 N) 沿序列维度切分为 SP 块，每个 GPU 分配到 N/SP 长度的子序列。 对于非注意力层 (如 MLP)，计算是完全局部的，每个 GPU 处理自己的子序列即可。 token 之间独立，token-level projection Ulysses SP的核心复杂性在于Attention层。为了让每个token在计算注意力时能够考虑到全局序列信息（或者说，让每个head在计算时能看到完整的序列，即使这个head只在当前rank计算），Attention模块前后需要进行两次精密的all-to-all数据重排。MLP层则没有这样的需求，数据在进入MLP时已经是按序列分片好的，可以直接进行本地计算。 对于注意力层: 步骤 1 (计算 Q, K, V): 每个 GPU 基于其本地子序列计算出本地的 Q_local, K_local, V_local (维度约为 N/SP x d，d 是隐藏维度)。 步骤 2 (全局 K, V 收集 - 关键): 使用 All-to-All 通信操作（All-Gather??）。每个 GPU 将自己的 K_local, V_local 发送给所有其他 GPU，并接收来自所有其他 GPU 的 K, V 块。执行后，每个 GPU 拥有完整的全局 K 和 V 矩阵 (维度 N x d)，但仍然只拥有本地的 Q_local (维度 N/SP x d)。 https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/usage/collectives.html 步骤 3 (本地注意力计算): 每个 GPU 使用其 Q_local 和完整的全局 K, V 计算其负责的那部分注意力输出 O_local (维度 N/SP x d)。计算公式为 Attention(Q_local, K_global, V_global)。这一步的计算量是 (N/SP) * N * d，内存瓶颈在于存储临时的注意力分数矩阵，大小约为 (N/SP) * N。相比原始的 **N*N**，内存显著降低。 步骤 4 (可选的输出重组): 如果后续层需要按序列拼接的完整输出，可能需要另一次通信（如 All-Gather 或另一次 All-to-All 的变种）来组合 O_local。但在 DeepSpeed 实现中，通常保持分布式状态，直接输入到下一个同样按序列并行的层。 ","date":"2025-07-08","objectID":"/ulysses_sequence_parallel/:0:0","tags":["LLM","大模型分布式"],"title":"ulysses_sequence_parallel","uri":"/ulysses_sequence_parallel/"},{"categories":["大模型分布式","LLM"],"content":"verl中的序列并行 在verl中，一般与remove_padding一起使用，即 if config.actor_rollout_ref.actor.strategy in {\"fsdp\", \"fsdp2\"}: if ( config.actor_rollout_ref.actor.get(\"ulysses_sequence_parallel_size\", 1) \u003e 1 or config.actor_rollout_ref.ref.get(\"ulysses_sequence_parallel_size\", 1) \u003e 1 ): assert config.actor_rollout_ref.model.use_remove_padding, ( \"When using sequence parallelism for actor/ref policy, you must enable `use_remove_padding`.\" ) if self.use_critic and config.critic.strategy in {\"fsdp\", \"fsdp2\"}: if config.critic.get(\"ulysses_sequence_parallel_size\", 1) \u003e 1: assert config.critic.model.use_remove_padding, ( \"When using sequence parallelism for critic, you must enable `use_remove_padding`.\" ) 先进行remove padding操作 然后进行序列并行的pad和slice操作 ## 参考 pytorch_distribute_tutorials/tutorials/3D-parallel/SP-序列并行.ipynb at main · chunhuizhang/pytorch_distribute_tutorials · GitHub ","date":"2025-07-08","objectID":"/ulysses_sequence_parallel/:1:0","tags":["LLM","大模型分布式"],"title":"ulysses_sequence_parallel","uri":"/ulysses_sequence_parallel/"},{"categories":["","LLM","reasoning"],"content":"熵坍塌 UloRL：An Ultra-Long Output Reinforcement Learning Approach for Advancing Large Language Models’ Reasoning Abilities UloRL的核心创新 动态掩码熟练掌握正向词元（Dynamic Masking of well-Mastered Positive Tokens, DMMPTs）。论文作者敏锐地指出，熵坍塌的根源并非“训练正样本”，而是“过度训练已经熟练掌握的正向词元（MPTs）”。MPTs指的是那些在正确答案中，且模型已经能以极高概率（如\u003e99%）预测出来的词元。DMMPTs为此设计了一个“熵值恒温器”： 1. 设定一个理想的“目标熵值”。 2. 在训练时，如果模型的当前熵低于这个目标值，说明模型开始变得“僵化”了。此时，系统会自动“屏蔽”（mask）掉那些MPTs，不再对它们进行训练，迫使模型关注那些还未掌握好的部分。 3. 如果模型熵值高于或等于目标值，则正常进行训练。 ProRL：Prolonged Reinforcement Learning Expands Reasoning Boundaries in Large Language Models ","date":"2025-07-06","objectID":"/entropyreasoning/:1:0","tags":["LLM","reasoning"],"title":"entropy(reasoning)","uri":"/entropyreasoning/"},{"categories":["","LLM","reasoning"],"content":"利用熵 ","date":"2025-07-06","objectID":"/entropyreasoning/:2:0","tags":["LLM","reasoning"],"title":"entropy(reasoning)","uri":"/entropyreasoning/"},{"categories":["","LLM","reasoning"],"content":"First Return, Entropy-Eliciting Explore ","date":"2025-07-06","objectID":"/entropyreasoning/:2:1","tags":["LLM","reasoning"],"title":"entropy(reasoning)","uri":"/entropyreasoning/"},{"categories":["","LLM","reasoning"],"content":"AGENTIC REINFORCED POLICY OPTIMIZATION ","date":"2025-07-06","objectID":"/entropyreasoning/:2:2","tags":["LLM","reasoning"],"title":"entropy(reasoning)","uri":"/entropyreasoning/"},{"categories":["","LLM","reasoning"],"content":"参考 小作坊的强化之路 ","date":"2025-07-06","objectID":"/entropyreasoning/:3:0","tags":["LLM","reasoning"],"title":"entropy(reasoning)","uri":"/entropyreasoning/"},{"categories":["","LLM","大模型分布式"],"content":"参考 RL 系统深思：FSDP 训练后端 PyTorch FSDP 设计解读 ","date":"2025-07-06","objectID":"/fsdp/:1:0","tags":["LLM","大模型分布式"],"title":"fsdp","uri":"/fsdp/"},{"categories":["","LLM","infra"],"content":"进入大模型时代，基本上所有大模型都使用 decoder 部分，因此本文只分析 decoder 部分的参数量。 Transformer 的 decoder 每一层由 attention 和 mlp 组成，一般有 l 层。 ","date":"2025-07-06","objectID":"/transformer%E5%8F%82%E6%95%B0%E9%87%8F%E5%88%86%E6%9E%90/:0:0","tags":["LLM","infra"],"title":"transformer参数量分析","uri":"/transformer%E5%8F%82%E6%95%B0%E9%87%8F%E5%88%86%E6%9E%90/"},{"categories":["","LLM","infra"],"content":"Self-attention Self-attention 层由 \\(W_{Q}\\) 、\\(W_{K}\\)、\\(W_{V}\\) 和输出矩阵 \\(W_{O}\\) 和它们的偏置组成，权重矩阵的形状为 \\([h,h]\\)，偏置形状为 \\([h]\\)，则 self-attention 部分的参数量为 \\(4h^2+4h\\) ","date":"2025-07-06","objectID":"/transformer%E5%8F%82%E6%95%B0%E9%87%8F%E5%88%86%E6%9E%90/:1:0","tags":["LLM","infra"],"title":"transformer参数量分析","uri":"/transformer%E5%8F%82%E6%95%B0%E9%87%8F%E5%88%86%E6%9E%90/"},{"categories":["","LLM","infra"],"content":"MLP MLP 由 2 个线性层构成，第一个线性层将维度从 h 变为 4 h，第二个将维度由 4 h 变为 h，第一个权重矩阵形状为 \\([h,4h]\\)，偏置为 \\([4h]\\)，第二个形状为 \\([4h,h]\\)，偏置为 \\([h]\\)，则参数量为 \\(8h^2+5h\\) ","date":"2025-07-06","objectID":"/transformer%E5%8F%82%E6%95%B0%E9%87%8F%E5%88%86%E6%9E%90/:2:0","tags":["LLM","infra"],"title":"transformer参数量分析","uri":"/transformer%E5%8F%82%E6%95%B0%E9%87%8F%E5%88%86%E6%9E%90/"},{"categories":["","LLM","infra"],"content":"Layer norm 在 self-attention 和 mlp 中都存在 layer norm，有 2 个可训练参数：缩放参数 \\(\\gamma\\) 和平移参数 \\(\\beta\\)，形状都是 \\([h]\\)，2 个 layer norm 的参数量为 4 h。 ","date":"2025-07-06","objectID":"/transformer%E5%8F%82%E6%95%B0%E9%87%8F%E5%88%86%E6%9E%90/:3:0","tags":["LLM","infra"],"title":"transformer参数量分析","uri":"/transformer%E5%8F%82%E6%95%B0%E9%87%8F%E5%88%86%E6%9E%90/"},{"categories":["","LLM","infra"],"content":"词嵌入 词嵌入矩阵的参数量和词表大小 V 有关，而且输入和输出一般公用一个矩阵，因此参数量为 \\(Vh\\) ","date":"2025-07-06","objectID":"/transformer%E5%8F%82%E6%95%B0%E9%87%8F%E5%88%86%E6%9E%90/:4:0","tags":["LLM","infra"],"title":"transformer参数量分析","uri":"/transformer%E5%8F%82%E6%95%B0%E9%87%8F%E5%88%86%E6%9E%90/"},{"categories":["","LLM","infra"],"content":"位置编码 如果是可训练式的位置编码，则占据一定的参数量，否则不占参数量 ","date":"2025-07-06","objectID":"/transformer%E5%8F%82%E6%95%B0%E9%87%8F%E5%88%86%E6%9E%90/:5:0","tags":["LLM","infra"],"title":"transformer参数量分析","uri":"/transformer%E5%8F%82%E6%95%B0%E9%87%8F%E5%88%86%E6%9E%90/"},{"categories":["","LLM","infra"],"content":"总参数 综上所述，transformer 一个层的参数量为 \\(12h^2+13h\\)，l 层就是 \\(l(12h^2+13h)\\)，再加上词嵌入矩阵，总参数量为 \\(l(12h^2+13h)+Vh\\)，h 较大时，可以忽略一次项，近似为 \\(12lh^2\\) 实际参数量 隐藏维度h 层数l 12lh^2 6.7B 4096 32 6,442,450,944 13.0B 5120 40 12,582,912,000 32.5B 6656 60 31,897,681,920 65.2B 8192 80 64,424,509,440 表来自 分析 transformer 模型的参数量、计算量、中间激活、KV cache ## 参考 # 分析transformer模型的参数量、计算量、中间激活、KV cache Transformer Math (Part 1) - Counting Model Parameters ","date":"2025-07-06","objectID":"/transformer%E5%8F%82%E6%95%B0%E9%87%8F%E5%88%86%E6%9E%90/:6:0","tags":["LLM","infra"],"title":"transformer参数量分析","uri":"/transformer%E5%8F%82%E6%95%B0%E9%87%8F%E5%88%86%E6%9E%90/"},{"categories":["","LLM","infra"],"content":"训练时 模型参数：我们模型的可学习权重。 Optimizer states（优化器状态）：您需要跟踪的确切状态取决于您使用的优化器;例如，如果您使用的是 AdamW，则除了模型参数之外，您还需要跟踪第一和第二动量估计值。 模型激活值：这将根据您的网络架构和批处理大小而有所不同，但会显著影响内存使用。反向传播需要此信息，以便我们能够有效地计算梯度。 梯度：为模型的每个参数存储，与模型参数相同的内存占用。 Input data：要传递给模型的 Importing 数据批次，内存占用取决于正在建模的数据的大小和类型。 图示： 具体数值： 对于一个 transformer 来说，参数量可以由以下公式给出（详见 transformer参数量分析）： \\[N=h*v+L*(12*h^2+13*h)+2*h\\] In that equation, \\(h\\) is the hidden dimension, \\(v\\) the vocabulary size, and \\(L\\) the number of layers in the model. Note that looking at the equation we can see that the term that will dominate with large hidden dimensions is the \\(h^{2}\\) term, since it’s the only one growing quadratically As we scale the parameters. 在全精度训练中（所有的存储单位都是 fp 32），优化器使用 adam 的情况下，模型部分我们需要存储： \\[\\begin{aligned}\u0026m_{params}=4*N\\\\\u0026m_{grad}=4*N\\\\\u0026m_{opt}=(4+4)*N\\end{aligned}\\] 而在使用混合精度的情况下，模型的参数和梯度使用 bf 16，为了稳定性，优化器还需要存储 fp 32 的模型参数，即： \\[\\begin{aligned}\u0026m_{params}=2*N\\\\\u0026m_{grad}=2*N\\\\\u0026m_{params\\_fp32}=4*N\\\\\u0026m_{opt} =(4+4)*N\\end{aligned}\\] Some libraries store grads in FP32, which would require an additional mparams_fp32=4∗Nmparams_fp32​=4∗N memory. This is done, for example, in Nanotron, because BF16 is lossy for smaller values and we always prioritize stability. See this DeepSpeed issue for more information. 也就是说有的库还实现了存储 fp 32 的梯度，考虑稳定性。 The FP32 copy of the parameters (mparams_fp32mparams_fp32​) is sometimes called the “master weights” in the literature and codebases. 保存 fp 32 模型参数的原因是 bf 16 的精度不足以支持高效参数更新，fp 32 可以避免误差累计，保证优化器的数值稳定性和训练效果。具体分析如下（来自为什么LLM一般使用较大的权重衰减系数？）： 从浮点数的存储格式建立了「计算机浮点数的数值绝对值越大，则精度越低」的结论，对于深度学习训练过程（前向-反向-更新）来说： 如果使用低精度浮点数保存和更新模型参数时，如果模型参数绝对值比较大，而更新的步幅比较小，那么更新会由于舍入误差而失效，这就是为什么要维护一个 fp 32 的模型参数的原因。 并且从一个高精度的模型转化为低精度模型的时候，参数的绝对值越大，则丢失的精度越多。在模型更新了fp32的备份之后，还需要将fp32的权重转化为低精度的版本，参与后续的forward过程。由于浮点数的精度随着绝对值的增加而降低，因此参数的绝对值越大，在精度的转化中损失的精度也越多。此外，在前向和反向计算的过程中，激活值也会存在类似的精度损失问题。如果我们在训练过程中引入权重衰减，那么模型的权重的绝对值就可以得到一定的控制。除了提供一定的正则化效应之外，也能够降低由于模型的参数范数增长而导致的精度损失的风险。 混合精度训练示意图： 1. 参数以FP32存储；这主要是因为，在基于梯度更新权重的时候，往往公式:权重 = 旧权重 + lr * 梯度，而在深度模型中，lr * 梯度这个值往往是非常小的，如果利用 fp16 来进行相加的话， 则很可能出现精度的问题，导致模型无法更新。因此参数以FP32的形式存储 2. 正向计算过程中，遇到FP16算子，需要把算子输入和参数从FP32 cast成FP16进行计算； 3. 将Loss层设置为FP32进行计算； 4. 反向计算过程中，首先乘以Loss Scale值，避免反向梯度过小而产生下溢； 5. FP16参数参与梯度计算，其结果将被cast回FP32； 6. 除以Loss scale值，还原被放大的梯度； 7. 判断梯度是否存在溢出，如果溢出则跳过更新，否则优化器以FP32对原始参数进行更新。 根据上述公式可以快速得到一些模型训练时占用显存： image.png 此外激活值也是显存的巨大杀手，随着句子长度的增加而增加，有以下的计算公式： \\[m_{act}=L\\cdot seq\\cdot bs\\cdot h\\cdot(34+\\frac{5\\cdot n_{heads}\\cdot seq}h)\\] Here, \\(L\\) is the number of layers, seq the sequence length, \\(bs\\) the batch size in samples, \\(h\\) the hidden dimension of the model, and \\(n_{heads}\\) the number of heads. image.png 可见在长上下文的训练中，激活值才是显存最大的杀手。这就需要Activation checkpointing 来降低这部分的显存占用，详见 Activation checkpointing ","date":"2025-07-06","objectID":"/%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97/:1:0","tags":["LLM","infra"],"title":"显存占用计算","uri":"/%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97/"},{"categories":["","LLM","infra"],"content":"推理时 一个经验法则是：推理时的峰值显存大致是模型参数显存的 1.5 - 2.5 倍（尤其在处理长序列或大批次时）。更精确的估计需要结合具体模型和输入 输入/输出的 Token 存储：需要显存存储输入的 Token 嵌入（embedding）和生成的输出 Token。 Key-Value 缓存（KV Cache）：自回归生成时，为避免重复计算历史 Token 的 Key/Value，需缓存这些中间结果（显存占用与输入+输出长度成正比） 关于 kv cache 占用显存的计算，详见 KV cache ## 参考 The Ultra-Scale Playbook - a Hugging Face Space by nanotron ","date":"2025-07-06","objectID":"/%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97/:2:0","tags":["LLM","infra"],"title":"显存占用计算","uri":"/%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97/"},{"categories":["","面经"],"content":"常见问题总结 ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:0:0","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"多轮对话sft样本怎么构造？ [大模型微调样本构造 trick]（https://zhuanlan.zhihu.com/p/641562439) 多轮对话的传统组织方式：将多轮对话拆分为多条独立的训练样本，如 Q1A1/Q2A2/Q3A3 可拆分为 Q1—\u003eA1， Q1A1Q2-\u003eA2， Q1A1Q2A2Q3-\u003eA3 三条样本。 将整个 session 的对话内容拼接成一个长文本序列，例如：Q1 A1 Q2 A2 Q3 A3。这样，整个 session 被表示为一个连续的文本序列，而不是多条独立的样本。 构造时计算损失有一些坑，详见 https://zhuanlan.zhihu.com/p/721652210 ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:1:0","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"SFT 是否可以注入知识？ continue pretrain 注入知识。 sft 对齐输出格式。（sft 在一些特定的场景下确实是可以注入知识的） ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:2:0","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"如何解决灾难性遗忘？ 保留通用数据：在进行领域数据训练时，仍然需要保留一部分通用数据用于模型训练。这样可以确保模型仍然能够学习到通用的语言和知识，从而保持一定的通用能力。 增量学习：使用增量学习（Incremental Learning）的方法，将领域数据与通用数据逐步交替进行训练。这样可以在学习新领域的同时，保持对通用知识的记忆。 数据重采样：在进行领域数据训练时，可以使用数据重采样的方法，使得模型在训练过程中能够更多地接触到通用数据，从而缓解遗忘通用能力的问题。 强化学习：使用强化学习的方法，通过给模型设置奖励机制，鼓励模型在领域任务上表现好，同时保持一定的通用能力。 领域适应技术：使用领域适应技术，如领域自适应（Domain Adaptation）和领域对抗训练（Domain Adversarial Training），帮助模型在不同领域之间进行迁移学习，从而减少遗忘通用能力的问题。 SDFT：微调前，让大模型将任务数据集重写一遍。这样的话，重写后的任务数据集的分布和大模型的差异就小了很多。在这样的数据集上微调对大模型分布上的改变会小很多，对大模型通用能力的损害也会降低。 Llama-Pro:在原始模型中每个Transformer块或者某几个Transformer块后增加一个Transformer块，但为了保持扩展后的模型输出保持不变，需要增加的块为恒等块（输入输出相同） 为什么大模型都是 Decoder-Only 架构？（https://www.zhihu.com/question/588325646/answer/3357252612） 泛化性能更好：ICML 22的What language model architecture and pretraining objective works best for zero-shot generalization?. 在最大5B参数量、170B token数据量的规模下做了一些列实验，发现用next token prediction预训练的decoder-only模型在各种下游任务上zero-shot泛化性能最好 苏神强调的注意力满秩的问题，双向attention的注意力矩阵容易退化为低秩状态，而 causal attention的注意力矩阵是下三角矩阵，必然是满秩的，建模能力更强； @yili大佬强调的预训练任务难度问题，纯粹的decoder-only架构+next token predicition预训练，每个位置所能接触的信息比其他架构少，要预测下一个token难度更高，当模型足够大，数据足够多的时候，decoder-only模型学习通用表征的上限更高； @mimimumu 大佬强调，上下文学习为decoder-only架构带来的更好的few-shot性能：prompt 和demonstration的信息可以视为对模型参数的隐式微调，decoder-only的架构相比encoder-decoder在in-context learning上会更有优势，因为prompt可以更加直接地作用于decoder每一层的参数，微调的信号更强； 多位大佬强调了一个很容易被忽视的属性，causal attention（就是decoder-only的单向 attention）具有隐式的位置编码功能，打破了transformer的位置不变性，而带有双向 attention的模型，如果不带位置编码，双向attention的部分token可以对换也不改变表示，对语序的区分能力天生较弱。 decoder-only支持一直复用KV-Cache，对多轮对话更友好，因为每个token的表示只和它之前的输入有关，而encoder-decoder和PrefixLM就难以做到。 ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:3:0","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"Transfomer attention计算为什么除以根号 d？ 为什么不在rollout阶段保存logp而是再计算一遍logp？ 因为forward的时候和generate的时候logprob由于推理引擎（vllm）和训练引擎（fsdp）的优化目标不一样，会造成两者对不上，因此需要做两次。 batch 算子的细微差异，都会造成这两个 log_prob 不完全一致。推理引擎要的是快速出 token id，训练引擎需要保证一定的log_prob 精度。 ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:4:0","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"为什么需要 Server 来完成 rollout？ 为了配合 agentic LLM 的训练，在现有的PPO/GRPO 算法的基础上，从 single turn rollout 改动为 environment interactive multi-turn rollout 的需求非常强烈。 这一过程中，policy 与 environment 的交互存在绝对不可忽视的延迟，turn 之间的等待时间很长。一直用 Engine 做 rollout 的话（ engine.generate），可能连 continuous batching 都组不起来。所以，改用 server 来通过 https 做 rollout的需求就呼之欲出了。实际上，这也是 最自然的工作方式。除此之外，environment 的交互往往也是通过 https 请求来完成的。譬如，众多 coding sandbox 都是 environment 自己启动一个 server 暴露一个 port，然后往里面发请求来实现交互的。 总之，为了在 training engine,rollout 和 environment 三个子进程中保持良好的通讯和交互，选择 server 势在必行。 MCP和fuction call的区别？（https://zhuanlan.zhihu.com/p/1898326676087223572） 函数调用是一种机制，它允许 LLM 根据用户的输入识别它需要什么工具以及何时调用它。 MCP（即模型上下文协议,Model Context Protocol）试图标准化此过程。 MCP (Model Context Protocol):是一个开放协议和标准，旨在标准化AI 应用（MCP 客户端）如何发现、连接和与外部工具/数据源（实现为 MCP 服务器）进行交互。它关注的是系统间的通信和集成，解决 Function Calling 指令生成后，如何高效、安全、可扩展地执行这些调用。 ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:5:0","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"为什么R1不使用模型reward？ reward hacking 训练资源问题，成本过高。 为什么PRM+MCTS这条路走不通？（https://zhuanlan.zhihu.com/p/19623772462） 在reasoning任务中如何显式定义step，比如以\\n 还是以推理逻辑来划分step？ 如何定义step正确性，将影响step labeler来高效标注 PRM容易reward hacking LLM比象棋搜索空间大太多 MCTS价值影响模型生成质量（不如纯CoT采样） ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:6:0","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"GRPO中可以去掉KL项吗？ 可以。 去除KL项, 意味着不需要ref-model, 减少一个模型的显存，减少一次前向ref_policy的计算。 没有KL的约束，那么可以将过大的梯度进行裁剪(max_grad_norm)，避免优化的不稳定性(这也是另一种层面的clip)。 没有KL的约束，参数的优化更加自由，更容易探索到好的回答 GRPO 的损失为什么会为负（参考 https://zhuanlan.zhihu.com/p/28326620566） 总结：组奖励变化对 loss 上升影响不直观。优化策略远离 ref，KL 变化大，导致 Loss 上升明显。 Qwen模型为什么随机奖励也能work？（https://rethink-rlvr.notion.site/Spurious-Rewards-Rethinking-Training-Signals-in-RLVR-1f4df34dac1880948858f95aeb88872f） 模型依赖性：研究发现，RLVR的有效性更多地依赖于模型的预训练能力，而不是监督信号的质量。Qwen模型在预训练期间学会了特定的推理策略，这些策略可以通过RLVR轻易地被激发出来，而其他模型则不具备这些策略。 代码推理策略：Qwen-Math模型在预训练阶段就频繁地使用Python代码来解决数学问题，即使在没有代码执行器的情况下，也能生成正确的代码输出和答案。RLVR训练（无论奖励质量如何）进一步增加了这种代码推理的频率，从而提高了性能。 奖励信号的作用：不可靠奖励通过放大模型在预训练期间学到的有用推理表示来发挥作用。这些奖励信号并没有教会模型任务质量，而是触发了一种集中效应，使模型专注于其现有的推理模式分布。 为什么DPO里Chosen和Rejected概率会同时下降?（https://zhuanlan.zhihu.com/p/6327313416） ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:7:0","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"reward hacking如何解决？ 梯度累积两次，跟 batch size 增大 2 倍，在多数情况下，效果一样吗？（loss 的 3 次平均） 理论上，梯度累计在数学上应该等同于全批量训练，但实际发现 loss 并不匹配。( Gradient accumulation yields worse results than the equivalent batch size · Issue #2175 · huggingface/trl) 一般情况下，loss 计算会经历三次平均 micro batch 维度，分母是这个 micro batch 中的所有 label 不是 -100 的 token 数（不同 token 之间 loss 的平均） DP 维度，分母是 DP size （和 GPU 数量相关，不同机器之间 loss 的平均） 梯度累加维度，分母是梯度累加数。（不同 batch 之间的 loss 的平均） ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:8:0","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"为什么不用大模型做 embedding？ 大模型主要训练的预测 next token 的能力，而非判断整个句子 embedding 的好坏。因此使用 LLM 做嵌入效果不理想。 部署成本高。 基础知识 Post-Training总结（https://mp.weixin.qq.com/s/VLWU3YnJa1SZRCySZQc4Hw） ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:9:0","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"Flash Attention ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:10:0","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"MoE ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:11:0","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"KV cache ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:12:0","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"从 MHA 到 MLA ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:13:0","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"Transformer 相关 ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:14:0","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"手撕各模块代码 free-running mode 和 teacher forcing mode（https://zhuanlan.zhihu.com/p/630356292) ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:14:1","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"Transformer 参数量计算 ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:14:2","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"overthinking 怎么解决 ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:15:0","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"相关文献 ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:15:1","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"方法 推理链压缩：在保持推理质量的同时，减少生成的 token 数量。 长度预算控制：在推理过程中动态调整生成内容的长度，以提高效率。 系统切换与模型切换：根据任务需求灵活选择不同的模型或推理路径。 并行搜索：利用并行计算加速推理过程。 ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:15:2","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"DeepSpeed（zero 显存优化） 模型显存占用（bf16/fp16）（https://zhuanlan.zhihu.com/p/665172400） 训练时 可见激活值占大头。 优化方法如下： 推理时 一个经验法则是：推理时的峰值显存大致是模型参数显存的 1.5 - 2.5 倍（尤其在处理长序列或大批次时）。更精确的估计需要结合具体模型和输入 输入/输出的 Token 存储：需要显存存储输入的 Token 嵌入（embedding）和生成的输出 Token。 中间激活值（Intermediate Activations）：前向传播过程中每一层的输出（如 Attention 的 Key/Value 缓存、FFN 的中间结果等）。 Key-Value 缓存（KV Cache）：自回归生成时，为避免重复计算历史 Token 的 Key/Value，需缓存这些中间结果（显存占用与输入+输出长度成正比） ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:16:0","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"zero3 这是inter-layer + broadcast + reduce-scatter的实现方法，是很久之前官方的实现，现在官方的真正做法是：intra-layer + all-gather+ reduce-scatter（与fsdp一致） ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:16:1","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"位置编码（RoPE） ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:17:0","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"LoRA（手撕） ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:18:0","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"R1 相关 ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:19:0","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"训练整体流程 ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:19:1","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"aha monment 在训练过程中，研究团队使用数学问题来训练和评估模型的逻辑推理能力。在观察模型输出时，研究人员正是在下面这个数学方程的解题过程中捕捉到了一个引人注目的”顿悟时刻”，充分展现了模型通过强化学习自然获得的自主反思能力： ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:19:2","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"k1 k2 k3 ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:19:3","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"R1-zero qwen2.5-0.5B 模型，num_generations 为 2，gsm8k 数据集准确率 0.45489006823351025。num_generations 为 4，准确率为 0.47763457164518575 ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:19:4","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"Rule-based reward 准确性奖励（Accuracy Rewards）：答案是否正确 格式奖励（Format Rewards）：是否有思考标签 语言混合问题：对语言一致性进行打分 ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:19:5","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"梯度累计 代码（https://zhuanlan.zhihu.com/p/423359955) 暂时无法在飞书文档外展示此内容 gradient_accumulation_steps 是梯度累积次数，累积几次，原本的 loss 就要除以几，这是为了对多个批次的数据的梯度做累积。 有人说，应该有这一行代码才算累加 暂时无法在飞书文档外展示此内容 这样理解是错误的。 要明白最重要的一点是，梯度累加，累加的并不是损失，而是根据损失得到的梯度。 梯度累计如何节省显存 减少瞬时激活值显存：每次仅处理小批量的数据，激活值显存占用降低为原来的 1/k（例如 k=4 时，显存占用降至 25%）。 复用显存：每次小批量计算完成后，释放当前激活值显存，供下一次计算使用（显存占用峰值始终为小批量对应的量）。 梯度显存不变：模型参数和梯度的显存占用与批量大小无关，因此不受影响（但需额外存储累积梯度的变量，这部分开销极小）。 ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:20:0","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"Adam 和 AdamW ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:21:0","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"RLHF 相关（PPO、RLOO、REINFORCE++、ReMax、GRPO、SAC） on-policy 和 off-policy（参考 https://zhuanlan.zhihu.com/p/346433931） Off-policy: the learning is from the data off the target policy（引自《Reinforcement Learning An Introduction》）。也就是说 RL 算法中，数据来源于一个单独的用于探索的策略（不是最终要求的策略）。（Off-policy 方法中不一定非要采用重要性采样，要根据实际情况采用（比如，需要精确估计值函数时需要采用重要性采样；若是用于使值函数靠近最优值函数则不一定）） On-policy: the target and the behavior polices are the same. 也就是说 on-policy 里面只有一种策略，它既为目标策略又为行为策略。 总结：PPO 算法，虽然有 2 个 policy，用\\(\\pi_{old}\\)采样去更新 pi，但是由于 pi_old 的参数是从 pi 复制的，本质上还是属于同一个策略。所以 PPO 是一个看起来很像 off-policy 的 on-policy 算法。 ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:22:0","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"online 和 offline 更新的数据是否是最新 agent 的模型生成的数据 Online: 更新的数据为最新模型采样得到的（采样的数据一次性用完） Offline: 更新的数据为 x 次更新前模型采样得到的（采样的数据更新多次） online、offline、on-policy、off-policy online 学习中可以是 on/off policy 的。而 offline 学习中除了第一次更新模型的学习可能是 on policy 的，之后的所有学习只有仍是 offline 的则一定是 off policy。 critic 和 reward 区别（参考 https://www.zhihu.com/question/1900547615495545054/answer/1901411039406457541） reward model 评估整个 response 质量，给出整体奖励信号，无法直接映射到每个 token 的贡献。 critic model 估计价值函数，预测未来可能获得的累积奖励，为策略更新提供稳定的 advantage 信号 reward 扮演的是环境的角色，而 critic 属于 llm 这个智能体的一部分，就好比在考试中，你自己检查卷子和老师给你打分的区别。 ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:22:1","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"clip 细节 ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:22:2","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"PPO 和 GRPO 的区别 优势值区别 kl 散度区别 PPO 的 KL 计算是在每个 token 的生成过程中发生的，不断计算当前 token 和 ref_model 的 KL 散度。 GRPO 的 KL 计算是在一个回答生成结束后发生的，一次性对句子中的每个 token 计算 KL 散度，并参与最终 loss 的计算； PPO 的 KL 塞到 reward 里（reward shaping） GRPO 的 KL 是独立的损失项。 advantage 角度来看，PPO 的 KL 惩罚是 token-level 的 GRPO 的 KL 惩罚是 sentence-level（但是也是逐个 token 算 kl 再取 mean）的 ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:22:3","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"REINFORECE++ ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:22:4","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"RLOO（REINFORCE leave-one-out） ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:22:5","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"ReMAX（REINFORCE argmax） ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:22:6","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"DPO a变大，b变小，理想情况，chosen response概率提升，rejected response概率下降 ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:22:7","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"针对GRPO的改进 DAPO（参考 https://www.zhihu.com/question/1895273986537014226/answer/1899582779408245950） DAPO 是对 GRPO 的改进。DAPO（Decoupled Clip and Dynamic sAmpling Policy Optimization，即解耦裁剪和动态采样策略优化）的优化点有四个（其中前 2 个是主要亮点，是命名的来源）： 更高裁剪 动态采样（Dynamic Sampling） Token 级策略梯度损失（Token-Level Policy Gradient Loss） 超长奖励塑造（Overlong Reward Shaping） ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:23:0","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"DR.GRPO ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:23:1","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"GPG GPG彻底使用policy-based的方法，去除了其他的PPO小trick ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:23:2","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"FP16 和 BF16 的区别 ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:24:0","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"Tokenize 相关 ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:25:0","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","面经"],"content":"面经 大模型微调经验 ai 八股 ","date":"2025-07-02","objectID":"/%E9%9D%A2%E7%BB%8F2025/:26:0","tags":["面经"],"title":"面经2025","uri":"/%E9%9D%A2%E7%BB%8F2025/"},{"categories":["","NLP","agent","world-model"],"content":"我理解的agent中的world model即可以预测采取某个action之后state的变化，这样做的好处是可以降低试错带来的时间成本或者是其它潜在的成本、风险。 目前agent中常用的模块为reflexion，即反思模块。作用是评价行动轨迹的结果是成功还是失败，如果评估为失败，则接受失败的轨迹和评估结果，生成一段失败总结文本。 这当然是可行的，但问题是这需要不断试错才有可能纠错从而执行正确的action，这就会造成时间成本，甚至如果agent负责的是一个购物任务，错误的action甚至有可能是下单错误的商品。 所以我认为world model的作用就是预测action之后state会如何变化，这相当于走一步，看一步，来避免出错。 reflexion是必要的，这是对整个轨迹的评估，如果评估结果为失败的话，还是要进行反思，与world model结合的作用是降低评估失败的概率，使试错的次数降低。我认为这在实际应用当中是有必要的，试错的时间成本要远远大于每一步调用world model所带来的开销。 ","date":"2025-06-30","objectID":"/world_model/:0:0","tags":["NLP","agent","world-model"],"title":"world_model","uri":"/world_model/"},{"categories":["","coding","verl"],"content":"前置知识，ray前置知识 我将用此文来详细介绍veRL中有关single_controller和SPMD的相关内容。本文不涉及ppo训练相关，只是记录一下理解veRL架构实现的核心。 实现single_controller方法的核心有以下方法： Worker RayResourcePool RayWorkerGroup RayClassWithInitArgs 实现SPMD的有以下方法： register dispatch_fn和collect_fn execute_fn func_generator 推荐阅读：verl 解读 - 源码阅读(part3) ","date":"2025-06-26","objectID":"/init_workers%E8%AF%A6%E8%A7%A3/:0:0","tags":["coding","verl"],"title":"init_workers详解","uri":"/init_workers%E8%AF%A6%E8%A7%A3/"},{"categories":["","coding","verl"],"content":"原生Ray 代码改编自# verl 解读 - ray 相关前置知识 (part1) ray分配资源的单位是bundle，一个bundle一般由1个cpu和1个gpu构成。 而一个placement_group由多个bundle组成，当参数设置为pack通常为同1个node上的bundle构成的。参数设置为spread为不同node的bundle组成。如下图所示： 在python中，定义placement_group如下： pg = placement_group([ {\"CPU\": 1, \"GPU\": 1} for _ in range(total_devices) ], strategy=\"STRICT_PACK\", name=\"ray_multi_group_comm\") ray.get(pg.ready()) print(f\"=\u003e Placement group is ready, total_devices: {total_devices}\") ray中的基本单位有task和actor，一个无状态，一个有状态（可以简单理解为一个是函数，一个是面向对象的类）。都需要用worker来代替运行。因此我们需要定义一个worker来完成各种任务。这个worker都是上述资源的分配单位，它只会看到ray分配给它的资源，而看不到其它的资源，对于分布式训练而言，可以在这个worker中定义分布式训练的各种东西、加载模型、前向训练等。一个worker定义如下： class WorkerBase: \"\"\" 通用的 Worker 基类。 每个 Worker 实例是一个 Ray Actor，它会在一个独立的进程中运行，并持有一个模型副本。 \"\"\" def __init__(self, model_cls, temp_init: bool = False): # 获取当前 Ray Actor 所在的节点 ID 和 Actor ID self._node_id = ray.get_runtime_context().get_node_id() self._actor_id = ray.get_runtime_context().get_actor_id() # 获取当前主机的 IP 地址 self._ip_address = socket.gethostbyname(socket.gethostname()) if temp_init: # 如果是临时初始化，则直接返回，不进行模型和分布式环境的设置 return # 设置随机种子 self._set_seed(42) # 初始化 PyTorch 分布式环境 if not dist.is_initialized(): # 检查是否已经初始化 dist.init_process_group( backend=\"nccl\", # 使用 NCCL 作为后端，适用于 NVIDIA GPU world_size=int(os.getenv(\"WORLD_SIZE\", \"1\")), # 从环境变量获取 world_size rank=int(os.getenv(\"RANK\", \"0\")), # 从环境变量获取当前进程的 rank # 从环境变量获取主节点的地址和端口，用于建立连接 init_method=f\"tcp://{os.getenv('MASTER_ADDR')}:{os.getenv('MASTER_PORT')}\" ) self._rank = dist.get_rank() # 获取当前进程的排名 self._world_size = dist.get_world_size() # 获取分布式组的大小 self.model = model_cls() # 实例化传入的模型类 self.model.to(\"cuda\") # 将模型移动到 GPU # 打印初始化信息 print(f\"=\u003e Rank {self._rank}/{self._world_size} in group '{os.getenv('GROUP_NAME')}' initialized model: {self.model.__class__.__name__}\") def get_actor_info(self): \"\"\"返回该 actor 的网络信息。\"\"\" return { \"ip_address\": self._ip_address } def _set_seed(self, seed: int = 42): \"\"\"设置随机种子。\"\"\" set_random_seed(seed) def train_step(self, data): \"\"\"执行一个训练步骤。\"\"\" x = data.to(\"cuda\") # 将输入数据移动到 GPU y = self.model(x) # 模型前向传播 loss = y.sum() # 计算一个简单的损失（所有输出的和） loss.backward() # 反向传播，计算梯度 return loss.cpu() # 返回在 CPU 上的 loss 值 def sample_grads(self): \"\"\"采样一个参数的梯度用于验证。\"\"\" for name, p in self.model.named_parameters(): # 遍历所有带名字的参数 if p.requires_grad is True: # 找到第一个需要梯度的参数 return name, p.grad.cpu() # 返回参数名和它在 CPU 上的梯度 其中model_cls就是定义的各种模型。 然后就可以给各种worker绑定资源。这里我定义了两种模型，node上有4张gpu，我实现的是两种模型分别占2张不同的卡： def setup_and_create_workers(pg, model_cls, group_name, start_bundle_index, num_workers_in_group): \"\"\" 一个辅助函数，用于设置一个分布式组并为其创建 workers。 \"\"\" print(f\"\\\\n========== 正在设置组: {group_name} ==========\") # 将 WorkerBase 类包装成 Ray Remote Actor Worker = ray.remote(WorkerBase) # 创建一个临时 worker 来获取该组的网络信息 # 这个 worker 会被放置在指定的 placement group bundle 上 temp_worker = Worker.options( scheduling_strategy=PlacementGroupSchedulingStrategy( placement_group=pg, placement_group_bundle_index=start_bundle_index, ), num_gpus=1, ).remote(model_cls=model_cls, temp_init=True) # 使用 temp_init=True，避免完全初始化 # 获取临时 worker 的网络信息，特别是 IP 地址，用作该组的 master 地址 network_info = ray.get(temp_worker.get_actor_info.remote()) master_addr = network_info[\"ip_address\"] master_port = str(find_free_port()) # 为该组找到一个空闲端口 ray.kill(temp_worker) # 销毁临时 worker print(f\"为组 {group_name} 使用的主节点地址: {master_addr}:{master_port}\") workers = [] # 存储创建的 worker # 循环创建指定数量的 worker for i in range(num_workers_in_group): rank = i # 当前 worker 在其组内的 rank bundle_index = start_bundle_index + i # 该 worker 在 placement group 中的 bundle 索引 # 设置分布式环境所需的环境变量 env_vars = { \"WORLD_SIZE\": str(num_workers_in_group), \"RANK\": str(rank), \"MASTER_ADDR\": master_addr, \"MASTER_PORT\": master_port, \"GROUP_NAME\": group_name } # 创建一个正式的 worker actor workers.append( Worker.options( name=f\"{group_name}_rank_{rank}\", # 为 actor 命名，方便调试 scheduling_strategy=PlacementGroupSchedulingStrategy( placement_group=pg, placement_group_bundle_index=bundle_index, ), runtime_env={\"env_vars\": env_vars}, # 将环境变量传递给 actor num_gpus=1, # 为每个 actor 分配一个 GPU ).remote(model_cls=model_cls)","date":"2025-06-26","objectID":"/ray%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86/:1:0","tags":["coding","verl"],"title":"ray前置知识","uri":"/ray%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86/"},{"categories":["","coding","verl"],"content":"veRL中的Ray 使用# 【AI Infra】【RLHF框架】二、VeRL中colocate实现源码解析中的代码： import ray from verl.single_controller.base import Worker from verl.single_controller.base.decorator import register, Dispatch from verl.single_controller.ray.base import RayResourcePool, RayClassWithInitArgs, RayWorkerGroup, create_colocated_worker_cls from verl import DataProto @ray.remote class Actor(Worker): def __init__(self) -\u003e None: super().__init__() @register(dispatch_mode=Dispatch.DP_COMPUTE_PROTO) def add(self, data: DataProto): data.batch['a'] = data.batch['a'].to(\"cuda\") data.batch['a'] += self.rank return data @ray.remote class Critic(Worker): def __init__(self, config) -\u003e None: super().__init__() self.config = config @register(dispatch_mode=Dispatch.DP_COMPUTE_PROTO) def sub(self, data: DataProto): data.batch['a'] = data.batch['a'].to(\"cuda\") data.batch['a'] -= self.config['b'] return data def test_colocated_workers(): ray.init() import torch # 构建一个DataProto，其中属性a是维度为10的零向量。 data = DataProto.from_dict({'a': torch.zeros(10)}) print(data.batch[\"a\"]) # 利用RayClassWithInitArgs将自定义的worker和参数封装起来 actor_cls = RayClassWithInitArgs(cls=Actor) critic_cls = RayClassWithInitArgs(cls=Critic, config={'b': 10}) # 定义资源池，仅包含一个2GPU的节点 resource_pool = RayResourcePool(process_on_nodes=[2]) # 利用create_colocated_worker_cls将自定义的两个worker绑定到WorkerDict上 cls_dict = {'actor': actor_cls, 'critic': critic_cls} ray_cls_with_init = create_colocated_worker_cls(cls_dict) # 启动WorkerDict wg_dict = RayWorkerGroup(resource_pool=resource_pool, ray_cls_with_init=ray_cls_with_init) # 分别获取actor和critic的workergroup spawn_wg = wg_dict.spawn(prefix_set=cls_dict.keys()) colocated_actor_wg = spawn_wg['actor'] colocated_critic_wg = spawn_wg['critic'] # actor执行add、critic执行sub actor_output = colocated_actor_wg.add(data) critic_output = colocated_critic_wg.sub(data) # actor_output.batch[\"a\"]==[0, 0, 0, 0, 0, 1, 1, 1, 1, 1] # critic_output.batch[\"a\"]==[-10, -10, -10, -10, -10, -10, -10, -10, -10, -10] print(actor_output.batch[\"a\"]) print(critic_output.batch[\"a\"]) ray.shutdown() if __name__ == '__main__': test_colocated_workers() 具体的操作我会在init_workers章节进行讲解，这里是对veRL中的single_controller的一个初探。 ","date":"2025-06-26","objectID":"/ray%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86/:2:0","tags":["coding","verl"],"title":"ray前置知识","uri":"/ray%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86/"},{"categories":["","coding","verl"],"content":"问题 有一个常见的问题是为什么在placement_group中分配了一个bundle为1个gpu，为什么还要指定num_gpus=1，这个参数有什么含义吗? 简单来说，两者都需要，因为它们在 Ray 的调度系统中扮演着不同但互补的角色： placement_group 中的 {\"GPU\": 1}：这是在做资源“预留” (Reservation)。 它的作用是告诉 Ray 集群：“我需要你为我准备好一个资源包（bundle），这个包里必须包含 1 个 CPU 和 1 个 GPU。” placement_group 的主要目的是确保一组相关的资源能够被原子性地、协同地调度。比如，strategy=\"STRICT_PACK\" 确保了所有这些 bundles 都会被放置在同一个节点上，这对于需要低延迟通信的分布式训练至关重要。 这就像是为一场宴会预订了一个能容纳4位客人的包间，并确保这4个座位都在同一张桌子上。它只是圈占了资源，但还没有指定谁来使用这些资源。 Worker.options(num_gpus=1)：这是在为 Actor 提出具体的“资源请求” (Request)。 它的作用是告诉 Ray：“我即将创建的这个 Worker Actor，它本身在运行时需要消耗 1 个 GPU。” Ray 的调度器需要根据这个明确的请求来为 Actor 分配具体的物理设备。没有这个声明，Ray 调度器会认为该 Actor 不需要 GPU。 这就像是告诉宴会的主管：“这位客人需要一个座位。” 为什么缺一不可？ PlacementGroupSchedulingStrategy 将这两者联系起来。它告诉 Ray：“请将这个需要1个GPU的Actor (num_gpus=1)，安排到我们之前预留的那个包含GPU的bundle ({\"GPU\": 1}) 上去。” 如果只有 placement_group 的预留而没有 Actor 的 num_gpus=1 请求，Ray 的调度器会看到一个矛盾：你试图将一个声称不需要 GPU 的 Actor 安排在一个为 GPU 使用者保留的“席位”上。这可能会导致调度失败或资源分配混乱。 反之，如果只有 Actor 的 num_gpus=1 请求而没有 placement_group，Ray 会在整个集群中寻找任何一个可用的 GPU 来满足这个 Actor，但无法保证它会和其他相关的 Actor 运行在同一个节点上，从而失去了分布式训练的性能优势。 总结： placement_group 是一个宏观的、用于资源预留和协同定位的机制，而 num_gpus=1 是一个微观的、用于声明单个 Actor 实际资源消耗的机制。两者必须同时使用并保持一致，才能确保 Ray 能够精确、高效地将需要特定资源的 Actor 调度到你为它们预留的、具有特定拓扑结构的资源包中。这种显式的设计让复杂的分布式资源管理变得更加清晰和可控。 ","date":"2025-06-26","objectID":"/ray%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86/:3:0","tags":["coding","verl"],"title":"ray前置知识","uri":"/ray%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86/"},{"categories":["","coding","verl"],"content":"参考 ","date":"2025-06-26","objectID":"/ray%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86/:4:0","tags":["coding","verl"],"title":"ray前置知识","uri":"/ray%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86/"},{"categories":["","NLP","agent"],"content":"根据Anthropic的定义，agent定义如下： At Anthropic, we categorize all these variations as agentic systems, but draw an important architectural distinction between workflows and agents: Workflows are systems where LLMs and tools are orchestrated through predefined code paths. Agents, on the other hand, are systems where LLMs dynamically direct their own processes and tool usage, maintaining control over how they accomplish tasks. 简单来说就是Workflows是预先定义好的一个路径，而Agents是让其自主完成各种流程，而无需预先定义。 ","date":"2025-06-14","objectID":"/agent%E6%A6%82%E8%A7%88/:0:0","tags":["NLP","agent"],"title":"agent概览","uri":"/agent%E6%A6%82%E8%A7%88/"},{"categories":["","NLP","agent"],"content":"workflows ","date":"2025-06-14","objectID":"/agent%E6%A6%82%E8%A7%88/:1:0","tags":["NLP","agent"],"title":"agent概览","uri":"/agent%E6%A6%82%E8%A7%88/"},{"categories":["","NLP","agent"],"content":"Prompt chaining image.png ","date":"2025-06-14","objectID":"/agent%E6%A6%82%E8%A7%88/:1:1","tags":["NLP","agent"],"title":"agent概览","uri":"/agent%E6%A6%82%E8%A7%88/"},{"categories":["","NLP","agent"],"content":"Routing image.png ","date":"2025-06-14","objectID":"/agent%E6%A6%82%E8%A7%88/:1:2","tags":["NLP","agent"],"title":"agent概览","uri":"/agent%E6%A6%82%E8%A7%88/"},{"categories":["","NLP","agent"],"content":"Parallelization image.png ","date":"2025-06-14","objectID":"/agent%E6%A6%82%E8%A7%88/:1:3","tags":["NLP","agent"],"title":"agent概览","uri":"/agent%E6%A6%82%E8%A7%88/"},{"categories":["","NLP","agent"],"content":"Orchestrator-workers image.png ","date":"2025-06-14","objectID":"/agent%E6%A6%82%E8%A7%88/:1:4","tags":["NLP","agent"],"title":"agent概览","uri":"/agent%E6%A6%82%E8%A7%88/"},{"categories":["","NLP","agent"],"content":"Evaluator-optimizer image.png 最近热门的Gemini 2.5 Pro Capable of Winning Gold at IMO 2025论文就是使用的这个工作流。 ","date":"2025-06-14","objectID":"/agent%E6%A6%82%E8%A7%88/:1:5","tags":["NLP","agent"],"title":"agent概览","uri":"/agent%E6%A6%82%E8%A7%88/"},{"categories":["","NLP","agent"],"content":"agents image.png ","date":"2025-06-14","objectID":"/agent%E6%A6%82%E8%A7%88/:2:0","tags":["NLP","agent"],"title":"agent概览","uri":"/agent%E6%A6%82%E8%A7%88/"},{"categories":["","NLP","agent"],"content":"参考 Agents Zero to One: Learning Agentic Patterns Building Effective AI Agents \\ Anthropic How we built our multi-agent research system \\ Anthropic ","date":"2025-06-14","objectID":"/agent%E6%A6%82%E8%A7%88/:3:0","tags":["NLP","agent"],"title":"agent概览","uri":"/agent%E6%A6%82%E8%A7%88/"},{"categories":["","coding","verl"],"content":"Hybrid Engine 在 RLHF 流程中，actor model 的 generation 和 rollout 占据了绝大多数运行时间（在 veRL 是 58.9%）。并且，由于 PPO 是 online 算法，经验（experiences）必须来自于被 train 的模型本身，因此，rollout 和 training 是必须串行的。如果这两者使用不同的资源组，比如 rollout 用 2 张卡，而 training 用 4 张卡，rollout 的时候 training 的资源闲置，training 的时候 rollout 的资源闲置，无论如何都会浪费大量的计算资源。由此，veRL 将 training 和 rollout engine 放置在同一个资源组中串行执行。training 时，将 rollout engine 的显存回收（offload 到 CPU 上 或者直接析构掉），rollout 时，再将 training engine 的显存释放掉。这种将 actor model 的不同 engine 放置在同一个资源组上的方案，就称为 hybrid engine。 image.png ","date":"2025-06-05","objectID":"/verl%E6%80%BB%E4%BD%93%E6%A6%82%E8%A7%88/:1:0","tags":["coding","verl"],"title":"verl总体概览","uri":"/verl%E6%80%BB%E4%BD%93%E6%A6%82%E8%A7%88/"},{"categories":["","coding","verl"],"content":"最原生的reward_mananger: class NaiveRewardManager: \"\"\"The reward manager.\"\"\" def __init__(self, tokenizer, num_examine, compute_score=None, reward_fn_key=\"data_source\") -\u003e None: self.tokenizer = tokenizer self.num_examine = num_examine # the number of batches of decoded responses to print to the console self.compute_score = compute_score or default_compute_score self.reward_fn_key = reward_fn_key def __call__(self, data: DataProto, return_dict=False): \"\"\"We will expand this function gradually based on the available datasets\"\"\" # If there is rm score, we directly return rm score. Otherwise, we compute via rm_score_fn if \"rm_scores\" in data.batch.keys(): if return_dict: return {\"reward_tensor\": data.batch[\"rm_scores\"]} else: return data.batch[\"rm_scores\"] reward_tensor = torch.zeros_like(data.batch[\"responses\"], dtype=torch.float32) reward_extra_info = defaultdict(list) already_print_data_sources = {} for i in range(len(data)): data_item = data[i] # DataProtoItem prompt_ids = data_item.batch[\"prompts\"] prompt_length = prompt_ids.shape[-1] valid_prompt_length = data_item.batch[\"attention_mask\"][:prompt_length].sum() valid_prompt_ids = prompt_ids[-valid_prompt_length:] response_ids = data_item.batch[\"responses\"] valid_response_length = data_item.batch[\"attention_mask\"][prompt_length:].sum() valid_response_ids = response_ids[:valid_response_length] # decode prompt_str = self.tokenizer.decode(valid_prompt_ids, skip_special_tokens=True) response_str = self.tokenizer.decode(valid_response_ids, skip_special_tokens=True) ground_truth = data_item.non_tensor_batch[\"reward_model\"][\"ground_truth\"] data_source = data_item.non_tensor_batch[self.reward_fn_key] extra_info = data_item.non_tensor_batch.get(\"extra_info\", None) score = self.compute_score( data_source=data_source, solution_str=response_str, ground_truth=ground_truth, extra_info=extra_info, ) if isinstance(score, dict): reward = score[\"score\"] # Store the information including original reward for key, value in score.items(): reward_extra_info[key].append(value) else: reward = score reward_tensor[i, valid_response_length - 1] = reward if data_source not in already_print_data_sources: already_print_data_sources[data_source] = 0 if already_print_data_sources[data_source] \u003c self.num_examine: already_print_data_sources[data_source] += 1 print(\"[prompt]\", prompt_str) print(\"[response]\", response_str) print(\"[ground_truth]\", ground_truth) if isinstance(score, dict): for key, value in score.items(): print(f\"[{key}]\", value) else: print(\"[score]\", score) if return_dict: return { \"reward_tensor\": reward_tensor, \"reward_extra_info\": reward_extra_info, } else: return reward_tensor 逻辑很简单，就是通过compute_score函数来计算score。 ","date":"2025-06-02","objectID":"/reward_mananger/:0:0","tags":["coding","verl"],"title":"reward_mananger","uri":"/reward_mananger/"},{"categories":["LLM","NLP","reasoning"],"content":"核心总结 PRM和MCTS实际上是两种可以独立使用的技术，只不过，往往它们组合使用时往往能产生1+1\u003e2的效果。例如， 单独使用PRM：我们可以让模型对同一个prompt采样多个不同solution，无需MCTS，只需利用模型的temperature等随机参数让每次生成结果不同，然后用PRM对每个solution的每一步打分，最终选择分数最高的路径返回。 单独使用MCTS：使用MCTS生成多个解题路径时，不一定要用PRM来决定哪个节点值得扩展，可以用外部大模型（如GPT-4）来选择，也可以用模型自身的perplexity来判断。本质上，我们需要的是找到最值得扩展的节点，PRM只是挑选的众多方法之一。 PRM 和 MCTS 既可以应用于优化训练数据，也可以用来预测用 用于得到高质量训练数据：如rStar论文中，可以用PRM和MCTS的方式来迭代地筛选得到质量更好的思维链SFT数据或者RLHF数据，还可以生成更精确的reward model训练数据。 用于推理：很简单，推理用MCTS的方式把 test-scaling 做上来，再结合PRM的方式从众多路径中挑选最佳答案。 PRM和MCTS的缺点 这方面 DeepSeek-R1和 kimi1.5的论文已经说得很情况了。 Process Reward Model(PRM) 在实际应用中有三大局限： 第一，难以清晰界定一般推理中的细粒度步骤，说白了，怎么定义什么为一个步骤。 第二，判断当前步骤的正误难度大，模型自动化标注不如人意，人工标注又难以拓展。 第三，引入基于模型的PRM易致reward hacking，有时为了训练 policy model，但反而更多时间去优化 reward model 去了。 对MCTS的看法： 文本的生成搜索空间指数级增长，为应对，给节点设扩展上限，却容易让模型陷入局部最优解困境。 MCTS往往要结合一个精确的PRM来用才能发挥最大效果，但PRM又有上述的问题，陷入一个死循环。 ","date":"2025-04-04","objectID":"/mcts%E5%92%8Cprm/:1:0","tags":["LLM","NLP","reasoning"],"title":"MCTS和PRM","uri":"/mcts%E5%92%8Cprm/"},{"categories":["LLM","NLP","reasoning"],"content":"参考 https://zhuanlan.zhihu.com/p/27278317894 rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking ","date":"2025-04-04","objectID":"/mcts%E5%92%8Cprm/:2:0","tags":["LLM","NLP","reasoning"],"title":"MCTS和PRM","uri":"/mcts%E5%92%8Cprm/"},{"categories":["","python","coding"],"content":"a = 'global' def outer(): # def len(in_var): # print('called my len() function: ', end=\"\") # l = 0 # for i in in_var: # l += 1 # return l a = 'local' def inner(): nonlocal a a += ' variable' inner() print('a is', a) # print(len(a)) outer() # print(len(a)) print('a is', a) 此时为nonlocal a，会按照local-闭包-global的顺序找到闭包变量a。a的值为local variable a = 'global' def outer(): # def len(in_var): # print('called my len() function: ', end=\"\") # l = 0 # for i in in_var: # l += 1 # return l a = 'local' def inner(): global a a += ' variable' inner() print('a is', a) # print(len(a)) outer() # print(len(a)) print('a is', a) 此时为global，会从全局变量中寻找a，a的值为global variable ","date":"2025-03-24","objectID":"/legb/:0:0","tags":["python","coding","LEGB"],"title":"LEGB","uri":"/legb/"},{"categories":["","coding","python"],"content":"python调试工具，类似于vscode的调试工具，使用命令行进行调试。 ","date":"2025-03-23","objectID":"/debugger/:0:0","tags":["coding","python"],"title":"debugger","uri":"/debugger/"},{"categories":["","coding","python"],"content":"使用方法 ","date":"2025-03-23","objectID":"/debugger/:1:0","tags":["coding","python"],"title":"debugger","uri":"/debugger/"},{"categories":["","coding","python"],"content":"插入式 import pdb; pdb.set_trace() 或者 breakpoint() ","date":"2025-03-23","objectID":"/debugger/:1:1","tags":["coding","python"],"title":"debugger","uri":"/debugger/"},{"categories":["","coding","python"],"content":"非插入式 python -m pdb [-c command] (-m module | pyfile) [args ...] ","date":"2025-03-23","objectID":"/debugger/:1:2","tags":["coding","python"],"title":"debugger","uri":"/debugger/"},{"categories":["","coding","python"],"content":"常用命令 ","date":"2025-03-23","objectID":"/debugger/:2:0","tags":["coding","python"],"title":"debugger","uri":"/debugger/"},{"categories":["","coding","python"],"content":"h 即help，可用命令如下 ","date":"2025-03-23","objectID":"/debugger/:2:1","tags":["coding","python"],"title":"debugger","uri":"/debugger/"},{"categories":["","coding","python"],"content":"p p x 即print(x)，用于打印变量。 pp x，使用pprint打印 ","date":"2025-03-23","objectID":"/debugger/:2:2","tags":["coding","python"],"title":"debugger","uri":"/debugger/"},{"categories":["","coding","python"],"content":"w 即where，查看当前调用栈。 ","date":"2025-03-23","objectID":"/debugger/:2:3","tags":["coding","python"],"title":"debugger","uri":"/debugger/"},{"categories":["","coding","python"],"content":"u和d u即up，回到上一个frame d即down，到下一个frame ","date":"2025-03-23","objectID":"/debugger/:2:4","tags":["coding","python"],"title":"debugger","uri":"/debugger/"},{"categories":["","coding","python"],"content":"l 即lst l 查看前后12行代码 ll查看当前函数全部代码 ","date":"2025-03-23","objectID":"/debugger/:2:5","tags":["coding","python"],"title":"debugger","uri":"/debugger/"},{"categories":["","coding","python"],"content":"b 即break，进行打断点 b x，在第x行打断点。 b 查看所有断点。 相同的有tbreak，与break的区别是第一次到该断点后会自动移除断点。即temporary breakpoint ","date":"2025-03-23","objectID":"/debugger/:2:6","tags":["coding","python"],"title":"debugger","uri":"/debugger/"},{"categories":["","coding","python"],"content":"n 即next，执行下一条语句，但忽视函数调用内部细节 ","date":"2025-03-23","objectID":"/debugger/:2:7","tags":["coding","python"],"title":"debugger","uri":"/debugger/"},{"categories":["","coding","python"],"content":"s 即step，执行下一条语句，如果有函数调用，则调用新frame，进入函数内部。 ","date":"2025-03-23","objectID":"/debugger/:2:8","tags":["coding","python"],"title":"debugger","uri":"/debugger/"},{"categories":["","coding","python"],"content":"c 即continue，继续程序的执行直到下一个断点 image.png ","date":"2025-03-23","objectID":"/debugger/:2:9","tags":["coding","python"],"title":"debugger","uri":"/debugger/"},{"categories":["","coding","python"],"content":"r 即return，直接跳转到当前函数return语句 ","date":"2025-03-23","objectID":"/debugger/:2:10","tags":["coding","python"],"title":"debugger","uri":"/debugger/"},{"categories":["","coding","python"],"content":"until until n，使程序继续执行直到执行到行数为n的语句。 ","date":"2025-03-23","objectID":"/debugger/:2:11","tags":["coding","python"],"title":"debugger","uri":"/debugger/"},{"categories":["","coding","python"],"content":"cl 即clear clear n，清除编号为n的断点 clear，清除所有断点。 ### j 即jump，向前或向后跳转，与until区别是，jump不会执行中间的语句，而是忽略他们。 ","date":"2025-03-23","objectID":"/debugger/:2:12","tags":["coding","python"],"title":"debugger","uri":"/debugger/"},{"categories":["","coding","python"],"content":"display 相当于一个监视器，用于监视变量的变化 ### retval 打印当前函数最后一次返回的返回值 ### q 即quit，退出pdb调试。 ","date":"2025-03-23","objectID":"/debugger/:2:13","tags":["coding","python"],"title":"debugger","uri":"/debugger/"},{"categories":["coding","LLM","generate"],"content":"理论部分在这：generate相关 ## generate参数 def generate( self, inputs: Optional[torch.Tensor] = None, generation_config: Optional[GenerationConfig] = None, logits_processor: Optional[LogitsProcessorList] = None, stopping_criteria: Optional[StoppingCriteriaList] = None, prefix_allowed_tokens_fn: Optional[Callable[[int, torch.Tensor], List[int]]] = None, synced_gpus: Optional[bool] = None, assistant_model: Optional[\"PreTrainedModel\"] = None, streamer: Optional[\"BaseStreamer\"] = None, negative_prompt_ids: Optional[torch.Tensor] = None, negative_prompt_attention_mask: Optional[torch.Tensor] = None, **kwargs, ) -\u003e Union[GenerateOutput, torch.LongTensor]: 在代码中可以看到在函数入口显式的定义了很多参数。他们的具体含义如下 inputs：tensor 形式的 token_id，通常先准备文本形式的提示词和输入，使用tokenizer转化为对应 id，这里维度通常为 [batch_size, seq_len] generation_config：一个用 GenerationConfig 类创建的对象，存储着模型生成的超参数，可以提前创建该对象并传入 .generate() logits_processor：高级功能，logits_processor 可以在每个 step 的输出概率计算完成后，对分数进行进一步的干预，改变输出的概率分布，从而影响生成的结果，例如最常见的，重复惩罚，就是使用 logits_processor 完成的。 stopping_criteria：高级功能，允许用户通过 stopping_criteria 自定义生成停止条件 prefix_allowed_tokens_fn：解码策略的一个超参数，用于前缀 token 约束 synced_gpus： DeepSpeed ZeRO Stage-3 多GPU时使用（ZeRO-3包括优化器状态+梯度+权重并行优化，而推理阶段只使用权重并行），此时需要将 synced_gpus 设置成 Ture。. 否则，如果一个 GPU 在另一个 GPU 之前完成生成，整个系统就会挂起，因为其余 GPU 尚未从最先完成的 GPU 接收到权重分片。 transformers\u003e=4.28 在生成时检测到多个 GPU 会自动设置 synced_gpus=True，transformers\u003c4.28 需要手动设置，本文代码环境transformers=4.41.1 assistant_model：高级功能，辅助生成模型，另一个词表完全相同的小模型，有些token使用辅助模型生成更快 streamer：流式输出控制器，现在的大模型平台都是一个字一个字显示出来的，这就是流式输出，否则的话会等所有生成完成再显示出来。这个可以自定义流式输出的方式 negative_prompt_ids：负面提示，一些前沿研究会用到，不用管 negative_prompt_attention_mask：负面提示的 attention_mask **kwargs 这里经常传入 temperature=0.7, top_k=20, max_new_tokens=512等参数，都是通过**kwargs传入进来的 其实传入的这些都是输入参数 generation_config 的属性（可以进入对应类中看一下有哪些属性，from transformers.generation.configuration_utils import GenerationConfig），你可以创建该对象并覆盖某些参数，也可以通过参数形式在调用.generate()时传进来 在后面会将传入的这些参数覆盖掉generation_config中对应的属性 下面只说明一些关键的地方 ## kwargs -\u003e generation_config 就是将kwargs中传入的kwargs的参数变成config。 generation_config, model_kwargs = self._prepare_generation_config(generation_config, **kwargs) ","date":"2025-03-09","objectID":"/generate/:0:0","tags":["coding","LLM"],"title":"generate","uri":"/generate/"},{"categories":["coding","LLM","generate"],"content":"准备logit处理器 prepared_logits_processor = self._get_logits_processor( generation_config=generation_config, input_ids_seq_length=input_ids_length, encoder_input_ids=inputs_tensor, prefix_allowed_tokens_fn=prefix_allowed_tokens_fn, logits_processor=logits_processor, device=inputs_tensor.device, model_kwargs=model_kwargs, negative_prompt_ids=negative_prompt_ids, negative_prompt_attention_mask=negative_prompt_attention_mask, ) 就是将generation_config中的采样参数封装成logit-processor，还有自己定义的processor ","date":"2025-03-09","objectID":"/generate/:1:0","tags":["coding","LLM"],"title":"generate","uri":"/generate/"},{"categories":["coding","LLM","generate"],"content":"准备stopping处理器 prepared_stopping_criteria = self._get_stopping_criteria( generation_config=generation_config, stopping_criteria=stopping_criteria, tokenizer=tokenizer, **kwargs ) 同理。将一些与停止有关的参数封装成stopping处理器。 ","date":"2025-03-09","objectID":"/generate/:2:0","tags":["coding","LLM"],"title":"generate","uri":"/generate/"},{"categories":["coding","LLM","generate"],"content":"logits warper logits warper 里面是采样时才需要运行的处理器 logits processor 是通用的处理器，每种生成模式都需要用到的 prepared_logits_warper = ( self._get_logits_warper(generation_config) if generation_config.do_sample else None ) ","date":"2025-03-09","objectID":"/generate/:3:0","tags":["coding","LLM"],"title":"generate","uri":"/generate/"},{"categories":["coding","LLM","generate"],"content":"正式生成 # 进入模型内部生成下一个token outputs = self( **model_inputs, return_dict=True, output_attentions=output_attentions, output_hidden_states=output_hidden_states, ) if synced_gpus and this_peer_finished: continue # don't waste resources running the code we don't need # 取出最后一个token，.logits维度为（batch_size, seq_len, vocab_size） next_token_logits = outputs.logits[:, -1, :] # 经过前面的处理器进行分数调整 next_token_scores = logits_processor(input_ids, next_token_logits) if do_sample: next_token_scores = logits_warper(input_ids, next_token_scores) 按照是否采样来生成下一个token： if do_sample: probs = nn.functional.softmax(next_token_scores, dim=-1) # torch.multinomial：按照输入probs的每一行（每个batch）作为采样的概率， # 每行不放回的取出num_samples个，随机采样每个batch按输入概率取出一个 next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1) else: # torch.argmax取出输入next_token_scores中值最大的索引 next_tokens = torch.argmax(next_token_scores, dim=-1) 最后判断是否可以停止： unfinished_sequences = unfinished_sequences \u0026 ~stopping_criteria(input_ids, scores) this_peer_finished = unfinished_sequences.max() == 0 ","date":"2025-03-09","objectID":"/generate/:4:0","tags":["coding","LLM"],"title":"generate","uri":"/generate/"},{"categories":["coding","LLM","generate"],"content":"参考 https://blog.csdn.net/qq_41496421/article/details/142346738?spm=1001.2014.3001.5502 https://blog.csdn.net/qq_41496421/article/details/142580960?spm=1001.2014.3001.5501 ","date":"2025-03-09","objectID":"/generate/:5:0","tags":["coding","LLM"],"title":"generate","uri":"/generate/"},{"categories":["","einops"],"content":" einops.einsum calls einsum operations with einops-style named axes indexing, computing tensor products with an arbitrary number of tensors. Unlike typical einsum syntax, here you must pass tensors first, and then the pattern. Also, note that rearrange operations such as \"(batch chan) out\", or singleton axes (), are not currently supported. 爱因斯坦求和 ","date":"2025-01-11","objectID":"/einsum/:0:0","tags":["einops"],"title":"einsum","uri":"/einsum/"},{"categories":["einops"],"content":"pack Packs several tensors into one. See einops tutorial for introduction into packing (and how it replaces stack and concatenation). ## unpack \u003eUnpacks a single tensor into several by splitting over a selected axes. See einops tutorial for introduction into packing (and how it replaces stack and concatenation). image.png ","date":"2025-01-11","objectID":"/pack-and-unpack/:1:0","tags":["einops"],"title":"pack and unpack","uri":"/pack-and-unpack/"},{"categories":["","einops"],"content":" einops.rearrange is a reader-friendly smart element reordering for multidimensional tensors. This operation includes functionality of transpose (axes permutation), reshape (view), squeeze, unsqueeze, stack, concatenate and other operations. 代替reshape，给维度命名。可以用…代表不想动的维度。 ","date":"2025-01-11","objectID":"/rearrange/:0:0","tags":["einops"],"title":"rearrange","uri":"/rearrange/"},{"categories":["","einops"],"content":" einops.reduce combines rearrangement and reduction using reader-friendly notation. reduce会使维度减少。 ","date":"2025-01-11","objectID":"/reduce/:0:0","tags":["einops"],"title":"reduce","uri":"/reduce/"},{"categories":["","einops"],"content":" einops.repeat allows reordering elements and repeating them in arbitrary combinations. This operation includes functionality of repeat, tile, and broadcast functions. repeat是使维度增加，与reduce相反。 ## 应用 比如说repeat_kv函数就可以用einops.repeat很方便的实现 def repeat_kv(x: torch.Tensor, n_rep: int) -\u003e torch.Tensor: \"\"\"torch.repeat_interleave(x, dim=2, repeats=n_rep)\"\"\" bs, slen, n_kv_heads, head_dim = x.shape if n_rep == 1: return x return ( x[:, :, :, None, :] .expand(bs, slen, n_kv_heads, n_rep, head_dim) .reshape(bs, slen, n_kv_heads * n_rep, head_dim) ) 等价于 def repeat_kv(x: torch.Tensor, n_rep: int) -\u003e torch.Tensor: einops.repeat(x, 'bs slen kvheads dim-\u003e bs slen (kvheads n_rep) dim', n_rep=n_rep).shape ","date":"2025-01-11","objectID":"/repeat/:0:0","tags":["einops"],"title":"repeat","uri":"/repeat/"},{"categories":["","einops"],"content":" Convert a tensor of an imperative framework (i.e. numpy/cupy/torch/jax/etc.) to numpy.ndarray image.png ","date":"2025-01-08","objectID":"/asnumpy/:0:0","tags":["einops"],"title":"asnumpy","uri":"/asnumpy/"},{"categories":["einops"],"content":" Parse a tensor shape to dictionary mapping axes names to their lengths. # Use underscore to skip the dimension in parsing. \u003e\u003e\u003e x = np.zeros([2, 3, 5, 7]) \u003e\u003e\u003e parse_shape(x, 'batch _ h w') {'batch': 2, 'h': 5, 'w': 7} # `parse_shape` output can be used to specify axes_lengths for other operations: \u003e\u003e\u003e y = np.zeros([700]) \u003e\u003e\u003e rearrange(y, '(b c h w) -\u003e b c h w', **parse_shape(x, 'b _ h w')).shape (2, 10, 5, 7) 也就是把维度的维数映射到对应的命名。与数据无关，只看得到维度。 ","date":"2025-01-08","objectID":"/parse_shape/:0:0","tags":["einops"],"title":"parse_shape","uri":"/parse_shape/"},{"categories":["","coding","torch"],"content":"gather 参数： input (Tensor) – the source tensor dim (int) – the axis along which to index index (LongTensor) – the indices of elements to gather out (Tensor_,__optional_) – the destination tensor sparse_grad (bool,optional) – If True, gradient w.r.t. input will be a sparse tensor. \u003e gather操作是scatter操作的逆操作，如果说scatter是根据index和src求self(input)，那么gather操作是根据self(input)和index求src。具体来说gather操作是根据index指出的索引，沿dim指定的轴收集input的值。 out[i][j][k] = input[index[i][j][k]][j][k] # if dim == 0 out[i][j][k] = input[i][index[i][j][k]][k] # if dim == 1 out[i][j][k] = input[i][j][index[i][j][k]] # if dim == 2 对于gather操作来说，有三个约束需要满足： （1）对于所有的维度d != dim，有input.size(d) == index.size(d)，对于维度dim来说，有index.size(d) \u003e= 1； （2）张量out的维度大小必须和index相同； （3）和scatter一样，index中的索引值必须在input.size(dim)范围内。 ### example ### code example import torch t = torch.Tensor([[1, 2], [3, 4]]) # t = 1 2 # 3 4 index = torch.LongTensor([[0, 0], [1, 0]]) # index = 0 0 # 1 0 # dim = 0 : [[1,2],[3,2]] # dim = 1 : [[1,1],[4,3]] # index = 0 # 1 # dim = 0 : [[1],[3]] # dim = 1 : [[1],[4]] # index = 0 1 # dim = 0 : [[1, 4]] # dim = 1 : [[1, 2]] ","date":"2024-12-20","objectID":"/gather%E5%92%8Cscatter/:1:0","tags":["coding","gather","scatter"],"title":"gather和scatter","uri":"/gather%E5%92%8Cscatter/"},{"categories":["","coding","torch"],"content":"scatter Writes all values from the tensor into at the indices specified in the tensor. For each value in , its output index is specified by its index in for and by the corresponding value in for .`src``self``index``src``src``dimension != dim``index``dimension = dim` For a 3-D tensor, is updated as:`self` 参数： - dim (int) – the axis along which to index - index (LongTensor) – the indices of elements to scatter, can be either empty or the same size of src. When empty, the operation returns identity - src (Tensor) – the source element(s) to scatter, incase value is not specified - value (float) – the source element(s) to scatter, incase src is not specified self[index[i][j][k]][j][k] = src[i][j][k] # if dim == 0 self[i][index[i][j][k]][k] = src[i][j][k] # if dim == 1 self[i][j][index[i][j][k]] = src[i][j][k] # if dim == 2 看了上面这个操作就理解了。 由此可以得出以下约束： 1. 张量self，张量index和张量src的维度数量必须相同（即三者的.dim()必须相等，注意不是维度大小）； 2. 对于每一个维度d，有index.size(d)\u003c=src.size(d)； 3. 对于每一个维度d，如果d!=dim，有index.size(d)\u003c=self.size(d)； 对于index也有一些约束： 1. 张量index中的每一个值大小必须在[0, self.size(dim)-1]之间； 2. 张量index沿dim维的那一行中所有值都必须是唯一的（弱约束，违反不会报错，但是会造成没有意义的操作）。 ","date":"2024-12-20","objectID":"/gather%E5%92%8Cscatter/:2:0","tags":["coding","gather","scatter"],"title":"gather和scatter","uri":"/gather%E5%92%8Cscatter/"},{"categories":["","coding","torch"],"content":"example ### code example import torch a = torch.arange(10).reshape(2,5).float() print(f\"a: \\n{a}\") b = torch.zeros(3, 5) print(f\"b: \\n{b}\") b_= b.scatter(dim=0, index=torch.LongTensor([[1, 2, 1, 1, 2], [2, 0, 2, 1, 0]]), src=a) print(f\"b_: \\n{b_}\") # tensor([[0, 6, 0, 0, 9], # [0, 0, 2, 8, 0], # [5, 1, 7, 0, 4]]) ","date":"2024-12-20","objectID":"/gather%E5%92%8Cscatter/:2:1","tags":["coding","gather","scatter"],"title":"gather和scatter","uri":"/gather%E5%92%8Cscatter/"},{"categories":["","coding","torch"],"content":"scatter_add_ 这个函数和scatter基本上没有任何区别，区别在于上图中的对于self中同一位置的填入是随机的，self[3,0]不确定是7还是9，self[0,1]不确定是8还是10，但是使用scatter_add就将所有即将填入同一位置的数相加，例子如下： ### example ","date":"2024-12-20","objectID":"/gather%E5%92%8Cscatter/:3:0","tags":["coding","gather","scatter"],"title":"gather和scatter","uri":"/gather%E5%92%8Cscatter/"},{"categories":["","coding","torch"],"content":"参考 https://zhuanlan.zhihu.com/p/158993858 ","date":"2024-12-20","objectID":"/gather%E5%92%8Cscatter/:4:0","tags":["coding","gather","scatter"],"title":"gather和scatter","uri":"/gather%E5%92%8Cscatter/"},{"categories":["","LLM","NLP"],"content":"LLaMA介绍 LLaMA 是目前为止，效果最好的开源 LLM 之一。 论文的核心思想：相比于GPT，更小的模型+更多的训练数据**也可以获得可比的效果 基于更多 tokens 的训练集，在各种推理预算下，训练出性能最佳的一系列语言模型，称为 LLaMA，参数范围从 7B 到 65B 不等，与现有最佳 LLM 相比，其性能是有竞争力的。比如，LLaMA-13B 在大多数基准测试中优于 GPT-3，尽管其尺寸只有 GPT-3 的十分之一。作者相信，LLaMA 将有助于使 LLM 的使用和研究平民化，因为它可以在单个 GPU 上运行！在规模较大的情况下，LLaMA-65B 也具有与最佳大型语言模型（如 Chinchilla 或 PaLM-540B）相竞争的能力。 LLaMA1、2的主要差别在训练上下文长度、训练token数、注意力机制以及对齐方法上。 模型 训练长度 分词器 词表大小 位置编码 激活层 标准化 训练token数 链接 精度 注意力机制 有无chat版本 Alignment LLaMA 2,048 BPE（Sentence-Piece） 32k ROPE SwiGLU 基于 RMSNorm 的 Pre-Norm 1万亿(6.7B,13B) 1.4万亿（32.5B,65.2B） http://arxiv.org/abs/2302.13971 fp16 MHA 0 LLaMA2 4,096 同上 32k ROPE 同上 同上 2万亿 https://arxiv.org/abs/2307.09288 bf16 34B,70B GQA, 其他MHA 1 SFT+RLHF(拒绝采样+PPO) （表来自LLaMA家族） LLaMA1 ","date":"2024-09-26","objectID":"/llama%E7%B3%BB%E5%88%97/:0:0","tags":["LLM","NLP","llama"],"title":"llama系列","uri":"/llama%E7%B3%BB%E5%88%97/"},{"categories":["","LLM","NLP"],"content":"训练数据 image.png ","date":"2024-09-26","objectID":"/llama%E7%B3%BB%E5%88%97/:1:0","tags":["LLM","NLP","llama"],"title":"llama系列","uri":"/llama%E7%B3%BB%E5%88%97/"},{"categories":["","LLM","NLP"],"content":"训练参数 image.png ","date":"2024-09-26","objectID":"/llama%E7%B3%BB%E5%88%97/:2:0","tags":["LLM","NLP","llama"],"title":"llama系列","uri":"/llama%E7%B3%BB%E5%88%97/"},{"categories":["","LLM","NLP"],"content":"RMSnorm 与 Layer Norm 相比，RMS Norm的主要区别在于去掉了减去均值的部分，计算公式为： \\[\\overline{a}_{i}=\\frac{a_{i}}{RMS(a)}\\] 其中 \\[RMS(a)=\\sqrt{\\frac{1}{n}\\Sigma_{i=1}^{n}a_{i}^{2}} \\\\ \\] 此外RMSNorm 还可以引入可学习的缩放因子g，从而得到 \\[\\overline{a}_i=\\frac{a_i}{RMS(\\boldsymbol{a})}g_i\\] ","date":"2024-09-26","objectID":"/llama%E7%B3%BB%E5%88%97/:3:0","tags":["LLM","NLP","llama"],"title":"llama系列","uri":"/llama%E7%B3%BB%E5%88%97/"},{"categories":["","LLM","NLP"],"content":"Pre-norm和Post-norm 注意其使用的是Pre-norm结构，与Post-norm结构差异如下： 关于Pre Norm的效果和Post Norm效果差异，相关分析在这两篇文章中： 模型优化漫谈：BERT的初始标准差为什么是0.02？ 为什么Pre Norm的效果不如Post Norm？ 总结来说就是Pre-norm加深的是模型的宽度，而不是深度，从而导致训练效果不如Post-norm，但可以缓解Post-norm的梯度消失。 ","date":"2024-09-26","objectID":"/llama%E7%B3%BB%E5%88%97/:3:1","tags":["LLM","NLP","llama"],"title":"llama系列","uri":"/llama%E7%B3%BB%E5%88%97/"},{"categories":["","LLM","NLP"],"content":"代码 class LlamaRMSNorm(nn.Module): def __init__(self, hidden_size, eps=1e-6): \"\"\" LlamaRMSNorm is equivalent to T5LayerNorm \"\"\" super().__init__() self.weight = nn.Parameter(torch.ones(hidden_size)) self.variance_epsilon = eps # eps 防止取倒数之后分母为0 def forward(self, hidden_states): input_dtype = hidden_states.dtype variance = hidden_states.to(torch.float32).pow(2).mean(-1, keepdim=True) hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon) # rsqrt 即sqrt后取倒数 # weight 是末尾乘的可训练参数, 即g_i return (self.weight * hidden_states).to(input_dtype) ","date":"2024-09-26","objectID":"/llama%E7%B3%BB%E5%88%97/:3:2","tags":["LLM","NLP","llama"],"title":"llama系列","uri":"/llama%E7%B3%BB%E5%88%97/"},{"categories":["","LLM","NLP"],"content":"RoPE RoPE 的核心思想是“通过绝对位置编码的方式实现相对位置编码”，可以说是具备了绝对位置编码的方便性，同时可以表示不同 token 之间的相对位置关系。RoPE 是将位置编码和 query或者key进行相乘。 \\[\\begin{bmatrix}\\cos m\\theta_0\u0026-\\sin m\\theta_0\u00260\u00260\u0026\\cdots\u00260\u00260\\\\\\sin m\\theta_0\u0026\\cos m\\theta_0\u00260\u00260\u0026\\cdots\u00260\u00260\\\\0\u00260\u0026\\cos m\\theta_1\u0026-\\sin m\\theta_1\u0026\\cdots\u00260\u00260\\\\0\u00260\u0026\\sin m\\theta_1\u0026\\cos m\\theta_1\u0026\\cdots\u00260\u00260\\\\\\vdots\u0026\\vdots\u0026\\vdots\u0026\\vdots\u0026\\ddots\u0026\\vdots\u0026\\vdots\\\\0\u00260\u00260\u00260\u0026\\cdots\u0026\\cos m\\theta_{d/2-1}\u0026-\\sin m\\theta_{d/2-1}\\\\0\u00260\u00260\u00260\u0026\\cdots\u0026\\sin m\\theta_{d/2-1}\u0026\\cos m\\theta_{d/2-1}\\end{bmatrix}\\begin{bmatrix}q_0\\\\q_1\\\\q_2\\\\q_3\\\\\\vdots\\\\q_{d-2}\\\\q_{d-1}\\end{bmatrix}\\] 由于矩阵太稀疏，会造成浪费，因此计算时是这么做的： \\[\\begin{bmatrix}q_0\\\\q_1\\\\q_2\\\\q_3\\\\\\vdots\\\\q_{d-2}\\\\q_{d-1}\\end{bmatrix}\\otimes\\begin{bmatrix}\\cos m\\theta_0\\\\\\cos m\\theta_0\\\\\\cos m\\theta_1\\\\\\cos m\\theta_1\\\\\\vdots\\\\\\cos m\\theta_{d/2-1}\\\\\\cos m\\theta_{d/2-1}\\end{bmatrix}+\\begin{bmatrix}-q_1\\\\q_0\\\\-q_3\\\\q_2\\\\\\vdots\\\\-q_{d-1}\\\\q_{d-2}\\end{bmatrix}\\otimes\\begin{bmatrix}\\sin m\\theta_0\\\\\\sin m\\theta_0\\\\\\sin m\\theta_1\\\\\\sin m\\theta_1\\\\\\vdots\\\\\\sin m\\theta_{d/2-1}\\\\\\sin m\\theta_{d/2-1}\\end{bmatrix}\\] 此外，角度的计算方式如下： \\[\\theta_j=10000^{-2j/d},j\\in[1,2,\\dots,d/2]\\] ","date":"2024-09-26","objectID":"/llama%E7%B3%BB%E5%88%97/:4:0","tags":["LLM","NLP","llama"],"title":"llama系列","uri":"/llama%E7%B3%BB%E5%88%97/"},{"categories":["","LLM","NLP"],"content":"代码 class LlamaRotaryEmbedding(torch.nn.Module): def __init__(self, dim, max_position_embeddings=2048, base=10000, device=None): super().__init__() inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float().to(device) / dim)) self.register_buffer(\"inv_freq\", inv_freq) # Build here to make `torch.jit.trace` work. self.max_seq_len_cached = max_position_embeddings t = torch.arange(self.max_seq_len_cached, device=self.inv_freq.device, dtype=self.inv_freq.dtype) freqs = torch.einsum(\"i,j-\u003eij\", t, self.inv_freq) # Different from paper, but it uses a different permutation # in order to obtain the same calculation emb = torch.cat((freqs, freqs), dim=-1) dtype = torch.get_default_dtype() self.register_buffer(\"cos_cached\", emb.cos()[None, None, :, :].to(dtype), persistent=False) self.register_buffer(\"sin_cached\", emb.sin()[None, None, :, :].to(dtype), persistent=False) def forward(self, x, seq_len=None): # x: [bs, num_attention_heads, seq_len, head_size] # This `if` block is unlikely to be run after we build sin/cos in `__init__`. # Keep the logic here just in case. if seq_len \u003e self.max_seq_len_cached: self.max_seq_len_cached = seq_len t = torch.arange(self.max_seq_len_cached, device=x.device, dtype=self.inv_freq.dtype) freqs = torch.einsum(\"i,j-\u003eij\", t, self.inv_freq) # Different from paper, but it uses a different permutation # in order to obtain the same calculation emb = torch.cat((freqs, freqs), dim=-1).to(x.device) self.register_buffer(\"cos_cached\", emb.cos()[None, None, :, :].to(x.dtype), persistent=False) self.register_buffer(\"sin_cached\", emb.sin()[None, None, :, :].to(x.dtype), persistent=False) return ( self.cos_cached[:, :, :seq_len, ...].to(dtype=x.dtype), self.sin_cached[:, :, :seq_len, ...].to(dtype=x.dtype), ) def rotate_half(x): \"\"\"Rotates half the hidden dims of the input.\"\"\" x1 = x[..., : x.shape[-1] // 2] x2 = x[..., x.shape[-1] // 2 :] return torch.cat((-x2, x1), dim=-1) def apply_rotary_pos_emb(q, k, cos, sin, position_ids): # The first two dimensions of cos and sin are always 1, so we can `squeeze` them. cos = cos.squeeze(1).squeeze(0) # [seq_len, dim] sin = sin.squeeze(1).squeeze(0) # [seq_len, dim] cos = cos[position_ids].unsqueeze(1) # [bs, 1, seq_len, dim] sin = sin[position_ids].unsqueeze(1) # [bs, 1, seq_len, dim] q_embed = (q * cos) + (rotate_half(q) * sin) k_embed = (k * cos) + (rotate_half(k) * sin) return q_embed, k_embed ","date":"2024-09-26","objectID":"/llama%E7%B3%BB%E5%88%97/:4:1","tags":["LLM","NLP","llama"],"title":"llama系列","uri":"/llama%E7%B3%BB%E5%88%97/"},{"categories":["","LLM","NLP"],"content":"SwiGLU \\[\\begin{aligned} \\mathrm{FFN}_{\\mathrm{SwiGLU}}(x,W,V,W_{2})\u0026=\\mathrm{SwiGLU}(x,W,V)W_{2}\\\\\\mathrm{SwiGLU}(x,W,V)\u0026=\\mathrm{Swish}_{\\beta}(xW)\\otimes xV\\\\\\mathrm{Swish}_{\\beta}(x)\u0026=x\\sigma(\\beta x) \\end{aligned}\\] ","date":"2024-09-26","objectID":"/llama%E7%B3%BB%E5%88%97/:5:0","tags":["LLM","NLP","llama"],"title":"llama系列","uri":"/llama%E7%B3%BB%E5%88%97/"},{"categories":["","LLM","NLP"],"content":"代码 class LlamaMLP(nn.Module): def __init__( self, hidden_size: int, intermediate_size: int, hidden_act: str, ): super().__init__() self.gate_proj = nn.Linear(hidden_size, intermediate_size, bias=False) self.down_proj = nn.Linear(intermediate_size, hidden_size, bias=False) self.up_proj = nn.Linear(hidden_size, intermediate_size, bias=False) # config 中 hidden_act = 'silu' # 'silu' 和 'swish' 对应的激活函数均为：SiLUActivation # https://github.com/huggingface/transformers/blob/717dadc6f36be9f50abc66adfd918f9b0e6e3502/src/transformers/activations.py#L229 self.act_fn = ACT2FN[hidden_act] def forward(self, x): # 对应上述公式的 SwiGLU return self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x)) ","date":"2024-09-26","objectID":"/llama%E7%B3%BB%E5%88%97/:5:1","tags":["LLM","NLP","llama"],"title":"llama系列","uri":"/llama%E7%B3%BB%E5%88%97/"},{"categories":["","LLM","NLP"],"content":"实验结果 ","date":"2024-09-26","objectID":"/llama%E7%B3%BB%E5%88%97/:6:0","tags":["LLM","NLP","llama"],"title":"llama系列","uri":"/llama%E7%B3%BB%E5%88%97/"},{"categories":["","LLM","NLP"],"content":"常识推理任务 image.png LLaMA - 13B模型虽然比GPT - 3小10倍，但在大多数基准上也优于GPT - 3。 除BoolQ外，LLaMA - 65B在所有报告的基准上都优于Chinchilla-70B。 除了在BoolQ和WinoGrande上，LLaMA-65B在所有地方都超过了PaLM540B。 ","date":"2024-09-26","objectID":"/llama%E7%B3%BB%E5%88%97/:6:1","tags":["LLM","NLP","llama"],"title":"llama系列","uri":"/llama%E7%B3%BB%E5%88%97/"},{"categories":["","LLM","NLP"],"content":"阅读理解任务 image.png 可以看到，LLaMA-13B比GPT-3高出了几个百分点。 LLaMA-65B的表现已经接近甚至超越PaLM-540B的表现。 LLaMA2 Llama1只做了预训练，Llama2做了预训练+SFT+RLHF ","date":"2024-09-26","objectID":"/llama%E7%B3%BB%E5%88%97/:6:2","tags":["LLM","NLP","llama"],"title":"llama系列","uri":"/llama%E7%B3%BB%E5%88%97/"},{"categories":["","LLM","NLP"],"content":"KV Cache image.png LLM推理过程分为Prefill和Decode两个阶段。 Prefill阶段会对Prompt中所有的token做并行计算，得到Prompt中所有Tokens的KV Cache以及计算得到生成的第一个Token。Prompt阶段Token计算得到的KV Cache会保存下来，留给Decode阶段复用。 Decode阶段是一个自回归过程，每decode一个新的Token，都需要用到所有之前计算得到的KV Cache来计算当前query token的Attention。因此，当输出长度越来越大或者context很长时，KV Cache将会占用大量的显存。 ","date":"2024-09-26","objectID":"/llama%E7%B3%BB%E5%88%97/:7:0","tags":["LLM","NLP","llama"],"title":"llama系列","uri":"/llama%E7%B3%BB%E5%88%97/"},{"categories":["","LLM","NLP"],"content":"使用KV cache时位置信息怎么注入？ 初次学习KV cache时，虽然原理比较简单易懂，但是对于后续的输入只有一个token这里产生了些许困惑，后续只输入一个token的话，位置编码该怎么办呢？于是我比较简单粗暴地猜测位置index随着推理不断更新，当时翻了各种资料也没有得到解释，后面翻了翻llama的源码，发现我的猜测还真是正确的。 def forward(self, tokens: torch.Tensor, start_pos: int): \"\"\" Perform a forward pass through the Transformer model. Args: tokens (torch.Tensor): Input token indices. start_pos (int): Starting position for attention caching. Returns: torch.Tensor: Output logits after applying the Transformer model. \"\"\" _bsz, seqlen = tokens.shape h = self.tok_embeddings(tokens) self.freqs_cis = self.freqs_cis.to(h.device) freqs_cis = self.freqs_cis[start_pos : start_pos + seqlen] mask = None if seqlen \u003e 1: mask = torch.full( (seqlen, seqlen), float(\"-inf\"), device=tokens.device ) mask = torch.triu(mask, diagonal=1) # When performing key-value caching, we compute the attention scores # only for the new sequence. Thus, the matrix of scores is of size # (seqlen, cache_len + seqlen), and the only masked entries are (i, j) for # j \u003e cache_len + i, since row i corresponds to token cache_len + i. mask = torch.hstack([ torch.zeros((seqlen, start_pos), device=tokens.device), mask ]).type_as(h) for layer in self.layers: h = layer(h, start_pos, freqs_cis, mask) h = self.norm(h) output = self.output(h).float() return output 可以看到forward函数中的start_pos参数代表着位置信息，freqs_cis是实现RoPE位置编码需要用到的。 注意 freqs_cis = self.freqs_cis[start_pos : start_pos + seqlen]这一行，即是实现了rope相对位置编码的kv cache的核心。 ","date":"2024-09-26","objectID":"/llama%E7%B3%BB%E5%88%97/:7:1","tags":["LLM","NLP","llama"],"title":"llama系列","uri":"/llama%E7%B3%BB%E5%88%97/"},{"categories":["","LLM","NLP"],"content":"代码 class Attention(nn.Module): # ... self.cache_k = torch.zeros( ( args.max_batch_size, args.max_seq_len, self.n_local_kv_heads, self.head_dim, ) ).cuda() self.cache_v = torch.zeros( ( args.max_batch_size, args.max_seq_len, self.n_local_kv_heads, self.head_dim, ) ).cuda() def forward( self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor], ): # 假设当前x为(1, 1, dim)，也就是上一个预测的token # self-attention的输入，标准的(bs, seqlen, hidden_dim) bsz, seqlen, _ = x.shape # 计算当前token的qkv # q k v分别进行映射，注意这里key, value也需要先由输入进行映射再和kv_cache里面的key, value进行拼接 xq, xk, xv = self.wq(x), self.wk(x), self.wv(x) xq = xq.view(bsz, seqlen, self.n_local_heads, self.head_dim) xk = xk.view(bsz, seqlen, self.n_local_kv_heads, self.head_dim) xv = xv.view(bsz, seqlen, self.n_local_kv_heads, self.head_dim) # 对当前输入的query和key进行RoPE，注意kv_cache里面的key已经做过了RoPE xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis) # 缓存当前token的kv self.cache_k = self.cache_k.to(xq) self.cache_v = self.cache_v.to(xq) self.cache_k[:bsz, start_pos: start_pos + seqlen] = xk self.cache_v[:bsz, start_pos: start_pos + seqlen] = xv # 取出前seqlen个token的kv缓存 # 取出全部缓存的key和value（包括之前在cache里面的和本次输入的），作为最终的key和value keys = self.cache_k[:bsz, : start_pos + seqlen] values = self.cache_v[:bsz, : start_pos + seqlen] # 将kv重复填充，使kv和q的头数个数相同 # repeat k/v heads if n_kv_heads \u003c n_heads，对齐头的数量 keys = repeat_kv(keys, self.n_rep) # (bs, cache_len + seqlen, n_local_heads, head_dim) values = repeat_kv(values, self.n_rep) # (bs, cache_len + seqlen, n_local_heads, head_dim) # 计算当前token的attention score，，注意mask需要加上，另外维度要对应上 xq = xq.transpose(1, 2) # (bs, n_local_heads, seqlen, head_dim) keys = keys.transpose(1, 2) # (bs, n_local_heads, cache_len + seqlen, head_dim) values = values.transpose(1, 2) # (bs, n_local_heads, cache_len + seqlen, head_dim) scores = torch.matmul(xq, keys.transpose(2, 3)) / math.sqrt(self.head_dim) if mask is not None: scores = scores + mask # (bs, n_local_heads, seqlen, cache_len + seqlen) scores = F.softmax(scores.float(), dim=-1).type_as(xq) output = torch.matmul(scores, values) # (bs, n_local_heads, seqlen, head_dim) output = output.transpose(1, 2).contiguous().view(bsz, seqlen, -1) return self.wo(output) ","date":"2024-09-26","objectID":"/llama%E7%B3%BB%E5%88%97/:7:2","tags":["LLM","NLP","llama"],"title":"llama系列","uri":"/llama%E7%B3%BB%E5%88%97/"},{"categories":["","LLM","NLP"],"content":"MQA\u0026GQA image.png ","date":"2024-09-26","objectID":"/llama%E7%B3%BB%E5%88%97/:8:0","tags":["LLM","NLP","llama"],"title":"llama系列","uri":"/llama%E7%B3%BB%E5%88%97/"},{"categories":["","LLM","NLP"],"content":"为什么不继续使用MHA？ 标准的mha中，KV heads的数量和Query heads的数量相同，每一个q head对应一个独立的kv head，但这样的开销比较大。 ","date":"2024-09-26","objectID":"/llama%E7%B3%BB%E5%88%97/:8:1","tags":["LLM","NLP","llama"],"title":"llama系列","uri":"/llama%E7%B3%BB%E5%88%97/"},{"categories":["","LLM","NLP"],"content":"MQA 标准的MHA中，KV heads的数量和Query heads的数量相同，每一个q head对应一个独立的kv head，但这样的开销比较大。 MQA比较极端，只保留一个KV Head，多个Query Heads共享相同的KV Head。这相当于不同Head的Attention差异，全部都放在了Query上，需要模型仅从不同的Query Heads上就能够关注到输入hidden states不同方面的信息。这样做的好处是，极大地降低了KV Cache的需求，但是会导致模型效果有所下降。 ","date":"2024-09-26","objectID":"/llama%E7%B3%BB%E5%88%97/:8:2","tags":["LLM","NLP","llama"],"title":"llama系列","uri":"/llama%E7%B3%BB%E5%88%97/"},{"categories":["","LLM","NLP"],"content":"GQA GQA就是在MHA和MQA之间做了一个平衡。对query heads进行分组，分成几组就对应多少个kv heads，然后每一组内的query Heads共享相同的KV head。 GQA可以在减少计算量和KV Cache同时确保模型效果不受到大的影响。 ","date":"2024-09-26","objectID":"/llama%E7%B3%BB%E5%88%97/:8:3","tags":["LLM","NLP","llama"],"title":"llama系列","uri":"/llama%E7%B3%BB%E5%88%97/"},{"categories":["","LLM","NLP"],"content":"SFT 监督微调（Supervised Fine-Tuning, SFT）是对已经预训练的模型进行特定任务的训练，以提高其在该任务上的表现。预训练模型通常在大量通用数据上进行训练，学到广泛的语言知识和特征。在SFT过程中，利用特定任务的数据，对模型进行进一步调整，使其更适合该任务。 SFT数据一般就是\u003cprompt, response\u003e数据对。在训练方式上和pretrain没有任何区别，即得到当前token对应的logit，以next token作为标签计算交叉熵损失。 pretrain 是在背书，纯粹的学习知识；sft 则是在做题，学习的是指令 follow 能力。 ","date":"2024-09-26","objectID":"/llama%E7%B3%BB%E5%88%97/:9:0","tags":["LLM","NLP","llama"],"title":"llama系列","uri":"/llama%E7%B3%BB%E5%88%97/"},{"categories":["","LLM","NLP"],"content":"一些要点 少量高质量数据集训练模型的效果，要好于大量低质量数据集的训练效果。分析数据和清洗数据就是 sft 阶段 90% 的工作量。 sft 会让模型见到最重要的 eos_token，pretrain 模型因为没见过该 token 而无法停止生成。 sft 的 prompt 不做 loss，但这并不是说它不能做 loss。主要原因是 prompt 的同质化比较严重，不做 loss_mask 的话，同样的一句话会被翻来覆去的学，但如果你能保证你的每条 prompt 都是独一无二的，就完全可以省去 prompt 的 loss_mask 环节。 为了提高模型训练效率，将多组数据进行拼接，尽量填满4096。但对于分类任务会出现问题，详见https://zhuanlan.zhihu.com/p/809229182。 经过一通分析后，我们发现，新的训练方式改变了短 answer 数据的 loss 占比，毕竟模型在计算 loss 的时候，是先算一个句子内每个 token 的 平均 loss，再算一个 batch_size 内的平均 loss。 分类任务的 answer 通常只有 1 个 token：不 concat 的时候，它的 loss 贡献就是 1 / batch_size；concat 的时候，它就需要先和别的 answer 的 token 算平均 loss，再贡献 1 / batch_size。 这也就是说，采用 llama2 提到的 先 concat 语料再做 sft 训练，会对短 answer 数据很不公平，也就更容易造成短 answer 数据的欠拟合，pretrain 由于所有 token 都算 loss 则没有这个现象。最终，我们通过上采样短 answer 数据，成功的避免了分类任务的效果下滑。 ","date":"2024-09-26","objectID":"/llama%E7%B3%BB%E5%88%97/:9:1","tags":["LLM","NLP","llama"],"title":"llama系列","uri":"/llama%E7%B3%BB%E5%88%97/"},{"categories":["","LLM","NLP"],"content":"实验结果 - Llama 2模型优于Llama 1模型。 - Llama 2-70B比Llama 1-65B在MMLU和BBH上的结果分别提高了≈5和≈8个点。 - Llama 2-7B和30B模型在除代码基准以外的所有类别上都优于相应大小的MPT模型。 - Llama 2-7B和34B在所有类别的基准测试集上都优于Falcon-7B和40B模型。 参考 [KV Cache优化]🔥MQA/GQA/YOCO/CLA/MLKV笔记: 层内和层间KV Cache共享 - 知乎 (zhihu.com) Transformers KV Caching Explained | by João Lages | Medium https://zhuanlan.zhihu.com/p/679640407 LLaMA家族 https://zhuanlan.zhihu.com/p/809229182 ","date":"2024-09-26","objectID":"/llama%E7%B3%BB%E5%88%97/:10:0","tags":["LLM","NLP","llama"],"title":"llama系列","uri":"/llama%E7%B3%BB%E5%88%97/"},{"categories":["","LLM","generate"],"content":" image.png LLM解码时采用的自回归采样，其过程如下： 小模型使用前缀作为输入，将输出结果处理+归一化成概率分布后，采样生成下一个token。 将生成的token和前缀拼接成新的前缀，重复执行1，直到生成EOS或者达到最大token数目。 将模型输出logits的转换成概率，有几种常用的采样方法，包括argmax、top-k和top-n等 # 贪心搜索 直接选择概率最高的单词。这种方法简单高效，但是可能会导致生成的文本过于单调和重复 # 随机采样 按照概率分布随机选择一个单词。这种方法可以增加生成的多样性，但是可能会导致生成的文本不连贯和无意义。 # beam search 维护一个大小为 k 的候选序列集合，每一步从每个候选序列的概率分布中选择概率最高的 k 个单词，然后保留总概率最高的 k 个候选序列。这种方法可以平衡生成的质量和多样性，但是可能会导致生成的文本过于保守和不自然。 # top-k 选取前k个token，然后再重新生成概率分布，再进行抽样 它可以与其他解码策略结合使用，例如温度调节（Temperature Scaling）、重复惩罚（Repetition Penalty）、长度惩罚（Length Penalty）等，来进一步优化生成的效果。 代码: import torch from labml_nn.sampling import Sampler # Top-k Sampler class TopKSampler(Sampler): # k is the number of tokens to pick # sampler is the sampler to use for the top-k tokens # sampler can be any sampler that takes a logits tensor as input and returns a token tensor; e.g. `TemperatureSampler`. def __init__(self, k: int, sampler: Sampler): self.k = k self.sampler = sampler # Sample from logits def __call__(self, logits: torch.Tensor): # New logits filled with −∞; i.e. zero probability zeros = logits.new_ones(logits.shape) * float('-inf') # Pick the largest k logits and their indices values, indices = torch.topk(logits, self.k, dim=-1) # Set the values of the top-k selected indices to actual logits. # Logits of other tokens remain −∞ zeros.scatter_(-1, indices, values) # Sample from the top-k logits with the specified sampler. return self.sampler(zeros) top-p top-k 有一个缺陷，那就是“k 值取多少是最优的？”非常难确定。于是出现了动态设置 token 候选列表大小策略——即核采样（Nucleus Sampling）。 top-p 采样的思路是，在每一步，只从累积概率超过某个阈值 p 的最小单词集合中进行随机采样，而不考虑其他低概率的单词。这种方法也被称为核采样（nucleus sampling），因为它只关注概率分布的核心部分，而忽略了尾部部分。例如，如果 p=0.9，那么我们只从累积概率达到 0.9 的最小单词集合中选择一个单词，而不考虑其他累积概率小于 0.9 的单词。这样可以避免采样到一些不合适或不相关的单词，同时也可以保留一些有趣或有创意的单词。 import torch from torch import nn from labml_nn.sampling import Sampler class NucleusSampler(Sampler): \"\"\" ## Nucleus Sampler \"\"\" def __init__(self, p: float, sampler: Sampler): \"\"\" :param p: is the sum of probabilities of tokens to pick $p$ :param sampler: is the sampler to use for the selected tokens \"\"\" self.p = p self.sampler = sampler # Softmax to compute $P(x_i | x_{1:i-1})$ from the logits self.softmax = nn.Softmax(dim=-1) def __call__(self, logits: torch.Tensor): \"\"\" Sample from logits with Nucleus Sampling \"\"\" # Get probabilities $P(x_i | x_{1:i-1})$ probs = self.softmax(logits) # Sort probabilities in descending order sorted_probs, indices = torch.sort(probs, dim=-1, descending=True) # Get the cumulative sum of probabilities in the sorted order cum_sum_probs = torch.cumsum(sorted_probs, dim=-1) # Find the cumulative sums less than $p$. nucleus = cum_sum_probs \u003c self.p # Prepend ones so that we add one token after the minimum number # of tokens with cumulative probability less that $p$. nucleus = torch.cat([nucleus.new_ones(nucleus.shape[:-1] + (1,)), nucleus[..., :-1]], dim=-1) # Get log probabilities and mask out the non-nucleus sorted_log_probs = torch.log(sorted_probs) sorted_log_probs[~nucleus] = float('-inf') # Sample from the sampler sampled_sorted_indexes = self.sampler(sorted_log_probs) # Get the actual indexes res = indices.gather(-1, sampled_sorted_indexes.unsqueeze(-1)) # return res.squeeze(-1) Temperature采样 详见温度超参数 speculative decoding 大型语言模型（LLM）的推理通常需要使用自回归采样。它们的推理过程相当缓慢，需要逐个token地进行串行解码。因此，大型模型的推理过程往往受制于访存速度，生成每个标记都需要将所有参数从存储单元传输到计算单元，因此内存访问带宽成为严重的瓶颈。 为了解决推理速度慢的问题，已经进行了许多针对推理的工程优化，例如改进的计算核心实现、多卡并行计算、批处理策略等等。然而，这些方法并没有从根本上解决LLM解码过程是受制于访存带宽的问题。 投机采样是一种可以从根本上解码计算访存比的方法，保证和使用原始模型的采样分布完全相同。它使用两个模型：一个是原始目标模型，另一个是比原始模型小得多的近似模型。近似模型用于进行自回归串行采样，而大型模型则用于评估采样结果。解码过程中，某些token的解码相对容易，某些token的解码则很困难。因此，简单的token生成可以交给小型模型处理，而困难的token则交给大型模型处理。这里的小型模型可以采用与原始模型相同的结构，但参数更少，或者干脆使用n-gram模型。小型模型不仅计算量较小，更重要的是减少了内存访问的需求。 ## 采样过程 投机采样过程如下： 用小模型Mq做自回归采样连续生成 γ 个tokens。 把生成的γ个tokens和前缀拼接一起送进大模Mp执行一次forwards。 使用大、小模型logits结果做比对，如果发现某个token小模型生成的不好，重新采样这个token。重复步骤1。 如果小模型生成结果都满意，则用大模型采样下一个token。重复步骤1。 第2步，将γ个tokens和前缀拼成一起作为大模型输入，和自回归相比，尽管计算量一样，但是γ个tokens可以同时参与计算，计算访存比显著提升。 第3步，如何评价一个token生成的不好？如果q(x) \u003e p(x)（p，q表示在大小模型采样概率，也就是logit","date":"2024-09-05","objectID":"/generate%E7%9B%B8%E5%85%B3/:0:0","tags":["LLM","generate"],"title":"frequency_penalty\u0026presence_penalty","uri":"/generate%E7%9B%B8%E5%85%B3/"},{"categories":["","LLM"],"content":"线性Transformer \\[V_i'=\\frac{\\sum_{j=1}^N sim(Q_i,K_j)V_j}{\\sum_{j=1}^N sim(Q_i,K_j)}\\] 注意下标i。 其中 \\[sim(Q_{i},K_{j})=\\phi(Q_{i},K_{j})\\] 此时有： \\[V_{i}^{\\prime}=\\frac{\\phi(Q_{i})\\sum_{j=1}^{i}\\phi(K_{j})^{T}V_{j}}{\\phi(Q_{i})\\sum_{j=1}^{i}\\phi(K_{j})^{T}}\\] 注意可以将\\(\\phi(Q_{i})\\)提出来。 原始Transformer的计算复杂度随序列长N呈二次方增长，这是因为attention的计算包含两层for循环，外层是对于每一个Query，我们需要计算它对应token的新表征；内层for循环是为了计算每一个Query对应的新表征，需要让该Query与每一个Key进行计算。 所以外层是 for q in Queries，内层是 for k in Keys。Queries数量和Keys数量都是N，所以复杂度是 O(N^2) 。而Linear Transformer，它只有外层for q in Queries这个循环了。因为求和项的计算与i无关，所以所有的 Qi 可以共享求和项的值。换言之，求和项的值可以只计算一次，然后存在内存中供所有 Qi 去使用。所以Linear Transformer的计算复杂度是O(N) 。 Attention Free Transformer \\[V_i'=\\sigma(Q_i)\\odot\\frac{\\sum_{j-1}^iexp(K_j+w_{i,j})\\odot V_j}{\\sum_{j=1}^iexp(K_j+w_{i,j})}\\] 其中σ是sigmoid函数\\(^{+};\\odot\\)是逐元素相乘 (element-wise product); wi,j是待训练的参数。 AFT采用的形式和上面的Linear Transformer不一样。首先是attention score, Linear Transformer仍然是同Transformer一样，为每一个Value赋予一个weight。而AFT会为每个 dimension\\(^{+}\\)赋予weight。换言之，在Linear Transformer中，同一个Value中不同dimension的weight是一致的；而AFT同一Value中不同dimension的weight不同(\\(w_{i,j}\\))。此外，attention score的计算也变得格外简单，用K去加一个可训练的bias\\(^{+}\\)。Q的用法很像一个gate。 可以很容易仿照公式(5)把AFT也写成递归形式，这样容易看出，AFT也可以像Linear Transformer,在inference阶段复用前面时刻的计算结果，表现如RNN形式，从而相比于 Transformer变得更加高效。 RWKV RWKV的特点如下： 改造AFT，通过Liner Transformer变换将self-attention复杂度由O(N^2)降为 O(N) 。 保留AFT简单的“attention”形式和Sequential Decoding，具有RNN表现形式。 ","date":"2024-09-04","objectID":"/rwkv/:0:0","tags":["LLM","rwkv"],"title":"rwkv","uri":"/rwkv/"},{"categories":["","LLM"],"content":"Time-Mixing image.png def time_mixing(x, last_x, last_num, last_den, decay, bonus, mix_k, mix_v, mix_r, Wk, Wv, Wr, Wout): k = Wk @ ( x * mix_k + last_x * (1 - mix_k) ) v = Wv @ ( x * mix_v + last_x * (1 - mix_v) ) r = Wr @ ( x * mix_r + last_x * (1 - mix_r) ) wkv = (last_num + exp(bonus + k) * v) / \\ (last_den + exp(bonus + k)) rwkv = sigmoid(r) * wkv num = exp(-exp(decay)) * last_num + exp(k) * v den = exp(-exp(decay)) * last_den + exp(k) return Wout @ rwkv, (x,num,den) ","date":"2024-09-04","objectID":"/rwkv/:1:0","tags":["LLM","rwkv"],"title":"rwkv","uri":"/rwkv/"},{"categories":["","LLM"],"content":"Channel-Mixing image.png def channel_mixing(x, last_x, mix_k, mix_r, Wk, Wr, Wv): k = Wk @ ( x * mix_k + last_x * (1 - mix_k) ) r = Wr @ ( x * mix_r + last_x * (1 - mix_r) ) vk = Wv @ np.maximum(k, 0)**2 return sigmoid(r) * vk, x 参考 How the RWKV language model works | The Good Minima (johanwind.github.io) ","date":"2024-09-04","objectID":"/rwkv/:2:0","tags":["LLM","rwkv"],"title":"rwkv","uri":"/rwkv/"},{"categories":["","LLM"],"content":"证明 核心思想就是找到一个转换，可以通过点积操作将位置信息注入，即： \\[\u003cf_q\\left(x_m,m\\right),f_k\\left(x_n,n\\right)\u003e=g\\left(x_m,x_n,m-n\\right)\\] 而通过复数的一些性质，找到了满足上述操作的转换： \\[\\begin{aligned} \u0026f_{q}\\left(\\boldsymbol{x}_{m},m\\right)=\\left(\\boldsymbol{W}_{q}\\boldsymbol{x}_{m}\\right)e^{im\\theta} \\\\ \u0026f_{k}\\left(\\boldsymbol{x}_{n},n\\right)=\\left(\\boldsymbol{W}_{k}\\boldsymbol{x}_{n}\\right)e^{in\\theta} \\\\ \u0026g\\left(\\boldsymbol{x}_{m},\\boldsymbol{x}_{n},m-n\\right)=\\mathrm{Re}\\left[\\left(\\boldsymbol{W}_{q}\\boldsymbol{x}_{m}\\right)\\left(\\boldsymbol{W}_{k}\\boldsymbol{x}_{n}\\right)^{*}e^{i(m-n)\\theta}\\right] \\end{aligned}\\] 可以发现g函数中存在相对位置信息。 欧拉公式：\\(e^{ix}=\\cos x+i\\sin x\\) \\[\\begin{aligned}\u0026\\text{基于上面面1点结论,可知}\\\\\u0026f_{q}\\left(x_{m},m\\right)=\\left(W_{q}x_{m}\\right)e^{im\\theta}=q_{m}e^{im\\theta}\\\\\u0026\\text{然后将}q_{m\\text{表示成复数形式（torch.view\\_as\\_complex）,可得}}\\\\\u0026q_{m}=\\left[q_{m}^{(1)},q_{m}^{(2)}\\right]=\\left[q_{m}^{(1)}+iq_{m}^{(2)}\\right]\\\\\u0026\\text{从而有}\\\\\u0026f_{q}\\left(x_{m},m\\right)=q_{m}e^{im\\theta}=\\left[q_{m}^{(1)}+iq_{m}^{(2)}\\right]e^{im\\theta}\\\\\u0026\\text{基于欧拉公式,可知}f_{q}\\left(x_{m},m\\right)_{\\text{即是两个复数相乘}}\\\\\u0026f_{q}\\left(x_{m},m\\right)=q_{m}e^{im\\theta}=\\left(q_{m}^{(1)}+iq_{m}^{(2)}\\right)*\\left(\\cos(m\\theta)+i\\sin(m\\theta)\\right)\\end{aligned}\\] 根据复数的计算，可得： \\[\\begin{aligned}q_{m}e^{im\\theta}=\\left(q_{m}^{(1)}+iq_{m}^{(2)}\\right)*(\\cos(m\\theta)+i\\sin(m\\theta))\\\\=\\left(q_{m}^{(1)}\\cos(m\\theta) -q_{m}^{(2)}\\sin(m\\theta)\\right)+i\\left(q_{m}^{(2)}\\cos(m\\theta)+q_{m}^{(1)}\\sin(m\\theta)\\right)\\end{aligned}\\] 再将结果写成向量的形式，即： \\[q_{m}e^{im\\theta}=\\left[q_{m}^{(1)}\\cos(m\\theta)-q_{m}^{(2)}\\sin(m\\theta),q_{m}^{(2)}\\cos(m\\theta)+q_{m}^{(1)}\\sin(m\\theta)\\right]\\] 即是query向量乘了一个旋转矩阵： \\[\\begin{gathered} f_{q}\\left(x_{m},m\\right)=\\left(W_{q}x_{m}\\right)e^{im\\theta}=q_{m}e^{im\\theta} \\\\ =\\left|q_{m}^{(1)}\\cos(m\\theta)-q_{m}^{(2)}\\sin(m\\theta),q_{m}^{(2)}\\cos(m\\theta)+q_{m}^{(1)}\\sin(m\\theta)\\right| \\\\ =\\left(\\begin{array}{cc}{\\cos(m\\theta)}\u0026{-\\sin(m\\theta)}\\\\{\\sin(m\\theta)}\u0026{\\cos(m\\theta)}\\end{array}\\right)\\left(\\begin{array}{c}{q_{m}^{(1)}}\\\\{q_{m}^{(2)}}\\end{array}\\right) \\end{gathered}\\] 后续的证明看一文通透位置编码：从标准位置编码、旋转位置编码RoPE到ALiBi、LLaMA 2 Long(含NTK-aware简介)-CSDN博客 将二维推广，有： \\[\\boldsymbol{R}_{\\Theta,m}^{d}=\\underbrace{\\left(\\begin{array}{ccccccc}{\\cos m\\theta_{0}}\u0026{-\\sin m\\theta_{0}}\u0026{0}\u0026{0}\u0026{\\cdots}\u0026{0}\u0026{0}\\\\{\\sin m\\theta_{0}}\u0026{\\cos m\\theta_{0}}\u0026{0}\u0026{0}\u0026{\\cdots}\u0026{0}\u0026{0}\\\\{0}\u0026{0}\u0026{\\cos m\\theta_{1}}\u0026{-\\sin m\\theta_{1}}\u0026{\\cdots}\u0026{0}\u0026{0}\\\\{0}\u0026{0}\u0026{\\sin m\\theta_{1}}\u0026{\\cos m\\theta_{1}}\u0026{\\cdots}\u0026{0}\u0026{0}\\\\{\\vdots}\u0026{\\vdots}\u0026{\\vdots}\u0026{\\vdots}\u0026{\\ddots}\u0026{\\vdots}\u0026{\\vdots}\\\\{0}\u0026{0}\u0026{0}\u0026{0}\u0026{\\cdots}\u0026{\\cos m\\theta_{d/2-1}}\u0026{-\\sin m\\theta_{d/2-1}}\\\\{0}\u0026{0}\u0026{0}\u0026{0}\u0026{0}\u0026{\\cdots}\u0026{\\sin m\\theta_{d/2-1}}\u0026{\\cos m\\theta_{d/2-1}}\\end{array}\\right)}\\] 则计算旋转编码，即有： \\[\\begin{bmatrix}\\cos m\\theta_0\u0026-\\sin m\\theta_0\u00260\u00260\u0026\\cdots\u00260\u00260\\\\\\sin m\\theta_0\u0026\\cos m\\theta_0\u00260\u00260\u0026\\cdots\u00260\u00260\\\\0\u00260\u0026\\cos m\\theta_1\u0026-\\sin m\\theta_1\u0026\\cdots\u00260\u00260\\\\0\u00260\u0026\\sin m\\theta_1\u0026\\cos m\\theta_1\u0026\\cdots\u00260\u00260\\\\\\vdots\u0026\\vdots\u0026\\vdots\u0026\\vdots\u0026\\ddots\u0026\\vdots\u0026\\vdots\\\\0\u00260\u00260\u00260\u0026\\cdots\u0026\\cos m\\theta_{d/2-1}\u0026-\\sin m\\theta_{d/2-1}\\\\0\u00260\u00260\u00260\u0026\\cdots\u0026\\sin m\\theta_{d/2-1}\u0026\\cos m\\theta_{d/2-1}\\end{bmatrix}\\begin{bmatrix}q_0\\\\q_1\\\\q_2\\\\q_3\\\\\\vdots\\\\q_{d-2}\\\\q_{d-1}\\end{bmatrix}\\] 由于矩阵太稀疏，会造成浪费，因此计算时是这么做的： \\[\\begin{bmatrix}q_0\\\\q_1\\\\q_2\\\\q_3\\\\\\vdots\\\\q_{d-2}\\\\q_{d-1}\\end{bmatrix}\\otimes\\begin{bmatrix}\\cos m\\theta_0\\\\\\cos m\\theta_0\\\\\\cos m\\theta_1\\\\\\cos m\\theta_1\\\\\\vdots\\\\\\cos m\\theta_{d/2-1}\\\\\\cos m\\theta_{d/2-1}\\end{bmatrix}+\\begin{bmatrix}-q_1\\\\q_0\\\\-q_3\\\\q_2\\\\\\vdots\\\\-q_{d-1}\\\\q_{d-2}\\end{bmatrix}\\otimes\\begin{bmatrix}\\sin m\\theta_0\\\\\\sin m\\theta_0\\\\\\sin m\\theta_1\\\\\\sin m\\theta_1\\\\\\vdots\\\\\\sin m\\theta_{d/2-1}\\\\\\sin m\\theta_{d/2-1}\\end{bmatrix}\\] 此外，角度的计算方式如下： \\[\\theta_j=10000^{-2j/d},j\\in[1,2,\\dots,d/2]\\] 代码 ","date":"2024-08-31","objectID":"/rope/:0:0","tags":["LLM"],"title":"rope","uri":"/rope/"},{"categories":["","LLM"],"content":"llama实现 llama实现比较简单，但是一开始很不容易理解，实现如下： def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0): \"\"\" Precompute the frequency tensor for complex exponentials (cis) with given dimensions. This function calculates a frequency tensor with complex exponentials using the given dimension 'dim' and the end index 'end'. The 'theta' parameter scales the frequencies. The returned tensor contains complex values in complex64 data type. Args: dim (int): Dimension of the frequency tensor. end (int): End index for precomputing frequencies. theta (float, optional): Scaling factor for frequency computation. Defaults to 10000.0. Returns: torch.Tensor: Precomputed frequency tensor with complex exponentials. \"\"\" # dim = 128 # end = 4096 # torch.arange(0, dim, 2) [0, 2, 4, 6, 8, 10,..., 124, 126] 共64个 # torch.arange(0, dim, 2)[: (dim // 2)] 保证是64个 freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim)) # rope中的角度 # freqs = [1/10000.0^(0/128), 1/10000.0^(2/128), 1/10000.0^(4/128), ..., 1/10000.0^(126/128)] t = torch.arange(end, device=freqs.device) # postition idx # t = [0, 1, 2, ..., 4095] freqs = torch.outer(t, freqs).float() # type: ignore # freqs 得到 freqs和t的笛卡尔积，维度为（4096，64） # freqs = [[0, 0, 0,..., 0], # [1/10000.0^(0/128), 1/10000.0^(2/128), 1/10000.0^(4/128), ..., 1/10000.0^(126/128)], # [2/10000.0^(0/128), 2/10000.0^(2/128), 2/10000.0^(4/128), ..., 2/10000.0^(126/128)], # ..., # [4095/10000.0^(0/128), 4095/10000.0^(2/128), 4095/10000.0^(4/128), ..., 4095/10000.0^(126/128)]] freqs_cis = torch.polar(torch.ones_like(freqs), freqs) # complex64 # freqs_cis的维度为(4096,64)，相当于半径为1，角度为freqs的极坐标的复数表示，如公式6所示。 return freqs_cis def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor): # 将除了position和dim其他的维度变为1 \"\"\" Reshape frequency tensor for broadcasting it with another tensor. This function reshapes the frequency tensor to have the same shape as the target tensor 'x' for the purpose of broadcasting the frequency tensor during element-wise operations. Args: freqs_cis (torch.Tensor): Frequency tensor to be reshaped. x (torch.Tensor): Target tensor for broadcasting compatibility. Returns: torch.Tensor: Reshaped frequency tensor. Raises: AssertionError: If the frequency tensor doesn't match the expected shape. AssertionError: If the target tensor 'x' doesn't have the expected number of dimensions. \"\"\" # freqs_cis.shape = [1024, 64] # x.shape = [2, 1024, 32, 64] ndim = x.ndim assert 0 \u003c= 1 \u003c ndim assert freqs_cis.shape == (x.shape[1], x.shape[-1]) # 将freqs_cis.shape变为[1, 1024, 1, 64] shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)] return freqs_cis.view(*shape) def apply_rotary_emb( xq: torch.Tensor, xk: torch.Tensor, freqs_cis: torch.Tensor, ): \"\"\" Apply rotary embeddings to input tensors using the given frequency tensor. This function applies rotary embeddings to the given query 'xq' and key 'xk' tensors using the provided frequency tensor 'freqs_cis'. The input tensors are reshaped as complex numbers, and the frequency tensor is reshaped for broadcasting compatibility. The resulting tensors contain rotary embeddings and are returned as real tensors. Args: xq (torch.Tensor): Query tensor to apply rotary embeddings. xk (torch.Tensor): Key tensor to apply rotary embeddings. freqs_cis (torch.Tensor): Precomputed frequency tensor for complex exponentials. Returns: Tuple[torch.Tensor, torch.Tensor]: Tuple of modified query tensor and key tensor with rotary embeddings. \"\"\" # 将xq和xk的最后一个维度进行复数运算，得到新的xq和xk # 为了进行复数运算，需要将xq和xk的最后一个维度展开为2维 # 例如，xq的形状为[2, seq_len, 32, 128], reshape后为[2, seq_len, 32 , 64, 2] # view_as_complex函数可以将张量中的最后一维的两个元素作为实部和虚部合成一个复数xq的形状变为[2, seq_len, 32, 64] xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2)) xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2)) # 将freqs_cis广播到xq和xk的最后一个维度 freqs_cis = reshape_for_broadcast(freqs_cis, xq_) # freqs_cis.shape = [1, 1024, 1, 64] # view_as_real和view_as_complex相反，可以将张量中最后一维的复数拆出实部和虚部 # (xq_ ","date":"2024-08-31","objectID":"/rope/:1:0","tags":["LLM"],"title":"rope","uri":"/rope/"},{"categories":["","LLM"],"content":"另一种实现 另一种实现(transformers)利用了下面这个式子： \\[ \\begin{bmatrix}q_0\\\\q_1\\\\q_2\\\\q_3\\\\\\vdots\\\\q_{d-2}\\\\q_{d-1}\\end{bmatrix}\\otimes\\begin{bmatrix}\\cos m\\theta_0\\\\\\cos m\\theta_0\\\\\\cos m\\theta_1\\\\\\cos m\\theta_1\\\\\\vdots\\\\\\cos m\\theta_{d/2-1}\\\\\\cos m\\theta_{d/2-1}\\end{bmatrix}+\\begin{bmatrix}-q_1\\\\q_0\\\\-q_3\\\\q_2\\\\\\vdots\\\\-q_{d-1}\\\\q_{d-2}\\end{bmatrix}\\otimes\\begin{bmatrix}\\sin m\\theta_0\\\\\\sin m\\theta_0\\\\\\sin m\\theta_1\\\\\\sin m\\theta_1\\\\\\vdots\\\\\\sin m\\theta_{d/2-1}\\\\\\sin m\\theta_{d/2-1}\\end{bmatrix} \\] class LlamaRotaryEmbedding(torch.nn.Module): def __init__(self, dim, max_position_embeddings=2048, base=10000, device=None): super().__init__() inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float().to(device) / dim)) self.register_buffer(\"inv_freq\", inv_freq) # Build here to make `torch.jit.trace` work. self.max_seq_len_cached = max_position_embeddings t = torch.arange(self.max_seq_len_cached, device=self.inv_freq.device, dtype=self.inv_freq.dtype) freqs = torch.einsum(\"i,j-\u003eij\", t, self.inv_freq) # Different from paper, but it uses a different permutation # in order to obtain the same calculation emb = torch.cat((freqs, freqs), dim=-1) dtype = torch.get_default_dtype() self.register_buffer(\"cos_cached\", emb.cos()[None, None, :, :].to(dtype), persistent=False) self.register_buffer(\"sin_cached\", emb.sin()[None, None, :, :].to(dtype), persistent=False) def forward(self, x, seq_len=None): # x: [bs, num_attention_heads, seq_len, head_size] # This `if` block is unlikely to be run after we build sin/cos in `__init__`. # Keep the logic here just in case. if seq_len \u003e self.max_seq_len_cached: self.max_seq_len_cached = seq_len t = torch.arange(self.max_seq_len_cached, device=x.device, dtype=self.inv_freq.dtype) freqs = torch.einsum(\"i,j-\u003eij\", t, self.inv_freq) # Different from paper, but it uses a different permutation # in order to obtain the same calculation emb = torch.cat((freqs, freqs), dim=-1).to(x.device) self.register_buffer(\"cos_cached\", emb.cos()[None, None, :, :].to(x.dtype), persistent=False) self.register_buffer(\"sin_cached\", emb.sin()[None, None, :, :].to(x.dtype), persistent=False) return ( self.cos_cached[:, :, :seq_len, ...].to(dtype=x.dtype), self.sin_cached[:, :, :seq_len, ...].to(dtype=x.dtype), ) def rotate_half(x): \"\"\"Rotates half the hidden dims of the input.\"\"\" x1 = x[..., : x.shape[-1] // 2] x2 = x[..., x.shape[-1] // 2 :] return torch.cat((-x2, x1), dim=-1) def apply_rotary_pos_emb(q, k, cos, sin, position_ids): # The first two dimensions of cos and sin are always 1, so we can `squeeze` them. cos = cos.squeeze(1).squeeze(0) # [seq_len, dim] sin = sin.squeeze(1).squeeze(0) # [seq_len, dim] cos = cos[position_ids].unsqueeze(1) # [bs, 1, seq_len, dim] sin = sin[position_ids].unsqueeze(1) # [bs, 1, seq_len, dim] q_embed = (q * cos) + (rotate_half(q) * sin) k_embed = (k * cos) + (rotate_half(k) * sin) return q_embed, k_embed 相对于llama的版本比较容易理解。 Long-term decay of RoPE 公式不看了，结论就是RoPE有长距离衰减的特性，相对距离越远的token之间的关注度也会降低，表现为attention score减小，这是个很好的特性。”This property coincides with the intuition that a pair of tokens with a long relative distance should have less connection.“ # 参考 一文通透位置编码：从标准位置编码、旋转位置编码RoPE到ALiBi、LLaMA 2 Long(含NTK-aware简介)-CSDN博客 LLM—llama2结构和源码解读 - 知乎 (zhihu.com) ","date":"2024-08-31","objectID":"/rope/:2:0","tags":["LLM"],"title":"rope","uri":"/rope/"},{"categories":[""],"content":"KV cache LLM推理过程分为Prefill和Decode两个阶段，其中Prefill阶段会对Prompt中所有的token做并行计算，得到Prompt中所有Tokens的KV Cache以及计算得到首Token。Prompt阶段Token计算得到的KV Cache会保存下来，留给Decode阶段复用，Decode阶段是一个自回归过程，每decode一个新的Token，都需要用到所有之前计算得到的KV Cache来计算当前query token的Attention。因此，当输出长度越来越大或者context很长时，KV Cache将会占用大量的显存。如何优化KV Cache的显存占用，一直都是LLM推理的核心主题之一。 之前一直疑惑kv cache既然每次只输入生成token就可以，那么位置信息该怎么注入呢？翻了翻llama的源码，找到了答案： def forward(self, tokens: torch.Tensor, start_pos: int): \"\"\" Perform a forward pass through the Transformer model. Args: tokens (torch.Tensor): Input token indices. start_pos (int): Starting position for attention caching. Returns: torch.Tensor: Output logits after applying the Transformer model. \"\"\" _bsz, seqlen = tokens.shape h = self.tok_embeddings(tokens) self.freqs_cis = self.freqs_cis.to(h.device) freqs_cis = self.freqs_cis[start_pos : start_pos + seqlen] mask = None if seqlen \u003e 1: mask = torch.full( (seqlen, seqlen), float(\"-inf\"), device=tokens.device ) mask = torch.triu(mask, diagonal=1) # When performing key-value caching, we compute the attention scores # only for the new sequence. Thus, the matrix of scores is of size # (seqlen, cache_len + seqlen), and the only masked entries are (i, j) for # j \u003e cache_len + i, since row i corresponds to token cache_len + i. mask = torch.hstack([ torch.zeros((seqlen, start_pos), device=tokens.device), mask ]).type_as(h) for layer in self.layers: h = layer(h, start_pos, freqs_cis, mask) h = self.norm(h) output = self.output(h).float() return output 注意freqs_cis = self.freqs_cis[start_pos : start_pos + seqlen]这一行，即是实现了rope相对位置编码的kv cache的核心。 kv cache代码 def repeat_kv(x: torch.Tensor, n_rep: int) -\u003e torch.Tensor: \"\"\"torch.repeat_interleave(x, dim=2, repeats=n_rep)\"\"\" bs, slen, n_kv_heads, head_dim = x.shape if n_rep == 1: return x return ( x[:, :, :, None, :] .expand(bs, slen, n_kv_heads, n_rep, head_dim) .reshape(bs, slen, n_kv_heads * n_rep, head_dim) ) class Attention(nn.Module): \"\"\"Multi-head attention module.\"\"\" def __init__(self, args: ModelArgs): \"\"\" Initialize the Attention module. Args: args (ModelArgs): Model configuration parameters. Attributes: n_kv_heads (int): Number of key and value heads. n_local_heads (int): Number of local query heads. n_local_kv_heads (int): Number of local key and value heads. n_rep (int): Number of repetitions for local heads. head_dim (int): Dimension size of each attention head. wq (ColumnParallelLinear): Linear transformation for queries. wk (ColumnParallelLinear): Linear transformation for keys. wv (ColumnParallelLinear): Linear transformation for values. wo (RowParallelLinear): Linear transformation for output. cache_k (torch.Tensor): Cached keys for attention. cache_v (torch.Tensor): Cached values for attention. \"\"\" super().__init__() self.n_kv_heads = args.n_heads if args.n_kv_heads is None else args.n_kv_heads model_parallel_size = fs_init.get_model_parallel_world_size() self.n_local_heads = args.n_heads // model_parallel_size self.n_local_kv_heads = self.n_kv_heads // model_parallel_size self.n_rep = self.n_local_heads // self.n_local_kv_heads self.head_dim = args.dim // args.n_heads self.wq = ColumnParallelLinear( args.dim, args.n_heads * self.head_dim, bias=False, gather_output=False, init_method=lambda x: x, ) self.wk = ColumnParallelLinear( args.dim, self.n_kv_heads * self.head_dim, bias=False, gather_output=False, init_method=lambda x: x, ) self.wv = ColumnParallelLinear( args.dim, self.n_kv_heads * self.head_dim, bias=False, gather_output=False, init_method=lambda x: x, ) self.wo = RowParallelLinear( args.n_heads * self.head_dim, args.dim, bias=False, input_is_parallel=True, init_method=lambda x: x, ) # kv_cache是缓存键值对，在训练过程中，我们只保存最近n个键值对 self.cache_k = torch.zeros( ( args.max_batch_size, args.max_seq_len, self.n_local_kv_heads, self.head_dim, ) ).cuda() self.cache_v = torch.zeros( ( args.max_batch_size, args.max_seq_len, self.n_local_kv_heads, self.head_dim, ) ).cuda() def forward( self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[","date":"2024-08-07","objectID":"/kv-cache/:0:0","tags":null,"title":"KV cache","uri":"/kv-cache/"},{"categories":[""],"content":"prefill和decode分离 在传统的 LLM 推理框架中，Prefill 和 Decode 阶段通常由同一块 GPU 执行。推理引擎的调度器会根据显存使用情况及请求队列状态，在 Prefill 和 Decode 之间切换，完成整个推理过程。 而在 Prefill-Decode 分离式架构（以下简称 PD 分离式架构）中，这两个阶段被拆分到不同的 GPU 实例上独立运行。如下图所示，这是 DistServe 提供的一张架构图： 在大模型推理中，常用以下两项指标评估性能： TTFT（Time-To-First-Token）：首 token 的生成时间，主要衡量 Prefill 阶段性能。 TPOT（Time-Per-Output-Token）：生成每个 token 的时间，主要衡量 Decode 阶段性能。 当 Prefill 和 Decode 在同一块 GPU 上运行时，由于两阶段的计算特性差异（Prefill 是计算密集型，而 Decode 是存储密集型），资源争抢会导致 TTFT 和 TPOT 之间的权衡。例如： 若优先处理 Prefill 阶段以降低 TTFT，Decode 阶段的性能（TPOT）可能下降。 若尽量提升 TPOT，则会增加 Prefill 请求的等待时间，导致 TTFT 上升。 PD 分离式架构的提出正是为了打破这一矛盾。通过将 Prefill 和 Decode 分离运行，可以针对不同阶段的特性独立优化资源分配，从而在降低首 token 延迟的同时提高整体吞吐量。 在 PD 分离架构中，Prefill 和 Decode 阶段的资源需求不同，分别体现为： Prefill 阶段：计算密集型（compute-bound）。在流量较大或用户提示长度较长时，Prefill 的计算压力更大。完成 KV Cache 的生成后，Prefill 阶段本身无需继续保留这些缓存。 Decode 阶段：存储密集型（memory-bound）。由于逐 token 生成的特性，Decode 阶段需频繁访问 KV Cache，因此需要尽可能多地保留缓存数据以保障推理效率。 Batching 策略对两阶段的性能影响显著，但趋势相反： Prefill 阶段：吞吐量随 batch size 增加逐渐趋于平稳。这是因为 Prefill 的计算受限特性（compute-bound），当 batch 中的总 token 数超过某个阈值时，计算资源成为瓶颈。 Decode 阶段：吞吐量随 batch size 增加显著提升。由于 Decode 阶段的存储受限特性（memory-bound），增大 batch size 可提高计算效率，从而显著增加吞吐量。 ","date":"2024-08-07","objectID":"/kv-cache/:1:0","tags":null,"title":"KV cache","uri":"/kv-cache/"},{"categories":[""],"content":"Chunked prefills image.png 常见问题 ","date":"2024-08-07","objectID":"/kv-cache/:2:0","tags":null,"title":"KV cache","uri":"/kv-cache/"},{"categories":[""],"content":"128k token输入需要多少显存存kv cache? image.png 超参数如上，如果我们采用int8精度，也就是每个参数占据一个字节，每个token占据的kv cache大小就是 2 * K * H * L = 2 (k 和 v) * 8 (n kv heads) * 128 (d_qkv) * 80 (n layers) * 1 (byte)= 160kB （这里的 2 是因为每个 token 需要存储k和v） 那么128k的kv cache就是： 162e3 * 128 * 1024 = 21.2GB 需要注意的是 llama 3 使用的是 gqa，所以 N 为 64，K 为 8. 套公式就是 （使用 bf 16 即 2 bytes）： \\[ b(s+n)h*l*2*2 \\] 其中 b 为 batch_size，s 为输入序列长度，n 为输出序列长度，h 为 k 或者 v 的总维度，不同的 attention 改变的是这个东西来降低显存。 参考 LLM—llama2结构和源码解读 - 知乎 (zhihu.com) # LLM推理优化 - Chunked prefills # 图解大模型计算加速系列：分离式推理架构1，从DistServe谈起 ","date":"2024-08-07","objectID":"/kv-cache/:3:0","tags":null,"title":"KV cache","uri":"/kv-cache/"},{"categories":[""],"content":"Low-Rank Adaption (LoRA)，即“低秩适配”，实现了预训练模型的参数高效微调，且不会增加模型的推理延迟。 ## 内在维度 2020年，A. Aghajanyan等人研究了这一现象，发现预训练模型存在一个较低的”内在维度”,使用少量样本微调时，实际上是在更新低维空间中的参数。把预训练模型的全部参数看成一个D维参数向量，记为\\(\\Theta^\\mathrm{(D)}\\),模型的原始参数为\\(\\Theta_0^\\mathrm{(D)}\\),设\\(\\Theta^{(d)}\\)是d维子空间中的一个向量，d\u003cD,利用一个固定的D*d映射矩阵P 把d维空间中的向量映射到D维空间，\\(\\Theta^{(\\mathrm{D})}\\)可写为： \\[\\mathrm{\\theta^{(D)}=\\theta_0^{(D)}+P\\theta^{(d)}}\\] 下图中，以D=3,d=2为例： 左图直接在3维空间中训练模型，直接优化原始模型参数\\(\\Theta_{0}^{(\\mathrm{D})}\\),把它更新为\\(\\Theta^{(\\mathrm{D})}\\)。右图冻结\\(\\Theta_{0}^{(\\mathrm{D})}\\),转而在2维空间中寻找一个\\(\\Theta^{(\\mathrm{d})}\\),再用矩阵P把\\(\\Theta^{(\\mathrm{d})}\\)映射到3维空间。如果用右图的方式可以把模型优化到良好的效果，例如，达到了全量参数微调效果的90%,则该模型的内在维度\\(\\mathrm{d}_{90}=2\\)。 实验表明，仅训练200个参数，就可以使RoBERTa-large在MRPC数据集上的效果达到全量参数微调效果的90%。 ## 低秩适配 预训练模型的权重矩阵通常具有满秩，这意味着权重矩阵的各个列向量之间线性无关，这样的矩阵没有冗余信息，是无法被压缩的。但是，“内在维度”现象表明，微调模型时只需更新少量参数，这启发我们微调时产生的权重增量矩阵\\(\\Delta\\)W可能包含大量冗余参数，\\(\\Delta\\)W很可能不是满秩的。对低秩矩阵做分解，可以利用较少的参数重建或近似原矩阵。这就是LoRA的核心思想。 设输入为x，微调时得到增量\\(\\Delta W\\),与原始权重\\(\\mathcal{W}_{0}\\)相加得到更新后的权重，输出h= ( \\(W_0\\)+ \\(\\Delta\\)W) x。根据矩阵的乘法分配律，有h= \\(W_0\\)x+ \\(\\Delta\\)Wx,这意味着微调时可以保持\\(W_0\\)不变，分别将\\(W_0\\)、\\(\\Delta\\)W与x相乘，最后把两个乘积相加即可得到输出h。 设\\(\\mathcal{W}_0\\in\\mathbb{R}^{\\mathrm{dxk}}\\),\\(\\Delta \\mathcal{W} _{\\mathrm{f} }\\)的秩为r。\\(\\Delta \\mathcal{W}= \\mathcal{B} \\mathcal{A}\\)是\\(\\Delta\\mathcal{W}\\)的一个满秩分解，其中 \\(\\mathcal{B} \\in \\mathbb{R} ^{\\mathrm{dxr}}, \\mathcal{A} \\in \\mathbb{R} ^{\\mathrm{rxk}}, \\mathcal{r} \\ll \\min ( \\mathcal{d} , \\mathcal{k} )\\)。训练时，分别用随机高斯和零矩阵初始化A和B，确保初始化时 BA是零矩阵，对模型效果没有影响。训练过程中冻结\\(\\mathcal{W}_0\\),只更新矩阵B和A，共r(d+k)个参数，从而实 现“参数高效”微调。推理时，分别计算\\(\\mathbf{W_{\\mathrm{n} }x}\\)和 BAx并相加，得到输出h，如下图所示： 实际上，r是一个超参，训练时可任意设定，\\(\\Delta\\)W真正的秩未必等于r。如果r恰好等于\\(\\Delta\\)W的秩，甚至大于\\(\\Delta\\)的秩(例如等于预训练权重矩阵\\(W_{0}\\)的秩),利用学到的B和A可以完全重建\\(\\Delta\\)W,这时，LoRA的效果近似于全量微调。如果r小于\\(\\Delta\\)W的秩，BA就是\\(\\Delta\\)W的一个低秩近似，利用矩阵B和A可以恢复矩阵\\(\\Delta W\\)中的部分信息。 还有一个超参数为lora_alpha: image.png ","date":"2024-08-07","objectID":"/lora%E5%BE%AE%E8%B0%83/:0:0","tags":null,"title":"Lora微调","uri":"/lora%E5%BE%AE%E8%B0%83/"},{"categories":[""],"content":"降低了哪部分显存需求 image.png image.png ","date":"2024-08-07","objectID":"/lora%E5%BE%AE%E8%B0%83/:1:0","tags":null,"title":"Lora微调","uri":"/lora%E5%BE%AE%E8%B0%83/"},{"categories":[""],"content":"代码 class LoraModel(torch.nn.Module): \"\"\" Creates Low Rank Adapter (Lora) model from a pretrained transformers model. Args: model ([`transformers.PreTrainedModel`]): The model to be adapted. config ([`LoraConfig`]): The configuration of the Lora model. Returns: `torch.nn.Module`: The Lora model. Example:: \u003e\u003e\u003e from transformers import AutoModelForSeq2SeqLM, LoraConfig \u003e\u003e\u003e from peft import LoraModel, LoraConfig \u003e\u003e\u003e config = LoraConfig( peft_type=\"LORA\", task_type=\"SEQ_2_SEQ_LM\", r=8, lora_alpha=32, target_modules=[\"q\", \"v\"], lora_dropout=0.01, ) \u003e\u003e\u003e model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\") \u003e\u003e\u003e lora_model = LoraModel(config, model) **Attributes**: - **model** ([`transformers.PreTrainedModel`]) -- The model to be adapted. - **peft_config** ([`LoraConfig`]): The configuration of the Lora model. \"\"\" def __init__(self, config, model): super().__init__() self.peft_config = config self.model = model self._find_and_replace() mark_only_lora_as_trainable(self.model, self.peft_config.bias) def _find_and_replace(self): kwargs = { \"r\": self.peft_config.r, \"lora_alpha\": self.peft_config.lora_alpha, \"lora_dropout\": self.peft_config.lora_dropout, \"fan_in_fan_out\": self.peft_config.fan_in_fan_out, \"merge_weights\": self.peft_config.merge_weights, } key_list = [key for key, _ in self.model.named_modules()] for key in key_list: if any(key.endswith(target_key) for target_key in self.peft_config.target_modules): # 对特定的层插入lora层 parent, target, target_name = self._get_submodules(key) bias = target.bias is not None if isinstance(target, torch.nn.Linear) and self.peft_config.enable_lora is None: new_module = Linear(target.in_features, target.out_features, bias=bias, **kwargs) elif self.peft_config.enable_lora is not None: kwargs.update({\"enable_lora\": self.peft_config.enable_lora}) if isinstance(target, Conv1D): in_features, out_features = target.weight.shape else: in_features, out_features = target.in_features, target.out_features if kwargs[\"fan_in_fan_out\"]: warnings.warn( \"fan_in_fan_out is set to True but the target module is not a Conv1D. \" \"Setting fan_in_fan_out to False.\" ) kwargs[\"fan_in_fan_out\"] = False new_module = MergedLinear(in_features, out_features, bias=bias, **kwargs) self._replace_module(parent, target_name, new_module, target) def _get_submodules(self, key): parent = self.model.get_submodule(\".\".join(key.split(\".\")[:-1])) target_name = key.split(\".\")[-1] target = self.model.get_submodule(key) return parent, target, target_name def _replace_module(self, parent_module, child_name, new_module, old_module): setattr(parent_module, child_name, new_module) new_module.weight = old_module.weight if old_module.bias is not None: new_module.bias = old_module.bias def forward(self, *args, **kwargs): return self.model(*args, **kwargs) def __getattr__(self, name: str): \"\"\"Forward missing attributes to the wrapped module.\"\"\" try: return super().__getattr__(name) # defer to nn.Module's logic except AttributeError: return getattr(self.model, name) @property def modules_to_save(self): return None def get_peft_config_as_dict(self, inference: bool = False): config = {k: v.value if isinstance(v, Enum) else v for k, v in asdict(self.peft_config).items()} if inference: config[\"inference_mode\"] = True return config 插入lora层的核心代码如下： class LoraLayer: def __init__( self, r: int, lora_alpha: int, lora_dropout: float, merge_weights: bool, ): self.r = r self.lora_alpha = lora_alpha # Optional dropout if lora_dropout \u003e 0.0: self.lora_dropout = nn.Dropout(p=lora_dropout) else: self.lora_dropout = lambda x: x # Mark the weight as unmerged self.merged = False self.merge_weights = merge_weights class Linear(nn.Linear, LoraLayer): # Lora implemented in a dense layer def __init__( self, in_features: int, out_features: int, r: int = 0, lora_alpha: int = 1, lora_dropout: float = 0.0, fan_in_fan_out: bool = False, # Set this to True if the layer to replace stores weight like (fan_in, fan_out) merge_weights: bool = True, **kwargs, ): nn.Linear.__init__(self, in","date":"2024-08-07","objectID":"/lora%E5%BE%AE%E8%B0%83/:2:0","tags":null,"title":"Lora微调","uri":"/lora%E5%BE%AE%E8%B0%83/"},{"categories":[""],"content":"参考 https://snailcoder.github.io/2023/08/06/parameter-efficient-llm-fine-tuning-lora.html # 当红炸子鸡 LoRA，是当代微调 LLMs 的正确姿势？ ","date":"2024-08-07","objectID":"/lora%E5%BE%AE%E8%B0%83/:3:0","tags":null,"title":"Lora微调","uri":"/lora%E5%BE%AE%E8%B0%83/"},{"categories":["","NLP","LLM","MoE"],"content":"MoE 的思想类似于集成学习中的 Ensemble Learning。MoE 作用于原本 transformer 模型的 MLP 层，即： 图片来自于Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity 论文。 总结来说，在混合专家模型 (MoE) 中，我们将传统 Transformer 模型中的每个前馈网络 (FFN) 层替换为 MoE 层，其中 MoE 层由两个核心部分组成: 一个路由器（或者叫门控网络）和若干数量的专家。 用多个 FeedForward 块替换单个 FeedForward 块 （如在 MoE 设置中所做的那样）会大大增加模型的总参数数。然而，关键的诀窍是，我们不会对每个token使用（“激活”）所有专家。相反，路由器仅为每个token选择一小部分专家。 image.png ","date":"2024-08-07","objectID":"/moe/:0:0","tags":["NLP","LLM","MoE"],"title":"MoE","uri":"/moe/"},{"categories":["","NLP","LLM","MoE"],"content":"技术选择 Expert Choice 路由（容量为 2，即每个专家选两个 token）在 NLP 模型效果好，Top-K 路由则在视觉模型效果好。 在 NLP 任务中，专家越多越好，而视觉任务中存在饱和点。 增加 MoE 层数也可以增加模型容量，但视觉任务中同样存在饱和点。 恢复优化器状态（一些统计量）和路由权重归一化可以提高视觉 MoE 模型的性能，对 NLP 任务无效。 ","date":"2024-08-07","objectID":"/moe/:1:0","tags":["NLP","LLM","MoE"],"title":"MoE","uri":"/moe/"},{"categories":["","NLP","LLM","MoE"],"content":"八股 image.png ","date":"2024-08-07","objectID":"/moe/:2:0","tags":["NLP","LLM","MoE"],"title":"MoE","uri":"/moe/"},{"categories":["","算法题"],"content":" Problem: ","date":"2024-03-29","objectID":"/%E8%AF%BE%E7%A8%8B%E8%A1%A8%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F/:0:0","tags":["算法题"],"title":"课程表（拓扑排序）","uri":"/%E8%AF%BE%E7%A8%8B%E8%A1%A8%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F/"},{"categories":["","算法题"],"content":"思路 注意拓扑排序最好是邻接表（哈系表实现），并用队列处理后续入度为0的点 ","date":"2024-03-29","objectID":"/%E8%AF%BE%E7%A8%8B%E8%A1%A8%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F/:1:0","tags":["算法题"],"title":"课程表（拓扑排序）","uri":"/%E8%AF%BE%E7%A8%8B%E8%A1%A8%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F/"},{"categories":["","算法题"],"content":"解题方法 描述你的解题方法 ","date":"2024-03-29","objectID":"/%E8%AF%BE%E7%A8%8B%E8%A1%A8%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F/:2:0","tags":["算法题"],"title":"课程表（拓扑排序）","uri":"/%E8%AF%BE%E7%A8%8B%E8%A1%A8%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F/"},{"categories":["","算法题"],"content":"复杂度 时间复杂度: 添加时间复杂度, 示例： \\(O(n)\\) 空间复杂度: 添加空间复杂度, 示例： \\(O(n)\\) ","date":"2024-03-29","objectID":"/%E8%AF%BE%E7%A8%8B%E8%A1%A8%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F/:3:0","tags":["算法题"],"title":"课程表（拓扑排序）","uri":"/%E8%AF%BE%E7%A8%8B%E8%A1%A8%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F/"},{"categories":["","算法题"],"content":"Code class Solution: def canFinish(self, numCourses: int, prerequisites: List[List[int]]) -\u003e bool: if not prerequisites: return True def get_zero(numCourses, prerequisites, temp): queue = [] for prerequisite in prerequisites: temp[prerequisite[0]] += 1 for i in range(len(temp)): if temp[i] == 0: queue.append(i) return queue temp = [0 for _ in range(numCourses)] queue = get_zero(numCourses, prerequisites, temp) if queue == []: return False from collections import defaultdict d = defaultdict(list) for prerequisite in prerequisites: d[prerequisite[1]].append(prerequisite[0]) while queue: idx = queue.pop(0) nexs = d[idx] if nexs: for nex in nexs: temp[nex] -= 1 if temp[nex] == 0: queue.append(nex) numCourses -= 1 return numCourses == 0 ","date":"2024-03-29","objectID":"/%E8%AF%BE%E7%A8%8B%E8%A1%A8%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F/:4:0","tags":["算法题"],"title":"课程表（拓扑排序）","uri":"/%E8%AF%BE%E7%A8%8B%E8%A1%A8%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F/"},{"categories":[""],"content":" Problem: ","date":"2024-03-18","objectID":"/%E4%B9%98%E7%A7%AF%E6%9C%80%E5%A4%A7%E7%9A%84%E6%95%B0%E7%BB%84/:0:0","tags":null,"title":"乘积最大的数组","uri":"/%E4%B9%98%E7%A7%AF%E6%9C%80%E5%A4%A7%E7%9A%84%E6%95%B0%E7%BB%84/"},{"categories":[""],"content":"思路 讲述看到这一题的思路 ","date":"2024-03-18","objectID":"/%E4%B9%98%E7%A7%AF%E6%9C%80%E5%A4%A7%E7%9A%84%E6%95%B0%E7%BB%84/:1:0","tags":null,"title":"乘积最大的数组","uri":"/%E4%B9%98%E7%A7%AF%E6%9C%80%E5%A4%A7%E7%9A%84%E6%95%B0%E7%BB%84/"},{"categories":[""],"content":"解题方法 描述你的解题方法 ","date":"2024-03-18","objectID":"/%E4%B9%98%E7%A7%AF%E6%9C%80%E5%A4%A7%E7%9A%84%E6%95%B0%E7%BB%84/:2:0","tags":null,"title":"乘积最大的数组","uri":"/%E4%B9%98%E7%A7%AF%E6%9C%80%E5%A4%A7%E7%9A%84%E6%95%B0%E7%BB%84/"},{"categories":[""],"content":"复杂度 时间复杂度: 添加时间复杂度, 示例： \\(O(n)\\) 空间复杂度: 添加空间复杂度, 示例： \\(O(n)\\) ","date":"2024-03-18","objectID":"/%E4%B9%98%E7%A7%AF%E6%9C%80%E5%A4%A7%E7%9A%84%E6%95%B0%E7%BB%84/:3:0","tags":null,"title":"乘积最大的数组","uri":"/%E4%B9%98%E7%A7%AF%E6%9C%80%E5%A4%A7%E7%9A%84%E6%95%B0%E7%BB%84/"},{"categories":[""],"content":"Code ","date":"2024-03-18","objectID":"/%E4%B9%98%E7%A7%AF%E6%9C%80%E5%A4%A7%E7%9A%84%E6%95%B0%E7%BB%84/:4:0","tags":null,"title":"乘积最大的数组","uri":"/%E4%B9%98%E7%A7%AF%E6%9C%80%E5%A4%A7%E7%9A%84%E6%95%B0%E7%BB%84/"},{"categories":["","贪心","算法题"],"content":"跳跃游戏 Problem: ","date":"2024-03-18","objectID":"/%E8%B7%B3%E8%B7%83%E6%B8%B8%E6%88%8F/:0:0","tags":["算法题","贪心"],"title":"跳跃游戏","uri":"/%E8%B7%B3%E8%B7%83%E6%B8%B8%E6%88%8F/"},{"categories":["","贪心","算法题"],"content":"思路 讲述看到这一题的思路 ","date":"2024-03-18","objectID":"/%E8%B7%B3%E8%B7%83%E6%B8%B8%E6%88%8F/:1:0","tags":["算法题","贪心"],"title":"跳跃游戏","uri":"/%E8%B7%B3%E8%B7%83%E6%B8%B8%E6%88%8F/"},{"categories":["","贪心","算法题"],"content":"解题方法 描述你的解题方法 ","date":"2024-03-18","objectID":"/%E8%B7%B3%E8%B7%83%E6%B8%B8%E6%88%8F/:2:0","tags":["算法题","贪心"],"title":"跳跃游戏","uri":"/%E8%B7%B3%E8%B7%83%E6%B8%B8%E6%88%8F/"},{"categories":["","贪心","算法题"],"content":"复杂度 时间复杂度: 添加时间复杂度, 示例： \\(O(n)\\) 空间复杂度: 添加空间复杂度, 示例： \\(O(n)\\) ","date":"2024-03-18","objectID":"/%E8%B7%B3%E8%B7%83%E6%B8%B8%E6%88%8F/:3:0","tags":["算法题","贪心"],"title":"跳跃游戏","uri":"/%E8%B7%B3%E8%B7%83%E6%B8%B8%E6%88%8F/"},{"categories":["","贪心","算法题"],"content":"Code ```Python3 [] # 跳跃游戏ii # 划分字母区间 [763. 划分字母区间 - 力扣（LeetCode）](https://leetcode.cn/problems/partition-labels/description/?envType=study-plan-v2\u0026envId=top-100-liked) 本题预处理完毕后思路和跳跃游戏2类似，当然也可以使用合并区间的思路来，都是贪心算法。 ## Code ```python class Solution: def partitionLabels(self, s: str) -\u003e List[int]: from collections import defaultdict d = defaultdict(list) for i, char in enumerate(s): d[char].append(i) # 也可以考虑合并区间做了，下面的解法类似跳跃游戏2 res = [] start = 0 max_jump = 0 for i, char in enumerate(s): max_jump = max(max_jump, d[char][-1]) if i == max_jump: res.append(i - start + 1) start = i + 1 max_jump = 0 return res ","date":"2024-03-18","objectID":"/%E8%B7%B3%E8%B7%83%E6%B8%B8%E6%88%8F/:4:0","tags":["算法题","贪心"],"title":"跳跃游戏","uri":"/%E8%B7%B3%E8%B7%83%E6%B8%B8%E6%88%8F/"},{"categories":["","算法题"],"content":"41. 缺失的第一个正数 - 力扣（LeetCode） 空间复杂度o(n)很好想，但o(1)不好想，还是个408考研真题 注意O(n) == O(2n)，即相较于边遍历边判断，还是遍历两次更加方便且不会有太多损失。类似思想：73. 矩阵置零 - 力扣（LeetCode） class Solution: def firstMissingPositive(self, nums: List[int]) -\u003e int: # 将原数组当作哈希表使用。 for i, num in enumerate(nums): if num \u003c= 0: # 先把小于0的先一步处理，以便于使用标记 nums[i] = len(nums) + 1 for i, num in enumerate(nums): num = abs(num) if num \u003e= 1 and num \u003c= len(nums): if nums[num-1] \u003e 0: # 不重复添加 nums[num-1] = -nums[num-1] res = len(nums) + 1 for i, num in enumerate(nums): if num \u003e 0: res = i + 1 break return res ","date":"2024-03-16","objectID":"/%E7%BC%BA%E5%A4%B1%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E6%AD%A3%E6%95%B0/:0:0","tags":["算法题"],"title":"缺失的第一个正数","uri":"/%E7%BC%BA%E5%A4%B1%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E6%AD%A3%E6%95%B0/"},{"categories":["","算法题"],"content":"题目地址 # 思路 通过前缀和+哈希表，并有简单的数学变换。前缀和即 \\(y[i]=y[i-1]+x[i]\\) 类比于accumlate函数，注意前缀和思想也可以应用为“前缀积、后缀和、后缀积”等思想。238. 除自身以外数组的乘积 - 力扣（LeetCode） \u003e 使用前缀和的方法可以解决这个问题，因为我们需要找到和为k的连续子数组的个数。通过计算前缀和，我们可以将问题转化为求解两个前缀和之差等于k的情况。 \u003e假设数组的前缀和数组为prefixSum，其中prefixSum[i]表示从数组起始位置到第i个位置的元素之和。那么对于任意的两个下标i和j（i \u003c j），如果prefixSum[j] - prefixSum[i] = k，即从第i个位置到第j个位置的元素之和等于k，那么说明从第i+1个位置到第j个位置的连续子数组的和为k。 通过遍历数组，计算每个位置的前缀和，并使用一个哈希表来存储每个前缀和出现的次数。在遍历的过程中，我们检查是否存在prefixSum[j] - k的前缀和，如果存在，说明从某个位置到当前位置的连续子数组的和为k，我们将对应的次数累加到结果中。 这样，通过遍历一次数组，我们可以统计出和为k的连续子数组的个数，并且时间复杂度为O(n)，其中n为数组的长度。 # 代码 class Solution: def subarraySum(self, nums: List[int], k: int) -\u003e int: from collections import defaultdict d = defaultdict(int) d[0] = 1 prefix = 0 res = 0 for num in nums: prefix += num temp = prefix - k if temp in d: res += d[temp] d[prefix] += 1 return res ","date":"2024-03-14","objectID":"/%E5%92%8C%E4%B8%BAk%E7%9A%84%E5%AD%90%E6%95%B0%E7%BB%84/:0:0","tags":["算法题"],"title":"和为K的子数组","uri":"/%E5%92%8C%E4%B8%BAk%E7%9A%84%E5%AD%90%E6%95%B0%E7%BB%84/"},{"categories":["","算法题"],"content":"题目地址 # 思路 通过前缀和+哈希表，并有简单的数学变换。前缀和即 \\(y[i]=y[i-1]+x[i]\\) 类比于accumlate函数，注意前缀和思想也可以应用为“前缀积、后缀和、后缀积”等思想。238. 除自身以外数组的乘积 - 力扣（LeetCode） \u003e 使用前缀和的方法可以解决这个问题，因为我们需要找到和为k的连续子数组的个数。通过计算前缀和，我们可以将问题转化为求解两个前缀和之差等于k的情况。 \u003e假设数组的前缀和数组为prefixSum，其中prefixSum[i]表示从数组起始位置到第i个位置的元素之和。那么对于任意的两个下标i和j（i \u003c j），如果prefixSum[j] - prefixSum[i] = k，即从第i个位置到第j个位置的元素之和等于k，那么说明从第i+1个位置到第j个位置的连续子数组的和为k。 通过遍历数组，计算每个位置的前缀和，并使用一个哈希表来存储每个前缀和出现的次数。在遍历的过程中，我们检查是否存在prefixSum[j] - k的前缀和，如果存在，说明从某个位置到当前位置的连续子数组的和为k，我们将对应的次数累加到结果中。 这样，通过遍历一次数组，我们可以统计出和为k的连续子数组的个数，并且时间复杂度为O(n)，其中n为数组的长度。 # 代码 class Solution: def subarraySum(self, nums: List[int], k: int) -\u003e int: from collections import defaultdict d = defaultdict(int) d[0] = 1 prefix = 0 res = 0 for num in nums: prefix += num temp = prefix - k if temp in d: res += d[temp] d[prefix] += 1 return res ","date":"2024-03-14","objectID":"/%E5%92%8C%E4%B8%BAk%E7%9A%84%E5%AD%90%E6%95%B0%E7%BB%84-1/:0:0","tags":["算法题"],"title":"和为K的子数组","uri":"/%E5%92%8C%E4%B8%BAk%E7%9A%84%E5%AD%90%E6%95%B0%E7%BB%84-1/"},{"categories":["","算法题"],"content":"def find(x): if (p[x] != x): p[x] = find(p[x]) return p[x] 上面是y总的模板，实现了路径压缩。 ","date":"2024-03-13","objectID":"/%E5%B9%B6%E6%9F%A5%E9%9B%86/:0:0","tags":["算法题"],"title":"并查集","uri":"/%E5%B9%B6%E6%9F%A5%E9%9B%86/"},{"categories":["训练trick"],"content":"温度超参数t，一般为softmax结果除以该参数，或者在对比学习中，相似度除以参数t。 如图： 上图为无监督simcse中的损失函数。 t越大，结果越平滑，t越小，得到的概率分布更“尖锐”。 当t趋于0时： 此时只关注最困难的负样本（smax）。 当t趋于∞时： 此时对比损失对所有负样本的权重都相同。 因此t越大，可以避免陷入局部最优解。(局部最优是过早地确定了优化的梯度方向，失去了在其他方向上探索的机会。较大的温度使得各个方向上的梯度差异没有那么明显，从而获得了在早期更多的探索机会。) [!note] 温度系数的作用是调节对困难样本的关注程度：越小的温度系数越关注于将本样本和最相似的困难样本分开，去得到更均匀的表示。然而困难样本往往是与本样本相似程度较高的，很多困难负样本其实是潜在的正样本，过分强迫与困难样本分开会破坏学到的潜在语义结构，因此，温度系数不能过小 考虑两个极端情况，温度系数趋向于0时，对比损失退化为只关注最困难的负样本的损失函数；当温度系数趋向于无穷大时，对比损失对所有负样本都一视同仁，失去了困难样本关注的特性。 可以把不同的负样本想像成同极点电荷在不同距离处的受力情况，距离越近的点电荷受到的库伦斥力更大，而距离越远的点电荷受到的斥力越小。对比损失也是这样的。这种性质更有利于形成在超球面均匀分布的特征。 语言建模 (lena-voita.github.io)中有个小游戏可以看到随着温度的变化导致概率分布的变化 参考 CVPR2021自监督学习论文: 理解对比损失的性质以及温度系数的作用 - 知乎 (zhihu.com) ","date":"2024-01-14","objectID":"/%E6%B8%A9%E5%BA%A6%E8%B6%85%E5%8F%82%E6%95%B0/:0:0","tags":["训练trick","温度超参数"],"title":"温度超参数","uri":"/%E6%B8%A9%E5%BA%A6%E8%B6%85%E5%8F%82%E6%95%B0/"},{"categories":["算法题"],"content":"leetcode地址：953. 验证外星语词典 - 力扣（LeetCode） ","date":"2024-01-08","objectID":"/%E9%AA%8C%E8%AF%81%E5%A4%96%E6%98%9F%E8%AF%AD%E8%AF%8D%E5%85%B8/:0:0","tags":["算法题","验证外星语词典"],"title":"验证外星语词典","uri":"/%E9%AA%8C%E8%AF%81%E5%A4%96%E6%98%9F%E8%AF%AD%E8%AF%8D%E5%85%B8/"},{"categories":["算法题"],"content":"简单方法 python列表之间也可以进行比较（太灵活了），比如[1, 2, 3] \u003c [2, 2, 3]成立，即按照字典序进行比较，与其是一样的比较规则。因此对于本题可以利用python的特性轻松解决。 好久没写python了，变得很生疏，一开始写的很蠢： class Solution: def isAlienSorted(self, words: List[str], order: str) -\u003e bool: d = dict(zip(order, range(len(order)))) words = list(map(lambda s: [d[i] for i in s], words)) print([1, 2, 3] \u003c [2, 2, 3]) return words == sorted(words) 后来想起来了sorted中还有个key参数，并且列表还有个index方法（我基本上没用过），于是改成了一行 class Solution: def isAlienSorted(self, words: List[str], order: str) -\u003e bool: return words == sorted(words, key=lambda w:[order.index(x) for x in w]) ","date":"2024-01-08","objectID":"/%E9%AA%8C%E8%AF%81%E5%A4%96%E6%98%9F%E8%AF%AD%E8%AF%8D%E5%85%B8/:1:0","tags":["算法题","验证外星语词典"],"title":"验证外星语词典","uri":"/%E9%AA%8C%E8%AF%81%E5%A4%96%E6%98%9F%E8%AF%AD%E8%AF%8D%E5%85%B8/"},{"categories":["Deep Learning","网络正则化"],"content":"L1正则化 L2正则化 权重衰减 L2正则化和权重衰减的区别 L2正则化是在损失函数上做文章。 权重衰减是在梯度更新时增加一项。 ","date":"2023-03-22","objectID":"/l1-l2%E6%AD%A3%E5%88%99%E5%8C%96%E5%92%8C%E6%9D%83%E9%87%8D%E8%A1%B0%E5%87%8F/:0:0","tags":["Deep Learning","网络正则化","L1 L2正则化"],"title":"L1 L2正则化","uri":"/l1-l2%E6%AD%A3%E5%88%99%E5%8C%96%E5%92%8C%E6%9D%83%E9%87%8D%E8%A1%B0%E5%87%8F/"},{"categories":["Deep Learning","网络正则化"],"content":"pre-norm Pre-norm:\\(X_t+1=X_{t}+F_{t}(Norm(X_{t}))\\) \\(先来看Pre-norm^{+},递归展开：\\) \\[X_{t+1}=X_t+F_t(Norm(X_t))\\] \\(=X_{0}+F_{1}(Norm(X_{1}))+\\ldots+F_{t-1}(Norm(X_{t-1}))+F_{t}(Norm(X_{t}))\\) 其中，展开\\(^{+}\\)后的每一项( \\(F_{1}( Norm( X_{1}) ) , \\ldots\\), \\(F_{t- 1}( Norm( X_{t- 1}) )\\), \\(F_{t}( Norm( X_{t}) )\\))之间都是同一量级的， 所以\\(F_1(Norm(X_1))+\\ldots F_{t-1}(Norm(X_{t-1}))+F_t(Norm(X_t))\\)和 \\(F_1(Norm(X_1))+\\ldots F_{t-1}(Norm(X_{t-1}))\\)之间的区别就像t和t-1的区别一样，我们可以将 其记为\\(X_t+ 1= \\mathscr{O} ( t+ 1)\\) . 这种特性就导致当t足够大的时候，\\(X_{t+1}\\)和\\(X_t\\)之间区别可以忽略不计（直觉上），那么就有： \\[F_t(X_t)+F_{t+1}(X_{t+1})\\approx F_t(X_t)+F_{t+1}(X_t)=(F_t\\bigoplus F_{t+1})(X_t)\\] 这就是所谓的增加宽度，而没有增加深度。从而导致pre-norm的精度不高。 ## post-norm Post-norm:\\(X_{t+1}=Norm(X_{t}+F_{t}(x_{t}))\\) 本来layernorm是为了缓解梯度消失，但是在post-norm这里却成为了梯度消失的罪魁祸首。也导致了收敛较难、需要大量调参。 \\[X_{t+1}=Norm(X_t+F_t(X_t))=\\frac{X_t+F_t(X_t)}{\\sqrt{2}}\\] \\[=\\frac{X_0}{\\sqrt{2}^{t+1}}+\\frac{F_0(X_0)}{\\sqrt{2}^{t+1}}+\\ldots+\\frac{F_{t-1}(X_{t-1})}{\\sqrt{2}^2}+\\frac{F_t(X_t)}{\\sqrt{2}}\\:(\\] 这个结构跟pre-norm比起来充分考虑了所有分支 (残差\\(^{+})\\) 的输出，做到了真正增加深度，自然精度会相对好一些。 不过它也有它很显然的问题，当t足够大、也就是叠加的attention层足够多以后，底层那些分支(残差)的影响力被衰减掉了，残差有利于解决梯度消失，但是在Post Norm中，残差这条通道被严重削弱了，越靠近输入，削弱得越严重，残差“名存实亡”，那么势必会有梯度消失的问题，这也就是文章开头所说的postnorm难收敛、参数难调的原因。本来我们做Norm也是为了处理梯度消失，但从分析看来，transformer结构中的layernorm\\(^{+}\\)并没有完全实现它的作用。那这就意味着transformer原始结构的失败吗？并不是的，因为这种梯度消失的问题在整个结构上来看(配合上adam系优化器和学习率warmup，warmup对于post-norm极为重要) 是并不明显的。 离输入层的残差影响力弱这一特性，也有它的用武之地，比如在finetune的时候，我们就希望不要过多调整靠近输入层的参数、以免破坏预训练的效果。 ","date":"2023-03-22","objectID":"/layer-norm/:1:0","tags":["Deep","Learning","网络正则化"],"title":"Layer Norm","uri":"/layer-norm/"},{"categories":["Deep Learning","网络正则化"],"content":"warmup的重要性 Post-LN Transformer在训练的初始阶段，输出层附近的期望梯度非常大，所以，如果没有warm-up，模型优化过程就会炸裂，非常不稳定。 模型对越靠后的层越敏感，也就是越靠后的层学习得越快，然后后面的层是以前面的层的输出为输入的，前面的层根本就没学好，所以后面的层虽然学得快，但却是建立在糟糕的输入基础上的。 很快地，后面的层以糟糕的输入为基础到达了一个糟糕的局部最优点，此时它的学习开始放缓（因为已经到达了它认为的最优点附近），同时反向传播给前面层的梯度信号进一步变弱，这就导致了前面的层的梯度变得不准。但 Adam 的更新量是常数量级的，梯度不准，但更新量依然是常数量级，意味着可能就是一个常数量级的随机噪声了，于是学习方向开始不合理，前面的输出开始崩盘，导致后面的层也一并崩盘。 从上图中就可以看出来，post-ln在开始阶段层数越高梯度越大，此时需要小学习率，而当warmup完后，梯度变得很小（绿色部分）。此时可以使用大学习率。 ","date":"2023-03-22","objectID":"/layer-norm/:2:0","tags":["Deep","Learning","网络正则化"],"title":"Layer Norm","uri":"/layer-norm/"},{"categories":["Deep Learning","网络正则化"],"content":"很好的总结回答 ","date":"2023-03-22","objectID":"/layer-norm/:3:0","tags":["Deep","Learning","网络正则化"],"title":"Layer Norm","uri":"/layer-norm/"},{"categories":["Deep Learning","网络正则化"],"content":"为什么 layer norm 会使方差累积和训练不稳定 让我们来追踪一下 Pre-Norm 结构中数据 x 的方差变化： 假设我们有一个输入 \\(x_l\\)，它进入第 l 个残差块。 在 Sublayer 分支中，我们首先对 \\(x_l\\) 进行 LayerNorm。\\(LayerNorm(x_l)\\) 的输出具有严格的均值为0，方差为1 的特性。 这个归一化后的结果被送入 Sublayer（例如一个全连接网络或注意力层）。经过计算后，输出 \\(Sublayer(LayerNorm(x_l))\\) 的方差通常不再是1，我们假设它的方差是 Var(S)。 最后，这个 Sublayer 的输出被加回到原始的、未归一化的输入 \\(x_l\\) 上，得到该层的最终输出 \\(x_{l+1}\\)： \\(x_{l+1} = x_l + Sublayer(LayerNorm(x_l))\\) 现在我们来计算 x_{l+1} 的方差。在统计学中，如果两个变量（这里是 x_l 和 Sublayer(…)）大致不相关，那么它们和的方差约等于它们各自方差的和： \\(Var(x_{l+1}) ≈ Var(x_l) + Var(Sublayer(LayerNorm(x_l)))\\) \\(Var(x_{l+1}) ≈ Var(x_l) + Var(S)\\) 这个公式清晰地揭示了问题所在：每一层的输出方差 \\(Var(x_{l+1})\\) 都是在前一层方差 \\(Var(x_l)\\) 的基础上，又增加了一个正数 \\(Var(S)\\)。 因此，随着网络层数的加深（l 变大），\\(x_l\\) 的方差会像滚雪球一样不断累加，导致主干分支上的数值越来越大。这可能会在训练后期导致数值不稳定。 对比 Post-Norm： 在 Post-Norm 中，\\(x_{l+1} = LayerNorm(...)\\)。无论括号里的值 \\((x_l + Sublayer(x_l))\\) 方差多大，经过最后的 LayerNorm 后，输出 \\(x_{l+1}\\) 的方差都会被强制重置为 1。因此，Post-Norm 不存在方差累积增大的问题，但它也因此带来了训练初期不稳定、需要特殊学习率热身（warm-up）等其他问题。 Prenorm公式还意味着，流经网络主干道（即 x_0, x_1, x_2, …）的信号，其“能量”（方差）在一层层地单调递增。经过几十上百层网络后，x_l 的数值大小（即激活值）就会变得非常巨大。这就是“巨量激活值”（massive activations）的直接来源。 现在我们有了“巨量激活值”，为什么这会导致训练不稳定呢？这与反向传播和参数更新的机制有关。 产生巨量梯度 (Massive Gradients)：在反向传播计算梯度时，很多层的梯度都与其前向传播时的激活值成正比。举一个简化的例子，对于一个权重 W，它的梯度 ∂L/∂W 通常会包含一个与输入激活值 x 相乘的项。如果 x 是一个“巨量激活值”，那么计算出的梯度 ∂L/∂W 也会是一个“巨量梯度”。 破坏优化器状态 (Corrupting Optimizer State)：像 Adam 这样的现代优化器，会维护梯度的历史信息（如一阶矩和二阶矩的移动平均）。一个突然出现的巨量梯度会严重“污染”这些历史平均值，使得优化器对学习率的自适应调整产生剧烈摆动。 灾难性的参数更新 (Catastrophic Weight Updates)：优化器使用这个被污染的巨量梯度来更新模型权重：W_new = W_old - lr * massive_gradient。这个更新步长会异常巨大，相当于在复杂的损失地形上进行了一次“盲目的、大跨步的跳跃”。 损失尖峰 (Loss Spikes)：这次“大跳跃”很可能会让模型参数跳到一个非常糟糕的位置，导致模型的预测性能急剧下降，训练损失（Loss）瞬间飙升，在训练曲线上就形成了一个“尖峰”。 训练发散 (Training Divergence)：如果这个“尖峰”过于极端，参数更新可能会导致数值溢出（inf）或非法操作（NaN），整个训练过程就此崩溃，即“训练发散”。 ","date":"2023-03-22","objectID":"/layer-norm/:4:0","tags":["Deep","Learning","网络正则化"],"title":"Layer Norm","uri":"/layer-norm/"},{"categories":["Deep Learning","网络正则化"],"content":"Adam如何缓解梯度消失 其实。最关键的原因是，在当前的各种自适应优化技术“下，我们已经不大担心梯度消失问题了。这是因为，当前 NLP 中主流的优化器是 Adam 及其变种。对于 Adam 来说，由于包含了动量和二阶矩校正，所以近似来看，它的更新量大致上为 \\[\\Delta\\theta=-\\eta\\frac{\\mathbb{E}_{t}[g_{t}]}{\\sqrt{\\mathbb{E}_{t}[g_{t}^{2}]}}\\] 可以看到，分子分母是都是同量纲的，因此分式结果其实就是 (1)的量级，而更新量就是 (n)量级。也就是说，理论上只要梯度的绝对值大于随机误差，那么对应的参数都会有常数量级的更新量（意思就是参数的更新量与梯度的关系不是很大，因此受梯度消失影响较小）；这跟 SGD 不一样，SGD 的更新量是正比于梯度的，只要梯度小，更新量也会很小，如果梯度 过小，那么参数几乎会没被更新。 所以，Post Norm 的残差虽然被严重削弱，但是在 base、large 级别的模型中，它还不至于削弱到小于随机误差的地步，因此配合 Adam 等优化器，它还是可以得到有效更新的，也就有可能成功训练了。当然，只是有可能，事实上越深的 Post Norm 模型确实越难训练，比如要仔细调节学习率和 Warmup 等 ","date":"2023-03-22","objectID":"/layer-norm/:5:0","tags":["Deep","Learning","网络正则化"],"title":"Layer Norm","uri":"/layer-norm/"},{"categories":["Deep Learning","网络正则化"],"content":"Deep-norm \\(最后再提一下DeepNet中结合Post-LN^+的良好性能以及Pre-LN的训练稳定性做出的改良\\)。 \\[X_{t+1}=Norm(\\alpha X_t+F_t(X_t))\\text{(6)}\\] \\(它在add norm之前给输入乘了一个up-scale^+的常数系数 α\u003e1\\)。 现在 (5) 的展开为： \\[X_{t+1}=\\frac{\\alpha^{t+1}X_{0}}{\\sqrt{2}^{t+1}}+\\frac{\\alpha^{t}F_{0}(X_{0})}{\\sqrt{2}^{t+1}}+\\ldots+\\frac{\\alpha F_{t-1}(X_{t-1})}{\\sqrt{2}^{2}}+\\frac{F_{t}(X_{t})}{\\sqrt{2}}\\] 因为\\(\\alpha\u003e1\\) ,所以它能够在保留post-norm真正增加了深度这优点的同时，一定程度避免了梯度消失。（本质还是post-norm） ","date":"2023-03-22","objectID":"/layer-norm/:6:0","tags":["Deep","Learning","网络正则化"],"title":"Layer Norm","uri":"/layer-norm/"},{"categories":["Deep Learning","网络正则化"],"content":"参考 Transformer梳理（一）：Post-Norm VS Pre-Norm - 知乎 (zhihu.com) 模型优化漫谈：BERT的初始标准差为什么是0.02？ - 科学空间|Scientific Spaces (kexue.fm) 为什么Pre Norm的效果不如Post Norm？ - 科学空间|Scientific Spaces (kexue.fm) 香侬读 | Transformer中warm-up和LayerNorm的重要性探究 - 知乎 (zhihu.com) Bert/Transformer 被忽视的细节（或许可以用来做面试题） - 知乎 (zhihu.com) ","date":"2023-03-22","objectID":"/layer-norm/:7:0","tags":["Deep","Learning","网络正则化"],"title":"Layer Norm","uri":"/layer-norm/"},{"categories":["Deep Learning","损失函数"],"content":"在机器学习中，hinge loss是一种损失函数，它通常用于”maximum-margin”的分类任务中，如支持向量机。数学表达式为： 其中 \\(\\hat{y}\\) 表示预测输出，通常都是软结果（就是说输出不是0，1这种，可能是0.87。）， \\(y\\) 表示正确的类别。 - 如果 \\(\\hat{y}y\u003c1\\) ，则损失为： \\(1-\\hat{y}y\\) - 如果\\(\\hat{y}y\u003e1\\) ，则损失为：0 ","date":"2023-03-13","objectID":"/hinge-loss/:0:0","tags":["Deep Learning","损失函数","hinge loss"],"title":"hinge loss","uri":"/hinge-loss/"},{"categories":["面经"],"content":"前几天试着投了简历，没想到有两家约了面试，一个是得物一个是北京百分点，得物面试没有怎么准备，太仓促了，二面挂了，百分点拿到了offer，但决定考研了就没去，记录一下面试的问题。岗位是nlp算法岗。 ","date":"2023-03-10","objectID":"/%E5%8C%97%E4%BA%AC%E7%99%BE%E5%88%86%E7%82%B9%E9%9D%A2%E7%BB%8F/:0:0","tags":["面经"],"title":"北京百分点面经","uri":"/%E5%8C%97%E4%BA%AC%E7%99%BE%E5%88%86%E7%82%B9%E9%9D%A2%E7%BB%8F/"},{"categories":["面经"],"content":"一面：技术面 先自我介绍，然后介绍了一下项目。根据印象提问有以下内容： 有没有数据不平衡问题，是怎么解决的？欠采样，过采样，focal loss，着重介绍了一下focal loss的参数含义。 对分类问题最后一层要怎么做：max、mean，全连接 有没有尝试过别的模型：没有，然后面试官说其实textcnn和fasttext效果不一定比bert效果差。 对传统的神经网络了解吗？了解。介绍一下lstm。按照三个门分析就行，哪个门是什么作用，注意一下激活函数的不同。 介绍一下bert，从输入开始介绍就行，把两个任务也展开说一下。 介绍一下tfidf，这个很简单，说一下tf和idf的含义和公式就行。 数据增强怎么做的？同义词替换、回译。 介绍一下提示学习。说一下主要思想，还有离散prompts和连续prompts。 大体就记得问了这些，总体来说不是很难，而且大多数都是神经网络相关的，准备了一些传统的机器学习方法也没有用上。 然后是两道算法题： 第一题：已知一随机发生器，产生0的概率是p，产生1的概率是1-p， 现在要你构造一个发生器， 使得它构造0和1的概率均为 1/2； def res(): a = random() b = random() if a == 0 and b == 1: return 0 if a == 1 and b == 0: return 1 else: return res() 由于需要产生1/2，而用1位0，或1位1无法产生等概率， 因此，考虑将随机数扩展成2位： 00 pp 01 p(1-p) 10 (1-p)p 11 (1-p)(1-p) 有上述分析知道，01和10是等概率的，因此我们只需要产生01和10就行了。 于是可以，遇到00和11就丢弃，只记录01和10。可以令，01表示0,10表示1，则等概率1/2产生0和1了。 当时面试官问了这个问题的时候有点懵，因为之前从来没有做过，但是经过面试官的提示也是写出来了。 第二题是LCS问题，就是最长公共子序列问题，当时想到了使用动态规划，但是懒得在纸上推转移方程了，就直接暴力解决了。 def LCS(s1, s2): dp = [[0 for _ in range(len(s1))] for _ in range(len(s2))] res = 0 for i in range(len(s1)): for j in range(i, len(s2)): if s1[i:j+1] in s2: res = max(res, j+1-i) return res print(LCS(\"baced\", \"acefg\")) ","date":"2023-03-10","objectID":"/%E5%8C%97%E4%BA%AC%E7%99%BE%E5%88%86%E7%82%B9%E9%9D%A2%E7%BB%8F/:1:0","tags":["面经"],"title":"北京百分点面经","uri":"/%E5%8C%97%E4%BA%AC%E7%99%BE%E5%88%86%E7%82%B9%E9%9D%A2%E7%BB%8F/"},{"categories":["面经"],"content":"二面综合面 上来也是自我介绍加项目介绍，有些问题和一面重复了，就不赘述。 介绍几种bert的变体，albert、roberta，就介绍了这两种。 bert的mask策略。 具体的也忘了，当时也没有想直接记录下来，后面就等到了口头offer，过几天也发了正式offer，但是因为要考研等一些原因就拒了，等考完研再找吧。这次只在软件上投了投简历，没有内推等，还是挺有收获的。 ","date":"2023-03-10","objectID":"/%E5%8C%97%E4%BA%AC%E7%99%BE%E5%88%86%E7%82%B9%E9%9D%A2%E7%BB%8F/:2:0","tags":["面经"],"title":"北京百分点面经","uri":"/%E5%8C%97%E4%BA%AC%E7%99%BE%E5%88%86%E7%82%B9%E9%9D%A2%E7%BB%8F/"},{"categories":["面经"],"content":"总结 这几轮面试还是很有收获的，也算是模拟了以后的考研复试，虽然以后大概率是线下复试了。还有就是简历上最最重要的就是实习经历，我之前也没有实习经历，因此没有实习经历的情况下最重要的就是项目，别的基本上都没有问，不过还是要保证你写上去的都是真的会的。因此重要的就是实习和项目，获奖经历可能只是给面试的机会更大一些。这次拒绝offer少了一次实习经历还算有点可惜，不过相对而言还是考研重要一些。 ","date":"2023-03-10","objectID":"/%E5%8C%97%E4%BA%AC%E7%99%BE%E5%88%86%E7%82%B9%E9%9D%A2%E7%BB%8F/:3:0","tags":["面经"],"title":"北京百分点面经","uri":"/%E5%8C%97%E4%BA%AC%E7%99%BE%E5%88%86%E7%82%B9%E9%9D%A2%E7%BB%8F/"},{"categories":["算法题","串"],"content":"KMP是字符串匹配问题的算法。“字符串A是否为字符串B的子串?如果是的话出现在B的哪些位置?”该问题就是字符串匹配问题，字符串A称为模式串，字符串B称为主串。 ## BF算法 BF算法就是暴力匹配，即对主串从头开始慢慢移动模式串，直到找到相匹配的位置。 代码很简单暴力： 假设n为主串长度，m为模式串长度。 每一轮字符串比较：最差的情况为模式串最后一个字与主串不同其他都相同（如模式串为AAB，主串对应部分为AAC），必须走完整个字符串才能得出结果，因此复杂度为O(m)。 所有轮字符串比较：最差的情况是移动到最后一次比较才寻找得到，总共需要n-m+1次，主串通常比模式串长很多，故Brute-Force时间复杂度为O(nm) 在匹配上没有办法进行优化，因此可以从模式串的移动上入手，由此引入了Kmp算法。 ","date":"2023-03-08","objectID":"/kmp/:0:0","tags":["算法题","串"],"title":"KMP","uri":"/kmp/"},{"categories":["算法题","串"],"content":"KMP KMP 算法的不同之处在于，它会花费空间来记录一些信息。目的就是为了减少匹配的趟数，算法的核心就是每次匹配过程中推断出后续完全不可能匹配成功的匹配过程，从而减少比较的趟数。 ","date":"2023-03-08","objectID":"/kmp/:1:0","tags":["算法题","串"],"title":"KMP","uri":"/kmp/"},{"categories":["算法题","串"],"content":"Next数组 next数组实质上就是找出模式串中前后字符重复出现的个数，为了能够跳跃不可能匹配的步骤。 next数组的定义为：next[i]表示模式串A[0]至A[i]这个字串，使得前k个字符等于后k个字符的最大值，特别的k不能取i+i,因为字串一共才i+1个字符，自己跟自己相等毫无意义。 如何确定在移动过程中需要跳过多少步呢？下图更直观的体现了跳跃的过程： 也就是跳到模式串中的后缀相同字符串开始。因为这时可以确定前面的字符串肯定无法匹配了，过的趟数=匹配上字符串中间字符长度-重复字符串长度 在实际代码编写中，移动的实际上是模式串的匹配位置。前面展示的只是理解减小匹配次数这一过程。实际上跳动就是模式串比较指针的移动。模式串向右移动也就是比较指针向左移动，移动的距离就是跳过的趟数 移动后的指针为：\\(j=j-(j-next[j-1]) =next[j-1]\\) 其中原来的j为匹配成功的字符串长度，也就是匹配失败的指针位置。next[j-1]就是匹配成功的字符串的最长相同前后缀数，也就是要跳转到的指针的下标。（下标从0开始的，如果下标从1开始则在原来基础上+1就是要跳转到的位置，这也是为什么书上要+1）。 即下图所示。 然后再用移动后的指针和主串的上一轮匹配错误的位置相比，这时已经保证了前面的字符已经匹配了，即当前指针前面的子串已经和上一轮匹配成功的子串的最长后缀相同了。 因此可以看到，Kmp算法的核心就是构造Next数组。 最简单的方法就是根据定义暴力构造时间复杂度为O(m2法)：： 第二种构建方案，是一种递推的方式进行构建，时间复杂度为O(n+m): 考虑：如果next[0], next[1], … next[x-1]均已知，那么如何求出 next[x] ？我们已经知道next[x-1],标记next[x-1]=temp,则可以讨论A[temp]和A[x]的值，分2种情况讨论： 第一种情况：A[temp]等于A[x]，也就是说在前一个next结果上又多了一个字符串相同的长度，因此next[x]为next[x-1]+1 这种情况说明了x-1时最长前缀的后一位和x位置的字符相同，则说明了前缀和后缀都增加了相同的1位，next[x] = next[x-1] + 1。 （这里给一下我自己的理解，因为next中保存的是前后缀最大相同的长度，因此通常代表着最大相同前缀的后一位） 第二种情况：当A[temp]和A[x]不相等的时候，我们需要缩小temp,把temp变成next[temp-1]，直到A[temp]=A[x]为止。A[now]=A[x]时，就可以直接向右扩展了。 如何理解这张图，当发现A[temp] != A[x]的时候，就一直缩小temp，也就是temp = next[temp-1]，也就是找原来的最长前缀中对应的next[temp-1]，因为前缀中的相同前后缀最大长度（图中为2）肯定也与后缀中的相同前后缀最大长度（图中为2）相同，也说明了前缀中的前缀（图中为0和1上的A和B）等于后缀中的后缀（图中为10和11上的A和B），此时还是原来的思路temp为前缀中的前缀的下一位，判断是否与后缀中的后缀的下一位相同（就是当前的A[x]），如果相同就是第一种情况，next[x] = temp + 1，如果一直没找到则设为0，说明没有。 学到这不得不感叹kmp三位大佬的恐怖。。 大体的思想就是这样，不过如果对于做题来说的话，有很多不一样的地方，比如王道书上的next数组是从下标1开始的，对于本文的内容，需要得到匹配失败位置-1的next数组值，因此书上将整体右移了一位，开头补上了-1，这样匹配失败的位置就是对应的next数组值。又下一次匹配要从最长前缀的下一位开始，而对于下标从0开始，next数组值就是下一位（前面解释了），而对于下标从1开始，需要再+1才是对应下标，因此也对next数组最后进行了+1操作。不管怎么样，next的含义都是最长前缀的下一个位置。主要思想都是一样的，随机应变即可。 ","date":"2023-03-08","objectID":"/kmp/:1:1","tags":["算法题","串"],"title":"KMP","uri":"/kmp/"},{"categories":["算法题","串"],"content":"代码： class KMP: def __init__(self, text, pattern) -\u003e None: self.text = text self.pattern = pattern self.next = [] def init_next(self): self.next.append(0) # first for i, s in enumerate(self.pattern[1:], 1): tmp = self.next[i-1] if s == self.pattern[tmp]: self.next.append(tmp + 1) else: while self.pattern[tmp] != s and tmp != 0: tmp = self.next[tmp-1] if tmp == 0 and self.pattern[tmp] != s: self.next.append(0) continue self.next.append(tmp + 1) def search(self): i = 0 # text index j = 0 # partten index while i \u003c len(self.text): if self.text[i] == self.pattern[j]: i += 1 j += 1 elif j: j = self.next[j-1] else: i += 1 if j == len(self.pattern): return i - j return -1 kmp = KMP(\"hello\", \"ll\") kmp.init_next() print(kmp.search()) print(kmp.next) ","date":"2023-03-08","objectID":"/kmp/:1:2","tags":["算法题","串"],"title":"KMP","uri":"/kmp/"},{"categories":["算法题","串"],"content":"nextval 还有一种改进的next，因为匹配错误的位置重新移动指针后的位置的值可能与原来的值相同，因此在构建next数组的时候可以直接跳转到不相同的位置，这样就减小了重复的比较。 比如aaabaaaab和aaaab，当在主串中第一个b位置出错时，此时模式串为a，会比较str[next[2]]与b，但此时str[next[2]]也是a，再次比较也会错误，但再移动后发现还是a还是错误，这些比较都是没有意义的，最后要移动到模式串开头，然后将主串指针+1再比较，所以构建nextval减少了这些比较。 我是根据已经构建好的next数组推理来的。代码如下： def create_nextval(self): length = len(self.pattern) self.nextval = [0] * length for i in range(1, len(self.next)): tmp = self.next[i-1] if self.pattern[tmp] != self.pattern[i]: self.nextval[i-1] = tmp else: while tmp and self.pattern[tmp] == self.pattern[i]: tmp = self.next[tmp-1] self.nextval[i-1] = tmp 因为用不到最后一位的数值，所以考研书上就直接全部右移一位，理论上都是相同的。原理就是匹配错误的位置的字符和要跳转到的位置的字符相同的话就要继续跳转直到等于0或者不相同为止。 ","date":"2023-03-08","objectID":"/kmp/:1:3","tags":["算法题","串"],"title":"KMP","uri":"/kmp/"},{"categories":["Machine Learning"],"content":"特征选择是特征工程里的一个重要问题，其目标是寻找最优特征子集。特征选择能剔除不相关(irrelevant)或冗余(redundant )的特征，从而达到减少特征个数，提高模型精确度，减少运行时间的目的。另一方面，选取出真正相关的特征简化模型，协助理解数据产生的过程。并且常能听到“数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已”，由此可见其重要性。但是它几乎很少出现于机器学习书本里面的某一章。然而在机器学习方面的成功很大程度上在于如果使用特征工程。 根据特征选择的形式，可分为三大类： - Filter(过滤法)：按照发散性或相关性对各个特征进行评分，设定阈值或者待选择特征的个数进行筛选 - Wrapper(包装法)：根据目标函数（往往是预测效果评分），每次选择若干特征，或者排除若干特征 - Embedded(嵌入法)：先使用某些机器学习的模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征（类似于Filter，只不过系数是通过训练得来的） ## 过滤式 基本想法是：分别对每个特征 \\(x_i\\) ，计算 \\(x_i\\) 相对于类别标签 y 的信息量 S(i) ，得到 n 个结果。然后将 n 个 S(i) 按照从大到小排序，输出前 k 个特征。显然，这样复杂度大大降低。那么关键的问题就是使用什么样的方法来度量 S(i) ，我们的目标是选取与 y 关联最密切的一些 特征\\(x_i\\) 。 - Pearson相关系数 - 卡方验证 - 互信息和最大信息系数 - 距离相关系数 - 方差选择法 ### ","date":"2023-03-08","objectID":"/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/:0:0","tags":["Machine Learning","特征选择"],"title":"特征选择","uri":"/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/"},{"categories":["Machine Learning"],"content":"包裹式 ","date":"2023-03-08","objectID":"/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/:1:0","tags":["Machine Learning","特征选择"],"title":"特征选择","uri":"/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/"},{"categories":["Machine Learning"],"content":"嵌入式 ","date":"2023-03-08","objectID":"/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/:2:0","tags":["Machine Learning","特征选择"],"title":"特征选择","uri":"/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/"},{"categories":["Deep Learning","训练trick"],"content":"介绍 早停止（Early Stopping）是 当达到某种或某些条件时，认为模型已经收敛，结束模型训练，保存现有模型的一种手段。 如何判断已经收敛？主要看以下几点： - 验证集上的Loss在模型多次迭代后，没有下降 - 验证集上的Loss开始上升。 这时就可以认为模型没有必要训练了，可以停止了，因为训练下去可能就会发生过拟合，所以早停法是一种防止模型过拟合的方法。 ","date":"2023-03-06","objectID":"/early-stopping/:1:0","tags":["Deep Learning","训练trick","early-stopping"],"title":"early-stopping","uri":"/early-stopping/"},{"categories":["Deep Learning","训练trick"],"content":"代码 import numpy as np import torch import os class EarlyStopping: \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\" def __init__(self, save_path, patience=7, verbose=False, delta=0): \"\"\" Args: save_path : 模型保存文件夹 patience (int): How long to wait after last time validation loss improved. Default: 7 verbose (bool): If True, prints a message for each validation loss improvement. Default: False delta (float): Minimum change in the monitored quantity to qualify as an improvement. Default: 0 \"\"\" self.save_path = save_path self.patience = patience self.verbose = verbose self.counter = 0 self.best_score = None self.early_stop = False self.val_loss_min = np.Inf self.delta = delta def __call__(self, val_loss, model): score = -val_loss if self.best_score is None: self.best_score = score self.save_checkpoint(val_loss, model) elif score \u003c self.best_score + self.delta: self.counter += 1 print(f'EarlyStopping counter: {self.counter} out of {self.patience}') if self.counter \u003e= self.patience: self.early_stop = True else: self.best_score = score self.save_checkpoint(val_loss, model) self.counter = 0 def save_checkpoint(self, val_loss, model): '''Saves model when validation loss decrease.''' if self.verbose: print(f'Validation loss decreased ({self.val_loss_min:.6f} --\u003e {val_loss:.6f}). Saving model ...') path = os.path.join(self.save_path, 'best_network.pth') torch.save(model.state_dict(), path) # 这里会存储迄今最优模型的参数 self.val_loss_min = val_loss ","date":"2023-03-06","objectID":"/early-stopping/:2:0","tags":["Deep Learning","训练trick","early-stopping"],"title":"early-stopping","uri":"/early-stopping/"},{"categories":["Deep Learning","损失函数"],"content":"Focal Loss Focal Loss主要是为了解决类别不平衡的问题，Focal Loss可以运用于二分类，也可以运用于多分类。下面以二分类为例： ","date":"2023-03-06","objectID":"/focal-loss/:0:0","tags":["Deep Learning","损失函数","focal loss"],"title":"focal loss","uri":"/focal-loss/"},{"categories":["Deep Learning","损失函数"],"content":"原始Loss 原始的二分类： 其中 所以： 很容易理解，因为CE就是softmax在二分类的形式，实际运算中只关注对应标签的概率，对于二分类，如果是负样本的话，预测概率小于0.5则说明预测正确，则对应的实际的概率应该为1-p。最大化概率，就是最大化Log概率，也就是最小化-log概率。 ","date":"2023-03-06","objectID":"/focal-loss/:0:1","tags":["Deep Learning","损失函数","focal loss"],"title":"focal loss","uri":"/focal-loss/"},{"categories":["Deep Learning","损失函数"],"content":"什么是易分类样本 对于正样本，如果预测的结果总是在0.5以上，就是易分类样本，如果总是在0.5以下，则说明是难分类样本。 对于负样本，如果预测的结果总是在0.5以下，就是易分类样本，如果总是在0.5以上，则说明是难分类样本。 对应\\(p_t\\)来说，就是\\(p_t\u003e0.5\\)为易分类，\\(p_t\u003c0.5\\)为难分类。 ","date":"2023-03-06","objectID":"/focal-loss/:0:2","tags":["Deep Learning","损失函数","focal loss"],"title":"focal loss","uri":"/focal-loss/"},{"categories":["Deep Learning","损失函数"],"content":"gamma参数 在模型训练的时候，我们更希望关注难分类的样本，因此focal loss在原始loss上增加了一项，对整体进行了衰减： 对于公式中的参数\\(\\gamma\\)，一般会选择2，对于易分类的样本，即\\(p_t\u003e0.5\\)的样本，\\(1-p_t\\)则会小于0.5，则loss会衰减的更多，最终的损失就变的很小。而对于难分类的样本，loss会衰减的比较小，通过这种衰减的对比，则变相增加了模型对于难分类样本的权重。 ","date":"2023-03-06","objectID":"/focal-loss/:0:3","tags":["Deep Learning","损失函数","focal loss"],"title":"focal loss","uri":"/focal-loss/"},{"categories":["Deep Learning","损失函数"],"content":"alpha参数 对于二分类任务，负样本的数量远远多于正样本，导致模型更多关注在负样本上，忽略正样本。因此在使用交叉熵损失的时候通常会增加一个平衡参数用来调节正负样本的比重。 所以会增加一个平衡参数来调节正负样本的比重。 其实这就是balanced cross entropy，可以将它引入focal loss 在式子中，\\(\\gamma\\)占据了主导地位，因此其实不用太在意\\(\\alpha\\)的数值。 ","date":"2023-03-06","objectID":"/focal-loss/:0:4","tags":["Deep Learning","损失函数","focal loss"],"title":"focal loss","uri":"/focal-loss/"},{"categories":["Deep Learning","损失函数"],"content":"对于多分类 对于多分类任务，其实是一样的，因为如果一个类别的样本预测结果总是大于0.5，也说明它是易分类的，对于平衡因子，在实现的时候，可以提前设置好各类别的平衡因子，对于每一个类别都有一个对应的。 ","date":"2023-03-06","objectID":"/focal-loss/:1:0","tags":["Deep Learning","损失函数","focal loss"],"title":"focal loss","uri":"/focal-loss/"},{"categories":["Deep Learning","损失函数"],"content":"为什么有效 focal loss从样本难易分类角度出发，解决样本非平衡带来的模型训练问题。 直觉上来讲样本非平衡造成的问题就是样本数少的类别分类难度较高。因此从样本难易分类角度出发，使得loss聚焦于难分样本，解决了样本少的类别分类准确率不高的问题，当然难分样本不限于样本少的类别，也就是focal loss不仅仅解决了样本非平衡的问题，同样有助于模型的整体性能提高。 ","date":"2023-03-06","objectID":"/focal-loss/:2:0","tags":["Deep Learning","损失函数","focal loss"],"title":"focal loss","uri":"/focal-loss/"},{"categories":["Deep Learning","损失函数"],"content":"思考 难分类样本与易分类样本其实是一个动态概念，也就是说 p 会随着训练过程而变化。原先易分类样本即 p大的样本，可能随着训练过程变化为难训练样本即p小的样本。 上面讲到，由于Loss梯度中，难训练样本起主导作用，即参数的变化主要是朝着优化难训练样本的方向改变。当参数变化后，可能会使原先易训练的样本 p 发生变化，即可能变为难训练样本。当这种情况发生时，可能会造成模型收敛速度慢，正如苏剑林在他的文章中提到的那样。 为了防止难易样本的频繁变化，应当选取小的学习率。 ## 代码 ### 二分类 class Focal_Loss(): \"\"\" 二分类Focal Loss \"\"\" def __init__(self,alpha=0.25,gamma=2): super(Focal_Loss,self).__init__() self.alpha=alpha self.gamma=gamma def forward(self,preds,labels): \"\"\" preds:sigmoid的输出结果 labels：标签 \"\"\" eps=1e-7 loss_1=-1*self.alpha*torch.pow((1-preds),self.gamma)*torch.log(preds+eps)*labels loss_0=-1*(1-self.alpha)*torch.pow(preds,self.gamma)*torch.log(1-preds+eps)*(1-labels) loss=loss_0+loss_1 return torch.mean(loss) ","date":"2023-03-06","objectID":"/focal-loss/:3:0","tags":["Deep Learning","损失函数","focal loss"],"title":"focal loss","uri":"/focal-loss/"},{"categories":["Deep Learning","损失函数"],"content":"多分类 class Focal_Loss(): def __init__(self,weight,gamma=2): super(Focal_Loss,self).__init__() self.gamma=gamma self.weight=weight def forward(self,preds,labels): \"\"\" preds:softmax输出结果 labels:真实值 \"\"\" eps=1e-7 y_pred =preds.view((preds.size()[0],preds.size()[1],-1)) #B*C*H*W-\u003eB*C*(H*W) target=labels.view(y_pred.size()) #B*C*H*W-\u003eB*C*(H*W) ce=-1*torch.log(y_pred+eps)*target floss=torch.pow((1-y_pred),self.gamma)*ce floss=torch.mul(floss,self.weight) floss=torch.sum(floss,dim=1) return torch.mean(floss) ","date":"2023-03-06","objectID":"/focal-loss/:3:1","tags":["Deep Learning","损失函数","focal loss"],"title":"focal loss","uri":"/focal-loss/"},{"categories":["Deep Learning","损失函数"],"content":"参考 https://zhuanlan.zhihu.com/p/266023273 ","date":"2023-03-06","objectID":"/focal-loss/:4:0","tags":["Deep Learning","损失函数","focal loss"],"title":"focal loss","uri":"/focal-loss/"},{"categories":["Deep Learning","训练trick"],"content":"在训练开始的时候，如果学习率太高的话，可能会导致loss来回跳动，会导致无法收敛，因此在训练开始的时候就可以设置一个很小的learning rate，然后随着训练的批次增加，逐渐增大学习率，直到达到原本想要设置的学习率。 关于warmup的好处，有： - 有助于减缓模型在初始阶段对mini-batch的提前过拟合现象，保持分布的平稳 - 有助于保持模型深层的稳定性。 warmup有助于网络的收敛，当达到预期的学习率时，之后的步骤就可以每固定批次进行学习率衰减，防止过拟合，以慢慢达到收敛。 ","date":"2023-03-05","objectID":"/warmup/:0:0","tags":["Deep Learning","训练trick","warmup"],"title":"warmup","uri":"/warmup/"},{"categories":["Deep Learning","训练trick"],"content":"神经网络会促使自身往正确标签和错误标签差值最大的方向学习，在训练数据较少，不足以表征所有的样本特征的情况下，会导致网络过拟合。因为onehot本身就是一个稀疏的向量，如果所有无关类别都为0的话，就可能会疏忽某些类别之间的联系。 具体的缺点有： - 真是标签与其它标签之间的关系被忽略了，很多有用的知识学不到了。 - 倾向于让模型更加武断，导致泛化性能差 - 面对有噪声的数据更容易收到影响。 label smoothing可以解决上述问题，这是一种正则化策略，主要是通过soft one-hot来加入噪声，减少了真实样本标签的类别在计算损失函数时的权重，最终起到抑制过拟合的效果。 增加label smoothing后真实的概率分布有如下改变： ","date":"2023-03-05","objectID":"/%E6%A0%87%E7%AD%BE%E5%B9%B3%E6%BB%91/:0:0","tags":["Deep Learning","训练trick","标签平滑"],"title":"标签平滑","uri":"/%E6%A0%87%E7%AD%BE%E5%B9%B3%E6%BB%91/"},{"categories":["Deep Learning","训练trick"],"content":" 基本原则：快速试错。 小步试错，快速迭代 可以试试无脑的配置 实时打印一些结果 自动调参：网格搜索、random search、贝叶斯优化、 参数初始化 学习率warmup，慢慢增加，然后学习率衰减。 batch_size和lr 大的batchsize收敛到sharp minimum，而小的batchsize收敛到flat minimum，后者具有更好的泛化能力。两者的区别就在于变化的趋势，一个快一个慢，如下图，造成这个现象的主要原因是小的batchsize带来的噪声有助于逃离sharp minimum。 大的batchsize性能下降是因为训练时间不够长，本质上并不少batchsize的问题，在同样的epochs下的参数更新变少了，因此需要更长的迭代次数。 如果增加了学习率，那么batch size最好也跟着增加，这样收敛更稳定。 尽量使用大的学习率，因为很多研究都表明更大的学习率有利于提高泛化能力。如果真的要衰减，可以尝试其他办法，比如增加batch size，学习率对模型的收敛影响真的很大，慎重调整。 ","date":"2023-03-02","objectID":"/%E8%B0%83%E5%8F%82%E6%8A%80%E5%B7%A7/:0:0","tags":["Deep Learning","训练trick","调参技巧"],"title":"调参技巧","uri":"/%E8%B0%83%E5%8F%82%E6%8A%80%E5%B7%A7/"},{"categories":["Deep Learning","训练trick"],"content":"总结 学习率直接影响模型的收敛状态，batchsize则影响模型的泛化性能 ","date":"2023-03-02","objectID":"/%E8%B0%83%E5%8F%82%E6%8A%80%E5%B7%A7/:1:0","tags":["Deep Learning","训练trick","调参技巧"],"title":"调参技巧","uri":"/%E8%B0%83%E5%8F%82%E6%8A%80%E5%B7%A7/"},{"categories":["Deep Learning","训练trick"],"content":"Min-Max公式 $$ {} {(x,y) }U[{r{adv}}L(,x+r_{adv},y)] $$ 内部max是为了找到worst-case的扰动，也就是攻击，其中， \\(L\\)为损失函数， \\(\\mathbb{S}\\) 为扰动的范围空间。 外部min是为了基于该攻击方式，找到最鲁棒的模型参数，也就是防御，其中 \\(\\mathbb{D}\\) 是输入样本的分布。 简单理解就是在输入上进行梯度上升(增大loss)，在参数上进行梯度下降(减小loss) 加入扰动后的损失函数 $$ {} -P(y |x+r{adv};) \\[ 那扰动要如何计算呢？Goodfellow认为，**神经网络由于其线性的特点，很容易受到线性扰动的攻击。** # Fast Gradient Sign Method (FGSM) \\] r_{adv} = sgn(_{x}L(,x,y)) $$ # FGM ## 代码 代码来自[1]，注意的是一般扰动加在了embedding矩阵上，相当于x+r。 import torch class FGM(): def __init__(self, model): self.model = model self.backup = {} def attack(self, epsilon=1., emb_name='emb.'): # emb_name为embedding矩阵参数对应名 for name, param in self.model.named_parameters(): if param.requires_grad and emb_name in name: self.backup[name] = param.data.clone() norm = torch.norm(param.grad) if norm != 0 and not torch.isnan(norm): r_at = epsilon * param.grad / norm param.data.add_(r_at) def restore(self, emb_name='emb.'): for name, param in self.model.named_parameters(): if param.requires_grad and emb_name in name: assert name in self.backup param.data = self.backup[name] self.backup = {} 使用时： # 初始化 fgm = FGM(model) for batch_input, batch_label in data: # 正常训练 loss = model(batch_input, batch_label) loss.backward() # 反向传播，得到正常的grad # 对抗训练 fgm.attack() # 在embedding上添加对抗扰动 loss_adv = model(batch_input, batch_label) loss_adv.backward() # 反向传播，并在正常的grad基础上，累加对抗训练的梯度 fgm.restore() # 恢复embedding参数 # 梯度下降，更新参数 optimizer.step() model.zero_grad() 参考文献 【炼丹技巧】功守道：NLP中的对抗训练 + PyTorch实现 - 知乎 (zhihu.com) ","date":"2023-03-02","objectID":"/%E5%AF%B9%E6%8A%97%E8%AE%AD%E7%BB%83/:0:0","tags":["Deep","Learning","训练trick","对抗训练"],"title":"对抗训练","uri":"/%E5%AF%B9%E6%8A%97%E8%AE%AD%E7%BB%83/"},{"categories":["Deep Learning","训练trick"],"content":"数据不均衡 所谓的不平衡指的是不同类别的样本量差异非常大，或者少数样本代表了业务的关键数据（少量样本更重要），需要对少量样本的模式有很好的学习。样本类别分布不平衡主要出现在分类相关的建模问题上。样本类别分布不平衡从数据规模上可以分为大数据分布不平衡和小数据分布不平衡两种。 大数据分布不均衡。这种情况下整体数据规模大，只是其中的少样本类的占比较少。但是从每个特征的分布来看，小样本也覆盖了大部分或全部的特征。例如拥有1000万条记录的数据集中，其中占比50万条的少数分类样本便于属于这种情况。 小数据分布不均衡。这种情况下整体数据规模小，并且占据少量样本比例的分类数量也少，这会导致特征分布的严重不平衡。例如拥有1000条数据样本的数据集中，其中占有10条样本的分类，其特征无论如何拟合也无法实现完整特征值的覆盖，此时属于严重的数据样本分布不均衡。 如果不同分类间的样本量差异达到超过10倍就需要引起警觉并考虑处理该问题，超过20倍就要一定要解决该问题。 主要有三种解决方法： - 欠采样：在少量样本数量不影响模型训练的情况下，可通过对多数类样本欠采样，实现少数样本和多数样本均衡。 - 过采样：在少量样本数量不支持模型训练的情况下，可以通过对少数类样本过采样，实现少数样本和多数样本的均衡。 - 模型算法：通过引入有权重的模型算法，针对少量样本着重拟合，以提升对少量样本特征的学习。 ","date":"2023-03-02","objectID":"/%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1/:1:0","tags":["Deep Learning","训练trick","数据不平衡"],"title":"数据不平衡","uri":"/%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1/"},{"categories":["Deep Learning","训练trick"],"content":"欠采样 通过减少分类中多数类样本的样本数量来实现样本均衡。通过欠采样，在保留少数类样本的同时，会丢失多数样本中的一些信息。经过欠采样，样本数量在变少。因此我个人并不倾向于这种方法。 ","date":"2023-03-02","objectID":"/%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1/:2:0","tags":["Deep Learning","训练trick","数据不平衡"],"title":"数据不平衡","uri":"/%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1/"},{"categories":["Deep Learning","训练trick"],"content":"随机法 随机的删除一些多数类样本，使少数类样本和多数类样本数量达到均衡。 ","date":"2023-03-02","objectID":"/%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1/:2:1","tags":["Deep Learning","训练trick","数据不平衡"],"title":"数据不平衡","uri":"/%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1/"},{"categories":["Deep Learning","训练trick"],"content":"原型生成 PG 算法主要是在原有样本的基础上生成新的样本来实现样本均衡，对多数类样本生成新的样本去替代原样本，使得样本数目减少, 具体做法如下： ","date":"2023-03-02","objectID":"/%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1/:2:2","tags":["Deep Learning","训练trick","数据不平衡"],"title":"数据不平衡","uri":"/%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1/"},{"categories":["Deep Learning","训练trick"],"content":"原型选择 原理：从多数类样本中选取最具代表性的样本用于训练，主要是为了缓解随机欠采样中的信息丢失问题。 NearMiss 采用一些启发式的规则来选择样本，根据规则的不同可分为 3 类,通过设定 version 参数来确定： - NearMiss-1：选择到最近的 K 个少数类样本平均距离最近的多数类样本 - NearMiss-2：选择到最远的 K 个少数类样本平均距离最近的多数类样本 - 3: 对于每个少数类样本选择 K 个最近的多数类样本，目的是保证每个少数类样本都被多数类样本包围 ","date":"2023-03-02","objectID":"/%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1/:2:3","tags":["Deep Learning","训练trick","数据不平衡"],"title":"数据不平衡","uri":"/%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1/"},{"categories":["Deep Learning","训练trick"],"content":"过采样 过采样（over-sampling）方法通过增加分类中少数的数量来实现样本均衡，最直接的方法是简单的复制少数类样本形成多条记录，这种方式可能导致样本特征少而可能出现过拟合的问题。经过改进的过抽样方法通过在少数类中加入随机噪声、干扰数据或者通过一定规则产生新的合成样本。 ","date":"2023-03-02","objectID":"/%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1/:3:0","tags":["Deep Learning","训练trick","数据不平衡"],"title":"数据不平衡","uri":"/%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1/"},{"categories":["Deep Learning","训练trick"],"content":"随机复制 就是随机选择少量样本进行复制。 ","date":"2023-03-02","objectID":"/%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1/:3:1","tags":["Deep Learning","训练trick","数据不平衡"],"title":"数据不平衡","uri":"/%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1/"},{"categories":["Deep Learning","训练trick"],"content":"SMOTE 在随机过采样的基础上，通过样本构造一方面降低了直接复制样本代理的过拟合的风险，另一方法实现了样本的均衡。比如样本构造方法 SMOTE（Synthetic minority over-sampling technique）及其衍生算法。 ","date":"2023-03-02","objectID":"/%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1/:3:2","tags":["Deep Learning","训练trick","数据不平衡"],"title":"数据不平衡","uri":"/%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1/"},{"categories":["Deep Learning","训练trick"],"content":"模型算法 ","date":"2023-03-02","objectID":"/%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1/:4:0","tags":["Deep Learning","训练trick","数据不平衡"],"title":"数据不平衡","uri":"/%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1/"},{"categories":["Deep Learning","训练trick"],"content":"cost sensitive算法 ","date":"2023-03-02","objectID":"/%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1/:4:1","tags":["Deep Learning","训练trick","数据不平衡"],"title":"数据不平衡","uri":"/%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1/"},{"categories":["Deep Learning","训练trick"],"content":"focal loss 可以查看本博客focal loss内容Focal Loss ","date":"2023-03-02","objectID":"/%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1/:4:2","tags":["Deep Learning","训练trick","数据不平衡"],"title":"数据不平衡","uri":"/%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1/"},{"categories":["Deep Learning","GAN系列"],"content":"简介 生成对抗网络（Generative Adversarial Network，简称GAN）是无监督学习的一种方法，通过让两个神经网络相互博弈的方式进行学习。 大白话： 说就是生成对抗网络有一个生成网络和一个判别网络，假设有一个真实数据和一个生成网络生成的假数据，那么判别网络就是识别出这两种数据，判别网络努力分类成功，生成网络努力生成和真实数据相似的数据使判别网络分类不出来。这就是所说的相互博弈的方式。 专业的话： 生成式对抗网络由生成器和判别器构成。生成对抗网络的核心目的是训练生成器。生成器的目的是生成与真实样本尽可能相似的“假样本”，判别器的目的是尽可能区分出给定样本是真实样本还是生成的“假样本”。二者目的相悖，在不断博弈的过程中相互提高，最终在判别器判别能力足够可靠的前提下仍无法区分给定样本是真实样本还是生成样本，从而我们说生成器能够生成“以假乱真”的样本。 ","date":"2022-12-22","objectID":"/gan/:1:0","tags":["Deep Learning","GAN系列","GAN"],"title":"GAN","uri":"/gan/"},{"categories":["Deep Learning","GAN系列"],"content":"优化 优化目标 - 价值函数 (Value Function) \\(\\min_G \\max_D V(D, G)=\\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\text {data }}(\\boldsymbol{x})}[\\log D(\\boldsymbol{x})]+\\mathbb{E}_{\\boldsymbol{z} \\sim p_{\\boldsymbol{z}}(\\boldsymbol{z})}[\\log (1-D(G(\\boldsymbol{z})))]\\) - 优化方式 - 生成器优化方向: 最小化价值函数 - 判别器优化方向: 最大化价值函数 简单理解，判别器就是要使正确的样本分为1，生成的样本分为0，那么就是最大化价值函数。 生成器就是要以假乱真，使判别器判生成的样本为1，即最大化\\(D(G(z))\\)，就是最小化价值函数。 这里的价值函数与交叉熵类似。真实样本为正例，生成样本为负例，一般都是最小化损失函数，因此需要做一下变形： 这个很好理解，与交叉熵一样。 上面是判别器的优化，下面是生成器的优化： 总的来说，生成器得损失函数就是 \\[ J^{(G)} = -\\frac{1}{2}E_z\\log D(G(z)) \\] 即“以假乱真”。 ","date":"2022-12-22","objectID":"/gan/:2:0","tags":["Deep Learning","GAN系列","GAN"],"title":"GAN","uri":"/gan/"},{"categories":["Machine Learning","降维算法"],"content":"线性判别分析LDA(Linear Discriminant Analysis) 线性判别分析，也就是LDA（与主题模型中的LDA区分开），现在常常用于数据的降维中，但从它的名字中可以看出来它也是一个分类的算法，而且属于硬分类，也就是结果不是概率，是具体的类别，一起学习一下吧。 ","date":"2022-12-21","objectID":"/lda/:0:0","tags":["Machine Learning","降维算法","LDA"],"title":"LDA","uri":"/lda/"},{"categories":["Machine Learning","降维算法"],"content":"主要思想 类内方差小 类间方差大 ","date":"2022-12-21","objectID":"/lda/:1:0","tags":["Machine Learning","降维算法","LDA"],"title":"LDA","uri":"/lda/"},{"categories":["Machine Learning","降维算法"],"content":"推导 这里以二类为例，即只有两个类别。 首先是投影，我们假定原来的数据是向量 \\(x\\)，那么顺着 $ w$ 方向的投影就是标量： \\[ z=w^T\\cdot x(=|w|\\cdot|x|\\cos\\theta) \\] 对第一点，相同类内部的样本更为接近，我们假设属于两类的试验样本数量分别是 \\(N_1\\)和 \\(N_2\\)，那么我们采用方差矩阵来表征每一个类内的总体分布，这里我们使用了协方差的定义，用 \\(S\\) 表示原数据的协方差： \\[ \\begin{aligned} C_1:Var_z[C_1]\u0026=\\frac{1}{N_1}\\sum\\limits_{i=1}^{N_1}(z_i-\\bar{z_{c1}})(z_i-\\bar{z_{c1}})^T\\nonumber\\\\\\\\\\\\\\\\ \u0026=\\frac{1}{N_1}\\sum\\limits_{i=1}^{N_1}(w^Tx_i-\\frac{1}{N_1}\\sum\\limits_{j=1}^{N_1}w^Tx_j)(w^Tx_i-\\frac{1}{N_1}\\sum\\limits_{j=1}^{N_1}w^Tx_j)^T\\nonumber\\\\\\\\\\\\\\\\ \u0026=w^T\\frac{1}{N_1}\\sum\\limits_{i=1}^{N_1}(x_i-\\bar{x_{c1}})(x_i-\\bar{x_{c1}})^Tw\\nonumber\\\\\\\\ =w^TS_1w\\\\\\\\\\\\\\\\ C_2:Var_z[C_2]\u0026=\\frac{1}{N_2}\\sum\\limits_{i=1}^{N_2}(z_i-\\bar{z_{c2}})(z_i-\\bar{z_{c2}})^T\\nonumber\\\\\\\\ =w^TS_2w \\end{aligned} \\] 所以类内距离为： \\[ \\begin{align} Var_z[C_1]+Var_z[C_2]=w^T(S_1+S_2)w \\end{align} \\] 对于第二点，我们可以用两类的均值表示这个距离： \\[ \\begin{align} (\\bar{z_{c1}}-\\bar{z_{c2}})^2\u0026=(\\frac{1}{N_1}\\sum\\limits_{i=1}^{N_1}w^Tx_i-\\frac{1}{N_2}\\sum\\limits_{i=1}^{N_2}w^Tx_i)^2\\nonumber\\\\\\\\ \u0026=(w^T(\\bar{x_{c1}}-\\bar{x_{c2}}))^2\\nonumber\\\\\\\\ \u0026=w^T(\\bar{x_{c1}}-\\bar{x_{c2}})(\\bar{x_{c1}}-\\bar{x_{c2}})^Tw \\end{align} \\] 合这两点，由于协方差是一个矩阵，于是我们用将这两个值相除来得到我们的损失函数，并最大化这个值： \\[ \\begin{align} \\hat{w}=\\mathop{argmax}\\limits_wJ(w)\u0026=\\mathop{argmax}\\limits_w\\frac{(\\bar{z_{c1}}-\\bar{z_{c2}})^2}{Var_z[C_1]+Var_z[C_2]}\\nonumber\\\\\\\\ \u0026=\\mathop{argmax}\\limits_w\\frac{w^T(\\bar{x_{c1}}-\\bar{x_{c2}})(\\bar{x_{c1}}-\\bar{x_{c2}})^Tw}{w^T(S_1+S_2)w}\\nonumber\\\\\\\\\\\\\\\\ \u0026=\\mathop{argmax}\\limits_w\\frac{w^TS_bw}{w^TS_ww} \\end{align} \\] 这样，我们就把损失函数和原数据集以及参数结合起来了。下面对这个损失函数求偏导，注意我们其实对w的绝对值没有任何要求，只对方向有要求，因此只要一个方程就可以求解了： \\[ \\begin{aligned} \u0026\\frac{\\partial}{\\partial w}J(w)=2S_bw(w^TS_ww)^{-1}-2w^TS_bw(w^TS_ww)^{-2}S_ww=0\\nonumber\\\\\\\\\\\\\\\\ \u0026\\Longrightarrow S_bw(w^TS_ww)=(w^TS_bw)S_ww\\nonumber\\\\\\\\\\\\\\\\ \u0026\\Longrightarrow w\\propto S_w^{-1}S_bw=S_w^{-1}(\\bar{x_{c1}}-\\bar{x_{c2}})(\\bar{x_{c1}}-\\bar{x_{c2}})^Tw\\propto S_w^{-1}(\\bar{x_{c1}}-\\bar{x_{c2}}) \\end{aligned} \\] 也就是说最后我们的结果就是\\(w=S_w^{-1}(\\bar{x_{c1}}-\\bar{x_{c2}})\\) 可以归一化求得单位的w值。 ","date":"2022-12-21","objectID":"/lda/:2:0","tags":["Machine Learning","降维算法","LDA"],"title":"LDA","uri":"/lda/"},{"categories":["Machine Learning","降维算法"],"content":"多类情况 前面的很容易类比二类的情况，现在的目标函数变成了： \\[ \\frac{W^TS_bW}{W^TS_wW} \\] 现在的问题就是这些都是矩阵，不能像上面那样直接优化，需要替换优化目标。 \\[ \\underbrace{arg\\;max}_W\\;\\;J(W) = \\frac{\\prod\\limits_{diag}W^TS_bW}{\\prod\\limits_{diag}W^TS_wW} \\] 其中 \\(\\prod_{diag}A\\)为A的主对角线元素的乘积,W为\\(n \\times d\\)的矩阵，n为原来的维度，d为映射到超平面的维度，则最终的目标就变成了： \\[ J(W) = \\frac{\\prod\\limits_{i=1}^dw_i^TS_bw_i}{\\prod\\limits_{i=1}^dw_i^TS_ww_i} = \\prod\\limits_{i=1}^d\\frac{w_i^TS_bw_i}{w_i^TS_ww_i} \\] 根据广式瑞利商，最大值是矩阵\\(S_w^{-1}S_b\\)的最大特征值,最大的d个值的乘积就是矩阵的\\(S_w^{-1}S_b\\)最大的d个特征值的乘积,此时对应的矩阵\\(W\\)为这最大的d个特征值对应的特征向量张成的矩阵。 ","date":"2022-12-21","objectID":"/lda/:3:0","tags":["Machine Learning","降维算法","LDA"],"title":"LDA","uri":"/lda/"},{"categories":["Machine Learning","降维算法"],"content":"总结 LDA是一种监督学习的降维技术，也就是说它的数据集的每个样本是有类别输出的。这点和PCA不同。PCA是不考虑样本类别输出的无监督降维技术。LDA的思想可以用一句话概括，就是“投影后类内方差最小，类间方差最大”。什么意思呢？ 我们要将数据在低维度上进行投影，投影后希望每一种类别数据的投影点尽可能的接近，而不同类别的数据的类别中心之间的距离尽可能的大。 实际上LDA除了可以用于降维以外，还可以用于分类。一个常见的LDA分类基本思想是假设各个类别的样本数据符合高斯分布，这样利用LDA进行投影后，可以利用极大似然估计计算各个类别投影数据的均值和方差，进而得到该类别高斯分布的概率密度函数。当一个新的样本到来后，我们可以将它投影，然后将投影后的样本特征分别带入各个类别的高斯分布概率密度函数，计算它属于这个类别的概率，最大的概率对应的类别即为预测类别。 LDA用于降维，和PCA有很多相同，也有很多不同的地方，因此值得好好的比较一下两者的降维异同点。 首先我们看看相同点： 1）两者均可以对数据进行降维。 2）两者在降维时均使用了矩阵特征分解的思想。 3）两者都假设数据符合高斯分布。 我们接着看看不同点： 1）LDA是有监督的降维方法，而PCA是无监督的降维方法 2）LDA降维最多降到类别数k-1的维数，而PCA没有这个限制。 3）LDA除了可以用于降维，还可以用于分类。 4）LDA选择分类性能最好的投影方向，而PCA选择样本点投影具有最大方差的方向。 ","date":"2022-12-21","objectID":"/lda/:4:0","tags":["Machine Learning","降维算法","LDA"],"title":"LDA","uri":"/lda/"},{"categories":["Machine Learning","降维算法"],"content":"代码 mean_list = [] for i in range(2): mean_list.append(np.mean(X_train[y_train==i], axis=0)) mean_list = np.array(mean_list) S_W = np.zeros((X_train.shape[1], X_train.shape[1])) # 类内散度矩阵 for c, mv in zip(range(2), mean_list): class_scatter = np.zeros((X_train.shape[1], X_train.shape[1])) for row in X_train[y_train==c]: row, mv = row.reshape(X_train.shape[1], -1), mv.reshape(X_train.shape[1], -1) class_scatter += (row-mv).dot((row-mv).T) S_W += class_scatter over_all_mean = np.mean(X_train, axis=0) S_B = np.zeros((X_train.shape[1], X_train.shape[1])) # 类间散度矩阵 for i, mean_vec in enumerate(mean_list): n = X_train[y_train==i, :].shape[0] mean_list_temp = mean_list[i, :].reshape(1, -1) over_all_mean = over_all_mean.reshape(X_train.shape[1], 1) S_B += n*(mean_vec-over_all_mean).dot((mean_vec-over_all_mean).T) eig_vals, eig_vecs = np.linalg.eig(np.linalg.inv(S_W).dot(S_B)) eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:, i]) for i in range(len(eig_vals))] eig_pairs = sorted(eig_pairs, key=lambda k: k[0], reverse=True) # eigv_sum = sum(eig_vals) # for i, j in enumerate(eig_pairs): # print('eigenvalue {0:}: {1:.2%}'.format(i + 1, (j[0] / eigv_sum).real)) # 根据百分比显示特征值，从而选取最大的n个特征值 W = np.hstack((eig_pairs[0][1].reshape(X_train.shape[1], 1), eig_pairs[1][1].reshape(X_train.shape[1], 1))) ","date":"2022-12-21","objectID":"/lda/:5:0","tags":["Machine Learning","降维算法","LDA"],"title":"LDA","uri":"/lda/"},{"categories":["Deep Learning","循环神经网络系列"],"content":" image.png 其中\\(r_{t}\\)为reset门，用于重置上一step的状态。\\(z_{t}\\)为update门，用于得到当前step的状态。 ","date":"2022-12-04","objectID":"/gru/:0:0","tags":["Deep Learning","循环神经网络系列","GRU"],"title":"GRU","uri":"/gru/"},{"categories":["pandas","api"],"content":" 很简单，就是统计x中的数出现次数，返回结果的最大长度就是x中的最大值+1，idx为对应的数，值为出现的次数，没有出现的为0。 x = np.array([7, 6, 2, 1, 4]) # 索引0出现了0次，索引1出现了1次......索引5出现了0次...... np.bincount(x) #输出结果为：array([0, 1, 1, 0, 1, 0, 1, 1]) weight这个参数也很好理解，x会被它加权，也就是说，如果值n发现在位置i，那么out[n] += weight[i]而不是out[n] += 1。所以weight必须和x等长。 w = np.array([0.3, 0.5, 0.2, 0.7, 1., -0.6]) # 我们可以看到x中最大的数为4，因此bin的数量为5，那么它的索引值为0-\u003e4 x = np.array([2, 1, 3, 4, 4, 3]) # 索引0 -\u003e 0 # 索引1 -\u003e w[1] = 0.5 # 索引2 -\u003e w[0] = 0.3 # 索引3 -\u003e w[2] + w[5] = 0.2 - 0.6 = -0.4 # 索引4 -\u003e w[3] + w[4] = 0.7 + 1 = 1.7 np.bincount(x, weights=w) # 因此，输出结果为：array([ 0. , 0.5, 0.3, -0.4, 1.7]) 没出现的还是0，出现的要按照出现的地方的weight计算。 ","date":"2022-11-29","objectID":"/bincount/:0:0","tags":["pandas","api","bincount"],"title":"bincount","uri":"/bincount/"},{"categories":["算法题"],"content":"把数字翻译成字符串 ","date":"2022-11-17","objectID":"/%E6%8A%8A%E6%95%B0%E5%AD%97%E7%BF%BB%E8%AF%91%E6%88%90%E5%AD%97%E7%AC%A6%E4%B8%B2/:0:0","tags":["算法题","把数字翻译成字符串"],"title":"把数字翻译成字符串","uri":"/%E6%8A%8A%E6%95%B0%E5%AD%97%E7%BF%BB%E8%AF%91%E6%88%90%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"categories":["算法题"],"content":"题目： https://leetcode-cn.com/problems/ba-shu-zi-fan-yi-cheng-zi-fu-chuan-lcof/ ","date":"2022-11-17","objectID":"/%E6%8A%8A%E6%95%B0%E5%AD%97%E7%BF%BB%E8%AF%91%E6%88%90%E5%AD%97%E7%AC%A6%E4%B8%B2/:1:0","tags":["算法题","把数字翻译成字符串"],"title":"把数字翻译成字符串","uri":"/%E6%8A%8A%E6%95%B0%E5%AD%97%E7%BF%BB%E8%AF%91%E6%88%90%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"categories":["算法题"],"content":"思路： dp思想，不用管是什么字符，定义dp[i]为长度为i时 有多少个方法 ","date":"2022-11-17","objectID":"/%E6%8A%8A%E6%95%B0%E5%AD%97%E7%BF%BB%E8%AF%91%E6%88%90%E5%AD%97%E7%AC%A6%E4%B8%B2/:2:0","tags":["算法题","把数字翻译成字符串"],"title":"把数字翻译成字符串","uri":"/%E6%8A%8A%E6%95%B0%E5%AD%97%E7%BF%BB%E8%AF%91%E6%88%90%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"categories":["算法题"],"content":"代码: class Solution: def translateNum(self, num: int) -\u003e int: s = str(num) if len(s) \u003c 2: return 1 dp = [0] * len(s) dp[0] = 1 dp[1] = 2 if int(s[0] + s[1]) \u003c 26 else 1 for i in range(2,len(s)): dp[i] = dp[i-1] + dp[i-2] if int(s[i-1] + s[i]) \u003c 26 and s[i-1] != '0' else dp[i-1] return dp[-1] 注意如果长度小于等于1 则直接返回1 如果不是26个英文字母里面的 则dp[i] = dp[i-1] 说明方法次数并不改变 注意有首位为0的情况 所以要int一下 ","date":"2022-11-17","objectID":"/%E6%8A%8A%E6%95%B0%E5%AD%97%E7%BF%BB%E8%AF%91%E6%88%90%E5%AD%97%E7%AC%A6%E4%B8%B2/:3:0","tags":["算法题","把数字翻译成字符串"],"title":"把数字翻译成字符串","uri":"/%E6%8A%8A%E6%95%B0%E5%AD%97%E7%BF%BB%E8%AF%91%E6%88%90%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"categories":["NLP"],"content":"Seq2Seq （本文只介绍最原始的seq2seq，带有注意力在attention文章中） ","date":"2022-11-09","objectID":"/seq2seq/:0:0","tags":["NLP","seq2seq"],"title":"seq2seq","uri":"/seq2seq/"},{"categories":["NLP"],"content":"RNN 有关RNN Seq2Seq是典型的Encoder-decoder框架的模型，其中编码器和解码器都采用的RNN模型或者RNN模型的变体：GRU、LSTM等。 一般的RNN模型有几种形式，分别为一对一、一对多、多对一、多对多。 一对一： 就是一般的MLP，并不能称之为RNN模型 一对多: 典型的例子就是语音生成，比如输入某个值可以由程序生成一段音乐。 多对一： 最常见的文本分类或者情感分析就是这个模型架构 多对多： 序列标注、NER、分词，大多数标注任务就是用的这个模型架构。而Seq2Seq也属于多对多的任务，不过由于输入和输出的长度可能会不一样，因此采用encoder-decoder的框架，主要思想就是通过encoder将输入的信息编码，然后传入decoder再进行解码得到想要的结果。这常用于生成式的任务，比如说机器翻译、对话系统、文本摘要等等，都可以使用这个框架进行实现。著名的Transformer 就是使用的这个框架。 ","date":"2022-11-09","objectID":"/seq2seq/:1:0","tags":["NLP","seq2seq"],"title":"seq2seq","uri":"/seq2seq/"},{"categories":["NLP"],"content":"encoder-decoder 框架 encoder-decoder框架可以看作一种深度学习领域的研究模式，应用场景十分广泛， 文本处理领域的Encoder-Decoder框架可以这么直观地去理解：可以把它看作适合处理由一个句子（或篇章）生成另外一个句子（或篇章）的通用处理模型。对于句子对\u003cSource,Target\u003e，我们的目标是给定输入句子Source，期待通过Encoder-Decoder框架来生成目标句子Target。Source和Target可以是同一种语言，也可以是两种不同的语言。而Source和Target分别由各自的单词序列构成。 \\[ Source = \u003cx_1, x_2, \\dots, x_m\u003e \\\\\\\\ Target = \u003cy_1, y_2, \\dots, y_n\u003e \\] Encoder顾名思义就是对输入句子Source进行编码，将输入句子通过非线性变换转化为中间语义表示C： \\[ C = F(x_1, x_2, \\dots, x_m) \\] 对于解码器Decoder来说，其任务是根据句子Source的中间语义表示C和之前已经生成的历史信息\\(y_1,y_2,\\dots, y_{i-1}\\)来生成i时刻要生成的单词\\(y_i\\)： \\[ y_i = G(C, y_1,y_2,\\dots,y_{i-1}) \\] 每个yi都依次这么产生，那么看起来就是整个系统根据输入句子Source生成了目标句子Target。如果Source是中文句子，Target是英文句子，那么这就是解决机器翻译问题的Encoder-Decoder框架；如果Source是一篇文章，Target是概括性的几句描述语句，那么这是文本摘要的Encoder-Decoder框架；如果Source是一句问句，Target是一句回答，那么这是问答系统或者对话机器人的Encoder-Decoder框架。由此可见，在文本处理领域，Encoder-Decoder的应用领域相当广泛。 Encoder-Decoder框架不仅仅在文本领域广泛使用，在语音识别、图像处理等领域也经常使用。对于“图像描述”任务来说，Encoder部分的输入是一副图片，Decoder的输出是能够描述图片语义内容的一句描述语。一般而言，文本处理和语音识别的Encoder部分通常采用RNN模型，图像处理的Encoder一般采用CNN模型。 ","date":"2022-11-09","objectID":"/seq2seq/:2:0","tags":["NLP","seq2seq"],"title":"seq2seq","uri":"/seq2seq/"},{"categories":["NLP"],"content":"Seq2Seq模型 Seq2Seq模型是输出的长度不确定时采用的模型，这种情况一般是在机器翻译的任务中出现，将一句中文翻译成英文，那么这句英文的长度有可能会比中文短，也有可能会比中文长，所以输出的长度就不确定了。 ","date":"2022-11-09","objectID":"/seq2seq/:3:0","tags":["NLP","seq2seq"],"title":"seq2seq","uri":"/seq2seq/"},{"categories":["NLP"],"content":"结构 seq2seq属于encoder-decoder结构的一种，这里看看常见的encoder-decoder结构，基本思想就是利用两个RNN，一个RNN作为encoder，另一个RNN作为decoder。encoder负责将输入序列压缩成指定长度的向量，这个向量就可以看成是这个序列的语义，这个过程称为编码，获取语义向量最简单的方式就是直接将最后一个输入的隐状态作为语义向量C。也可以对最后一个隐含状态做一个变换得到语义向量，还可以将输入序列的所有隐含状态做一个变换得到语义变量。 而decoder则负责根据语义向量生成指定的序列，这个过程也称为解码，最简单的方式是将encoder得到的语义变量作为初始状态输入到decoder的RNN中，得到输出序列。可以看到上一时刻的输出会作为当前时刻的输入，而且其中语义向量C只作为初始状态参与运算，后面的运算都与语义向量C无关。 decoder处理方式还有另外一种，就是语义向量C参与了序列所有时刻的运算，如下图，上一时刻的输出仍然作为当前时刻的输入，但语义向量C会参与所有时刻的运算。 上面的这两种结构是我刚学的时候疑惑的一个地方，因为我在有的地方看到的代码是第一种结构的，而沐神的教程中的结构用的是第二种结构，其实这两种都是可以的。 ### 训练 最主要的思路就是语言模型，因为在RNN中，每一个step的输出层的大小就是单词表的大小，要预测最大概率出现的那个词汇，即最大化最有可能是当前输出的单词所在神经元的概率，实际上就是一个多分类问题，使用softmax归一化表示概率。 encoder就是简单的RNN系列模型，前文说的可以有多种方式计算语义向量c，并且c可以有两种方式参与到decoder的计算中。 decoder的主要训练方式就是将前一时刻的结果作为后一时刻的输入，也就是自回归。在训练中的体现是将语料进行错位训练，比如[“你好“ 世界”]，在训练中decoder中就是输入为[“S” ”你好“ “世界”]，而标签也就是实际值为[“你好” “世界” ”E“] ，按照这样的方式进行训练，训练过后，再进行测试，测试的过程就是严格按照前一时刻的输出作为后一时刻的输入，因为这时你也没有要输入的数据。也就是说训练时和测试时的decoder是不一样的。训练的时候我们有真实的数据，而预测的时候没有，只能自产自销，其实就是一个语言模型，叫做条件语言模型。这里引用两张图 既然是语言模型，可以用极大似然估计最大化输出序列的概率： \\[ \\begin{aligned} P(y_1,\\dots,y_{T} | x_1, \\dots x_T) = \\prod_{t=1}^TP(y_t|y_1 , \\dots y_{t-1}; c) \\end{aligned} \\] 在计算损失的时候，我们使用交叉熵作为损失函数，所以我们要找出这个V维向量中，正确预测对应的词的那一维的概率大小\\(\\hat{p}\\)，则这一步的损失就是它的负导数\\(-log(\\hat{p})\\)，将每一步的损失求和，即得到总体的损失函数： \\[ \\begin{aligned} J = -\\frac{1}{T}\\sum_{i}^Tlog(p(\\hat{y_i})) \\end{aligned} \\] 其中的\\(p(\\hat{y_i})\\)为时间t=i上的正确输出节点的概率值，即softmax值。 其中有三个特殊的标记，一个是S代表句子的开头，E代表句子的结尾，P代表Padding。 ## 束搜索(beam search) 一般来说，用前一步的结果作为下一步的输出，这种方式就是贪心策略，但也存在问题，也就是说每一步最优并不是全局最优，改进的办法就是束搜索。思想很简单，每一步就是多选几个作为候选，最后综合考虑，选出最优的组合。是不是和HMM中的维特比算法很像呢？ 以下为束搜索的步骤： - 首先需要设定一个候选集的大小beam size=k。 - 每一步的开始，我们从每个当前输入对应的所有可能输出，计算每一条路的序列得分 - 保留序列得分最大的k个作为下一步的输入 - 不断重复以上步骤，直至结束，选择序列得分最大的那个序列作为最终结果。 其中序列得分为： \\[ score(y_1,y_2, \\dots y_t) = \\sum_{i=1}^t \\log P(y_i|y_1,y_2,\\dots y_{i-1};x) \\] 过程如图所示： ","date":"2022-11-09","objectID":"/seq2seq/:3:1","tags":["NLP","seq2seq"],"title":"seq2seq","uri":"/seq2seq/"},{"categories":["NLP"],"content":"评价标准 ","date":"2022-11-09","objectID":"/seq2seq/:4:0","tags":["NLP","seq2seq"],"title":"seq2seq","uri":"/seq2seq/"},{"categories":["NLP"],"content":"BLUE指标 BLEU，全称是Bilingual Evaluation Understudy，它的主要思想是基于N-gram等特征来比较人工翻译和机器翻译结果的相似程度。 我们将BLEU定义为： \\[ \\exp \\left(\\min\\left(0,1-\\frac{len_{\\text {label }}}{len_{\\text {pred }}}\\right)\\right) \\prod_{n=1}^{k} p_{n}^{1 / 2^{n}} \\] 长的 \\(n\\) 元语法。另外, 用 \\(p_{n}\\) 表示 \\(n\\) 元语法的精确度, 它是两个数量的比值：第一个是预测序 列与标签序列中匹配的 \\(n\\) 元语法的数量, 第二个是预测序列中 \\(n\\) 元语法的数量的比率。具体 地说, 给定标签序列 \\(A 、 B 、 C 、 D 、 E 、 F\\) 和预测序列 \\(A 、 B 、 B 、 C 、 D\\), 我们有 \\(p_{1}=4 / 5 、 p_{2}=3 / 4 、 p_{3}=1 / 3\\) 和 \\(p_{4}=0\\) 。 根据 (9.7.4)中BLEU的定义，当预测序列与标签序列完全相同时, BLEU为 1 。 此外, 由于 \\(n\\) 元语法越长则匹配难度越大, 所以BLEU为更长的 \\(n\\) 元语法的精确度分配更大的权重。具体 来说, 当 \\(p_{n}\\) 固定时, \\(p_{n}^{1 / 2^{n}}\\) 会随着 \\(n\\) 的增长而增加（原始论文使用 \\(p_{n}^{1 / n}\\) )。而且, 由于预测 的序列越短获得的 \\(p_{n}\\) 值越高, 所以 (9.7.4)中乘法项之前的系数用于惩罚较短的预测序列。 例如, 当 \\(k=2\\) 时，给定标签序列 \\(A 、 B 、 C 、 D 、 E 、 F\\) 和预测序列 \\(A 、 B\\) ，尽管 \\(p_{1}=p_{2}=1\\) ， 惩罚因子 \\(\\exp (1-6 / 2) \\approx 0.14\\) 会降低BLEU。 ","date":"2022-11-09","objectID":"/seq2seq/:4:1","tags":["NLP","seq2seq"],"title":"seq2seq","uri":"/seq2seq/"},{"categories":["NLP"],"content":"代码 # code by Tae Hwan Jung @graykode import numpy as np import torch import torch.nn as nn # S: Symbol that shows starting of decoding input # E: Symbol that shows starting of decoding output # P: Symbol that will fill in blank sequence if current batch data size is short than time steps def make_batch(): input_batch, output_batch, target_batch = [], [], [] for seq in seq_data: for i in range(2): seq[i] = seq[i] + 'P' * (n_step - len(seq[i])) input = [num_dic[n] for n in seq[0]] output = [num_dic[n] for n in ('S' + seq[1])] target = [num_dic[n] for n in (seq[1] + 'E')] input_batch.append(np.eye(n_class)[input]) output_batch.append(np.eye(n_class)[output]) target_batch.append(target) # not one-hot # make tensor return torch.FloatTensor(input_batch), torch.FloatTensor(output_batch), torch.LongTensor(target_batch) # make test batch def make_testbatch(input_word): input_batch, output_batch = [], [] input_w = input_word + 'P' * (n_step - len(input_word)) input = [num_dic[n] for n in input_w] output = [num_dic[n] for n in 'S' + 'P' * n_step] input_batch = np.eye(n_class)[input] output_batch = np.eye(n_class)[output] return torch.FloatTensor(input_batch).unsqueeze(0), torch.FloatTensor(output_batch).unsqueeze(0) # Model class Seq2Seq(nn.Module): def __init__(self): super(Seq2Seq, self).__init__() self.enc_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5) self.dec_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5) self.fc = nn.Linear(n_hidden, n_class) def forward(self, enc_input, enc_hidden, dec_input): enc_input = enc_input.transpose(0, 1) # enc_input: [max_len(=n_step, time step), batch_size, n_class] dec_input = dec_input.transpose(0, 1) # dec_input: [max_len(=n_step, time step), batch_size, n_class] # enc_states : [num_layers(=1) * num_directions(=1), batch_size, n_hidden] _, enc_states = self.enc_cell(enc_input, enc_hidden) # outputs : [max_len+1(=6), batch_size, num_directions(=1) * n_hidden(=128)] outputs, _ = self.dec_cell(dec_input, enc_states) model = self.fc(outputs) # model : [max_len+1(=6), batch_size, n_class] return model if __name__ == '__main__': n_step = 5 n_hidden = 128 char_arr = [c for c in 'SEPabcdefghijklmnopqrstuvwxyz'] num_dic = {n: i for i, n in enumerate(char_arr)} seq_data = [['man', 'women'], ['black', 'white'], ['king', 'queen'], ['girl', 'boy'], ['up', 'down'], ['high', 'low']] n_class = len(num_dic) batch_size = len(seq_data) model = Seq2Seq() criterion = nn.CrossEntropyLoss() optimizer = torch.optim.Adam(model.parameters(), lr=0.001) input_batch, output_batch, target_batch = make_batch() for epoch in range(5000): # make hidden shape [num_layers * num_directions, batch_size, n_hidden] hidden = torch.zeros(1, batch_size, n_hidden) optimizer.zero_grad() # input_batch : [batch_size, max_len(=n_step, time step), n_class] # output_batch : [batch_size, max_len+1(=n_step, time step) (becase of 'S' or 'E'), n_class] # target_batch : [batch_size, max_len+1(=n_step, time step)], not one-hot output = model(input_batch, hidden, output_batch) # output : [max_len+1, batch_size, n_class] output = output.transpose(0, 1) # [batch_size, max_len+1(=6), n_class] loss = 0 for i in range(0, len(target_batch)): # output[i] : [max_len+1, n_class, target_batch[i] : max_len+1] loss += criterion(output[i], target_batch[i]) if (epoch + 1) % 1000 == 0: print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss)) loss.backward() optimizer.step() # Test def translate(word): input_batch, output_batch = make_testbatch(word) # make hidden shape [num_layers * num_directions, batch_size, n_hidden] hidden = torch.zeros(1, 1, n_hidden) output = model(input_batch, hidden, output_batch) # output : [max_len+1(=6), batch_size(=1), n_class] predict = output.data.max(2, keepdim=True)[1] # select n_class dimension decoded = [char_arr[i] for i in predict] end = decoded.index('E') translated = ''.join(decoded[:end]) return translated.replace('P', '') print('test') print('man -\u003e', translate('man')) prin","date":"2022-11-09","objectID":"/seq2seq/:5:0","tags":["NLP","seq2seq"],"title":"seq2seq","uri":"/seq2seq/"},{"categories":["Machine Learning","聚类算法"],"content":"DBSCAN属于密度聚类的一种。通常情形下，密度聚类算法从样 本密度的角度来考察样本之间的可连接性，并基于可连接样本不断扩展聚类簇 以获得最终的聚类结果。 DBSCAN基于一组“邻域”参数\\((\\epsilon, Minpts)\\)来刻画样本分布的紧密程度，给定数据集\\(D=\\\\{x_1,x_2, \\dots,x_m \\\\}\\)，定义几个概念： \\(\\epsilon\\)-邻域：对\\(x_j\\in D\\)，其\\(\\epsilon\\)-邻域包含样本集D中与\\(x_j\\)的距离不大于\\(\\epsilon\\)的样本，即\\(N_{\\epsilon}(x_j) = \\\\{dist(x_i, x_j) \\leq \\epsilon\\\\}\\)。 核心对象 (core object): 若 \\(x_j\\) 的 \\(\\epsilon\\)-邻域至少包含 MinPts 个样本, 即 \\(\\left|N_\\epsilon\\left(\\boldsymbol{x}_j\\right)\\right| \\geqslant \\operatorname{MinPts}\\), 则 \\(\\boldsymbol{x}_j\\) 是一个核心对象; 密度直达(directly density-reachable): 若 \\(\\boldsymbol{x}_j\\) 位于 \\(\\boldsymbol{x}_i\\) 的 \\(\\epsilon\\)-邻域中, 且 \\(\\boldsymbol{x}_i\\) 是 核心对象, 则称 \\(\\boldsymbol{x}_j\\) 由 \\(\\boldsymbol{x}_i\\) 密度直达; 密度可达(density-reachable): 对 \\(\\boldsymbol{x}_i\\) 与 \\(\\boldsymbol{x}_j\\), 若存在样本序列 \\(\\boldsymbol{p}_1, \\boldsymbol{p}_2, \\ldots, \\boldsymbol{p}_n\\), 其中 \\(\\boldsymbol{p}_1=\\boldsymbol{x}_i, \\boldsymbol{p}_n=\\boldsymbol{x}_j\\) 且 \\(\\boldsymbol{p}_{i+1}\\) 由 \\(\\boldsymbol{p}_i\\) 密度直达, 则称 \\(\\boldsymbol{x}_j\\) 由 \\(\\boldsymbol{x}_i\\) 密度可达; 密度相连 (density-connected): 对 \\(\\boldsymbol{x}_i\\) 与 \\(\\boldsymbol{x}_j\\), 若存在 \\(\\boldsymbol{x}_k\\) 使得 \\(\\boldsymbol{x}_i\\) 与 \\(\\boldsymbol{x}_j\\) 均由 \\(\\boldsymbol{x}_k\\) 密度可达, 则称 \\(\\boldsymbol{x}_i\\) 与 \\(\\boldsymbol{x}_j\\) 密度相连. 既然是聚类，那就要定义簇的概念 ","date":"2022-11-03","objectID":"/dbscan/:0:0","tags":["Machine Learning","聚类算法","DBSCAN"],"title":"DBSCAN","uri":"/dbscan/"},{"categories":["Machine Learning","关联规则算法"],"content":"参考：https://www.cnblogs.com/bill-h/p/14863262.html 大家可能听说过用于宣传数据挖掘的一个案例:啤酒和尿布；据说是沃尔玛超市在分析顾客的购买记录时，发现许多客户购买啤酒的同时也会购买婴儿尿布，于是超市调整了啤酒和尿布的货架摆放，让这两个品类摆放在一起；结果这两个品类的销量都有明显的增长；分析原因是很多刚生小孩的男士在购买的啤酒时，会顺手带一些婴幼儿用品。 不论这个案例是否是真实的，案例中分析顾客购买记录的方式就是关联规则分析法Association Rules。 关联规则分析也被称为购物篮分析，用于分析数据集各项之间的关联关系。 ","date":"2022-11-02","objectID":"/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%A6%82%E5%BF%B5/:0:0","tags":["Machine Learning","关联规则算法","关联规则概念"],"title":"关联规则概念","uri":"/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%A6%82%E5%BF%B5/"},{"categories":["Machine Learning","关联规则算法"],"content":"项集 item的集合，如集合{牛奶、麦片、糖}是一个3项集，可以认为是购买记录里物品的集合。 ","date":"2022-11-02","objectID":"/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%A6%82%E5%BF%B5/:1:0","tags":["Machine Learning","关联规则算法","关联规则概念"],"title":"关联规则概念","uri":"/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%A6%82%E5%BF%B5/"},{"categories":["Machine Learning","关联规则算法"],"content":"频繁项集 顾名思义就是频繁出现的item项的集合。如何定义频繁呢？用比例来判定，关联规则中采用支持度和置信度两个概念来计算比例值 ","date":"2022-11-02","objectID":"/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%A6%82%E5%BF%B5/:2:0","tags":["Machine Learning","关联规则算法","关联规则概念"],"title":"关联规则概念","uri":"/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%A6%82%E5%BF%B5/"},{"categories":["Machine Learning","关联规则算法"],"content":"支持度（support) 共同出现的项在整体项中的比例。以购买记录为例子，购买记录100条，如果商品A和B同时出现50条购买记录（即同时购买A和B的记录有50），那边A和B这个2项集的支持度为50% \\[ Support(A\\cap B) = \\frac{Freq(A\\cap B)}{N} \\] ","date":"2022-11-02","objectID":"/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%A6%82%E5%BF%B5/:3:0","tags":["Machine Learning","关联规则算法","关联规则概念"],"title":"关联规则概念","uri":"/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%A6%82%E5%BF%B5/"},{"categories":["Machine Learning","关联规则算法"],"content":"置信度（Confidence） 购买A后再购买B的条件概率，根据贝叶斯公式，可如下表示： \\[ Confidence = \\frac{Freq(A\\cap B)}{Freq(A)} \\] ","date":"2022-11-02","objectID":"/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%A6%82%E5%BF%B5/:4:0","tags":["Machine Learning","关联规则算法","关联规则概念"],"title":"关联规则概念","uri":"/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%A6%82%E5%BF%B5/"},{"categories":["Machine Learning","关联规则算法"],"content":"提升度 为了判断产生规则的实际价值，即使用规则后商品出现的次数是否高于商品单独出现的评率，提升度和衡量购买X对购买Y的概率的提升作用。如下公式可见，如果X和Y相互独立那么提升度为1，提升度越大，说明X-\u003eY的关联性越强 ","date":"2022-11-02","objectID":"/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%A6%82%E5%BF%B5/:5:0","tags":["Machine Learning","关联规则算法","关联规则概念"],"title":"关联规则概念","uri":"/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%A6%82%E5%BF%B5/"},{"categories":["算法题"],"content":"字符串转换整数 (atoi) https://leetcode-cn.com/problems/string-to-integer-atoi/ #重点是正则表达式 class Solution: def myAtoi(s: str): import re ss = re.findall(\"^[\\+\\-]?\\d+\",s.strip()) res = int(*ss) if res \u003e (231-1): res = (231-1) if res \u003c -231: res = -231 return res WA了四次才整出来，太菜了，以为很简单，没有认真读题，要吸取教训。 ","date":"2022-10-26","objectID":"/%E5%AD%97%E7%AC%A6%E4%B8%B2%E8%BD%AC%E6%8D%A2%E6%95%B4%E6%95%B0-atoi/:0:0","tags":["算法题","字符串转换整数 (atoi)"],"title":"字符串转换整数 (atoi)","uri":"/%E5%AD%97%E7%AC%A6%E4%B8%B2%E8%BD%AC%E6%8D%A2%E6%95%B4%E6%95%B0-atoi/"},{"categories":["Machine Learning","聚类算法"],"content":"基础就是高斯混合模型，假设我们熟知的高斯分布的概率密度函数为\\(p(x\\mid \\mu, \\Sigma)\\)。则高斯混合分布为： \\[ p_{\\mathcal{M}}(\\boldsymbol{x})=\\sum_{i=1}^k \\alpha_i \\cdot p\\left(\\boldsymbol{x} \\mid \\boldsymbol{\\mu}_i, \\boldsymbol{\\Sigma}_i\\right) \\] 分布共由 \\(k\\) 个混合成分组成, 每个混合成分对应一个高斯分布. 其中 \\(\\mu_i\\) 与 \\(\\Sigma_i\\) 是第 \\(i\\) 个高斯混合成分的参数, 而 \\(\\alpha_i\u003e0\\) 为相应的 “混合系数” (mixture coefficient), \\(\\sum_{i=1}^k \\alpha_i=1\\)。 假设样本的生成过程由高斯混合分布给出: 首先, 根据 \\(\\alpha_1, \\alpha_2, \\ldots, \\alpha_k\\) 定义 的先验分布选择高斯混合成分, 其中 \\(\\alpha_i\\) 为选择第 \\(i\\) 个混合成分的概率; 然后, 根 据被选择的混合成分的概率密度函数进行采样, 从而生成相应的样本。 ","date":"2022-10-25","objectID":"/%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E8%81%9A%E7%B1%BB/:0:0","tags":["Machine Learning","聚类算法","高斯混合聚类"],"title":"高斯混合聚类","uri":"/%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E8%81%9A%E7%B1%BB/"},{"categories":["Machine Learning","聚类算法"],"content":"聚类原理 如何利用高斯混合分布进行聚类？观察这个混合系数，思路就是有多少个混合的模型，就代表要聚多少类，对于给定数据集，可以定义 \\[ \\gamma_{j k}= \\begin{cases}1, \u0026 \\text { 第 } j \\text { 个观测来自第 } k \\text { 个分模型 } \\\\\\\\ 0, \u0026 \\text { 否则 }\\end{cases} \\] 则样本j的簇标记\\(\\lambda_j= \\underbrace{\\arg \\max}_{i\\in {1,2, \\dots ,k}} \\gamma_{jk}\\) ","date":"2022-10-25","objectID":"/%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E8%81%9A%E7%B1%BB/:1:0","tags":["Machine Learning","聚类算法","高斯混合聚类"],"title":"高斯混合聚类","uri":"/%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E8%81%9A%E7%B1%BB/"},{"categories":["Machine Learning","聚类算法"],"content":"EM算法 如何计算\\(\\gamma_{jk}\\)呢，如下式所示，其中\\(\\alpha_k\\)为混合系数，\\(\\theta_k\\)为第k个高斯分布的参数 \\[ \\begin{aligned} \\hat{\\gamma}_{j k} \u0026=E\\left(\\gamma_{j k} \\mid y, \\theta\\right)=P\\left(\\gamma_{j k}=1 \\mid y, \\theta\\right) \\\\\\\\ \u0026=\\frac{P\\left(\\gamma_{j k}=1, y_j \\mid \\theta\\right)}{\\sum_{k=1}^K P\\left(\\gamma_{j k}=1, y_j \\mid \\theta\\right)} \\\\\\\\ \u0026=\\frac{P\\left(y_j \\mid \\gamma_{j k}=1, \\theta\\right) P\\left(\\gamma_{j k}=1 \\mid \\theta\\right)}{\\sum_{k=1}^K P\\left(y_j \\mid \\gamma_{j k}=1, \\theta\\right) P\\left(\\gamma_{j k}=1 \\mid \\theta\\right)} \\\\\\\\ \u0026=\\frac{\\alpha_k \\phi\\left(y_j \\mid \\theta_k\\right)}{\\sum_{k=1}^K \\alpha_k \\phi\\left(y_j \\mid \\theta_k\\right)}, \\quad j=1,2, \\cdots, N ; \\quad k=1,2, \\cdots, K \\end{aligned} \\] 式子里的y其实就是观测样本。 那么模型的参数要怎么估计呢，很显然可以使用EM算法，\\(\\gamma\\)为隐变量，其实我这里的叙述顺序是有问题的，其实是EM算法中求Q函数的过程中需要计算的一个值，详细的过程在本博客的EM算法里面。总之得到了\\(\\gamma_{jk}\\)后，就得到了Q函数: \\[ Q\\left(\\theta, \\theta^{(i)}\\right)=\\sum_{k=1}^K\\{n_k \\log \\alpha_k+\\sum_{j=1}^N \\hat{\\gamma}_{j k}\\left[\\log \\left(\\frac{1}{\\sqrt{2 \\pi}}\\right)-\\log \\sigma_k-\\frac{1}{2 \\sigma_k^2}\\left(y_j-\\mu_k\\right)^2\\right]\\} \\] 极大似然估计Q函数就可以得到参数的下一轮估计值： \\[ \\theta^{(i+1)}=\\arg \\max_\\theta Q\\left(\\theta, \\theta^{(i)}\\right) \\] 用 \\(\\hat{\\mu}_k, \\hat{\\sigma}_k^2\\) 及 \\(\\hat{\\alpha}_k, k=1,2, \\cdots, K\\), 表示 \\(\\theta^{(i+1)}\\) 的各参数。求 \\(\\hat{\\mu}_k, \\hat{\\sigma}_k^2\\) 只需分别对 \\(\\mu_k, \\sigma_k^2\\) 求偏导数并令其为 0 , 即可得到; 求 \\(\\hat{\\alpha}_k\\) 是在 \\(\\sum_{k=1}^K \\alpha_k=1\\) 条件 下求偏导数并令其为 0 得到的。结果如下: \\[ \\begin{gathered} \\hat{\\mu}_k=\\frac{\\sum_{j=1}^N \\hat{\\gamma}_{j k} y_j}{\\sum_{j=1}^N \\hat{\\gamma}_{j k}}, \\quad k=1,2, \\cdots, K \\\\\\\\ \\hat{\\sigma}_k^2=\\frac{\\sum_{j=1}^N \\hat{\\gamma}_{j k}\\left(y_j-\\mu_k\\right)^2}{\\sum_{j=1}^N \\hat{\\gamma}_{j k}}, \\quad k=1,2, \\cdots, K \\\\\\\\ \\hat{\\alpha}_k=\\frac{n_k}{N}=\\frac{\\sum_{j=1}^N \\hat{\\gamma}_{j k}}{N}, \\quad k=1,2, \\cdots, K \\end{gathered} \\] 得到参数后，再进行新的一轮迭代，计算\\(\\gamma\\)值，如此反复。 算法收敛后，就可以对样本进行聚类，根据\\(\\lambda_j= \\underbrace{\\arg \\max}_{i\\in {1,2, \\dots ,k}} \\gamma_{jk}\\)可以得到每个样本的簇标记。具体的流程如下： ","date":"2022-10-25","objectID":"/%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E8%81%9A%E7%B1%BB/:2:0","tags":["Machine Learning","聚类算法","高斯混合聚类"],"title":"高斯混合聚类","uri":"/%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E8%81%9A%E7%B1%BB/"},{"categories":["Machine Learning","聚类算法"],"content":"总结 高斯混合分布的形式就注定了它可以用来进行聚类，并且还有EM算法如此强大的数学工具进行模型参数的学习，高斯混合聚类与Kmeans都属于原型聚类。 ","date":"2022-10-25","objectID":"/%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E8%81%9A%E7%B1%BB/:3:0","tags":["Machine Learning","聚类算法","高斯混合聚类"],"title":"高斯混合聚类","uri":"/%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E8%81%9A%E7%B1%BB/"},{"categories":["NLP"],"content":"Tokenization技术 本文章主要说说NLP领域中的Tokenization技术，这是很基础的但也是很容易被忽视的一个步骤。在我接的单子中经常会有此类问题，并且都是外国学校的，说明外国学校还是比较注重这一块的基础的。 首先明确一个概念：token可以理解为一个符号，就代表一个语言单位，tokenize的意思就是把一个句子或语料分成token. ","date":"2022-10-17","objectID":"/tokenization/:0:0","tags":["NLP","tokenization"],"title":"tokenization","uri":"/tokenization/"},{"categories":["NLP"],"content":"word ","date":"2022-10-17","objectID":"/tokenization/:1:0","tags":["NLP","tokenization"],"title":"tokenization","uri":"/tokenization/"},{"categories":["NLP"],"content":"char ","date":"2022-10-17","objectID":"/tokenization/:2:0","tags":["NLP","tokenization"],"title":"tokenization","uri":"/tokenization/"},{"categories":["NLP"],"content":"子词(subword) ","date":"2022-10-17","objectID":"/tokenization/:3:0","tags":["NLP","tokenization"],"title":"tokenization","uri":"/tokenization/"},{"categories":["NLP"],"content":"BPE BPE 是一种简单的数据压缩算法，它在 1994 年发表的文章“A New Algorithm for Data Compression”中被首次提出。下面的示例将解释 BPE。老规矩，我们先用一句话概括它的核心思想： BPE每一步都将最常见的一对相邻数据单位替换为该数据中没有出现过的一个新单位，反复迭代直到满足停止条件。 BPE 确保最常见的词在token列表中表示为单个token，而罕见的词被分解为两个或多个subword tokens，因此BPE也是典型的基于subword的tokenization算法。 合并字符可以让你用最少的token来表示语料库，这也是 BPE 算法的主要目标，即数据的压缩。为了合并，BPE 寻找最常出现的字节对。在这里，我们将字符视为与字节等价。当然，这只是英语的用法，其他语言可能有所不同。现在我们将最常见的字节对合并成一个token，并将它们添加到token列表中，并重新计算每个token出现的频率。这意味着我们的频率计数将在每个合并步骤后发生变化。我们将继续执行此合并步骤，直到达到我们预先设置的token数限制或迭代限制。 ","date":"2022-10-17","objectID":"/tokenization/:4:0","tags":["NLP","tokenization"],"title":"tokenization","uri":"/tokenization/"},{"categories":["NLP"],"content":"算法过程 准备语料库，确定期望的 subword 词表大小等参数 通常在每个单词末尾添加后缀 ，统计每个单词出现的频率，例如，low 的频率为 5，那么我们将其改写为 “l o w ”：5 将语料库中所有单词拆分为单个字符，用所有单个字符建立最初的词典，并统计每个字符的频率，本阶段的 subword 的粒度是字符 挑出频次最高的符号对 ，比如说 t 和 h 组成的 th，将新字符加入词表，然后将语料中所有该字符对融合（merge），即所有 t 和 h 都变为 th。 重复上述操作，直到词表中单词数达到设定量 或下一个最高频数为 1 ，如果已经打到设定量，其余的词汇直接丢弃 ","date":"2022-10-17","objectID":"/tokenization/:4:1","tags":["NLP","tokenization"],"title":"tokenization","uri":"/tokenization/"},{"categories":["NLP"],"content":"例子 获取语料库，这样一段话为例：“ FloydHub is the fastest way to build, train and deploy deep learning models. Build deep learning models in the cloud. Train deep learning models. ” 拆分，加后缀\u003c/w\u003e ，统计词频 建立词表，统计字符频率（顺便排个序）： 以第一次迭代为例，将字符频率最高的 d 和 e 替换为 de，后面依次迭代： 更新词表 继续迭代直到达到预设的 subwords 词表大小或下一个最高频的字节对出现频率为 1。 ### 优点 BPE 的优点就在于，可以很有效地平衡词典大小和编码步骤数（将语料编码所需要的 token 数量）。 随着合并的次数增加，词表大小通常先增加后减小。迭代次数太小，大部分还是字母，没什么意义；迭代次数多，又重新变回了原来那几个词。所以词表大小要取一个中间值。 ","date":"2022-10-17","objectID":"/tokenization/:4:2","tags":["NLP","tokenization"],"title":"tokenization","uri":"/tokenization/"},{"categories":["NLP"],"content":"适用范围 BPE 一般适用在欧美语言拉丁语系中，因为欧美语言大多是字符形式，涉及前缀、后缀的单词比较多。而中文的汉字一般不用 BPE 进行编码，因为中文是字无法进行拆分。对中文的处理通常只有分词和分字两种。理论上分词效果更好，更好的区别语义。分字效率高、简洁，因为常用的字不过 3000 字，词表更加简短。 ","date":"2022-10-17","objectID":"/tokenization/:4:3","tags":["NLP","tokenization"],"title":"tokenization","uri":"/tokenization/"},{"categories":["NLP"],"content":"编码过程 BPE的总体思想就是利用替换字节对来逐步构造词汇表。在使用的过程有编码和解码两种。 在之前的算法中，我们已经得到了subword的词表，对该词表按照子词长度由大到小排序。编码时，对于每个单词，遍历排好序的子词词表寻找是否有token是当前单词的子字符串，如果有，则该token是表示单词的tokens之一。 我们从最长的token迭代到最短的token，尝试将每个单词中的子字符串替换为token。 最终，我们将迭代所有tokens，并将所有子字符串替换为tokens。 如果仍然有子字符串没被替换但所有token都已迭代完毕，则将剩余的子词替换为特殊token，如 编码的计算量很大。 在实践中，我们可以pre-tokenize所有单词，并在词典中保存单词tokenize的结果。 如果我们看到字典中不存在的未知单词。 我们应用上述编码方法对单词进行tokenize，然后将新单词的tokenization添加到字典中备用。 ","date":"2022-10-17","objectID":"/tokenization/:4:4","tags":["NLP","tokenization"],"title":"tokenization","uri":"/tokenization/"},{"categories":["NLP"],"content":"代码 import re, collections def get_vocab(filename): vocab = collections.defaultdict(int) with open(filename, 'r', encoding='utf-8') as fhand: for line in fhand: words = line.strip().split() for word in words: vocab[' '.join(list(word)) + ' \u003c/w\u003e'] += 1 return vocab def get_stats(vocab): # 构建字符对频数字典 pairs = collections.defaultdict(int) for word, freq in vocab.items(): symbols = word.split() for i in range(len(symbols)-1): pairs[symbols[i],symbols[i+1]] += freq return pairs def merge_vocab(pair, v_in): # 将频率最大的字符对替换 v_out = {} bigram = re.escape(' '.join(pair)) # 不转义 p = re.compile(r'(?\u003c!\\S)' + bigram + r'(?!\\S)') # 意思是bigram前面没有非空格字符，后面也没有非空格字符 for word in v_in: w_out = p.sub(''.join(pair), word) v_out[w_out] = v_in[word] return v_out def get_tokens(vocab): tokens = collections.defaultdict(int) for word, freq in vocab.items(): word_tokens = word.split() for token in word_tokens: tokens[token] += freq return tokens vocab = {'l o w \u003c/w\u003e': 5, 'l o w e r \u003c/w\u003e': 2, 'n e w e s t \u003c/w\u003e': 6, 'w i d e s t \u003c/w\u003e': 3} print('==========') print('Tokens Before BPE') tokens = get_tokens(vocab) print('Tokens: {}'.format(tokens)) print('Number of tokens: {}'.format(len(tokens))) print('==========') num_merges = 5 for i in range(num_merges): pairs = get_stats(vocab) if not pairs: break best = max(pairs, key=pairs.get) vocab = merge_vocab(best, vocab) print('Iter: {}'.format(i)) print('Best pair: {}'.format(best)) print(vocab) # tokens = get_tokens(vocab) # print('Tokens: {}'.format(tokens)) ","date":"2022-10-17","objectID":"/tokenization/:4:5","tags":["NLP","tokenization"],"title":"tokenization","uri":"/tokenization/"},{"categories":["NLP"],"content":"wordpiece ","date":"2022-10-17","objectID":"/tokenization/:5:0","tags":["NLP","tokenization"],"title":"tokenization","uri":"/tokenization/"},{"categories":["NLP"],"content":"构造 wordpiece 词表的构造与BPE很相似，都是选择两个子词合并成新的子词。 最大的区别在于，BPE是选择频数最高的相邻子词合并，而wordpiece选择能够提升语言模型概率最大的相邻子词加入词表。 如何理解？ 假设各个子词之间是独立存在的，则句子S的语言模型似然值等价于所有子词概率的乘积 假设把相邻位置的x和y两个子词进行合并，合并后产生的子词记为z，此时句子S似然值的变化可表示为： 从上面的公式，很容易发现，似然值的变化就是两个子词之间的互信息。简而言之，WordPiece每次选择合并的两个子词，他们具有最大的互信息值，也就是两子词在语言模型上具有较强的关联性，它们经常在语料中以相邻方式同时出现。 与BPE相似，通过以上方式构建词表。 ### 编码 1. 从第一个位置开始，由于是最长匹配，结束位置需要从最右端依次递减，所以遍历的第一个子词 是其本身 unaffable，该子词不在词汇表中 2. 结束位置左移一位得到子词 unaffabl，同样不在词汇表中 3. 重复这个操作，直到 un，该子词在词汇表中，将其加入 output_tokens，以第一个位置开始 的遍历结束 4. 跳过 un，从其后的 a 开始新一轮遍历，结束位置依然是从最右端依次递减，但此时需要在前 面加上 ## 标记，得到 ##affable 不在词汇表中 5. 结束位置左移一位得到子词 ##affabl，同样不在词汇表中 6. 重复这个操作，直到 ##aff，该字词在词汇表中， 将其加入 output_tokens，此轮遍历结束 7. 跳过 aff，从其后的 a 开始新一轮遍历，结束位置依然是从最右端依次递减。##able 在词汇 表中，将其加入 output_tokens 8. able 后没有字符了，整个遍历结束 ","date":"2022-10-17","objectID":"/tokenization/:5:1","tags":["NLP","tokenization"],"title":"tokenization","uri":"/tokenization/"},{"categories":["NLP"],"content":"代码 (来自https://github.com/google-research/bert/blob/master/tokenization.py) class WordpieceTokenizer(object): \"\"\"Runs WordPiece tokenziation.\"\"\" def __init__(self, vocab, unk_token=\"[UNK]\", max_input_chars_per_word=200): self.vocab = vocab self.unk_token = unk_token self.max_input_chars_per_word = max_input_chars_per_word def tokenize(self, text): \"\"\"Tokenizes a piece of text into its word pieces. This uses a greedy longest-match-first algorithm to perform tokenization using the given vocabulary. For example: input = \"unaffable\" output = [\"un\", \"##aff\", \"##able\"] Args: text: A single token or whitespace separated tokens. This should have already been passed through `BasicTokenizer. Returns: A list of wordpiece tokens. \"\"\" text = convert_to_unicode(text) output_tokens = [] for token in whitespace_tokenize(text): chars = list(token) if len(chars) \u003e self.max_input_chars_per_word: output_tokens.append(self.unk_token) continue is_bad = False start = 0 sub_tokens = [] while start \u003c len(chars): end = len(chars) cur_substr = None while start \u003c end: substr = \"\".join(chars[start:end]) if start \u003e 0: substr = \"##\" + substr if substr in self.vocab: cur_substr = substr break end -= 1 if cur_substr is None: is_bad = True break sub_tokens.append(cur_substr) start = end if is_bad: output_tokens.append(self.unk_token) else: output_tokens.extend(sub_tokens) return output_tokens ","date":"2022-10-17","objectID":"/tokenization/:5:2","tags":["NLP","tokenization"],"title":"tokenization","uri":"/tokenization/"},{"categories":["NLP"],"content":"Unigram Language Model 与WordPiece一样，Unigram Language Model(ULM)同样使用语言模型来挑选子词。不同之处在于，BPE和WordPiece算法的词表大小都是从小到大变化，属于增量法。而Unigram Language Model则是减量法,即先初始化一个大词表，根据评估准则不断丢弃词表，直到满足限定条件。ULM算法考虑了句子的不同分词可能，因而能够输出带概率的多个子词分段。 初始时，建立一个足够大的词表(使用一些算法)。一般，可用语料中的所有字符加上常见的子字符串初始化词表，也可以通过BPE算法初始化。 针对当前词表，用EM算法求解每个子词在语料上的概率。 对于每个子词，计算当该子词被从词表中移除时，总的loss降低了多少，记为该子词的loss。 将子词按照loss大小进行排序，丢弃一定比例loss最小的子词(比如20%)，保留下来的子词生成新的词表。这里需要注意的是，单字符不能被丢弃，这是为了避免OOV情况。 重复步骤2到4，直到词表大小减少到设定范围。 可以看出，ULM会保留那些以较高频率出现在很多句子的分词结果中的子词，因为这些子词如果被丢弃，其损失会很大。 ### 代码 encode代码 def encode_word(word, model): # word初步分词，model中为-log值 best_segmentations = [{\"start\": 0, \"score\": 1}] + [ {\"start\": None, \"score\": None} for _ in range(len(word)) ] for start_idx in range(len(word)): # This should be properly filled by the previous steps of the loop best_score_at_start = best_segmentations[start_idx][\"score\"] for end_idx in range(start_idx + 1, len(word) + 1): token = word[start_idx:end_idx] if token in model and best_score_at_start is not None: score = model[token] + best_score_at_start # 加上start，即前缀对应的损失，log中相加等于原来概率相乘 # If we have found a better segmentation ending at end_idx, we update if ( best_segmentations[end_idx][\"score\"] is None or best_segmentations[end_idx][\"score\"] \u003e score # score即loss。越小越好 ): best_segmentations[end_idx] = {\"start\": start_idx, \"score\": score} print(token) print(best_segmentations[end_idx][\"score\"], score) print(best_segmentations) segmentation = best_segmentations[-1] if segmentation[\"score\"] is None: # We did not find a tokenization of the word -\u003e unknown return [\"\u003cunk\u003e\"], None # 从后向前的最佳路径，即维特比算法 score = segmentation[\"score\"] start = segmentation[\"start\"] end = len(word) tokens = [] while start != 0: tokens.insert(0, word[start:end]) next_start = best_segmentations[start][\"start\"] end = start start = next_start tokens.insert(0, word[start:end]) return tokens, score 计算Loss def compute_loss(model): loss = 0 for word, freq in word_freqs.items(): _, word_loss = encode_word(word, model) loss += freq * word_loss return loss 计算score(用于删除token) import copy def compute_scores(model): scores = {} model_loss = compute_loss(model) for token, score in model.items(): # We always keep tokens of length 1 if len(token) == 1: continue model_without_token = copy.deepcopy(model) _ = model_without_token.pop(token) scores[token] = compute_loss(model_without_token) - model_loss return scores ","date":"2022-10-17","objectID":"/tokenization/:6:0","tags":["NLP","tokenization"],"title":"tokenization","uri":"/tokenization/"},{"categories":["NLP"],"content":"参考 Unigram tokenization - Hugging Face NLP 课程 ","date":"2022-10-17","objectID":"/tokenization/:6:1","tags":["NLP","tokenization"],"title":"tokenization","uri":"/tokenization/"},{"categories":["NLP"],"content":"CoVe Cove代表上下文向量，它是一种有监督的预训练模型，其主要思想就是训练了一个NMT系统，并使用它的编码器， ","date":"2022-10-09","objectID":"/cove/:0:0","tags":["NLP","CoVe"],"title":"CoVe","uri":"/cove/"},{"categories":["NLP"],"content":"模型训练 主要假设是，为了翻译一个句子，NMT编码器学会理解句子。 因此来自编码器的向量包含有关单词上下文的信息。 形式上，作者训练了一个带注意力的LSTM模型，比如Bahdanau Model，由于最终我们想使用经过训练的编码器来处理英文句子（不是因为我们只关心英文，而是因为下游任务的大多数数据集都是英文的），所以 NMT 系统必须从英文翻译成其他的语言（例如，德语）。 ","date":"2022-10-09","objectID":"/cove/:1:0","tags":["NLP","CoVe"],"title":"CoVe","uri":"/cove/"},{"categories":["NLP"],"content":"双向编码器 请注意，在这个 NMT 模型中，编码器是双向的：它连接前向和后向 LSTM 的输出。因此，编码器输出包含有关令牌左右上下文的信息。 ","date":"2022-10-09","objectID":"/cove/:2:0","tags":["NLP","CoVe"],"title":"CoVe","uri":"/cove/"},{"categories":["NLP"],"content":"获取表示(连接 GloVe 和 Cove 向量) 训练 NTM 模型后，我们只需要它的编码器。对于给定的文本，CoVe 向量是编码器的输出。对于下游任务，作者建议使用 Glove（代表单个令牌）和 CoVe（在上下文中编码的令牌）向量的串联。这个想法是这些向量编码不同类型的信息，它们的组合可能很有用。 ","date":"2022-10-09","objectID":"/cove/:3:0","tags":["NLP","CoVe"],"title":"CoVe","uri":"/cove/"},{"categories":["NLP"],"content":"总结 其实思想很简单，就是将已经训练好的机器翻译模型的编码器作为编码，最后再与GloVe进行拼接，可以达到很好的效果，因为使用的是机器翻译模型，因此可以视为有监督学习，有监督的预训练模型是很少的，CoVe就是其中之一，其中更具体的分类可以看本博客的预训练模型。 ","date":"2022-10-09","objectID":"/cove/:4:0","tags":["NLP","CoVe"],"title":"CoVe","uri":"/cove/"},{"categories":["Machine Learning"],"content":"EM算法 ","date":"2022-10-03","objectID":"/em%E7%AE%97%E6%B3%95/:0:0","tags":["Machine Learning","EM算法"],"title":"EM算法","uri":"/em%E7%AE%97%E6%B3%95/"},{"categories":["Machine Learning"],"content":"引入 我们经常会从样本观察数据中，找出样本的模型参数。 最常用的方法就是极大化模型分布的对数似然函数。（最大似然估计：利用已知的样本结果，反推最有可能导致这样结果的一组参数）但是在一些情况下，我们得到的观察数据有未观察到的隐含数据，此时我们未知的有隐含数据和模型参数，因而无法直接用极大化对数似然函数得到模型分布的参数。用EM算法可以解决。 EM算法是一种迭代算法，用于含有隐变量的概率模型参数的极大似然估计，或极大后验概率估计。 EM算法的每次迭代由两步组成：E步，求期望；M步，求极大。所以被称为期望极大算法。 EM算法解决这个的思路是使用启发式的迭代方法，既然我们无法直接求出模型分布参数，那么我们可以先猜想隐含数据（EM算法的E步），接着基于观察数据和猜测的隐含数据一起来极大化对数似然，求解我们的模型参数（EM算法的M步)。由于我们之前的隐藏数据是猜测的，所以此时得到的模型参数一般还不是我们想要的结果。不过没关系，我们基于当前得到的模型参数，继续猜测隐含数据（EM算法的E步），然后继续极大化对数似然，求解我们的模型参数（EM算法的M步)。以此类推，不断的迭代下去，直到模型分布参数基本无变化，算法收敛，找到合适的模型参数。 ","date":"2022-10-03","objectID":"/em%E7%AE%97%E6%B3%95/:1:0","tags":["Machine Learning","EM算法"],"title":"EM算法","uri":"/em%E7%AE%97%E6%B3%95/"},{"categories":["Machine Learning"],"content":"三硬币模型 首先介绍一个使用 EM算法的例子。 (三硬币模型) 假设有 3 枚硬币, 分别记作 A, B, C。这些硬币正面出现 的概率分别是 \\(\\pi, p\\) 和 \\(q\\) 。进行如下郑硬币试验: 先掷硬币 \\(\\mathrm{A}\\), 根据其结果选出硬币 \\(\\mathrm{B}\\) 或硬币 \\(\\mathrm{C}\\), 正面选硬币 \\(\\mathrm{B}\\), 反面选硬币 \\(\\mathrm{C}\\); 然后郑选出的硬币, 掷硬币的结果, 出现正 面记作 1 , 出现反面记作 0 ; 独立地重复 \\(n\\) 次试验 (这里, \\(n=10\\) ), 观测结果如下: \\[ 1,1,0,1,0,0,1,0,1,1 \\] 假设只能观测到郑硬币的结果, 不能观测郑硬币的过程。问如何估计三硬币正面出现 的概率, 即三硬币模型的参数。 解 三硬币模型可以写作 \\[ \\begin{aligned} P(y \\mid \\theta) \u0026=\\sum_z P(y, z \\mid \\theta)=\\sum_z P(z \\mid \\theta) P(y \\mid z, \\theta) \\\\\\\\ \u0026=\\pi p^y(1-p)^{1-y}+(1-\\pi) q^y(1-q)^{1-y} \\end{aligned} \\] 这里, 随机变量 \\(y\\) 是观测变量, 表示一次试验观测的结果是 1 或 0 ; 随机变量 \\(z\\) 是隐 变量, 表示末观测到的掷硬币 \\(\\mathrm{A}\\) 的结果; \\(\\theta=(\\pi, p, q)\\) 是模型参数。这一模型是以上数 据的生成模型。注意, 随机变量 \\(y\\) 的数据可以观测, 随机变量 \\(z\\) 的数据不可观测。 将观测数据表示为 \\(Y=\\left(Y_1, Y_2, \\cdots, Y_n\\right)^{\\mathrm{T}}\\), 末观测数据表示为 \\(Z=\\left(Z_1, Z_2, \\cdots, Z_n\\right)^{\\mathrm{T}}\\) 则观测数据的似然函数为 \\[ P(Y \\mid \\theta)=\\sum_Z P(Z \\mid \\theta) P(Y \\mid Z, \\theta) \\] 即 \\[ P(Y \\mid \\theta)=\\prod_{j=1}^n\\left[\\pi p^{y_j}(1-p)^{1-y_j}+(1-\\pi) q^{y_j}(1-q)^{1-y_j}\\right] \\] 考虑求模型参数 \\(\\theta=(\\pi, p, q)\\) 的极大似然估计, 即 \\[ \\hat{\\theta}=\\arg \\max_\\theta \\log P(Y \\mid \\theta) \\] 这个问题没有解析解, 只有通过迭代的方法求解。EM算法就是可以用于求解这 个问题的一种迭代算法。下面给出针对以上问题的 EM算法, 其推导过程省略。 EM算法首先选取参数的初值, 记作 \\(\\theta^{(0)}=\\left(\\pi^{(0)}, p^{(0)}, q^{(0)}\\right)\\), 然后通过下面的 步骤迭代计算参数的估计值, 直至收敛为止。第 \\(i\\) 次迭代参数的估计值为 \\(\\theta^{(i)}=\\) \\(\\left(\\pi^{(i)}, p^{(i)}, q^{(i)}\\right)\\) 。EM算法的第 \\(i+1\\) 次迭代如下。 \\(\\mathrm{E}\\) 步：计算在模型参数 \\(\\pi^{(i)}, p^{(i)}, q^{(i)}\\) 下观测数据 \\(y_j\\) 来自郑硬币 \\(\\mathrm{B}\\) 的概率。这里就是使用的贝叶斯定理。 \\[ \\mu_j^{(i+1)}=\\frac{\\pi^{(i)}\\left(p^{(i)}\\right)^{y_j}\\left(1-p^{(i)}\\right)^{1-y_j}}{\\pi^{(i)}\\left(p^{(i)}\\right)^{y_j}\\left(1-p^{(i)}\\right)^{1-y_j}+\\left(1-\\pi^{(i)}\\right)\\left(q^{(i)}\\right)^{y_j}\\left(1-q^{(i)}\\right)^{1-y_j}} \\] \\(\\mathrm{M}\\) 步：计算模型参数的新估计值 \\[ \\pi^{(i+1)}=\\frac{1}{n} \\sum_{j=1}^n \\mu_j^{(i+1)} \\] \\[ \\begin{gathered} p^{(i+1)}=\\frac{\\sum_{j=1}^n \\mu_j^{(i+1)} y_j}{\\sum_{j=1}^n \\mu_j^{(i+1)}} \\\\\\\\ q^{(i+1)}=\\frac{\\sum_{j=1}^n\\left(1-\\mu_j^{(i+1)}\\right) y_j}{\\sum_{j=1}^n\\left(1-\\mu_j^{(i+1)}\\right)} \\end{gathered} \\] 进行数值计算。假设模型参数的初值取为 \\[ \\pi^{(0)}=0.5, \\quad p^{(0)}=0.5, \\quad q^{(0)}=0.5 \\] 对 \\(y_j=1\\) 与 \\(y_j=0\\) 均有 \\(\\mu_j^{(1)}=0.5\\) 。 利用迭代公式, 得到 \\[ \\pi^{(1)}=0.5, \\quad p^{(1)}=0.6, \\quad q^{(1)}=0.6 \\] \\[ \\mu_j^{(2)}=0.5, \\quad j=1,2, \\cdots, 10 \\] 继续迭代, 得 \\[ \\pi^{(2)}=0.5, \\quad p^{(2)}=0.6, \\quad q^{(2)}=0.6 \\] 于是得到模型参数 \\(\\theta\\) 的极大似然估计: \\[ \\hat{\\pi}=0.5, \\quad \\hat{p}=0.6, \\quad \\hat{q}=0.6 \\] \\(\\pi=0.5\\) 表示硬币 A 是均匀的, 这一结果容易理解。 如果取初值 \\(\\pi^{(0)}=0.4, p^{(0)}=0.6, q^{(0)}=0.7\\), 那么得到的模型参数的极大似然 估计是 \\(\\hat{\\pi}=0.4064, \\hat{p}=0.5368, \\hat{q}=0.6432\\) 。这就是说, EM算法与初值的选择有关, 选择不同的初值可能得到不同的参数估计值。 一般地, 用 \\(Y\\) 表示观测随机变量的数据, \\(Z\\) 表示隐随机变量的数据。 \\(Y\\) 和 \\(Z\\) 连 在一起称为完全数据 (complete-data), 观测数据 \\(Y\\) 又称为不完全数据 (incompletedata）。假设给定观测数据 \\(Y\\), 其概率分布是 \\(P(Y \\mid \\theta)\\), 其中 \\(\\theta\\) 是需要估计的模型参数, 那么不完全数据 \\(Y\\) 的似然函数是 \\(P(Y \\mid \\theta)\\), 对数似然函数 \\(L(\\theta)=\\log P(Y \\mid \\theta)\\); 假设 \\(Y\\) 和 \\(Z\\) 的联合概率分布是 \\(P(Y, Z \\mid \\theta)\\), 那么完全数据的对数似然函数是 \\(\\log P(Y, Z \\mid \\theta)\\) 。 ","date":"2022-10-03","objectID":"/em%E7%AE%97%E6%B3%95/:2:0","tags":["Machine Learning","EM算法"],"title":"EM算法","uri":"/em%E7%AE%97%E6%B3%95/"},{"categories":["Machine Learning"],"content":"算法步骤 输入: 观测变量数据 \\(Y\\), 隐变量数据 \\(Z\\), 联合分布 \\(P(Y, Z \\mid \\theta)\\), 条件分布 \\(P(Z \\mid Y, \\theta)\\); 输出：模型参数 \\(\\theta\\) 。 （1）选择参数的初值 \\(\\theta^{(0)}\\), 开始迭代; (2) \\(\\mathrm{E}\\) 步: 记 \\(\\theta^{(i)}\\) 为第 \\(i\\) 次迭代参数 \\(\\theta\\) 的估计值, 在第 \\(i+1\\) 次迭代的 \\(\\mathrm{E}\\) 步, 计算 \\[ \\begin{aligned} Q\\left(\\theta, \\theta^{(i)}\\right) \u0026=E_Z\\left[\\log P(Y, Z \\mid \\theta) \\mid Y, \\theta^{(i)}\\right] \\\\\\\\ \u0026=\\sum_Z \\log P(Y, Z \\mid \\theta) P\\left(Z \\mid Y, \\theta^{(i)}\\right) \\end{aligned} \\] 这里, \\(P\\left(Z \\mid Y, \\theta^{(i)}\\right)\\) 是在给定观测数据 \\(Y\\) 和当前的参数估计 \\(\\theta^{(i)}\\) 下隐变量数据 \\(Z\\) 的条 件概率分布; (3) \\(\\mathrm{M}\\) 步：求使 \\(Q\\left(\\theta, \\theta^{(i)}\\right)\\) 极大化的 \\(\\theta\\), 确定第 \\(i+1\\) 次迭代的参数的估计值 \\(\\theta^{(i+1)}\\) \\[ \\theta^{(i+1)}=\\arg \\max_\\theta Q\\left(\\theta, \\theta^{(i)}\\right) \\] 重复第 (2) 步和第 (3) 步, 直到收敛。 ","date":"2022-10-03","objectID":"/em%E7%AE%97%E6%B3%95/:3:0","tags":["Machine Learning","EM算法"],"title":"EM算法","uri":"/em%E7%AE%97%E6%B3%95/"},{"categories":["Machine Learning"],"content":"Q函数 函数 \\(Q\\left(\\theta, \\theta^{(i)}\\right)\\) 是 EM算法的核心, 称为 \\(Q\\) 函数 ( \\(Q\\) function)。 \\({Q}\\) 函数 : 完全数据 的对数似然函数 \\(\\log P(Y, Z \\mid \\theta)\\) 关于在给定观测数 据 \\(Y\\) 和当前参数 \\(\\theta^{(i)}\\) 下对未观测数据 \\(Z\\) 的条件概率分布 \\(P\\left(Z \\mid Y, \\theta^{(i)}\\right)\\) 的期望称为 \\(Q\\) 函数, 即 \\[ Q\\left(\\theta, \\theta^{(i)}\\right)=E_Z\\left[\\log P(Y, Z \\mid \\theta) \\mid Y, \\theta^{(i)}\\right] = \\sum_Z \\log P(Y,Z\\mid \\theta) P\\left (Z\\mid Y, \\theta^{(i)}\\right) \\] ","date":"2022-10-03","objectID":"/em%E7%AE%97%E6%B3%95/:4:0","tags":["Machine Learning","EM算法"],"title":"EM算法","uri":"/em%E7%AE%97%E6%B3%95/"},{"categories":["Machine Learning"],"content":"Jensen不等式 如果f是凸函数，X是随机变量，那么有 \\[ E[f(X)] \\geq f[E(X)] \\] 如果f是凹函数则相反 这个图可以比较清晰的看出这个结论。 ","date":"2022-10-03","objectID":"/em%E7%AE%97%E6%B3%95/:5:0","tags":["Machine Learning","EM算法"],"title":"EM算法","uri":"/em%E7%AE%97%E6%B3%95/"},{"categories":["Machine Learning"],"content":"EM算法的导出 为什么 EM算法能近似实现对观测数据的极大似然估计 呢? 下面通过近似求解观测数据的对数似然函数的极大化问题来导出 EM算法, 由此 可以清楚地看出 EM算法的作用。 我们面对一个含有隐变量的概率模型, 目标是极大化观测数据 (不完全数据) \\(Y\\) 关于参数 \\(\\theta\\) 的对数似然函数, 即极大化 \\[ \\begin{aligned} L(\\theta) \u0026=\\log P(Y \\mid \\theta)=\\log \\sum_Z P(Y, Z \\mid \\theta) \\\\\\\\ \u0026=\\log \\left(\\sum_Z P(Y \\mid Z, \\theta) P(Z \\mid \\theta)\\right) \\end{aligned} \\] 注意到这一极大化的主要困难是式中有末观测数据并有包含和 (或积分) 的 对数。 事实上, EM算法是通过迭代逐步近似极大化 \\(L(\\theta)\\) 的。假设在第 \\(i\\) 次迭代后 \\(\\theta\\) 的 估计值是 \\(\\theta^{(i)}\\) 。我们希望新估计值 \\(\\theta\\) 能使 \\(L(\\theta)\\) 增加, 即 \\(L(\\theta)\u003eL\\left(\\theta^{(i)}\\right)\\), 并逐步达到极 大值。为此, 考虑两者的差: \\[ L(\\theta)-L\\left(\\theta^{(i)}\\right)=\\log \\left(\\sum_Z P(Y \\mid Z, \\theta) P(Z \\mid \\theta)\\right)-\\log P\\left(Y \\mid \\theta^{(i)}\\right) \\] 利用 Jensen 不等式 (Jensen inequality)得到其下界，这里的f即为log函数，是凹函数，则结论与凸函数时的结论是相反的。: \\[ \\begin{aligned} L(\\theta)-L\\left(\\theta^{(i)}\\right) \u0026=\\log \\left(\\sum_Z P\\left(Z \\mid Y, \\theta^{(i)}\\right) \\frac{P(Y \\mid Z, \\theta) P(Z \\mid \\theta)}{P\\left(Z \\mid Y, \\theta^{(i)}\\right)}\\right)-\\log P\\left(Y \\mid \\theta^{(i)}\\right) \\\\\\\\ \u0026 \\geqslant \\sum_Z P\\left(Z \\mid Y, \\theta^{(i)}\\right) \\log \\frac{P(Y \\mid Z, \\theta) P(Z \\mid \\theta)}{P\\left(Z \\mid Y, \\theta^{(i)}\\right)}-\\log P\\left(Y \\mid \\theta^{(i)}\\right) \\\\\\\\ \u0026=\\sum_Z P\\left(Z \\mid Y, \\theta^{(i)}\\right) \\log \\frac{P(Y \\mid Z, \\theta) P(Z \\mid \\theta)}{P\\left(Z \\mid Y, \\theta^{(i)}\\right) P\\left(Y \\mid \\theta^{(i)}\\right)} \\end{aligned} \\] 令 \\[ B\\left(\\theta, \\theta^{(i)}\\right) \\hat{=} L\\left(\\theta^{(i)}\\right)+\\sum_Z P\\left(Z \\mid Y, \\theta^{(i)}\\right) \\log \\frac{P(Y \\mid Z, \\theta) P(Z \\mid \\theta)}{P\\left(Z \\mid Y, \\theta^{(i)}\\right) P\\left(Y \\mid \\theta^{(i)}\\right)} \\] 则要求： \\[ L(\\theta) \\geqslant B\\left(\\theta, \\theta^{(i)}\\right) \\] 即函数 \\(B\\left(\\theta, \\theta^{(i)}\\right)\\) 是 \\(L(\\theta)\\) 的一个下界, 可知, \\[ L\\left(\\theta^{(i)}\\right)=B\\left(\\theta^{(i)}, \\theta^{(i)}\\right) \\] 因此, 任何可以使 \\(B\\left(\\theta, \\theta^{(i)}\\right)\\) 增大的 \\(\\theta\\), 也可以使 \\(L(\\theta)\\) 增大。这里回顾一下我们最原始的目标，就是为了最大化\\(L(\\theta)\\)，为了使 \\(L(\\theta)\\) 有尽可能大 的增长, 选择 \\(\\theta^{(i+1)}\\) 使 \\(B\\left(\\theta, \\theta^{(i)}\\right)\\) 达到极大, 即 \\[ \\theta^{(i+1)}=\\arg \\max_\\theta B\\left(\\theta, \\theta^{(i)}\\right) \\] 现在求 \\(\\theta^{(i+1)}\\) 的表达式。省去对 \\(\\theta\\) 的极大化而言是常数的项 \\[ \\begin{aligned} \\theta^{(i+1)} \u0026=\\arg \\max_\\theta\\left(L\\left(\\theta^{(i)}\\right)+\\sum_Z P\\left(Z \\mid Y, \\theta^{(i)}\\right) \\log \\frac{P(Y \\mid Z, \\theta) P(Z \\mid \\theta)}{P\\left(Z \\mid Y, \\theta^{(i)}\\right) P\\left(Y \\mid \\theta^{(i)}\\right)}\\right) \\\\\\\\ \u0026=\\arg \\max_\\theta\\left(\\sum_Z P\\left(Z \\mid Y, \\theta^{(i)}\\right) \\log (P(Y \\mid Z, \\theta) P(Z \\mid \\theta))\\right) \\\\\\\\ \u0026=\\arg \\max_\\theta\\left(\\sum_Z P\\left(Z \\mid Y, \\theta^{(i)}\\right) \\log P(Y, Z \\mid \\theta)\\right) \\\\\\\\ \u0026=\\arg \\max_\\theta Q\\left(\\theta, \\theta^{(i)}\\right) \\end{aligned} \\] 这等价于 EM算法的一次迭代, 即求 \\(Q\\) 函数及其极大化。EM算法是通过 不断求解下界的极大化逼近求解对数似然函数极大化的算法。 下图给出 EM算法的直观解释。注意两个曲线的交点就是在\\(\\theta^{(i)}\\) 这里其实就是相当于推导为什么最大化Q函数对应的参数就是当前迭代的最佳参数。 ","date":"2022-10-03","objectID":"/em%E7%AE%97%E6%B3%95/:6:0","tags":["Machine Learning","EM算法"],"title":"EM算法","uri":"/em%E7%AE%97%E6%B3%95/"},{"categories":["Machine Learning"],"content":"高斯混合模型 高斯混合模型是指有如下形式的概率分布模型： \\[ P(y\\mid \\theta ) = \\sum_{k=1}^K\\alpha_k \\Phi(y\\mid \\theta_k) \\] 其中\\(\\alpha_k\\)为系数，\\(\\alpha_k \\geq 0, \\sum_{k=1}^K\\alpha_k=1\\); \\(\\Phi(y\\mid \\theta_k)\\)为高斯密度函数，\\(\\theta_k=(\\mu_k,\\sigma_k^2)\\) \\[ \\Phi(y\\mid \\theta_k) = \\frac{1}{\\sqrt{2\\pi}\\sigma_k}\\exp \\left(-\\frac{(y-\\mu_k)^2}{2\\sigma_k^2} \\right) \\] 为第k个模型。 ","date":"2022-10-03","objectID":"/em%E7%AE%97%E6%B3%95/:7:0","tags":["Machine Learning","EM算法"],"title":"EM算法","uri":"/em%E7%AE%97%E6%B3%95/"},{"categories":["Machine Learning"],"content":"EM算法的应用 明确隐变量, 写出完全数据的对数似然函数 可以设想观测数据 \\(y_j, j=1,2, \\cdots, N\\), 是这样产生的: 首先依概率 \\(\\alpha_k\\) 选择第 \\(k\\) 个高斯分布分模型 \\(\\phi\\left(y \\mid \\theta_k\\right)\\), 然后依第 \\(k\\) 个分模型的概率分布 \\(\\phi\\left(y \\mid \\theta_k\\right)\\) 生成观测数据 \\(y_j\\) 。这时观测数据 \\(y_j, j=1,2, \\cdots, N\\), 是已知的; 反映观测数据 \\(y_j\\) 来自第 \\(k\\) 个分模 型的数据是末知的, \\(k=1,2, \\cdots, K\\), 以隐变量 \\(\\gamma_{j k}\\) 表示, 其定义如下: \\[ \\gamma_{j k}= \\begin{cases}1, \u0026 \\text { 第 } j \\text { 个观测来自第 } k \\text { 个分模型 } \\\\\\\\ 0, \u0026 \\text { 否则 }\\end{cases} \\] \\[ j=1,2, \\cdots, N ; \\quad k=1,2, \\cdots, K \\] \\(\\gamma_{j k}\\) 是 0-1 随机变量。 有了观测数据 \\(y_j\\) 及末观测数据 \\(\\gamma_{j k}\\), 那么完全数据是 \\[ \\left(y_j, \\gamma_{j 1}, \\gamma_{j 2}, \\cdots, \\gamma_{j K}\\right), \\quad j=1,2, \\cdots, N \\] 于是, 可以写出完全数据的似然函数: \\[ \\begin{aligned} P(y, \\gamma \\mid \\theta) \u0026=\\prod_{j=1}^N P\\left(y_j, \\gamma_{j 1}, \\gamma_{j 2}, \\cdots, \\gamma_{j K} \\mid \\theta\\right) \\\\\\\\ \u0026=\\prod_{k=1}^K \\prod_{j=1}^N\\left[\\alpha_k \\phi\\left(y_j \\mid \\theta_k\\right)\\right]^{\\gamma_{j k}} \\\\\\\\ \u0026=\\prod_{k=1}^K \\alpha_k^{n_k} \\prod_{j=1}^N\\left[\\phi\\left(y_j \\mid \\theta_k\\right)\\right]^{\\gamma_{j k}} \\\\\\\\ \u0026=\\prod_{k=1}^K \\alpha_k^{n_k} \\prod_{j=1}^N\\left[\\frac{1}{\\sqrt{2 \\pi} \\sigma_k} \\exp \\left(-\\frac{\\left(y_j-\\mu_k\\right)^2}{2 \\sigma_k^2}\\right)\\right]^{\\gamma_{j k}} \\end{aligned} \\] 式中, \\(n_k=\\sum_{j=1}^N \\gamma_{j k}, \\sum_{k=1}^K n_k=N\\) 。 那么, 完全数据的对数似然函数为 \\[ \\log P(y, \\gamma \\mid \\theta)=\\sum_{k=1}^K\\left\\\\{n_k \\log \\alpha_k+\\sum_{j=1}^N \\gamma_{j k}\\left[\\log \\left(\\frac{1}{\\sqrt{2 \\pi}}\\right)-\\log \\sigma_k-\\frac{1}{2 \\sigma_k^2}\\left(y_j-\\mu_k\\right)^2\\right]\\right\\} \\] EM 算法的 \\(\\mathrm{E}\\) 步: 确定 \\(Q\\) 函数 \\[ \\begin{aligned} Q\\left(\\theta, \\theta^{(i)}\\right) \u0026=E\\left[\\log P(y, \\gamma \\mid \\theta) \\mid y, \\theta^{(i)}\\right] \\\\\\\\ \u0026=E\\left{\\sum_{k=1}^K\\left{n_k \\log \\alpha_k+\\sum_{j=1}^N \\gamma_{j k}\\left[\\log \\left(\\frac{1}{\\sqrt{2 \\pi}}\\right)-\\log \\sigma_k-\\frac{1}{2 \\sigma_k^2}\\left(y_j-\\mu_k\\right)^2\\right]\\right}\\right} \\\\\\\\ \u0026=\\sum_{k=1}^K\\left\\\\{\\sum_{j=1}^N\\left(E \\gamma_{j k}\\right) \\log \\alpha_k+\\sum_{j=1}^N\\left(E \\gamma_{j k}\\right)\\left[\\log \\left(\\frac{1}{\\sqrt{2 \\pi}}\\right)-\\log \\sigma_k-\\frac{1}{2 \\sigma_k^2}\\left(y_j-\\mu_k\\right)^2\\right]\\right} \\end{aligned} \\] 这里需要计算 \\(E\\left(\\gamma_{j k} \\mid y, \\theta\\right)\\), 记为 \\(\\hat{\\gamma}_{j k}\\) 。 \\[ \\begin{aligned} \\hat{\\gamma}_{j k} \u0026=E\\left(\\gamma_{j k} \\mid y, \\theta\\right)=P\\left(\\gamma_{j k}=1 \\mid y, \\theta\\right) \\\\\\\\ \u0026=\\frac{P\\left(\\gamma_{j k}=1, y_j \\mid \\theta\\right)}{\\sum_{k=1}^K P\\left(\\gamma_{j k}=1, y_j \\mid \\theta\\right)} \\\\\\\\ \u0026=\\frac{P\\left(y_j \\mid \\gamma_{j k}=1, \\theta\\right) P\\left(\\gamma_{j k}=1 \\mid \\theta\\right)}{\\sum_{k=1}^K P\\left(y_j \\mid \\gamma_{j k}=1, \\theta\\right) P\\left(\\gamma_{j k}=1 \\mid \\theta\\right)} \\\\\\\\ \u0026=\\frac{\\alpha_k \\phi\\left(y_j \\mid \\theta_k\\right)}{\\sum_{k=1}^K \\alpha_k \\phi\\left(y_j \\mid \\theta_k\\right)}, \\quad j=1,2, \\cdots, N ; \\quad k=1,2, \\cdots, K \\end{aligned} \\] \\(\\hat{\\gamma}_{j k}\\) 是在当前模型参数下第 \\(j\\) 个观测数据来自第 \\(k\\) 个分模型的概率, 称为分模型 \\(k\\) 对 观测数据 \\(y_j\\) 的响应度。 将 \\(\\hat{\\gamma}_{j k}=E \\gamma_{j k}\\) 及 \\(n_k=\\sum_{j=1}^N E \\gamma_{j k}\\) 代入, 即得 \\[ Q\\left(\\theta, \\theta^{(i)}\\right)=\\sum_{k=1}^K\\left\\\\{n_k \\log \\alpha_k+\\sum_{j=1}^N \\hat{\\gamma}_{j k}\\left[\\log \\left(\\frac{1}{\\sqrt{2 \\pi}}\\right)-\\log \\sigma_k-\\frac{1}{2 \\sigma_k^2}\\left(y_j-\\mu_k\\right)^2\\right]\\right\\\\\\} \\] 确定 EM 算法的 \\(M\\) 步 迭代的 \\(\\mathrm{M}\\) 步是求函数 \\(Q\\left(\\theta, \\theta^{(i)}\\right)\\) 对 \\(\\theta\\) 的极大值, 即求新一轮迭代的模型参数: \\[ \\theta^{(i+1)}=\\arg \\max_\\theta Q\\left(\\theta, \\theta^{(i)}\\right) \\] 用 \\(\\hat{\\mu}_k, \\hat{\\sigma}_k^2\\) 及 \\(\\hat{\\alpha}_k, k=1,2, \\cdots, K\\), 表示 \\(\\theta^{(i+1)}\\) 的各参数。求 \\(\\hat{\\mu}_k, \\hat{\\sigma}_k^2\\) 只需分别对 \\(\\mu_k, \\sigma_k^2\\) 求偏导数并令其为 0 , 即可得到; 求 \\(\\hat{\\alpha}_k\\) 是在 \\(\\sum_{k=1}^K \\alpha_k=1\\) 条件 下求偏导数并令其为 0 得到的。结果如下: \\[ \\begin{gathered} \\hat{\\mu}_k=\\frac{\\sum_{j=1}^N \\hat{\\gamma}_{j k} y_j}{\\sum_{j=1}^N \\hat{\\gamma}_{j k}}, \\quad k=1,2, \\cdots, K \\\\\\\\ \\hat{\\sigma}_k^2=\\frac{\\sum_{j=1}^N \\hat{\\gamma}_{j k}\\left(y_j-\\mu_k\\right)^2}{\\sum_{j=1}^N \\ha","date":"2022-10-03","objectID":"/em%E7%AE%97%E6%B3%95/:7:1","tags":["Machine Learning","EM算法"],"title":"EM算法","uri":"/em%E7%AE%97%E6%B3%95/"},{"categories":["Machine Learning"],"content":"算法应用总结 (高斯混合模型参数估计的EM算法) 输入: 观测数据 \\(y_1, y_2, \\cdots, y_N\\), 高斯混合模型; 输出：高斯混合模型参数。 （1）取参数的初始值开始迭代; (2) \\(\\mathrm{E}\\) 步: 依据当前模型参数, 计算分模型 \\(k\\) 对观测数据 \\(y_j\\) 的响应度 \\[ \\hat{\\gamma}_{j k}=\\frac{\\alpha_k \\phi\\left(y_j \\mid \\theta_k\\right)}{\\sum_{k=1}^K \\alpha_k \\phi\\left(y_j \\mid \\theta_k\\right)}, \\quad j=1,2, \\cdots, N ; \\quad k=1,2, \\cdots, K \\] \\(\\mathrm{M}\\) 步：计算新一轮迭代的模型参数 \\[ \\hat{\\mu}_k=\\frac{\\sum_{j=1}^N \\hat{\\gamma}_{j k} y_j}{\\sum_{j=1}^N \\hat{\\gamma}_{j k}}, \\quad k=1,2, \\cdots, K \\] \\[ \\hat{\\sigma}_k^2=\\frac{\\sum_{j=1}^N \\hat{\\gamma}_{jk}(y_j-\\mu_k)^2}{\\sum_{j=1}^N \\hat{\\gamma}_{jk}}, \\quad k= 1,2,\\dots, K \\] \\[ \\hat{\\alpha}_k = \\frac{\\sum_{j=1}^N \\hat{\\gamma}_{jk}}{N} ,\\quad k=1,2,\\dots, K \\] 重复直到收敛。 ","date":"2022-10-03","objectID":"/em%E7%AE%97%E6%B3%95/:7:2","tags":["Machine Learning","EM算法"],"title":"EM算法","uri":"/em%E7%AE%97%E6%B3%95/"},{"categories":["Machine Learning"],"content":"总结 总之来说em算法作为数据挖掘十大算法之一，应用范围十分广泛，它不能看作是一个具体的模型，常常用于模型的求解，比如HMM的学习参数问题等等，是必须要学会的算法之一。 ","date":"2022-10-03","objectID":"/em%E7%AE%97%E6%B3%95/:8:0","tags":["Machine Learning","EM算法"],"title":"EM算法","uri":"/em%E7%AE%97%E6%B3%95/"},{"categories":["算法题"],"content":"分发饼干 https://leetcode-cn.com/problems/assign-cookies/ class Solution: def findContentChildren(g, s) -\u003e int: g = sorted(g) s = sorted(s) n = 0 for i in range(len(s)): if g[n] \u003c= s[i]: n += 1 if n == len(g): return n return n 贪心算法的题目，考虑局部最优 ","date":"2022-10-03","objectID":"/%E5%88%86%E5%8F%91%E9%A5%BC%E5%B9%B2/:0:0","tags":["算法题","分发饼干"],"title":"分发饼干","uri":"/%E5%88%86%E5%8F%91%E9%A5%BC%E5%B9%B2/"},{"categories":["工具"],"content":"正则表达式 [abcd]匹配中括号里的所有字符 [^abcd]匹配除了括号里的所有字符 [A-Za-z]匹配所有字母 [\\s\\S]是匹配所有空白符，包括换行，非空白符，包括换行 [\\w] 匹配字母、数字、下划线。等价于 [A-Za-z0-9_] 匹配有特殊含义的，比如* ^ 等 记得要加上反斜杠进行转义 ？匹配前面的表达式0次或1次 **.匹配除* +匹配前面的表达式1次或多次 *匹配前面的表达式0次或多次 {n}匹配n次，{n,m}最少匹配n次，最多m次，{n,}至少匹配n次 定位符：^ $ 即限定在哪里匹配 （）灵活应用 [.]等价于\\. ","date":"2022-09-28","objectID":"/regex/:0:0","tags":["工具","regex"],"title":"regex","uri":"/regex/"},{"categories":["工具"],"content":"运算优先级 image.png ","date":"2022-09-28","objectID":"/regex/:1:0","tags":["工具","regex"],"title":"regex","uri":"/regex/"},{"categories":["工具"],"content":"零宽度断言（前后预查） ","date":"2022-09-28","objectID":"/regex/:2:0","tags":["工具","regex"],"title":"regex","uri":"/regex/"},{"categories":["工具"],"content":"?=…正先行断言 ?=...表示正先行断言，表示第一部分表达式之后必须跟着?=...定义的表达式。 返回结果只包含满足匹配条件的第一部分表达式。 定义一个正先行断言要使用 ()。在括号内部使用一个问号和等号： (?=...)。 正先行断言的内容写在括号中的等号后面。 例如，表达式 (T|t)he(?=\\sfat) 匹配 The 和 the，在括号中我们又定义了正先行断言 (?=\\sfat) ，即 The 和 the 后面紧跟着 (空格)fat。 ","date":"2022-09-28","objectID":"/regex/:2:1","tags":["工具","regex"],"title":"regex","uri":"/regex/"},{"categories":["工具"],"content":"?!… 负先行断言 负先行断言 ?! 用于筛选所有匹配结果，筛选条件为 其后不跟随着断言中定义的格式。 正先行断言 定义和 负先行断言 正好相反。 表达式 (T|t)he(?!\\sfat) 匹配 The 和 the，且其后不跟着 (空格)fat。 ### ?\u003c=… 正后发断言 正后发断言 记作(?\u003c=...) 用于筛选所有匹配结果，筛选条件为 其前跟随着断言中定义的格式。 例如，表达式 (?\u003c=(T|t)he\\s)(fat|mat) 匹配 fat 和 mat，且其前跟着 The 或 the。 ### ?\u003c!… 负后发断言 负后发断言 记作 (?\u003c!...) 用于筛选所有匹配结果，筛选条件为 其前不跟随着断言中定义的格式。 例如，表达式 (?\u003c!(T|t)he\\s)(cat) 匹配 cat，且其前不跟着 The 或 the。 此外还有一种是?:，用于括号匹配中，即non-capturing group， # 实战 ","date":"2022-09-28","objectID":"/regex/:2:2","tags":["工具","regex"],"title":"regex","uri":"/regex/"},{"categories":["工具"],"content":"Matching a decimal numbers 来源:https://regexone.com/problem/matching_decimal_numbers 意思就是要匹配Match的还要避开Skip的 具体实现： ^-?\\d+(,\\d+)*(\\.\\d+(e\\d+)?)?$ 解释： ​ 开头匹配负号，其实这里可以变成[\\\\-\\\\+]? 以防出现正号 ​ 然后匹配带逗号的数字，匹配0次或多次 ​ 然后匹配带小数点的数字，匹配0次或1次，因为小数点最多出现一次 ​ 显然后面跟着匹配指数，显然指数也最多出现一次。 ","date":"2022-09-28","objectID":"/regex/:3:0","tags":["工具","regex"],"title":"regex","uri":"/regex/"},{"categories":["pandas"],"content":"pandas实践1 在读取数据之前，我修改了表格里面的表头，以便程序的编写。 先从 excel 读取数据,然后看看 shape 了解行数列数,然后调用 info 方法， 看看有没有缺失值，发现并没有缺失值，但题目里说了可能有重复或者格式 不对的数据，因为最主要的是学号,一般学号的长度都是 12 个数字，所以筛 选出不是 12 位数的 data[data['studentid'].apply(lambda x:len(x)!=12)] 考虑到可能出现中文的情况，先尝试转化为整数试试 data[‘studentid’] = data[‘studentid’].astype(“int64”) 发现报错了，然后就看见了那个学号是’忘记了’的 最后修改成了 data[data['studentid'].apply(lambda x:len(x)!=12 or x=='忘记了')] 将这些数据删除 data = data.drop(data[data['studentid'].apply(lambda x:len(x)!=12 or x=='忘记了')].index) 考虑到有重复，重复的两个因素就是姓名和学号，因此进行去重处理 data.drop_duplicates(subset=['name','studentid'],keep='first',inplace=Tru e) 此外，对专业的处理，将无用的 xx-x 去掉即可，这里考虑到了正则表达式 data['class'] = data['class'].apply(lambda s:re.sub(r\"[\\s*\\d*\\-*\\—*\\ － *\\–*\\/*]?\",'',s)) 因为各种各样的-负号千奇百怪，我只能一次次修改后然后统计一下即调用 data[‘class’].value_counts() 有没有没有处理到的，然后把那个-符号加进去 还发现了有/号。 最后就成了那样，写到这里我有了更好的想法，和下面的 某两个个例有关系。 然后就是那个 maps 表，都简化为简称，对称呼进行统一，用了 apply 方 法 再统计一下，发现了两个专业后面带名字的学长学姐，因为就两个，就把他 们加到 maps 里面了，其实也可以判断名字是否在专业里面，如果在就替换 为空吧。 之后就差不多可以了，数据预处理完毕，按照要求保存即可。 #数据预处理文件 import pandas as pd import re data = pd.read_excel(\"附件1.xlsx\") #去除错误数据 data = data.drop(data[data['studentid'].apply(lambda x:len(x)!=12 or x=='忘记了')].index) #去重 data.drop_duplicates(subset=['name','studentid'], keep='first', inplace=True) data['class'] = data['class'].apply(lambda s:re.sub(r\"[\\s*\\d*\\-*\\—*\\－*\\–*\\/*]?\", '', s)) maps = { '智能科学':'智科', '云计算':'云计', '应用统计学':'统计', '信息与计算科学':'信计', '智能科学与技术':'智科', '应用统计':'统计', '软件工程':'软工', '信息与计算科学（云计算）':'信计', '光电信息与科学':'光电', '信计（云计算）':'信计', '光电信息科学与工程':'光电', '数据科学':'大数据', '智科科学':'智科', '信计学长':'信计', '信计学姐':'信计', '统计学':'统计', '信息计算与科学':'信计', '信计与计算科学':'信计' } def replaces(clas): if clas in maps.keys(): return maps[clas] else: return clas data['class'] = data['class'].apply(replaces) res = pd.DataFrame() res['账号'] = '21aidc' + data['studentid'] res['姓名'] = data['name'] res['密码'] = res['账号'] res['专业'] = data['class'] res.to_excel(\"result.xlsx\", index=False,encoding='utf-8') ","date":"2022-09-20","objectID":"/aidc%E6%B5%8B%E8%AF%95/:0:0","tags":["pandas","task1"],"title":"aidc测试","uri":"/aidc%E6%B5%8B%E8%AF%95/"},{"categories":["Deep Learning","优化算法","优化器"],"content":"moment(矩) 矩在数学中的定义，一阶矩(first moment)就是样本的均值(mean), 二阶矩就是方差（variance）。 ## 滑动平均 滑动平均(exponential moving average)，或者叫做指数加权平均(exponentially weighted moving average)，可以用来估计变量的局部均值，使得变量的更新与一段时间内的历史取值有关。在时间序列预测中也常用。 变量 \\(v\\) 在 \\(t\\) 时刻记为 \\(v_{t} ，\\text{可以理解为0到t时刻的平均值} 。\\quad \\theta_{t}\\) 为变量 \\(v\\) 在 \\(t\\) 时刻的取值，即在不使用滑动平均模型时 \\(v_{t}=\\theta_{t}\\) ，在使用滑动平均模型后， \\(v_{t}\\) 的更新公式如下: \\[ v_{t}=\\beta \\cdot v_{t-1}+(1-\\beta) \\cdot \\theta_{t} \\] 上式中， \\(\\beta \\in[0,1) ， \\beta=0\\) 相当于没有使用滑动平均。 这也是RMSProp和Adam等算法里使用的最重要的思想。通过滑动平均来降低梯度的波动值。 ## Adam 下面看最经典的伪代码： adam算法比起adagrad和RMSProp，不仅加入了一阶和二阶moment的计算。而且加入了bias-correction term。以下将展开分析： ","date":"2022-09-11","objectID":"/adam/:1:0","tags":["Deep","Learning","优化算法","Adam算法","优化器"],"title":"Adam算法","uri":"/adam/"},{"categories":["Deep Learning","优化算法","优化器"],"content":"adam的更新率（stepsize) adam算法中最重要的就是每次迭代的迭代率（step size），他决定了adam算法的效率。根据上 文的算法， step size等于: \\(\\Delta_{t}=\\alpha \\cdot \\widehat{m}_{t} / \\sqrt{\\hat{v}_{t}}\\) 1) 当 \\(\\left(1-\\beta_{1}\\right)\u003e\\sqrt{1-\\beta_{2}}\\) 的时候，它的上界满足不等式: \\(\\left|\\Delta_{t}\\right| \\leq \\alpha \\cdot\\left(1-\\beta_{1}\\right) / \\sqrt{1-\\beta_{2}}\\) 2) 否则 \\(\\left|\\Delta_{t}\\right| \\leq \\alpha\\) 1）通常发生在数据很稀疏的时候。当数据密集的时候， stepsize会更小。 3) 当 \\(\\left(1-\\beta_{1}\\right)=\\sqrt{1-\\beta_{2}}\\) 的时候，因为 \\(\\left|\\widehat{m}_{t} / \\sqrt{\\hat{v}_{t}}\\right|\u003c1\\) 所以，也满足条件 2 的 \\(\\left|\\Delta_{t}\\right| \\leq \\alpha\\) 总结以上3个条件，可以近似得出stepsize 满足 \\(\\left|\\Delta_{t}\\right| \\cong \\alpha\\) 这里的 \\(\\widehat{m}_{t} / \\sqrt{\\hat{v}_{t}}\\) 通常也成为信噪比（Signal-to-noise ratio SNR)，并且满足SND越小， stepsize也越小。 ","date":"2022-09-11","objectID":"/adam/:1:1","tags":["Deep","Learning","优化算法","Adam算法","优化器"],"title":"Adam算法","uri":"/adam/"},{"categories":["Deep Learning","优化算法","优化器"],"content":"初始化偏差矫正项 原算法中的这两行 \\[ \\begin{aligned} \u0026\\widehat{m}_{t} \\leftarrow m_{t} /\\left(1-\\beta_{1}^{t}\\right) \\\\\\\\ \u0026\\hat{v}_{t} \\leftarrow v_{t} /\\left(1-\\beta_{2}^{t}\\right) \\end{aligned} \\] 称为偏差校正项(bias-correction term),他使用了滑动平均值(EMA: exponential moving average)的思想，例如计算二次moment的 \\(v_{t}=\\beta_{2} \\cdot v_{t-1}+\\left(1-\\beta_{2}\\right) \\cdot g_{t}^{2}\\) 可以写成如下的形 式： \\[ v_{t}=\\left(1-\\beta_{2}\\right) \\sum_{i=1}^{t} \\beta_{2}^{t-i} \\cdot g_{i}^{2} \\] 我们的目的是求得 \\(\\mathbb{E}\\left[v_{t}\\right]\\) (EMA) 和二阶moment \\(\\mathbb{E}\\left[g_{t}^{2}\\right]\\) 之间的关系，推导如下: \\[ \\begin{aligned} \\mathbb{E}\\left[v_{t}\\right] \u0026=\\mathbb{E}\\left[\\left(1-\\beta_{2}\\right) \\sum_{i=1}^{t} \\beta_{2}^{t-i} \\cdot g_{i}^{2}\\right] \\\\\\\\ \u0026=\\mathbb{E}\\left[g_{t}^{2}\\right] \\cdot\\left(1-\\beta_{2}\\right) \\sum_{i=1}^{t} \\beta_{2}^{t-i}+\\zeta \\\\\\\\ \u0026=\\mathbb{E}\\left[g_{t}^{2}\\right] \\cdot\\left(1-\\beta_{2}^{t}\\right)+\\zeta \\end{aligned} \\] 最后得出 \\(\\mathbb{E}\\left[g_{t}^{2}\\right]=\\frac{\\mathbb{E}\\left[v_{t}\\right]-\\zeta}{\\left(1-\\beta_{2}^{t}\\right)}\\) 通常可以忽略常数 \\(\\zeta\\) 。得出 \\[ \\bar{v_t} = \\frac{v_t}{1-\\beta_2^t} \\] 综上所述，Adam 优化器可以根据历史梯度的震荡情况和过滤震荡后的真实历史梯度对变量进行更新 ","date":"2022-09-11","objectID":"/adam/:1:2","tags":["Deep","Learning","优化算法","Adam算法","优化器"],"title":"Adam算法","uri":"/adam/"},{"categories":["Machine Learning","性能指标"],"content":"精确率和召回率 ","date":"2022-08-21","objectID":"/%E7%B2%BE%E7%A1%AE%E7%8E%87%E5%92%8C%E5%8F%AC%E5%9B%9E%E7%8E%87/:1:0","tags":["Machine Learning","性能指标","精确率和召回率"],"title":"精确率和召回率","uri":"/%E7%B2%BE%E7%A1%AE%E7%8E%87%E5%92%8C%E5%8F%AC%E5%9B%9E%E7%8E%87/"},{"categories":["Machine Learning","性能指标"],"content":"混淆矩阵 True Positive(真正, TP)：将正类预测为正类数. True Negative(真负 , TN)：将负类预测为负类数. False Positive(假正, FP)：将负类预测为正类数 False Negative(假负 , FN)：将正类预测为负类数 ","date":"2022-08-21","objectID":"/%E7%B2%BE%E7%A1%AE%E7%8E%87%E5%92%8C%E5%8F%AC%E5%9B%9E%E7%8E%87/:1:1","tags":["Machine Learning","性能指标","精确率和召回率"],"title":"精确率和召回率","uri":"/%E7%B2%BE%E7%A1%AE%E7%8E%87%E5%92%8C%E5%8F%AC%E5%9B%9E%E7%8E%87/"},{"categories":["Machine Learning","性能指标"],"content":"精确率 \\[ P = \\frac{TP}{TP+FP} \\] ","date":"2022-08-21","objectID":"/%E7%B2%BE%E7%A1%AE%E7%8E%87%E5%92%8C%E5%8F%AC%E5%9B%9E%E7%8E%87/:1:2","tags":["Machine Learning","性能指标","精确率和召回率"],"title":"精确率和召回率","uri":"/%E7%B2%BE%E7%A1%AE%E7%8E%87%E5%92%8C%E5%8F%AC%E5%9B%9E%E7%8E%87/"},{"categories":["Machine Learning","性能指标"],"content":"准确率 \\[ ACC = \\frac{TP+TN}{TP+TN+FP+FN} \\] ","date":"2022-08-21","objectID":"/%E7%B2%BE%E7%A1%AE%E7%8E%87%E5%92%8C%E5%8F%AC%E5%9B%9E%E7%8E%87/:2:0","tags":["Machine Learning","性能指标","精确率和召回率"],"title":"精确率和召回率","uri":"/%E7%B2%BE%E7%A1%AE%E7%8E%87%E5%92%8C%E5%8F%AC%E5%9B%9E%E7%8E%87/"},{"categories":["Machine Learning","性能指标"],"content":"召回率 \\[ R = \\frac{TP}{TP+FN} \\] ","date":"2022-08-21","objectID":"/%E7%B2%BE%E7%A1%AE%E7%8E%87%E5%92%8C%E5%8F%AC%E5%9B%9E%E7%8E%87/:3:0","tags":["Machine Learning","性能指标","精确率和召回率"],"title":"精确率和召回率","uri":"/%E7%B2%BE%E7%A1%AE%E7%8E%87%E5%92%8C%E5%8F%AC%E5%9B%9E%E7%8E%87/"},{"categories":["Machine Learning","性能指标"],"content":"F1 \\[ \\frac{2}{F_1} = \\frac{1}{P} + \\frac{1}{R} \\] ","date":"2022-08-21","objectID":"/%E7%B2%BE%E7%A1%AE%E7%8E%87%E5%92%8C%E5%8F%AC%E5%9B%9E%E7%8E%87/:4:0","tags":["Machine Learning","性能指标","精确率和召回率"],"title":"精确率和召回率","uri":"/%E7%B2%BE%E7%A1%AE%E7%8E%87%E5%92%8C%E5%8F%AC%E5%9B%9E%E7%8E%87/"},{"categories":["Machine Learning","性能指标"],"content":"区别 精确率（查准率）：在所有预测为正的样本中（分母），真正为正的有多少（分子）。 召回率（查全率）：在所有实际为正的样本中（分母），成功预测出来的有多少（分子） img img ","date":"2022-08-21","objectID":"/%E7%B2%BE%E7%A1%AE%E7%8E%87%E5%92%8C%E5%8F%AC%E5%9B%9E%E7%8E%87/:5:0","tags":["Machine Learning","性能指标","精确率和召回率"],"title":"精确率和召回率","uri":"/%E7%B2%BE%E7%A1%AE%E7%8E%87%E5%92%8C%E5%8F%AC%E5%9B%9E%E7%8E%87/"},{"categories":["Machine Learning","分类算法"],"content":"参考：https://cuijiahua.com/blog/2017/11/ml_2_decision_tree_1.html 《机器学习》周志华 决策树 决策树是什么？决策树(decision tree)是一种基本的分类与回归方法。举个通俗易懂的例子，如下图所示的流程图就是一个决策树，长方形代表判断模块(decision block)，椭圆形成代表终止模块(terminating block)，表示已经得出结论，可以终止运行。从判断模块引出的左右箭头称作为分支(branch)，它可以达到另一个判断模块或者终止模块。我们还可以这样理解，分类决策树模型是一种描述对实例进行分类的树形结构。决策树由结点(node)和有向边(directed edge)组成。结点有两种类型：内部结点(internal node)和叶结点(leaf node)。内部结点表示一个特征或属性，叶结点表示一个类。蒙圈没？？如下图所示的决策树，长方形和椭圆形都是结点。长方形的结点属于内部结点，椭圆形的结点属于叶结点，从结点引出的左右箭头就是有向边。而最上面的结点就是决策树的根结点(root node)。这样，结点说法就与模块说法对应上了，理解就好。 ","date":"2022-08-21","objectID":"/%E5%86%B3%E7%AD%96%E6%A0%91/:0:0","tags":["Machine Learning","分类算法","决策树"],"title":"决策树","uri":"/%E5%86%B3%E7%AD%96%E6%A0%91/"},{"categories":["Machine Learning","分类算法"],"content":"步骤 1.特征选择 特征选择在于选取对训练数据具有分类能力的特征。这样可以提高决策树学习的效率，如果利用一个特征进行分类的结果与随机分类的结果没有很大差别，则称这个特征是没有分类能力的。经验上扔掉这样的特征对决策树学习的精度影响不大。通常特征选择的标准是信息增益(information gain)或信息增益比，为了简单，本文使用信息增益作为选择特征的标准。那么，什么是信息增益？在讲解信息增益之前，让我们看一组实例，贷款申请样本数据表。 机器学习实战教程（二）：决策树基础篇之让我们从相亲说起 希望通过所给的训练数据学习一个贷款申请的决策树，用于对未来的贷款申请进行分类，即当新的客户提出贷款申请时，根据申请人的特征利用决策树决定是否批准贷款申请。 特征选择就是决定用哪个特征来划分特征空间。比如，我们通过上述数据表得到两个可能的决策树，分别由两个不同特征的根结点构成。 (1).香农熵 在可以评测哪个数据划分方式是最好的数据划分之前，我们必须学习如何计算信息增益。集合信息的度量方式称为香农熵或者简称为熵(entropy)，这个名字来源于信息论之父克劳德·香农。 如果看不明白什么是信息增益和熵，请不要着急，因为他们自诞生的那一天起，就注定会令世人十分费解。克劳德·香农写完信息论之后，约翰·冯·诺依曼建议使用”熵”这个术语，因为大家都不知道它是什么意思。 熵定义为信息的期望值。在信息论与概率统计中，熵是表示随机变量不确定性的度量。如果待分类的事物可能划分在多个分类之中，则符号xi的信息定义为 ： \\[ l(x_i) = -log_{2}p(x_i) \\] 其中p(xi)是选择该分类的概率。有人可能会问，信息为啥这样定义啊？答曰：前辈得出的结论。这就跟1+1等于2一样，记住并且会用即可。上述式中的对数以2为底，也可以e为底(自然对数)。 通过上式，我们可以得到所有类别的信息。为了计算熵，我们需要计算所有类别所有可能值包含的信息期望值(数学期望)，通过下面的公式得到： \\[ H = -\\sum_{i=1}^np(x_i)log_2p(x_i) \\] 期中n是分类的数目。熵越大，随机变量的不确定性就越大。 当熵中的概率由数据估计(特别是最大似然估计)得到时，所对应的熵称为经验熵(empirical entropy)。什么叫由数据估计？比如有10个数据，一共有两个类别，A类和B类。其中有7个数据属于A类，则该A类的概率即为十分之七。其中有3个数据属于B类，则该B类的概率即为十分之三。浅显的解释就是，这概率是我们根据数据数出来的。我们定义贷款申请样本数据表中的数据为训练数据集D，则训练数据集D的经验熵为H(D)，|D|表示其样本容量，及样本个数。设有K个类Ck, = 1,2,3,.. .,K,|Ck|为属于类Ck的样本个数，因此经验熵公式就可以写为 ： \\[ H(D) = -\\sum_{k=1}^K \\frac{|c_k|}{|D|}log_2\\frac{|c_k|}{|D|} \\] 根据此公式计算经验熵H(D)，分析贷款申请样本数据表中的数据。最终分类结果只有两类，即放贷和不放贷。根据表中的数据统计可知，在15个数据中，9个数据的结果为放贷，6个数据的结果为不放贷。所以数据集D的经验熵H(D)为： \\[ H(D) = -\\frac{9}{15}log_2\\frac{9}{15} - \\frac{6}{15}log_2\\frac{6}{15} = 0.971 \\] (2)信息增益 在上面，我们已经说过，如何选择特征，需要看信息增益。也就是说，信息增益是相对于特征而言的，信息增益越大，特征对最终的分类结果影响也就越大，我们就应该选择对最终分类结果影响最大的那个特征作为我们的分类特征。 在讲解信息增益定义之前，我们还需要明确一个概念，条件熵。 熵我们知道是什么，条件熵又是个什么鬼？条件熵H(Y|X)表示在已知随机变量X的条件下随机变量Y的不确定性，随机变量X给定的条件下随机变量Y的条件熵(conditional entropy)H(Y|X)，定义为X给定条件下Y的条件概率分布的熵对X的数学期望： \\[ H(Y|X) = \\sum_{i=1}^np_iH(Y|X = x_i), \\\\\\\\ p_i = P(X = x_i) \\] 明确了条件熵和经验条件熵的概念。接下来，让我们说说信息增益。前面也提到了，信息增益是相对于特征而言的。所以，特征A对训练数据集D的信息增益g(D,A)，定义为集合D的经验熵H(D)与特征A给定条件下D的经验条件熵H(D|A)之差，即： \\[ g(D,A) = H(D) - H(D|A) \\] 一般地，熵H(D)与条件熵H(D|A)之差称为互信息(mutual information)。决策树学习中的信息增益等价于训练数据集中类与特征的互信息。 设特征A有n个不同的取值{a1,a2,···,an}，根据特征A的取值将D划分为n个子集{D1,D2，···,Dn}，|Di|为Di的样本个数。记子集Di中属于Ck的样本的集合为Dik，即Dik = Di ∩ Ck，|Dik|为Dik的样本个数。于是经验条件熵的公式可以些为 \\[ H(D|A) = \\sum_{i=1}^n\\frac{|D_i|}{|D|}H(D_i) = -\\sum_{i=1}^n\\frac{|D_i|}{|D|}\\sum_{k=1}^K\\frac{|D_{ik}|}{|D_i|}log_2\\frac{|D_{ik}|}{|D_i|} \\] 说了这么多概念性的东西，没有听懂也没有关系，举几个例子，再回来看一下概念，就懂了。 以贷款申请样本数据表为例进行说明。看下年龄这一列的数据，也就是特征A1，一共有三个类别，分别是：青年、中年和老年。我们只看年龄是青年的数据，年龄是青年的数据一共有5个，所以年龄是青年的数据在训练数据集出现的概率是十五分之五，也就是三分之一。同理，年龄是中年和老年的数据在训练数据集出现的概率也都是三分之一。现在我们只看年龄是青年的数据的最终得到贷款的概率为五分之二，因为在五个数据中，只有两个数据显示拿到了最终的贷款，同理，年龄是中年和老年的数据最终得到贷款的概率分别为五分之三、五分之四。所以计算年龄的信息增益，过程如下： 机器学习实战教程（二）：决策树基础篇之让我们从相亲说起 同理，计算其余特征的信息增益g(D,A2)、g(D,A3)和g(D,A4)。分别为： 机器学习实战教程（二）：决策树基础篇之让我们从相亲说起 机器学习实战教程（二）：决策树基础篇之让我们从相亲说起 最后，比较特征的信息增益，由于特征A3(有自己的房子)的信息增益值最大，所以选择A3作为最优特征。 由于特征A3(有自己的房子)的信息增益值最大，所以选择特征A3作为根结点的特征。它将训练集D划分为两个子集D1(A3取值为”是”)和D2(A3取值为”否”)。由于D1只有同一类的样本点，所以它成为一个叶结点，结点的类标记为“是”。 对D2则需要从特征A1(年龄)，A2(有工作)和A4(信贷情况)中选择新的特征，计算各个特征的信息增益： 机器学习实战教程（三）：决策树实战篇之为自己配个隐形眼镜 根据计算，选择信息增益最大的特征A2(有工作)作为结点的特征。由于A2有两个可能取值，从这一结点引出两个子结点：一个对应”是”(有工作)的子结点，包含3个样本，它们属于同一类，所以这是一个叶结点，类标记为”是”；另一个是对应”否”(无工作)的子结点，包含6个样本，它们也属于同一类，所以这也是一个叶结点，类标记为”否”。 这样就生成了一个决策树，该决策树只用了两个特征(有两个内部结点)，生成的决策树如下图所示。 机器学习实战教程（三）：决策树实战篇之为自己配个隐形眼镜 ","date":"2022-08-21","objectID":"/%E5%86%B3%E7%AD%96%E6%A0%91/:1:0","tags":["Machine Learning","分类算法","决策树"],"title":"决策树","uri":"/%E5%86%B3%E7%AD%96%E6%A0%91/"},{"categories":["Machine Learning","分类算法"],"content":"总结 我们已经学习了从数据集构造决策树算法所需要的子功能模块，包括经验熵的计算和最优特征的选择，其工作原理如下：得到原始数据集，然后基于最好的属性值划分数据集，由于特征值可能多于两个，因此可能存在大于两个分支的数据集划分。第一次划分之后，数据集被向下传递到树的分支的下一个结点。在这个结点上，我们可以再次划分数据。因此我们可以采用递归的原则处理数据集。 构建决策树的算法有很多，比如C4.5、ID3和CART，这些算法在运行时并不总是在每次划分数据分组时都会消耗特征。由于特征数目并不是每次划分数据分组时都减少，因此这些算法在实际使用时可能引起一定的问题。目前我们并不需要考虑这个问题，只需要在算法开始运行前计算列的数目，查看算法是否使用了所有属性即可。 决策树生成算法递归地产生决策树，直到不能继续下去未为止。这样产生的树往往对训练数据的分类很准确，但对未知的测试数据的分类却没有那么准确，即出现过拟合现象。过拟合的原因在于学习时过多地考虑如何提高对训练数据的正确分类，从而构建出过于复杂的决策树。解决这个问题的办法是考虑决策树的复杂度，对已生成的决策树进行简化。 决策树的一些优点： 易于理解和解释。决策树可以可视化。 几乎不需要数据预处理。其他方法经常需要数据标准化，创建虚拟变量和删除缺失值。决策树还不支持缺失值。 使用树的花费（例如预测数据）是训练数据点(data points)数量的对数。 可以同时处理数值变量和分类变量。其他方法大都适用于分析一种变量的集合。 可以处理多值输出变量问题。 使用白盒模型。如果一个情况被观察到，使用逻辑判断容易表示这种规则。相反，如果是黑盒模型（例如人工神经网络），结果会非常难解释。 即使对真实模型来说，假设无效的情况下，也可以较好的适用。 决策树的一些缺点： 决策树学习可能创建一个过于复杂的树，并不能很好的预测数据。也就是过拟合。修剪机制（现在不支持），设置一个叶子节点需要的最小样本数量，或者数的最大深度，可以避免过拟合。 决策树可能是不稳定的，因为即使非常小的变异，可能会产生一颗完全不同的树。这个问题通过decision trees with an ensemble来缓解。 概念难以学习，因为决策树没有很好的解释他们，例如，XOR, parity or multiplexer problems。 如果某些分类占优势，决策树将会创建一棵有偏差的树。因此，建议在训练之前，先抽样使样本均衡。 ","date":"2022-08-21","objectID":"/%E5%86%B3%E7%AD%96%E6%A0%91/:2:0","tags":["Machine Learning","分类算法","决策树"],"title":"决策树","uri":"/%E5%86%B3%E7%AD%96%E6%A0%91/"},{"categories":["Machine Learning","分类算法"],"content":"代码 import numpy as np import math def equalNums(label_list, label): \"\"\" 函数说明： 计算标记集中某个标记的数量 Parameters： label_list - 标记集 label - 某个标记 Returns： num - 某个标记的数量 \"\"\" return np.sum(label_list == label) def calcShannonEnt(label_list): \"\"\" 函数说明： 计算信息熵 对应公式 Ent(D) = -∑ Pk*log2(Pk) k=1..len(label_set) Parameters： label_list - 标记集 Returns： shannonEnt - 当前标记集的信息熵 \"\"\" label_set = set(label_list) len_label_list = label_list.size shannonEnt = 0.0 for label in label_set: prob = equalNums(label_list, label)/len_label_list shannonEnt -= prob * math.log2(prob) return shannonEnt def conditionnalEntropy(feature_list, label_list): \"\"\" 函数说明： 计算条件信息熵，对应信息增益公式中的被减项 Parameters： feature_list - sample_list中某一列，表示当前属性的所有值 label_list - 标记集 Returns： entropy - 条件信息熵 \"\"\" feature_list = np.asarray(feature_list) label_list = np.asarray(label_list) feature_set = set(feature_list) entropy = 0.0 for feat in feature_set: pro = equalNums(feature_list, feat)/feature_list.size entropy += pro * calcShannonEnt(label_list[feature_list == feat]) return entropy def calcInfoGain(feature_list, label_list): \"\"\" 函数说明： 计算信息增益 Parameters： feature_list - sample_list中某一列，表示当前属性的所有值 label_list - 标记集 Returns： 当前属性的信息增益 \"\"\" return calcShannonEnt(label_list) - conditionnalEntropy(feature_list, label_list) def splitDataSet(sample_list, label_list, axis, value): \"\"\" 函数说明： 决策树在选好当前最优划分属性之后划分样本集 依据value选择对应样例，并去除第axis维属性 Parameters： feature_list - sample_list中某一列，表示当前属性的所有值 label_list - 标记集 Returns： return_sample_list, return_label_list \"\"\" # sample_list[sample_list[...,axis] == value] 利用了numpy数组的布尔索引 filtered_sample_list = sample_list[sample_list[...,axis] == value] return_label_list = label_list[sample_list[...,axis] == value] # np.hstack 将数组横向拼接，也就是去除第axis维属性 return_sample_list = np.hstack((filtered_sample_list[...,:axis], filtered_sample_list[...,axis+1:])) return return_sample_list, return_label_list def chooseBestFeatureToSplit(sample_list, label_list): \"\"\" 函数说明： 选取最优划分属性 Parameters： sample_list - 样本集 label_list - 标记集 Returns： bestFeat_index - 最优划分属性的索引值 \"\"\" numFeatures = sample_list.shape[1] bestInfoGain = 0 bestFeat_index = -1 for i in range(numFeatures): infoGain = calcInfoGain(sample_list[..., i], label_list) if infoGain \u003e bestInfoGain: bestInfoGain = infoGain bestFeat_index = i return bestFeat_index def createTree(sample_list, label_list, attr_list_copy): \"\"\" 函数说明： 生成决策树 Parameters： sample_list - 样本集 label_list - 标记集 attr_list_copy - 属性集（之所以加copy是为了删属性的时候是在副本上，防止递归出错） Returns： myTree - 最终的决策树 \"\"\" # attr_list 有del操作，不用副本的话递归会出错 attr_list = attr_list_copy.copy() if len(set(label_list)) == 1: # 如果只有一种标记，直接返回标记 return label_list[0] elif sample_list.size == 0: # 如果所有属性都被遍历，返回最多的标记 return voteLabel(label_list) # bestFeat_index 最优划分属性的索引值 # bestAttr 最优划分属性对应的名字 bestFeat_index = chooseBestFeatureToSplit(sample_list, label_list) bestAttr = attr_list[bestFeat_index] myTree = {bestAttr: {}} del(attr_list[bestFeat_index]) feat_set = set(sample_list[..., bestFeat_index]) # 依据最优划分属性进行划分，并向下递归 for feat in feat_set: return_sample_list, return_label_list = splitDataSet(sample_list, label_list, bestFeat_index, feat) myTree[bestAttr][feat] = createTree(return_sample_list, return_label_list, attr_list) return myTree def voteLabel(label_list): \"\"\" 函数说明： 这个函数是用在遍历完所有特征时，返回最多的类别 Parameters： label_list: 标记列表 Returns： 数量最多的标记 \"\"\" # unique_label_list 是label_list中标记种类列表 # label_num 是unique_label_list对应的数量列表 unique_label_list = list(set(label_list)) label_num_list = [] for label in unique_label_list: label_num_list.append(equalNums(label_list, label)) # label_num.index(max(label_num))是label_num数组中最大值的下标 return unique_label_list[label_num_list.index(max(label_num_list))] def classify(decisionTree, testVec, attr_list): \"\"\" 函数说明： 对tesVec进行分类 Parameters： decisionTree - 决策树 attr_list - 属性名列表 testVec - 测试向量 Returns： label - 预测的标记 \"\"\" feature = list(decisionTree.keys())[0] # feature为决策树的根节点 feature_dict = decisionTree[feature] # feature_dict为根节点下的子树 feature_index = attr_list.index(feature) # feature_index为featur","date":"2022-08-21","objectID":"/%E5%86%B3%E7%AD%96%E6%A0%91/:3:0","tags":["Machine Learning","分类算法","决策树"],"title":"决策树","uri":"/%E5%86%B3%E7%AD%96%E6%A0%91/"},{"categories":["Machine Learning","分类算法"],"content":"分类算法 主要区分一下生成模型和判别模型，首先要知道生成模型和判别模型都属于监督学习，即样本有其对应的标签的。还有一个概念就是硬分类和软分类，简单理解就是硬分类是直接分出类别，比如线性判别分析、感知机。而软分类是计算出概率，根据概率来得到类别，生成模型和判别模型都是软分类。 ","date":"2022-08-12","objectID":"/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0/:0:0","tags":["Machine Learning","分类算法","分类算法概述"],"title":"分类算法概述","uri":"/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0/"},{"categories":["Machine Learning","分类算法"],"content":"生成模型 学习得到联合概率分布\\(P(x,y)\\)，即特征x与标签y共同出现的概率，然后求条件概率分布。能够学习到数据生成的机制。通俗的说就是如果有k类，就学习k个概率密度分布，对于样本，算出在每个概率密度分布下的概率，哪个概率大就属于哪一类。 生成模型要求的数据量比较大，能够更好地估计概率密度。 ## 判别模型 学习得到条件概率分布\\(P(y|x)\\)，即在特征x出现的情况下标记y出现的概率。 判别模型对样本的要求没有那么多。 ","date":"2022-08-12","objectID":"/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0/:1:0","tags":["Machine Learning","分类算法","分类算法概述"],"title":"分类算法概述","uri":"/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0/"},{"categories":["Machine Learning","分类算法"],"content":"理解 无论是生成还是判别模型都是来求有监督模型的，目的是通过分类函数或者条件概率函数进行数据分类。 算出属于正负样本的概率再互相对比的就是生成模型，直接得到结果概率的就是判别模型，生成模型得到分布，判别模型得到最优划分。 生成模型可以得到判别模型，反之不成立。 生成模型是求联合概率分布，判别模型是求条件概率分布。 生成方法的学习收敛速度更快，当样本容量增加的时候，学到的模型可以更快的收敛于真实模型。 判别学习不能反映训练数据本身的特性，但它寻找不同类别之间的最优分类面，反映的是异类数据之间的差异，直接面对预测，往往学习的准确率高于生成模型。 简单的说，生成模型是从大量的数据中找规律，属于统计学习；而判别模型只关心不同类型的数据的差别，利用差别来分类。 ","date":"2022-08-12","objectID":"/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0/:2:0","tags":["Machine Learning","分类算法","分类算法概述"],"title":"分类算法概述","uri":"/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0/"},{"categories":["Machine Learning","分类算法"],"content":"生成式模型： 朴素贝叶斯 混合高斯模型 隐马尔科夫模型(HMM) 贝叶斯网络 Sigmoid Belief Networks 马尔科夫随机场(Markov Random Fields) 深度信念网络(DBN) ","date":"2022-08-12","objectID":"/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0/:2:1","tags":["Machine Learning","分类算法","分类算法概述"],"title":"分类算法概述","uri":"/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0/"},{"categories":["Machine Learning","分类算法"],"content":"判别式模型 K近邻(KNN) 线性回归(Linear Regression) 逻辑回归(Logistic Regression) 神经网络(NN) 支持向量机(SVM) 高斯过程(Gaussian Process) 条件随机场(CRF) CART(Classification and Regression Tree) ","date":"2022-08-12","objectID":"/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0/:2:2","tags":["Machine Learning","分类算法","分类算法概述"],"title":"分类算法概述","uri":"/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0/"},{"categories":["NLP"],"content":"BM25算法 BM25算法，通常用来作搜索相关性平分。一句话概况其主要思想：对Query进行语素解析，生成语素qi；然后，对于每个搜索结果D，计算每个语素qi与D的相关性得分，最后，将qi相对于D的相关性得分进行加权求和，从而得到Query与D的相关性得分。 ","date":"2022-08-07","objectID":"/bm25/:0:0","tags":["NLP","BM25"],"title":"BM25","uri":"/bm25/"},{"categories":["NLP"],"content":"原理 BM25一般公式如下： \\[ score(Q,d) = \\sum_{i}^nW_iR(q_i, d) \\] 其中Q表示为Query，\\(q_i\\)表示Q解析后的一个语素(对中文而言，我们可以把对Query的分词作为语素分析，每个词看成语素)。d表示一个搜索结果文档，\\(W_i\\)表示语素\\(q_i\\)的权重，\\(R(q_i, d)\\)表示语素\\(q_i\\)与文档d的相关性得分。 ","date":"2022-08-07","objectID":"/bm25/:1:0","tags":["NLP","BM25"],"title":"BM25","uri":"/bm25/"},{"categories":["NLP"],"content":"权重 下面我们来看如何定义Wi。判断一个词与一个文档的相关性的权重，方法有多种，较常用的是IDF。这里以IDF为例，公式如下： \\[ IDF(q_i) = \\log \\frac{N-n(q_i)+0.5}{n(q_i)+0.5} \\] 其中，N为索引中的全部文档数，n(qi)为包含了qi的文档数。 根据IDF的定义可以看出，对于给定的文档集合，包含了qi的文档数越多，qi的权重则越低。也就是说，当很多文档都包含了qi时，qi的区分度就不高，因此使用qi来判断相关性时的重要度就较低。 ","date":"2022-08-07","objectID":"/bm25/:2:0","tags":["NLP","BM25"],"title":"BM25","uri":"/bm25/"},{"categories":["NLP"],"content":"相关性得分 下面定义相关性得分\\(R(q_i,d)\\) 首先来看BM25中相关性得分的一般形式： 其中\\(k_1, k_2, b\\)为调节因子，根据经验设置，一般\\(k_1=2,b=0.75\\) ，\\(f_i\\)为\\(q_i\\)在文档d中出现的频率，\\(qf_i\\)为\\(q_i\\)在Query中出现的频率，dl为文档d的长度，avgdl为所有文档的平均长度，绝大部分情况下\\(q_i\\)在Query中只会出现一次，因此 \\(qf_i=1\\)，所以可以简化为： 从K的定义中可以看到，参数b的作用是调整文档长度对相关性影响的大小。b越大，文档长度的对相关性得分的影响越大，反之越小。而文档的相对长度越长，K值将越大，则相关性得分会越小。这可以理解为，当文档较长时，包含qi的机会越大，因此，同等fi的情况下，长文档与qi的相关性应该比短文档与qi的相关性弱。 综上，BM25算法的相关性得分公式可总结为： 从BM25的公式可以看到，通过使用不同的语素分析方法、语素权重判定方法，以及语素与文档的相关性判定方法，我们可以衍生出不同的搜索相关性得分计算方法，这就为我们设计算法提供了较大的灵活性。 ","date":"2022-08-07","objectID":"/bm25/:3:0","tags":["NLP","BM25"],"title":"BM25","uri":"/bm25/"},{"categories":["NLP"],"content":"代码 import math import jieba import re text = ''' 自然语言处理是计算机科学领域与人工智能领域中的一个重要方向。 它研究能实现人与计算机之间用自然语言进行有效通信的各种理论和方法。 自然语言处理是一门融语言学、计算机科学、数学于一体的科学。 因此，这一领域的研究将涉及自然语言，即人们日常使用的语言， 所以它与语言学的研究有着密切的联系，但又有重要的区别。 自然语言处理并不是一般地研究自然语言， 而在于研制能有效地实现自然语言通信的计算机系统， 特别是其中的软件系统。因而它是计算机科学的一部分。 ''' class BM25(object): def __init__(self, docs): self.D = len(docs) # doc个数 self.avgdl = sum([len(doc)+0.0 for doc in docs]) / self.D # 每篇平均长度 self.docs = docs self.f = [] # 列表的每一个元素是一个dict，dict存储着一个文档中每个词的出现次数 self.df = {} # 存储每个词及出现了该词的文档数量(count) self.idf = {} # 存储每个词的idf值，当作权重 self.k1 = 1.5 self.b = 0.75 self.init() def init(self): for doc in self.docs: tmp = {} for word in doc: tmp[word] = tmp.get(word, 0) + 1 # 存储每个文档中每个词的出现次数（也可以用defaultdict) self.f.append(tmp) # idx为索引，f[idx]为一个dict，dict存储着第idx+1个文档中每个词的出现次数,idx代表第几个文档。 for k in tmp.keys(): # 如果词k出现在了当前文档中，则df[k]即文档数量加1 self.df[k] = self.df.get(k, 0) + 1 for k, v in self.df.items(): self.idf[k] = math.log(self.D-v+0.5)-math.log(v+0.5) # 计算idf def sim(self, query, index): # 与单个文档的相似度 score = 0 for word in query: if word not in self.f[index]: continue d = len(self.docs[index]) # 当前文档的长度 score += (self.idf[word]*(self.f[index][word]/d)*(self.k1+1) / ((self.f[index][word]/d)+self.k1*(1-self.b+self.b*d / self.avgdl))) return score def simall(self, query): scores = [] for index in range(self.D): score = self.sim(query, index) scores.append(score) return scores def get_sentences(doc): line_break = re.compile('[\\r\\n]') # 以换行符分割 delimiter = re.compile('[，。？！；]') # 以中文标点符号分割 sentences = [] for line in line_break.split(doc): line = line.strip() if not line: continue for sent in delimiter.split(line): sent = sent.strip() if not sent: continue sentences.append(sent) return sentences if __name__ == '__main__': sents = get_sentences(text) print(sents) doc = [] for sent in sents: words = list(jieba.cut(sent)) doc.append(words) # print(doc) s = BM25(doc) # print(s.f) # print(s.df) # print(s.idf) print(s.simall(['自然语言', '计算机科学', '领域', '人工智能', '领域'])) ","date":"2022-08-07","objectID":"/bm25/:4:0","tags":["NLP","BM25"],"title":"BM25","uri":"/bm25/"},{"categories":["NLP"],"content":"GPT ","date":"2022-07-27","objectID":"/gpt/:0:0","tags":["NLP","GPT"],"title":"GPT","uri":"/gpt/"},{"categories":["NLP"],"content":"预训练(从左到右的 Transformer 语言模型) GPT 是一种基于 Transformer 的从左到右的语言模型。该架构是一个 12 层的 Transformer 解码器（没有解码器-编码器）。 ## 模型架构 就是12层的transformer-decoder。其中只使用了transformer模型中的decoder部分，并且把decoder里面的encoder-decoder attention部分去掉了，只保留了masked self-attention，再加上feed-forward部分。再提一句，masked self-attention保证了GPT模型是一个单向的语言模型。 另外，作者在position encoding上做了调整，使用了可学习的位置编码，不同于transformer的三角函数位置编码。 ","date":"2022-07-27","objectID":"/gpt/:1:0","tags":["NLP","GPT"],"title":"GPT","uri":"/gpt/"},{"categories":["NLP"],"content":"微调：将 GPT 用于下游任务 微调损失包括特定于任务的损失以及语言建模损失： \\[ L = L_{xent} + \\lambda \\cdot L_{task}. \\] ","date":"2022-07-27","objectID":"/gpt/:2:0","tags":["NLP","GPT"],"title":"GPT","uri":"/gpt/"},{"categories":["Deep Learning","网络正则化"],"content":"Dropout 在标准dropout正则化中，通过按保留（未丢弃）的节点的分数进行归一化来消除每一层的偏差。换言之，每个中间激活值h以保留概率概率p由随机变量替换(即drop经过神经元后的值代替drop神经元) \\[ h^{'}= \\begin{cases} 0, \\quad 概率为1-p \\\\\\\\ \\frac{h}{p}, \\quad 概率为p \\end{cases} \\] 注意期望不要变，即 \\[ E[h^{'}] = (1-p)*0 + p *\\frac{h}{p} = h \\] 也可以训练时非丢弃单元不除以概率p，而是测试时模型参数乘以p，这样可以保证训练集和测试集的期望相同。和上面的效果相同。 注意：正则项（Dropout）只在训练过程中使用，因为其会影响模型参数的更新 所以在推理过程中，丢弃法直接返回输入。 ","date":"2022-07-21","objectID":"/dropout%E6%AD%A3%E5%88%99%E5%8C%96/:0:0","tags":["Deep Learning","网络正则化","Dropout正则化"],"title":"Dropout正则化","uri":"/dropout%E6%AD%A3%E5%88%99%E5%8C%96/"},{"categories":["Deep Learning","网络正则化"],"content":"代码 import torch from torch import nn from d2l import torch as d2l import torchvision from torchvision import transforms from torch.utils import data def dropout_layer(X,dropout): assert 0\u003c=dropout \u003c= 1 # 如果keep_prob设置为1，全部元素被保留 if dropout == 1: return X # 如果keep_prob设置为0，全部元素被丢弃 if dropout == 0: return torch.zeros_like(X) mask = (torch.rand(X.shape) \u003c dropout).float() #使用mask而不是直接置零是为了提高计算效率 return mask * X/(dropout) ","date":"2022-07-21","objectID":"/dropout%E6%AD%A3%E5%88%99%E5%8C%96/:1:0","tags":["Deep Learning","网络正则化","Dropout正则化"],"title":"Dropout正则化","uri":"/dropout%E6%AD%A3%E5%88%99%E5%8C%96/"},{"categories":["算法题"],"content":"最长回文子串 ","date":"2022-07-21","objectID":"/%E6%9C%80%E9%95%BF%E5%9B%9E%E6%96%87%E5%AD%90%E4%B8%B2/:0:0","tags":["算法题","最长回文子串"],"title":"最长回文子串","uri":"/%E6%9C%80%E9%95%BF%E5%9B%9E%E6%96%87%E5%AD%90%E4%B8%B2/"},{"categories":["算法题"],"content":"题目： ​ https://leetcode-cn.com/problems/longest-palindromic-substring/ ","date":"2022-07-21","objectID":"/%E6%9C%80%E9%95%BF%E5%9B%9E%E6%96%87%E5%AD%90%E4%B8%B2/:1:0","tags":["算法题","最长回文子串"],"title":"最长回文子串","uri":"/%E6%9C%80%E9%95%BF%E5%9B%9E%E6%96%87%E5%AD%90%E4%B8%B2/"},{"categories":["算法题"],"content":"思路： ​ 一开始暴力解法，比较好想，结果超时了哎，后来看见了标签是动态规划，才知道不能暴力 class Solution: def longestPalindrome(self, s: str) -\u003e str: if len(s) \u003c= 1: return s maxs = -float(\"inf\") res = collections.defaultdict(list) left,right = 0,len(s)-1 while left \u003c right: for i in range(left,right+2): if s[left:i] == s[left:i][::-1]: maxs = max(maxs,len(s[left:i])) res[maxs].append(s[left:i]) left += 1 return max(res[max(res.keys())],key=len) 也用到了双指针，超时在情理之中。 后来用到了动态规划 class Solution: def longestPalindrome(self, s: str) -\u003e str: if len(s) \u003c= 1: return s length = len(s) dp = [[False for _ in range(length)] for _ in range(length)] for i in range(length): dp[i][i] = True start = 0 max_len = 1 for j in range(1, length): for i in range(0, j): if s[i] == s[j]: if j - i \u003c 3: dp[i][j] = True else: dp[i][j] = dp[i + 1][j - 1] else: dp[i][j] = False if dp[i][j]: cur_len = j - i + 1 if cur_len \u003e max_len: max_len = cur_len start = i return s[start:start + max_len] ","date":"2022-07-21","objectID":"/%E6%9C%80%E9%95%BF%E5%9B%9E%E6%96%87%E5%AD%90%E4%B8%B2/:2:0","tags":["算法题","最长回文子串"],"title":"最长回文子串","uri":"/%E6%9C%80%E9%95%BF%E5%9B%9E%E6%96%87%E5%AD%90%E4%B8%B2/"},{"categories":["算法题"],"content":"有效的数独 https://leetcode-cn.com/problems/valid-sudoku/ #有效的数独 难点在将3*3里的数取出来 class Solution: def isValidSudoku(board) -\u003e bool: for line1,line2 in zip(board,zip(*board)): #行列 for n1,n2 in zip(line1,line2): if (n1 != '.' and line1.count(n1) \u003e 1) or (n2!='.' and line2.count(n2) \u003e1): return False pal = [[board[i+m][j+n] for m in range(3) for n in range(3) if board[i+m][j+n] != '.'] for i in (0, 3, 6) for j in (0, 3, 6)] for line in pal: if len(set(line)) != len(line): return False return True ","date":"2022-07-20","objectID":"/%E6%9C%89%E6%95%88%E7%9A%84%E6%95%B0%E7%8B%AC/:0:0","tags":["算法题","有效的数独"],"title":"有效的数独","uri":"/%E6%9C%89%E6%95%88%E7%9A%84%E6%95%B0%E7%8B%AC/"},{"categories":["算法题"],"content":"使括号有效的最少添加 ","date":"2022-07-17","objectID":"/%E4%BD%BF%E6%8B%AC%E5%8F%B7%E6%9C%89%E6%95%88%E7%9A%84%E6%9C%80%E5%B0%91%E6%B7%BB%E5%8A%A0/:0:0","tags":["算法题","使括号有效的最少添加"],"title":"使括号有效的最少添加","uri":"/%E4%BD%BF%E6%8B%AC%E5%8F%B7%E6%9C%89%E6%95%88%E7%9A%84%E6%9C%80%E5%B0%91%E6%B7%BB%E5%8A%A0/"},{"categories":["算法题"],"content":"题目： https://leetcode-cn.com/problems/minimum-add-to-make-parentheses-valid/ ","date":"2022-07-17","objectID":"/%E4%BD%BF%E6%8B%AC%E5%8F%B7%E6%9C%89%E6%95%88%E7%9A%84%E6%9C%80%E5%B0%91%E6%B7%BB%E5%8A%A0/:1:0","tags":["算法题","使括号有效的最少添加"],"title":"使括号有效的最少添加","uri":"/%E4%BD%BF%E6%8B%AC%E5%8F%B7%E6%9C%89%E6%95%88%E7%9A%84%E6%9C%80%E5%B0%91%E6%B7%BB%E5%8A%A0/"},{"categories":["算法题"],"content":"思路： 通过一个值来判断是否匹配 ","date":"2022-07-17","objectID":"/%E4%BD%BF%E6%8B%AC%E5%8F%B7%E6%9C%89%E6%95%88%E7%9A%84%E6%9C%80%E5%B0%91%E6%B7%BB%E5%8A%A0/:2:0","tags":["算法题","使括号有效的最少添加"],"title":"使括号有效的最少添加","uri":"/%E4%BD%BF%E6%8B%AC%E5%8F%B7%E6%9C%89%E6%95%88%E7%9A%84%E6%9C%80%E5%B0%91%E6%B7%BB%E5%8A%A0/"},{"categories":["算法题"],"content":"代码： class Solution: def minAddToMakeValid(self, S: str) -\u003e int: res,temp = 0,0 for i in S: if i == '(': temp += 1 if i == ')': temp -= 1 if temp == -1: temp = 0 res += 1 return res + temp 如果右括号过多的话，就在左边补一个左括号。这时结果+1 如果一直是左括号的话，res 为0 temp就是应该补的个数 如果都相匹配的话，temp = 0 相应 res也为0 ","date":"2022-07-17","objectID":"/%E4%BD%BF%E6%8B%AC%E5%8F%B7%E6%9C%89%E6%95%88%E7%9A%84%E6%9C%80%E5%B0%91%E6%B7%BB%E5%8A%A0/:3:0","tags":["算法题","使括号有效的最少添加"],"title":"使括号有效的最少添加","uri":"/%E4%BD%BF%E6%8B%AC%E5%8F%B7%E6%9C%89%E6%95%88%E7%9A%84%E6%9C%80%E5%B0%91%E6%B7%BB%E5%8A%A0/"},{"categories":["Machine Learning","集成学习"],"content":"集成学习 在机器学习的有监督学习算法中，我们的目标是学习出一个稳定的且在各个方面表现都较好的模型，但实际情况往往不这么理想，有时我们只能得到多个有偏好的模型（弱监督模型，在某些方面表现的比较好）。集成学习就是组合这里的多个弱监督模型以期得到一个更好更全面的强监督模型，集成学习潜在的思想是即便某一个弱分类器得到了错误的预测，其他的弱分类器也可以将错误纠正回来。 集成学习在各个规模的数据集上都有很好的策略。 数据集大：划分成多个小数据集，学习多个模型进行组合 数据集小：利用Bootstrap方法进行抽样，得到多个数据集，分别训练多个模型再进行组合 集成学习主要有两类： 1. Bagging Boosting Bagging算法是这样做的：每个分类器都随机从原样本中做有放回的采样，然后分别在这些采样后的样本上训练分类器，然后再把这些分类器组合起来。简单的多数投票一般就可以。其代表算法是随机森林。 Boosting的意思是这样，他通过迭代地训练一系列的分类器，每个分类器采用的样本分布都和上一轮的学习结果有关。其代表算法是AdaBoost, GBDT。 ","date":"2022-07-09","objectID":"/ensemble-learning/:0:0","tags":["Machine Learning","集成学习","Ensemble Learning"],"title":"Ensemble Learning","uri":"/ensemble-learning/"},{"categories":["Machine Learning","集成学习"],"content":"Bagging bagging的名称来源于 （ Bootstrap Aggregating ），意思是自助抽样集成，这种方法将训练集分成m个新的训练集，然后在每个新训练集上构建一个模型，各自不相干，最后预测时我们将这个m个模型的结果进行整合，得到最终结果。整合方式就是：分类问题用majority voting，回归用均值。 因此Bagging使用的抽样方法是Bootstrap方法，即自助法，本质上就是一个有放回的随机抽样问题。 每一个样本在每一次抽的时候有同样的概率\\(\\frac{1}{N}\\)被抽中。没被抽中的概率为\\(1-\\frac{1}{N}\\)，一共抽了N次，即\\(1-(\\frac{1}{N})^N\\)当N趋于无穷时，由高等数学学的极限的求解可以算出来是\\(\\frac{1}{e}\\)，大概为36.8%，这些留下来的1/3的样本可以作为验证集，这样的方式叫做包外估计(out of bag estimate) ","date":"2022-07-09","objectID":"/ensemble-learning/:1:0","tags":["Machine Learning","集成学习","Ensemble Learning"],"title":"Ensemble Learning","uri":"/ensemble-learning/"},{"categories":["Machine Learning","集成学习"],"content":"Boosting Boosting与Bagging的区别就是取样方式不同，Bagging采用均匀取样，而Boosting根据错误率来取样，因此Boosting的分类精度要优于Bagging。。Bagging的训练集的选择是随机的，各轮训练集之间相互独立，而Boostlng的各轮训练集的选择与前面各轮的学习结果有关；Bagging的各个预测函数没有权重，而Boosting是有权重的；Bagging的各个预测函数可以并行生成，而Boosting的各个预测函数只能顺序生成。对于象神经网络这样极为耗时的学习方法。Bagging可通过并行训练节省大量时间开销。很好理解吧。 ","date":"2022-07-09","objectID":"/ensemble-learning/:2:0","tags":["Machine Learning","集成学习","Ensemble Learning"],"title":"Ensemble Learning","uri":"/ensemble-learning/"},{"categories":["Machine Learning","集成学习"],"content":"一个故事 一个故事用于理解，来源：https://www.joinquant.com/view/community/detail/adfb5ce37f0b39e348aae32e8412c68c 有一个医学专（砖）家，他看过很多很多病人，还记了小本本来归类这些病人的特征和病情来方便以后诊断。有一天来了个病人，这个专家就问病人了，“大爷您贵姓？多少岁，哪不舒服，病情怎么样？”大爷说 “我姓李，48，最近老吐痰，老咳嗽，还发烧…”。这个专家拿出他的小本本一查“”属性：“姓李”，“年龄48”，“吐痰”，“咳嗽”，“发烧”…,根据我的小本本以前这样的病例有80个，有76个是感冒，成，就诊断他是感冒了！”这个专家就是棵决策树 镜头一转，来到医院A，同样的病人来医院A治病。医院有很大的病例数据库，有100个医学专家通过学习数据库的一部分知识形成了自己的诊断方案。医院想：“我财大气粗，为了提供更好的医疗服务，我让100个专家做诊断，然后他们投票决出最后的判断”。 随机森林 完成 医院B就不爽了，你这治疗方案太受欢迎，把客户都抢走了，我要用科学的治疗方案来击败你。医院B想了想，大家投票不一定针对到用户情况，我先从我的100个专家里找一个最好的先给病人做一个诊疗方案，再根据第一个专家的不足找第二个，根据第二个再找第三个…… 最后不同专家再根据他们诊断的表现以不同权重投票。这样岂不是更针对病人痛点？ Boosting 方法就被这群人建立起来了 到了医院C想搞差异化，你医院B根据上一个专家的全部不足找新专家，那我就根据上一个专家判断最偏颇的方向找专家，虽然听起来差不多，但我的差异化说不定就能更好。 Gradient Boosting 产生了 更加财大气粗的医院D来了，他觉得虽然整个市场的大格调基本确定，但我可以通过提升整个诊疗的流程大大小小的细节来取胜啊！于是医院D在C的基础上改进了很多，于是找偏颇的方向更快更准，纠结专家，诊疗的速度也大大加快，整个医院的硬件设施也前所未有的提高。这差不多就是 XGBoost 了 突然有股叫大数据的潮流吹来，本来医院D已经在医院C一分钟治疗10000人的基础上提升了10多倍速度，但新的要求是：一分钟不行，最多给你3秒，10万人也不行，我现在有全世界的数据，你得分秒内召集几百几千个专家，这些专家每一个的知识得相当于以前一个医院那没多，还得分秒内服务数10倍的病人，最后治疗的精度不能下降。 LightGBM 出场了，虽然精度提高不多，但速度大大加快了。 ","date":"2022-07-09","objectID":"/ensemble-learning/:3:0","tags":["Machine Learning","集成学习","Ensemble Learning"],"title":"Ensemble Learning","uri":"/ensemble-learning/"},{"categories":["算法题"],"content":"旋转图像 https://leetcode-cn.com/problems/rotate-image/ 没难度的中等题，这方法很python class Solution: def rotate(self, matrix: List[List[int]]) -\u003e None: \"\"\" Do not return anything, modify matrix in-place instead. \"\"\" n = len(matrix) for i in list(map(list,map(reversed,zip(*matrix)))): matrix.append(i) del matrix[:n] ","date":"2022-07-07","objectID":"/%E6%97%8B%E8%BD%AC%E5%9B%BE%E5%83%8F/:0:0","tags":["算法题","旋转图像"],"title":"旋转图像","uri":"/%E6%97%8B%E8%BD%AC%E5%9B%BE%E5%83%8F/"},{"categories":["Machine Learning","分类算法"],"content":"KNN 参考：https://cuijiahua.com/blog/2017/11/ml_1_knn.html 《统计学习方法》李航（kd树） ","date":"2022-06-25","objectID":"/knn/:0:0","tags":["Machine Learning","分类算法","KNN"],"title":"KNN","uri":"/knn/"},{"categories":["Machine Learning","分类算法"],"content":"简介 k近邻法(k-nearest neighbor, k-NN)是1967年由Cover T和Hart P提出的一种基本分类与回归方法。它的工作原理是：存在一个样本数据集合，也称作为训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每一个数据与所属分类的对应关系。输入没有标签的新数据后，将新的数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本最相似数据(最近邻)的分类标签。一般来说，我们只选择样本数据集中前k个最相似的数据，这就是k-近邻算法中k的出处，通常k是不大于20的整数。最后，选择k个最相似数据中出现次数最多的分类，作为新数据的分类。 ","date":"2022-06-25","objectID":"/knn/:1:0","tags":["Machine Learning","分类算法","KNN"],"title":"KNN","uri":"/knn/"},{"categories":["Machine Learning","分类算法"],"content":"步骤 k-近邻算法步骤如下： 计算已知类别数据集中的点与当前点之间的距离； 按照距离递增次序排序； 选取与当前点距离最小的k个点； 确定前k个点所在类别的出现频率； 返回前k个点所出现频率最高的类别作为当前点的预测分类。 ","date":"2022-06-25","objectID":"/knn/:2:0","tags":["Machine Learning","分类算法","KNN"],"title":"KNN","uri":"/knn/"},{"categories":["Machine Learning","分类算法"],"content":"总结 优点 简单好用，容易理解，精度高，理论成熟，既可以用来做分类也可以用来做回归； 可用于数值型数据和离散型数据； 训练时间复杂度为O(n)；无数据输入假定； 对异常值不敏感 缺点 计算复杂性高；空间复杂性高； 样本不平衡问题（即有些类别的样本数量很多，而其它样本的数量很少）； 一般数值很大的时候不用这个，计算量太大。但是单个样本又不能太少，否则容易发生误分。 最大的缺点是无法给出数据的内在含义。 关于algorithm参数kd_tree的原理，可以查看《统计学方法 李航》书中的讲解； 关于距离度量的方法还有切比雪夫距离、马氏距离、巴氏距离等； ","date":"2022-06-25","objectID":"/knn/:3:0","tags":["Machine Learning","分类算法","KNN"],"title":"KNN","uri":"/knn/"},{"categories":["NLP"],"content":"主题模型 主题模型也可以看成一种词向量表达，主要有LSA、PLSA、LDA。按照这个顺序来逐渐发展的 ","date":"2022-06-16","objectID":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/:0:0","tags":["NLP","主题模型"],"title":"主题模型","uri":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"词袋模型 将所有词语装进一个袋子里，不考虑其词法和语序的问题，即每个词语都是独立的 例子： 句子1：我 爱 北 京 天 安 门 转换为 [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0] 句子2：我 喜 欢 上 海 转换为 [1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1] from sklearn.feature_extraction.text import CountVectorizer corpus = [ 'This is the first document.', 'This document is the second document.', 'And this is the third one.', 'Is this the first document?', ] vectorizer = CountVectorizer() vectorizer.fit_transform(corpus).toarray() 结果： [[0 1 1 1 0 0 1 0 1] [0 2 0 1 0 1 1 0 1] [1 0 0 1 1 0 1 1 1] [0 1 1 1 0 0 1 0 1]] ","date":"2022-06-16","objectID":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/:1:0","tags":["NLP","主题模型"],"title":"主题模型","uri":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"LSA LSA就是潜在语义分析。特点是通过矩阵分解发现文本与单词之间基于主题（话题）的语义关系。 首先要清楚几个概念： ","date":"2022-06-16","objectID":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/:2:0","tags":["NLP","主题模型"],"title":"主题模型","uri":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"单词-文本矩阵 \\[ X=\\left[\\begin{array}{cccc} x_{11} \u0026 x_{12} \u0026 \\cdots \u0026 x_{1 n} \\\\\\\\ x_{21} \u0026 x_{22} \u0026 \\cdots \u0026 x_{2 n} \\\\\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots \\\\\\\\ x_{m 1} \u0026 x_{m 2} \u0026 \\cdots \u0026 x_{m n} \\end{array}\\right] \\] 这是一个 \\(m \\times n\\) 矩阵, 元素 \\(x_{i j}\\) 表示单词 \\(w_i\\) 在文本 \\(d_j\\) 中出现的频数或权值。由于单 词的种类很多, 而每个文本中出现单词的种类通常较少, 所以单词-文本矩阵是一个稀 疏矩阵。 权值通常用单词频率-逆文本频率 (term frequency-inverse document frequency, TF-IDF）表示，其定义是 \\[ \\operatorname{TFIDF}_{i j}=\\frac{\\mathrm{tf}_{i j}}{\\mathrm{tf}_{\\bullet j}} \\log \\frac{\\mathrm{df}}{\\mathrm{df}_i}, \\quad i=1,2, \\cdots, m ; \\quad j=1,2, \\cdots, n \\] 直观上讲，可以直接用每一列作为文本语义表达， 因此可以通过余弦相似度等计算文本之间的相似性，并且矩阵稀疏，计算量较少。但其并不关心文本中词语出现的顺序等信息，因此需要改进。 ### 单词-主题矩阵 假设所有文本共含有 \\(k\\) 个话题。假设每个话题由一个定义在单词集合 \\(W\\) 上的 \\(m\\) 维向量表示, 称为话题向量, 即 \\[ t_l=\\left[\\begin{array}{c} t_{1 l} \\\\\\\\ t_{2 l} \\\\\\\\ \\vdots \\\\\\\\ t_{m l} \\end{array}\\right], \\quad l=1,2, \\cdots, k \\] 其中 \\(t_{i l}\\) 是单词 \\(w_i\\) 在话题 \\(t_l\\) 的权值, \\(i=1,2, \\cdots, m\\), 权值越大, 该单词在该话题中 的重要度就越高。这 \\(k\\) 个话题向量 \\(t_1, t_2, \\cdots, t_k\\) 张成一个话题向量空间 (topic vector 话题向量空间 \\(T\\) 也可以表示为一个矩阵, 称为单词-主题矩阵 (word-topic matrix）, 记作 \\[ T=\\left[\\begin{array}{cccc} t_{11} \u0026 t_{12} \u0026 \\cdots \u0026 t_{1 k} \\\\\\\\ t_{21} \u0026 t_{22} \u0026 \\cdots \u0026 t_{2 k} \\\\\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots \\\\\\\\ t_{m 1} \u0026 t_{m 2} \u0026 \\cdots \u0026 t_{m k} \\end{array}\\right] \\] ","date":"2022-06-16","objectID":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/:2:1","tags":["NLP","主题模型"],"title":"主题模型","uri":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"主题-文本矩阵 将单词-文本矩阵中的文本\\(x_j\\)投影到主题向量空间\\(J\\)中，得到在主题空间中的一个向量\\(y_j\\)。 \\[ Y=\\left[\\begin{array}{cccc} y_{11} \u0026 y_{12} \u0026 \\cdots \u0026 y_{1 n} \\\\\\\\ y_{21} \u0026 y_{22} \u0026 \\cdots \u0026 y_{2 n} \\\\\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots \\\\\\\\ y_{k 1} \u0026 y_{k 2} \u0026 \\cdots \u0026 y_{k n} \\end{array}\\right] \\] 从单词向量空间到主题向量空间的线性变换 单词-文本矩阵\\(X\\)可以近似表示为单词-主题矩阵\\(T\\)与主题-文本矩阵\\(Y\\)的乘积，这就是潜在语义分析： \\[ X\\approx TY \\] ","date":"2022-06-16","objectID":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/:2:2","tags":["NLP","主题模型"],"title":"主题模型","uri":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"潜在语义分析 给定单词-文本矩阵\\(X\\)，每一行代表一个单词，每一列代表一个文本。其中的元素代表单词在文本中的权重或者频数（词袋模型）。 截断奇异值分析 \\[ X \\approx U_k \\Sigma_k V_k^{\\mathrm{T}}=\\left[\\begin{array}{llll} u_1 \u0026 u_2 \u0026 \\cdots \u0026 u_k \\end{array}\\right]\\left[\\begin{array}{cccc} \\sigma_1 \u0026 0 \u0026 0 \u0026 0 \\\\\\\\ 0 \u0026 \\sigma_2 \u0026 0 \u0026 0 \\\\\\\\ 0 \u0026 0 \u0026 \\ddots \u0026 0 \\\\\\\\ 0 \u0026 0 \u0026 0 \u0026 \\sigma_k \\end{array}\\right]\\left[\\begin{array}{c} v_1^{\\mathrm{T}} \\\\\\\\ v_2^{\\mathrm{T}} \\\\\\\\ \\vdots \\\\\\\\ v_k^{\\mathrm{T}} \\end{array}\\right] \\] 接下来考虑文本在主题空间中的表示。 \\[ \\begin{aligned} X \u0026=\\left[\\begin{array}{llll} x_1 \u0026 x_2 \u0026 \\cdots \u0026 x_n \\end{array}\\right] \\approx U_k \\Sigma_k V_k^{\\mathrm{T}} \\\\\\\\ \u0026=\\left[\\begin{array}{llll} u_1 \u0026 u_2 \u0026 \\cdots \u0026 u_k \\end{array}\\right]\\left[\\begin{array}{cccc} \\sigma_1 \u0026 \u0026 \u0026 \\\\\\\\ \u0026 \\sigma_2 \u0026 0 \u0026 \\\\\\\\ 0 \u0026 \\ddots \u0026 \\\\\\\\ \u0026 \u0026 \\sigma_k \\end{array}\\right]\\left[\\begin{array}{cccc} v_{11} \u0026 v_{21} \u0026 \\cdots \u0026 v_{n 1} \\\\\\\\ v_{12} \u0026 v_{22} \u0026 \\cdots \u0026 v_{n 2} \\\\\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots \\\\\\\\ v_{1 k} \u0026 v_{2 k} \u0026 \\cdots \u0026 v_{n k} \\end{array}\\right] \\\\\\\\ \u0026=\\left[\\begin{array}{llll} u_1 \u0026 u_2 \u0026 \\cdots \u0026 u_k \\end{array}\\right]\\left[\\begin{array}{cccc} \\sigma_1 v_{11} \u0026 \\sigma_1 v_{21} \u0026 \\cdots \u0026 \\sigma_1 v_{n 1} \\\\\\\\ \\sigma_2 v_{12} \u0026 \\sigma_2 v_{22} \u0026 \\cdots \u0026 \\sigma_2 v_{n 2} \\\\\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots \\\\\\\\ \\sigma_k v_{1 k} \u0026 \\sigma_k v_{2 k} \u0026 \\cdots \u0026 \\sigma_k v_{n k} \\end{array}\\right] \\end{aligned} \\] 其中: \\[ u_l = \\begin{bmatrix}u_{1l} \\\\\\\\u_{2l} \\\\\\\\ \\vdots \\\\\\\\u_{ml} \\end{bmatrix}, \\quad l= 1, 2, \\dots, k \\] 代表单词对主题的权重。 由式知, 矩阵 \\(X\\) 的第 \\(j\\) 列向量 \\(x_j\\) 满足 \\[ \\begin{aligned} x_j \u0026 \\approx U_k\\left(\\Sigma_k V_k^{\\mathrm{T}}\\right)\\_j \\\\\\\\ \u0026=\\left[\\begin{array}{llll} u_1 \u0026 u_2 \u0026 \\cdots \u0026 u_k \\end{array}\\right]\\left[\\begin{array}{c} \\sigma_1 v_{j 1} \\\\\\\\ \\sigma_2 v_{j 2} \\\\\\\\ \\vdots \\\\\\\\ \\sigma_k v_{j k} \\end{array}\\right] \\\\\\\\ \u0026=\\sum_{l=1}^k \\sigma_l v_{j l} u_l, \\quad j=1,2, \\cdots, n \\end{aligned} \\] 则\\(\\Sigma_kV_k^T\\)每一个列向量是一个文本在主题向量空间中的表示。 ","date":"2022-06-16","objectID":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/:2:3","tags":["NLP","主题模型"],"title":"主题模型","uri":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"PLSA ","date":"2022-06-16","objectID":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/:3:0","tags":["NLP","主题模型"],"title":"主题模型","uri":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"生成模型 假设有单词集合 \\(W={w_1, w_2, \\cdots, w_M}\\), 其中 \\(M\\) 是单词个数; 文本 (指标) 集 合 \\(D={d_1, d_2, \\cdots, d_N}\\), 其中 \\(N\\) 是文本个数; 话题集合 \\(Z={z_1, z_2, \\cdots, z_K}\\), 其中 \\(K\\) 是预先设定的话题个数。随机变量 \\(w\\) 取值于单词集合; 随机变量 \\(d\\) 取值于文本集 合, 随机变量 \\(z\\) 取值于话题集合。概率分布 \\(P(d)\\) 、条件概率分布 \\(P(z \\mid d)\\) 、条件概率分 布 \\(P(w \\mid z)\\) 皆属于多项分布, 其中 \\(P(d)\\) 表示生成文本 \\(d\\) 的概率, \\(P(z \\mid d)\\) 表示文本 \\(d\\) 生 成话题 \\(z\\) 的概率, \\(P(w \\mid z)\\) 表示话题 \\(z\\) 生成单词 \\(w\\) 的概率。 每个文本 \\(d\\) 拥有自己的话题概率分布 \\(P(z \\mid d)\\), 每个话题 \\(z\\) 拥有自己的单词概率分 布 \\(P(w \\mid z)\\); 也就是说一个文本的内容由其相关话题决定, 一个话题的内容由其相关单词决定。 生成模型通过以下步骤生成文本-单词共现数据: (1) 依据概率分布 \\(P(d)\\), 从文本 (指标) 集合中随机选取一个文本 \\(d\\), 共生成 \\(N\\) 个文本; 针对每个文本, 执行以下操作; (2) 在文本 \\(d\\) 给定条件下, 依据条件概率分布 \\(P(z \\mid d)\\), 从话题集合随机选取一个 话题 \\(z\\), 共生成 \\(L\\) 个话题, 这里 \\(L\\) 是文本长度; (3) 在话题 \\(z\\) 给定条件下, 依据条件概率分布 \\(P(w \\mid z)\\), 从单词集合中随机选取一 个单词 \\(w\\) 。 生成模型中, 单词变量 \\(w\\) 与文本变量 \\(d\\) 是观测变量, 话题变量 \\(z\\) 是隐变量。也就 是说模型生成的是单词-话题-文本三元组 \\((w, z, d)\\) 的集合, 但观测到的是单词-文本二 元组 \\((w, d)\\) 的集合, 观测数据表示为单词-文本矩阵 \\(T\\) 的形式, 矩阵 \\(T\\) 的行表示单词, 列表示文本, 元素表示单词-文本对 \\((w, d)\\) 的出现次数。 从数据的生成过程可以推出, 文本-单词共现数据 \\(T\\) 的生成概率为所有单词-文本 对 \\((w, d)\\) 的生成概率的乘积, \\[ P(T)=\\prod_{(w, d)} P(w, d)^{n(w, d)} \\] 这里 \\(n(w, d)\\) 表示 \\((w, d)\\) 的出现次数, 单词-文本对出现的总次数是 \\(N \\times L\\) 。每个单 词-文本对 \\((w, d)\\) 的生成概率由以下公式决定: \\[ \\begin{aligned} P(w, d) \u0026=P(d) P(w \\mid d) \\\\\\\\ \u0026=P(d) \\sum_z P(w, z \\mid d) \\\\\\\\ \u0026=P(d) \\sum_z P(z \\mid d) P(w \\mid z) \\end{aligned} \\] 即生成模型的定义。 生成模型假设在话题 \\(z\\) 给定条件下, 单词 \\(w\\) 与文本 \\(d\\) 条件独立, 即 \\[ P(w, z \\mid d)=P(z \\mid d) P(w \\mid z) \\] ","date":"2022-06-16","objectID":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/:3:1","tags":["NLP","主题模型"],"title":"主题模型","uri":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"共现模型 \\[ P(T)=\\prod_{(w, d)} P(w, d)^{n(w, d)} \\] 每个单词-文本对 \\((w, d)\\) 的概率由以下公式决定: \\[ P(w, d)=\\sum_{z \\in Z} P(z) P(w \\mid z) P(d \\mid z) \\] 式 (18.5) 即共现模型的定义。容易验证, 生成模型 (18.2) 和共现模型 (18.5) 是等价的。 共现模型假设在话题 \\(z\\) 给定条件下, 单词 \\(w\\) 与文本 \\(d\\) 是条件独立的, 即 \\[ P(w, d \\mid z)=P(w \\mid z) P(d \\mid z) \\] 直观解释： ","date":"2022-06-16","objectID":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/:3:2","tags":["NLP","主题模型"],"title":"主题模型","uri":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"与潜在语义分析的关系 共现模型也可以表示为三个矩阵乘积的形式。这样, 概率潜在语义分析与 潜在语义分析的对应关系可以从中看得很清楚。下面是共现模型的矩阵乘积形式: \\[ \\begin{aligned} X^{\\prime} \u0026=U^{\\prime} \\Sigma^{\\prime} V^{\\prime \\mathrm{T}} \\\\\\\\ X^{\\prime} \u0026=[P(w, d)]\\_{M \\times N} \\\\\\\\ U^{\\prime} \u0026=[P(w \\mid z)]\\_{M \\times K} \\\\\\\\ \\Sigma^{\\prime} \u0026=[P(z)]\\_{K \\times K} \\\\\\\\ V^{\\prime} \u0026=[P(d \\mid z)]\\_{N \\times K} \\end{aligned} \\] ","date":"2022-06-16","objectID":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/:3:3","tags":["NLP","主题模型"],"title":"主题模型","uri":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"概率潜在语义分析的算法 Plsa是含有隐变量的模型，其学习通常使用EM算法。 E步是计算Q函数，M步是极大化Q函数。 设单词集合为 \\(W={w_1, w_2, \\cdots, w_M}\\), 文本集合为 \\(D={d_1, d_2, \\cdots, d_N}\\), 话 题集合为 \\(Z={z_1, z_2, \\cdots, z_K}\\) 。给定单词-文本共现数据 \\(T={n\\left(w_i, d_j\\right)}, i=\\) \\(1,2, \\cdots, M, j=1,2, \\cdots, N\\), 目标是估计概率潜在语义分析模型（生成模型）的 参数。如果使用极大似然估计, 对数似然函数是 \\[ \\begin{aligned} L \u0026=\\sum_{i=1}^M \\sum_{j=1}^N n\\left(w_i, d_j\\right) \\log P\\left(w_i, d_j\\right) \\\\\\\\ \u0026=\\sum_{i=1}^M \\sum_{j=1}^N n\\left(w_i, d_j\\right) \\log \\left[\\sum_{k=1}^K P\\left(w_i \\mid z_k\\right) P\\left(z_k \\mid d_j\\right)\\right] \\end{aligned} \\] 但是模型含有隐变量, 对数似然函数的优化无法用解析方法求解, 这时使用 EM算法。 应用 EM算法的核心是定义 \\(Q\\) 函数。 \\(\\mathrm{E}\\) 步：计算 \\(Q\\) 函数 \\(Q\\) 函数为完全数据的对数似然函数对不完全数据的条件分布的期望。针对概率潜 在语义分析的生成模型, \\(Q\\) 函数是 \\[ Q=\\sum_{k=1}^K{\\sum_{j=1}^N n\\left(d_j\\right)\\left[\\log P\\left(d_j\\right)+\\sum_{i=1}^M \\frac{n\\left(w_i, d_j\\right)}{n\\left(d_j\\right)} \\log P\\left(w_i \\mid z_k\\right) P\\left(z_k \\mid d_j\\right)\\right]} P\\left(z_k \\mid w_i, d_j\\right) \\] 式中 \\(n\\left(d_j\\right)=\\sum_{i=1}^M n\\left(w_i, d_j\\right)\\) 表示文本 \\(d_j\\) 中的单词个数, \\(n\\left(w_i, d_j\\right)\\) 表示单词 \\(w_i\\) 在文本 \\(d_j\\) 中出现的次数。条件概率分布 \\(P\\left(z_k \\mid w_i, d_j\\right)\\) 代表不完全数据, 是已知变量。条件概 率分布 \\(P\\left(w_i \\mid z_k\\right)\\) 和 \\(P\\left(z_k \\mid d_j\\right)\\) 的乘积代表完全数据, 是末知变量。 由于可以从数据中直接统计得出 \\(P\\left(d_j\\right)\\) 的估计, 这里只考虑 \\(P\\left(w_i \\mid z_k\\right), P\\left(z_k \\mid d_j\\right)\\) 的估计, 可将 \\(Q\\) 函数简化为函数 \\(Q^{\\prime}\\) \\[ Q^{\\prime}=\\sum_{i=1}^M \\sum_{j=1}^N n\\left(w_i, d_j\\right) \\sum_{k=1}^K P\\left(z_k \\mid w_i, d_j\\right) \\log \\left[P\\left(w_i \\mid z_k\\right) P\\left(z_k \\mid d_j\\right)\\right] \\] \\(Q^{\\prime}\\) 函数中的 \\(P\\left(z_k \\mid w_i, d_j\\right)\\) 可以根据贝叶斯公式计算 \\[ P\\left(z_k \\mid w_i, d_j\\right)=\\frac{P\\left(w_i \\mid z_k\\right) P\\left(z_k \\mid d_j\\right)}{\\sum_{k=1}^K P\\left(w_i \\mid z_k\\right) P\\left(z_k \\mid d_j\\right)} \\] 其中 \\(P\\left(z_k \\mid d_j\\right)\\) 和 \\(P\\left(w_i \\mid z_k\\right)\\) 由上一步迭代得到。 \\(\\mathrm{M}\\) 步: 极大化 \\(Q\\) 函数。 通过约束最优化求解 \\(Q\\) 函数的极大值, 这时 \\(P\\left(z_k \\mid d_j\\right)\\) 和 \\(P\\left(w_i \\mid z_k\\right)\\) 是变量。因为 变量 \\(P\\left(w_i \\mid z_k\\right), P\\left(z_k \\mid d_j\\right)\\) 形成概率分布, 满足约束条件 \\[ \\begin{aligned} \u0026\\sum_{i=1}^M P\\left(w_i \\mid z_k\\right)=1, \\quad k=1,2, \\cdots, K \\\\\\\\ \u0026\\sum_{k=1}^K P\\left(z_k \\mid d_j\\right)=1, \\quad j=1,2, \\cdots, N \\end{aligned} \\] 应用拉格朗日法, 引入拉格朗日乘子 \\(\\tau_k\\) 和 \\(\\rho_j\\), 定义拉格朗日函数 \\(A\\) \\[ \\Lambda=Q^{\\prime}+\\sum_{k=1}^K \\tau_k\\left(1-\\sum_{i=1}^M P\\left(w_i \\mid z_k\\right)\\right)+\\sum_{j=1}^N \\rho_j\\left(1-\\sum_{k=1}^K P\\left(z_k \\mid d_j\\right)\\right) \\] 将拉格朗日函数 \\(\\Lambda\\) 分别对 \\(P\\left(w_i \\mid z_k\\right)\\) 和 \\(P\\left(z_k \\mid d_j\\right)\\) 求偏导数, 并令其等于 0 , 得到下面 的方程组 \\[ \\begin{aligned} \u0026\\sum_{j=1}^N n\\left(w_i, d_j\\right) P\\left(z_k \\mid w_i, d_j\\right)-\\tau_k P\\left(w_i \\mid z_k\\right)=0, \\quad i=1,2, \\cdots, M ; \\quad k=1,2, \\cdots, K \\\\\\\\ \u0026\\sum_{i=1}^M n\\left(w_i, d_j\\right) P\\left(z_k \\mid w_i, d_j\\right)-\\rho_j P\\left(z_k \\mid d_j\\right)=0, \\quad j=1,2, \\cdots, N ; \\quad k=1,2, \\cdots, K \\end{aligned} \\] 解方程组得到 \\(M\\) 步的参数估计公式: \\[ P\\left(w_i \\mid z_k\\right)=\\frac{\\sum_{j=1}^N n\\left(w_i, d_j\\right) P\\left(z_k \\mid w_i, d_j\\right)}{\\sum_{m=1}^M \\sum_{j=1}^N n\\left(w_m, d_j\\right) P\\left(z_k \\mid w_m, d_j\\right)} \\] \\[ P(z_k\\mid d_j) = \\frac{\\sum_{i=1}^Mn(w_i, d_j)P(z_k\\mid w_i,d_j)}{n(d_j)} \\] ","date":"2022-06-16","objectID":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/:3:4","tags":["NLP","主题模型"],"title":"主题模型","uri":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"总结算法 输入: 设单词集合为 \\(W={w_1, w_2, \\cdots, w_M}\\), 文本集合为 \\(D={d_1, d_2, \\cdots, d_N}\\), 话题集合为 \\(Z={z_1, z_2, \\cdots, z_K}\\), 共现数据 \\({n\\left(w_i, d_j\\right)}, i=1,2, \\cdots, M, j=1\\), \\(2, \\cdots, N\\); 输出: \\(P\\left(w_i \\mid z_k\\right)\\) 和 \\(P\\left(z_k \\mid d_j\\right)\\) 。 (1) 设置参数 \\(P\\left(w_i \\mid z_k\\right)\\) 和 \\(P\\left(z_k \\mid d_j\\right)\\) 的初始值。 (2) 迭代执行以下 \\(\\mathrm{E}\\) 步, \\(\\mathrm{M}\\) 步, 直到收敛为止。 \\(\\mathrm{E}\\) 步: \\[ P\\left(z_k \\mid w_i, d_j\\right)=\\frac{P\\left(w_i \\mid z_k\\right) P\\left(z_k \\mid d_j\\right)}{\\sum_{k=1}^K P\\left(w_i \\mid z_k\\right) P\\left(z_k \\mid d_j\\right)} \\] M 步: \\[ \\begin{aligned} P\\left(w_i \\mid z_k\\right) \u0026=\\frac{\\sum_{j=1}^N n\\left(w_i, d_j\\right) P\\left(z_k \\mid w_i, d_j\\right)}{\\sum_{m=1}^M \\sum_{j=1}^N n\\left(w_m, d_j\\right) P\\left(z_k \\mid w_m, d_j\\right)} \\\\\\\\ P\\left(z_k \\mid d_j\\right) \u0026=\\frac{\\sum_{i=1}^M n\\left(w_i, d_j\\right) P\\left(z_k \\mid w_i, d_j\\right)}{n\\left(d_j\\right)} \\end{aligned} \\] ","date":"2022-06-16","objectID":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/:3:5","tags":["NLP","主题模型"],"title":"主题模型","uri":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"用法 与LSA类似，可以把文档对各个主题的概率看作是文档的表示，最后用到的就是\\(P(z_k\\mid d_j)\\)。 k就是我们自己设定的主题数，一般来说K远远小于文档个数和词汇表大小，这样也达到了降维的目的。 ","date":"2022-06-16","objectID":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/:3:6","tags":["NLP","主题模型"],"title":"主题模型","uri":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"优点与不足 优点 pLSA是在一套比较完整的思想的基础上提出来的，模型中各项参数有明确的物理含义，可解释性比较强。相比LSA，pLSA对人类生成文本机制的刻画更加细致、更加符合我们的常识，比如，pLSA基于条件概率，引入了一个“隐含变量”（相对于可以看到的文档和词语，是不可观测变的），即主题，来描述文本生成的过程。 #### 不足 pLSA的理论与我们的实践不是那么的统一: (1) 我们说话的时候，根本不会考虑” 我说这段话的概率大小”，即 \\(p\\left(d_t\\right)\\) (2) pLSA认为，我们说话时面向的主题分布，取决于 “文档” （实际上是文档ID)。这个假设显然是不合理的，小说家不会因为自己写到第666回而调整 主题。 (3) 类似 (2)，随着上下文的变化，我们围绕一个主题说话的内容和方式也 会发生改变。在主题模型中，这种改变的体现，就是一个主题下的词语概率分 布会发生改变。而pLSA忽略了这样的事实。 从计算复杂度的角度看pLSA有两个比较大的缺陷: (1) pLSA中，对文档 出现的概率估计，来自对训练语料的学习。而对于一个 末知文档，我们是无法估计它出现的概率的一一因此pLSA无法对训练语料之 外的文档进行处理。pLSA的这个特点决定了，在在线(online) 场景中(数据是 持续增加的)，那么文档处理系统就需要定时使用pLSA对整个语料库进行计 算。因此，pLSA比较适合允许一定时滞的离线计算。 (2) pLSA认为一个文档对各个主题的隶属度是一定的——而一个主题对各个词语的隶属度也是一定的，因此pLSA在生成一个文档的各个词语时、使用了相同的词语概率分布。这样，pLSA需要为每一个文档记录一个专门的随着语料数据集规模的增加，pLSA的参数规模也会增加，导致模型训练越来越困难。 ","date":"2022-06-16","objectID":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/:3:7","tags":["NLP","主题模型"],"title":"主题模型","uri":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"LDA LDA模型是文本集合的生成概率模型。 LDA 的文本集合的生成过程如下: 首先随机生成一个文本的话题分布, 之后在该 文本的每个位置, 依据该文本的话题分布随机生成一个话题, 然后在该位置依据该话 题的单词分布随机生成一个单词, 直至文本的最后一个位置, 生成整个文本。重复以 上过程生成所有文本。 LDA 模型是含有隐变量的概率图模型。模型中, 每个话题的单词分布, 每个文 本的话题分布, 文本的每个位置的话题是隐变量; 文本的每个位置的单词是观测变 量。LDA 模型的学习与推理无法直接求解, 通常使用吉布斯抽样 (Gibbs sampling) 和 变分 EM算法 (variational EM algorithm), 前者是蒙特卡罗法, 而后者是近似算法。 ","date":"2022-06-16","objectID":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/:4:0","tags":["NLP","主题模型"],"title":"主题模型","uri":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"多项分布 (多项分布) 若多元离散随机变量 \\(X=\\left(X_1, X_2, \\cdots, X_k\\right)\\) 的概率质 量函数为 \\[ \\begin{aligned} P\\left(X_1=n_1, X_2=n_2, \\cdots, X_k=n_k\\right) \u0026=\\frac{n !}{n_{1} ! n_{2} ! \\cdots n_{k} !} p_1^{n_1} p_2^{n_2} \\cdots p_k^{n_k} \\\\\\\\ \u0026=\\frac{n !}{\\prod_{i=1}^k n_{i} !} \\prod_{i=1}^k p_i^{n_i} \\end{aligned} \\] 其中 \\(p=\\left(p_1, p_2, \\cdots, p_k\\right), p_i \\geqslant 0, i=1,2, \\cdots, k, \\sum_{i=1}^k p_i=1, \\sum_{i=1}^k n_i=n\\), 则称随机变 量 \\(X\\) 服从参数为 \\((n, p)\\) 的多项分布, 记作 \\(X \\sim \\operatorname{Mult}(n, p)\\) 。 当试验的次数 \\(n\\) 为 1 时, 多项分布变成类别分布 (categorical distribution)。类 别分布表示试验可能出现的 \\(k\\) 种结果的概率。显然多项分布包含类别分布。 ","date":"2022-06-16","objectID":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/:4:1","tags":["NLP","主题模型"],"title":"主题模型","uri":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"狄利克雷分布 狄利克雷分布 (Dirichlet distribution) 是一种多元连续随机变量的概率分布, 是 贝塔分布 (beta distribution) 的扩展。在贝叶斯学习中, 狄利克雷分布常作为多项分 布的先验分布使用。 (狄利克雷分布) 若多元连续随机变量 \\(\\theta=\\left(\\theta_1, \\theta_2, \\cdots, \\theta_k\\right)\\) 的概率密 度函数为 \\[ p(\\theta \\mid \\alpha)=\\frac{\\Gamma\\left(\\sum_{i=1}^k \\alpha_i\\right)}{\\prod_{i=1}^k \\Gamma\\left(\\alpha_i\\right)} \\prod_{i=1}^k \\theta_i^{\\alpha_i-1} \\] 其中 \\(\\sum_{i=1}^k \\theta_i=1, \\theta_i \\geqslant 0, \\alpha=\\left(\\alpha_1, \\alpha_2, \\cdots, \\alpha_k\\right), \\alpha_i\u003e0, i=1,2, \\cdots, k\\), 则称随机变量 \\(\\theta\\) 服从参数为 \\(\\alpha\\) 的狄利克雷分布, 记作 \\(\\theta \\sim \\operatorname{Dir}(\\alpha)\\) 。 式中 \\(\\Gamma(s)\\) 是伽马函数, 定义为 \\[ \\Gamma(s)=\\int_0^{\\infty} x^{s-1} \\mathrm{e}^{-x} \\mathrm{~d} x, \\quad s\u003e0 \\] 具有性质： \\[ \\Gamma(s+1) = s\\Gamma(s) \\] 当s为自然数时，有： \\[ \\Gamma(s+1) = s! \\] 令 \\[ \\mathrm{B}(\\alpha)=\\frac{\\prod_{i=1}^k \\Gamma\\left(\\alpha_i\\right)}{\\Gamma\\left(\\sum_{i=1}^k \\alpha_i\\right)} \\] 则狄利克雷分布的密度函数可以写成 \\[ p(\\theta \\mid \\alpha)=\\frac{1}{\\mathrm{~B}(\\alpha)} \\prod_{i=1}^k \\theta_i^{\\alpha_i-1} \\] \\(\\mathrm{B}(\\alpha)\\) 是规范化因子, 称为多元贝塔函数 (或扩展的贝塔函数)。由密度函数的性质 \\[ \\int \\frac{\\Gamma\\left(\\sum_{i=1}^k \\alpha_i\\right)}{\\prod_{i=1}^k \\Gamma\\left(\\alpha_i\\right)} \\prod_{i=1}^{\\alpha_i-1} \\mathrm{~d} \\theta=\\frac{\\Gamma\\left(\\sum_{i=1}^k \\alpha_i\\right)}{\\prod_{i=1}^k \\Gamma\\left(\\alpha_i\\right)} \\int \\prod_{i=1}^k \\theta_i^{\\alpha_i-1} \\mathrm{~d} \\theta=1 \\] 得 \\[ \\mathrm{B}(\\alpha)=\\int \\prod_{i=1}^k \\theta_i^{\\alpha_i-1} \\mathrm{~d} \\theta \\] ","date":"2022-06-16","objectID":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/:4:2","tags":["NLP","主题模型"],"title":"主题模型","uri":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"二项分布与贝塔分布 二项分布是多项分布的特殊情况, 贝塔分布是狄利克雷分布的特殊情况。 二项分布是指如下概率分布。 \\(X\\) 为离散随机变量, 取值为 \\(m\\), 其概率质量函数为 \\[ P(X=m)=\\left(\\begin{array}{c} n \\\\\\\\ m \\end{array}\\right) p^m(1-p)^{n-m}, \\quad m=0,1,2, \\cdots, n \\] 其中 \\(n\\) 和 \\(p(0 \\leqslant p \\leqslant 1)\\) 是参数。 贝塔分布是指如下概率分布, \\(X\\) 为连续随机变量, 取值范围为 \\([0,1]\\), 其概率密度 函数为 \\[ p(x)= \\begin{cases}\\frac{1}{\\mathrm{~B}(s, t)} x^{s-1}(1-x)^{t-1}, \u0026 0 \\leqslant x \\leqslant 1 \\\\\\\\ 0, \u0026 \\text { 其他 }\\end{cases} \\] 其中 \\(s\u003e0\\) 和 \\(t\u003e0\\) 是参数, \\(\\mathrm{B}(s, t)=\\frac{\\Gamma(s) \\Gamma(t)}{\\Gamma(s+t)}\\) 是贝塔函数, 定义为 \\[ \\mathrm{B}(s, t)=\\int_0^1 x^{s-1}(1-x)^{t-1} \\mathrm{~d} x = \\frac{\\Gamma(s)\\Gamma(t)}{\\Gamma(s+t)} \\] 当 \\(s, t\\) 是自然数时(\\(\\Gamma(s+1) = s!\\)), \\[ \\mathrm{B}(s, t)=\\frac{(s-1) !(t-1) !}{(s+t-1) !} \\] 当 \\(n\\) 为 1 时, 二项分布变成伯努利分布（Bernoulli distribution）或 0-1 分布。 伯努利分布表示试验可能出现的 2 种结果的概率。显然二项分布包含伯努利分布。给出几种概率分布的关系。 ","date":"2022-06-16","objectID":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/:4:3","tags":["NLP","主题模型"],"title":"主题模型","uri":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"基本想法 在LDA主题模型下，一篇文章由词语的序列组成。首先以一定概率选择一个主题，其次以一定概率在这个主题中选择一个词。如果一篇文章由1000个词组成，那么就把上述方式重复1000遍，就能组成这篇文章。那么值得注意的是，以一定概率选择一个主题是服从多项式分布的，而多项式分布的参数是服从Dirichlet分布的。以一定概率在特定主题中选择一个词也是服从多项式分布的，多项式分布的参数是服从Dirichlet分布的。为什么呢？因为Dirichlet分布是多项式分布的共轭分布，也就是说由贝叶斯估计得到的后验分布仍然是Dirichlet分布。 ","date":"2022-06-16","objectID":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/:4:4","tags":["NLP","主题模型"],"title":"主题模型","uri":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"LDA与PLSA的关系 二者都是概率模型，都是利用概率生成模型对文本集合进行主题分析的无监督学习方法。 PLSA是用了频率派的方法，利用极大似然进行学习，而LDA使用了贝叶斯派的方法，进行贝叶斯推断。 二者都假设存在两个分布：话题是单词的多项分布，文本是话题的多项分布，不同的在于LDA认为多项分布的参数也服从一个分布，而不是固定不变的，使用狄利克雷分布作为多项分布的先验分布，也就是多项分布的参数服从狄利克雷分布。 引入先验概率的作用可以防止过拟合。为啥选择狄利克雷分布呢？因为它是多项分布的共轭先验分布，先验分布与后验分布形式相同，便于由先验分布得到后验分布。 LDA是在Plsa的基础上，为单词分布和主题分布增加了两个狄利克雷先验。 ","date":"2022-06-16","objectID":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/:4:5","tags":["NLP","主题模型"],"title":"主题模型","uri":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"模型定义 模型要素 潜在狄利克雷分配 (LDA) 使用三个集合: 一是单词集合 \\(W={w_1, \\cdots, w_v, \\cdots}\\), , 其中 \\(w_v\\) 是第 \\(v\\) 个单词, \\(v=1,2, \\cdots, V, V\\) 是单词的个数。二是文本集合 \\(D={\\mathbf{w}_1, \\cdots, \\mathbf{w}_m, \\cdots, \\mathbf{w}_M}\\), 其中 \\(\\mathbf{w}_m\\) 是第 \\(m\\) 个文本, \\(m=1,2, \\cdots, M, M\\) 是文本 的个数。文本 \\(\\mathbf{w}_m\\) 是一个单词序列 \\(\\mathbf{w}_m=\\left(w_{m 1}, \\cdots, w_{m n}, \\cdots, w_{m N_m}\\right)\\), 其中 \\(w_{m n}\\) 是 文本 \\(\\mathbf{w}_m\\) 的第 \\(n\\) 个单词, \\(n=1,2, \\cdots, N_m, N_m\\) 是文本 \\(\\mathbf{w}_m\\) 中单词的个数。三是主题集合集合 \\(Z={z_1, \\cdots, z_k, \\cdots, z_K}\\), 其中 \\(z_k\\) 是第 \\(k\\) 个话题, \\(k=1,2, \\cdots, K, K\\) 是话题的个数。 每一个话题 \\(z_k\\) 由一个单词的条件概率分布 \\(p\\left(w \\mid z_k\\right)\\) 决定, \\(w \\in W\\) 。分布 \\(p\\left(w \\mid z_k\\right)\\) 服从多项分布 (严格意义上类别分布), 其参数为 \\(\\varphi_k\\) 。参数 \\(\\varphi_k\\) 服从狄利克雷分布 (先验分布), 其超参数为 \\(\\beta\\) 。参数 \\(\\varphi_k\\) 是一个 \\(V\\) 维向量 \\(\\varphi_k=\\left(\\varphi_{k 1}, \\varphi_{k 2}, \\cdots, \\varphi_{k V}\\right)\\), 其中 \\(\\varphi_{k v}\\) 表示话题 \\(z_k\\) 生成单词 \\(w_v\\) 的概率。所有话题的参数向量构成一个 \\(K \\times V\\) 矩阵 \\(\\varphi=\\{\\varphi_k\\}_{k=1}^K\\) 。超参数 \\(\\beta\\) 也是一个 \\(V\\) 维向量 \\(\\beta=\\left(\\beta_1, \\beta_2, \\cdots, \\beta_V\\right)\\_{\\text {。 }}\\)(对于话题\\(z_k\\)其生成单词\\(w_v\\)先验服从狄利克雷分布，因此是一个V维向量) 每一个文本 \\(\\mathbf{w}_m\\) 由一个话题的条件概率分布 \\(p\\left(z \\mid \\mathbf{w}_m\\right)\\) 决定, \\(z \\in Z_{\\text {。 }}\\) 分布 \\(p\\left(z \\mid \\mathbf{w}_m\\right)\\) 服从多项分布 (严格意义上类别分布), 其参数为 \\(\\theta_m\\) 。参数 \\(\\theta_m\\) 服从狄利克雷分布 (先验分布), 其超参数为 \\(\\alpha\\) , 参数 \\(\\theta_m\\) 是一个 \\(K\\) 维向量 \\(\\theta_m=\\left(\\theta_{m 1}, \\theta_{m 2}, \\cdots, \\theta_{m K}\\right)\\), 其中 \\(\\theta_{m k}\\) 表示文本 \\(\\mathrm{w}_m\\) 生成话题 \\(z_k\\) 的概率。所有文本的参数向量构成一个 \\(M \\times K\\) 矩阵 \\(\\theta=\\{\\theta_m\\}_{m=1}^M\\) 。超参数 \\(\\alpha\\) 也是一个 \\(K\\) 维向量 \\(\\alpha=\\left(\\alpha_1, \\alpha_2, \\cdots, \\alpha_K\\right)\\) 。 每一个文本 \\(\\mathbf{w}_m\\) 中的每一个单词 \\(w_{m n}\\) 由该文本的话题分布 \\(p\\left(z \\mid \\mathbf{w}_m\\right)\\) 以及所有话 题的单词分布 \\(p\\left(w \\mid z_k\\right)\\) 决定。 生成过程 LDA 文本集合的生成过程如下: 给定单词集合 \\(W\\), 文本集合 \\(D\\), 话题集合 \\(Z\\), 狄利克雷分布的超参数 \\(\\alpha\\) 和 \\(\\beta\\) 。 1.生成单词分布 随机生成 \\(K\\) 个话题的单词分布。具体过程如下, 按照狄利克雷分布 \\(\\operatorname{Dir}(\\beta)\\) 随机 生成一个参数向量 \\(\\varphi_k, \\varphi_k \\sim \\operatorname{Dir}(\\beta)\\), 作为话题 \\(z_k\\) 的单词分布 \\(p\\left(w \\mid z_k\\right), w \\in W, k=\\) \\(1,2, \\cdots, K\\) 。 2.生成主题分布 随机生成 \\(M\\) 个文本的主题分布。具体过程如下: 按照狄利克雷分布 \\(\\operatorname{Dir}(\\alpha)\\) 随 机生成一个参数向量 \\(\\theta_m, \\theta_m \\sim \\operatorname{Dir}(\\alpha)\\), 作为文本 \\(\\mathbf{w}_m\\) 的主题分布 \\(p\\left(z \\mid \\mathbf{w}_m\\right), m=\\) \\(1,2, \\cdots, M_{}\\) 。 3.生成文本的单词序列 随机生成 \\(M\\) 个文本的 \\(N_m\\) 个单词。文本 \\(\\mathbf{w}_m(m=1,2, \\cdots, M)\\) 的单词 \\(w_{m n}(n=\\) \\(\\left.1,2, \\cdots, N_m\\right)\\) 的生成过程如下: 3.1 首先按照多项分布 \\(\\operatorname{Mult}\\left(\\theta_m\\right)\\) 随机生成一个话题 \\(z_{m n}, z_{m n} \\sim \\operatorname{Mult}\\left(\\theta_m\\right)\\) 3.2 然后按照多项分布 \\(\\operatorname{Mult}\\left(\\varphi_{z_{m n}}\\right)\\) 随机生成一个单词 \\(w_{m n}, w_{m n} \\sim \\operatorname{Mult}\\left(\\varphi_{z_{m n}}\\right)\\_{\\text {。 }}\\) 文本 \\(\\mathbf{w}_m\\) 本身是单词序列 \\(\\mathbf{w}_m=\\left(w_{m 1}, w_{m 2}, \\cdots, w_{m N_m}\\right)\\), 对应着隐式的话题序列 \\(\\mathbf{z}_m=\\left(z_{m 1}, z_{m 2}, \\cdots, z_{m N_m}\\right) 。\\) 引用一下LDA数学八卦的图： \\(\\vec{\\alpha} \\rightarrow \\vec{\\theta}_m \\rightarrow z_{m, n}\\), 这个过程表示在生成第 \\(m\\) 篇文档的时候，先从第一个坛子中抽了一个doc-topic 骰子 \\(\\vec{\\theta}_m\\),然后投这个骰子生成了文档\\(m\\)中第 \\(n\\) 个词的topic编号 \\(z_{m, n}\\) ； \\(\\vec{\\beta} \\rightarrow \\vec{\\varphi}_k \\rightarrow w_{m, n} \\mid k=z_{m, n}\\), 这个过程表示用如下动作生成语料中第 \\(m\\) 篇文档的第 \\(n\\) 个词: 在上帝手头的 \\(K\\) 个topic-word 骰子 \\(\\vec{\\varphi}_k\\) 中，挑选编号为 \\(k=z_{m, n}\\) 的那个骰子进行投掷，然后生成 word \\(w_{m, n}\\) ; 理解 LDA最重要的就是理解这两个物理过程。LDA 模型在基于 \\(K\\) 个 topic 生成语料中的 \\(M\\) 篇文档的过程中， 由于是 bag-of-words 模型，有一些物理过程是相互独立可交换的。由此，LDA生成模型中， \\(M\\) 篇文档会对应 于 \\(M\\) 个独立的 Dirichlet-Multinomial 共轭结构；K个 个 topic 会对应于 \\(K\\) 个独立的 Dirichlet-Multinomial 共轭结 构。所以理解 LDA 所需要的所有数学就是理解 Dirichlet-Multiomail 共轭，其它都就是理解物理过程。 总结 对于话题 \\(z_k(k=1,2, \\cdots, K)\\) : 生成多项分布参数 \\(\\varphi_k \\sim \\operatorname{Dir}(\\beta)\\), 作为话题的单词分布 \\(p\\left(w \\mid z_k\\right)\\); 对于文本 \\(\\mathbf{w}_m(m=1,2, \\cdots, M)\\); 生成多项分布参数 \\(\\theta_m \\sim \\operatorname{Dir}(\\alpha)\\), 作为文本的话题分布 \\(p\\left(z \\mid \\mathb","date":"2022-06-16","objectID":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/:4:6","tags":["NLP","主题模型"],"title":"主题模型","uri":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"概率计算 LDA 模型整体是由观测变量和隐变量组成的联合概率分布, 可以表为 \\[ p(\\mathbf{w}, \\mathbf{z}, \\theta, \\varphi \\mid \\alpha, \\beta)=\\prod_{k=1}^K p\\left(\\varphi_k \\mid \\beta\\right) \\prod_{m=1}^M p\\left(\\theta_m \\mid \\alpha\\right) \\prod_{n=1}^{N_m} p\\left(z_{m n} \\mid \\theta_m\\right) p\\left(w_{m n} \\mid z_{m n}, \\varphi\\right) \\] (其中M为文本数，\\(N_m\\)为文档m的长度，K为主题数) 其中观测变量 \\(\\mathrm{w}\\) 表示所有文本中的单词序列, 隐变量 \\(\\mathrm{z}\\) 表示所有文本中的话题序列, 隐变量 \\(\\theta\\) 表示所有文本的话题分布的参数, 隐变量 \\(\\varphi\\) 表示所有话题的单词分布的参 数, \\(\\alpha\\) 和 \\(\\beta\\) 是超参数。 \\(p\\left(\\varphi_k \\mid \\beta\\right)\\) 表示超参数 \\(\\beta\\) 给定条件下第 \\(k\\) 个话题的单词分布的参数 \\(\\varphi_k\\) 的生成概率; \\(p\\left(\\theta_m \\mid \\alpha\\right)\\) 表示超参数 \\(\\alpha\\) 给定条件下第 \\(m\\) 个文本的话题分布的 参数 \\(\\theta_m\\) 的生成概率; \\(p\\left(z_{m n} \\mid \\theta_m\\right)\\) 表示第 \\(m\\) 个文本的话题分布 \\(\\theta_m\\) 给定条件下文本的 第 \\(n\\) 个位置的话题 \\(z_{m n}\\) 的生成概率; \\(p\\left(w_{m n} \\mid z_{m n}, \\varphi\\right)\\) 表示在第 \\(m\\) 个文本的第 \\(n\\) 个位 置的话题 \\(z_{m n}\\) 及所有话题的单词分布的参数 \\(\\varphi\\) 给定条件下第 \\(m\\) 个文本的第 \\(n\\) 个位 置的单词 \\(w_{m n}\\) 的生成概率。 第 \\(m\\) 个文本的联合概率分布可以表为 \\[ p\\left(\\mathbf{w}_m, \\mathbf{z}_m, \\theta_m, \\varphi \\mid \\alpha, \\beta\\right)=\\prod_{k=1}^K p\\left(\\varphi_k \\mid \\beta\\right) p\\left(\\theta_m \\mid \\alpha\\right) \\prod_{n=1}^{N_m} p\\left(z_{m n} \\mid \\theta_m\\right) p\\left(w_{m n} \\mid z_{m n}, \\varphi\\right) \\] 其中 \\(\\mathbf{w}_m\\) 表示该文本中的单词序列, \\(\\mathbf{z}_m\\) 表示该文本的话题序列, \\(\\theta_m\\) 表示该文本的话 题分布参数。 LDA 模型的联合分布含有隐变量, 对隐变量进行积分得到边缘分布。 参数 \\(\\theta_m\\) 和 \\(\\varphi\\) 给定条件下第 \\(m\\) 个文本的生成概率是 \\[ p\\left(\\mathbf{w}_m \\mid \\theta_m, \\varphi\\right)=\\prod_{n=1}^{N_m}\\left[\\sum_{k=1}^K p\\left(z_{m n}=k \\mid \\theta_m\\right) p\\left(w_{m n} \\mid \\varphi_k\\right)\\right] \\] 超参数 \\(\\alpha\\) 和 \\(\\beta\\) 给定条件下第 \\(m\\) 个文本的生成概率是 \\[ p\\left(\\mathbf{w}_m \\mid \\alpha, \\beta\\right)=\\prod_{k=1}^K \\int p\\left(\\varphi_k \\mid \\beta\\right)\\left[\\int p\\left(\\theta_m \\mid \\alpha\\right) \\prod_{n=1}^{N_m}\\left[\\sum_{l=1}^K p\\left(z_{m n}=l \\mid \\theta_m\\right) p\\left(w_{m n} \\mid \\varphi_l\\right)\\right] \\mathrm{d} \\theta_m\\right] \\mathrm{d} \\varphi_k \\] 超参数 \\(\\alpha\\) 和 \\(\\beta\\) 给定条件下所有文本的生成概率是 \\[ p(\\mathbf{w} \\mid \\alpha, \\beta)=\\prod_{k=1}^K \\int p\\left(\\varphi_k \\mid \\beta\\right)\\left[\\prod_{m=1}^M \\int p\\left(\\theta_m \\mid \\alpha\\right) \\prod_{n=1}^{N_m}\\left[\\sum_{l=1}^K p\\left(z_{m n}=l \\mid \\theta_m\\right) p\\left(w_{m n} \\mid \\varphi_l\\right)\\right] \\mathrm{d} \\theta_m\\right] \\mathrm{d} \\varphi_k \\] ","date":"2022-06-16","objectID":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/:4:7","tags":["NLP","主题模型"],"title":"主题模型","uri":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"吉布斯抽样 基本思想 有三个主要目标： - 话题序列的集合\\(z=(z_1, z_2, \\cdots, z_M)\\)的后验概率分布，其中\\(z_m\\)是第m个文本的主题序列，\\(z_m=(z_{m1}, \\cdots, z_{mN_{m}})\\); - 参数\\(\\theta=(\\theta_1, \\cdots, \\theta_{M})\\)，其中\\(\\theta_m\\)是第m个文本的主题分布的参数； - 参数\\(\\varphi=(\\varphi_1, \\cdots, \\varphi_K)\\)，其中\\(\\varphi_k\\)是第k个主题的单词分布的参数。 对\\(p(\\mathbf{w}, \\mathbf{z}, \\theta, \\varphi \\mid \\alpha, \\beta)\\)进行估计 吉布斯抽样, 这是一种常用的马尔可夫链蒙特卡罗法。为了估计 多元随机变量 \\(x\\) 的联合分布 \\(p(x)\\), 吉布斯抽样法选择 \\(x\\) 的一个分量, 固定其他分量, 按照其条件概率分布进行随机抽样, 依次循环对每一个分量执行这个操作, 得到联合 分布 \\(p(x)\\) 的一个随机样本, 重复这个过程, 在燃烧期之后, 得到联合概率分布 \\(p(x)\\) 的 样本集合。 LDA 模型的学习通常采用收缩的吉布斯抽样 (collapsed Gibbs sampling) , 基本想法是, 通过对隐变量 \\(\\theta\\) 和 \\(\\varphi\\) 积分, 得到边缘概率分布 \\(p(\\mathbf{w}, \\mathbf{z} \\mid \\alpha, \\beta)\\) (也是联合分 布), 其中变量 \\(\\mathbf{w}\\) 是可观测的, 变量 \\(\\mathbf{z}\\) 是不可观测的; 对后验概率分布 \\(p(\\mathbf{z} \\mid \\mathbf{w}, \\alpha, \\beta)\\) 进 行吉布斯抽样, 得到分布 \\(p(\\mathbf{z} \\mid \\mathbf{w}, \\alpha, \\beta)\\) 的样本集合; 再利用这个样本集合对参数 \\(\\theta\\) 和 \\(\\varphi\\) 进行估计, 最终得到 LDA 模型 \\(p(\\mathbf{w}, \\mathbf{z}, \\theta, \\varphi \\mid \\alpha, \\beta)\\) 的所有参数估计。 #### 算法流程 输入: 文本的单词序列 \\(\\mathbf{w}=\\{\\mathbf{w}_1, \\cdots, \\mathbf{w}_m, \\cdots, \\mathbf{w}_M\\}, \\mathbf{w}_m=\\left(w_{m 1}, \\cdots, w_{m n}, \\cdots\\right.\\), \\(\\left.w_{m_{N_m}}\\right)\\); 输出: 文本的话题序列 \\(\\mathrm{z}=\\{\\mathbf{z}_1, \\cdots, \\mathbf{z}_m, \\cdots, \\mathbf{z}_M\\}, \\mathbf{z}_m=\\left(z_{m 1}, \\cdots, z_{m n}, \\cdots, z_{m_{N_m}}\\right)\\) 的后验概率分布 \\(p(\\mathbf{z} \\mid \\mathbf{w}, \\alpha, \\beta)\\) 的样本计数, 模型的参数 \\(\\varphi\\) 和 \\(\\theta\\) 的估计值; 参数: 超参数 \\(\\alpha\\) 和 \\(\\beta\\), 话题个数 \\(K\\) 。 设所有计数矩阵的元素 \\(n_{m k}, n_{k v}\\), 计数向量的元素 \\(n_m, n_k\\) 初值为 0 ; 对所有文本 \\(\\mathbf{w}_m, m=1,2, \\cdots, M\\) 对第 \\(m\\) 个文本中的所有单词 \\(w_{m n}, n=1,2, \\cdots, N_m\\) 抽样话题 \\(z_{m n}=z_k \\sim \\operatorname{Mult}\\left(\\frac{1}{K}\\right)\\);(对于文本m，其多项分布的参数为\\(\\frac{1}{K}\\)，由\\(\\alpha\\)生成，即\\(\\theta_m \\sim Dir(\\alpha)\\)，\\(\\theta_m\\)为长度为K的向量。) 增加文本-话题计数 \\(n_{m k}=n_{m k}+1\\), 增加文本-话题和计数 \\(n_m=n_m+1\\), 增加话题-单词计数 \\(n_{k v}=n_{k v}+1\\), 增加话题-单词和计数 \\(n_k=n_k+1\\); （3）循环执行以下操作, 直到进入燃烧期 对所有文本 \\(\\mathbf{w}_m, m=1,2, \\cdots, M\\) 对第 \\(m\\) 个文本中的所有单词 \\(w_{m n}, n=1,2, \\cdots, N_m\\) 当前的单词 \\(w_{m n}\\) 是第 \\(v\\) 个单词, 话题指派 \\(z_{m n}\\) 是第 \\(k\\) 个话题; 减少计数 \\(n_{m k}=n_{m k}-1, n_m=n_m-1, n_{k v}=n_{k v}-1, n_k=n_k-1\\); 按照满条件分布进行抽样 \\[ p\\left(z_i \\mid \\mathbf{z}_{-i}, \\mathbf{w}, \\alpha, \\beta\\right) \\propto \\frac{n_{k v}+\\beta_v}{\\sum_{v=1}^V\\left(n_{k v}+\\beta_v\\right)} \\cdot \\frac{n_{m k}+\\alpha_k}{\\sum_{k=1}^K\\left(n_{m k}+\\alpha_k\\right)} \\] 得到新的第 \\(k^{\\prime}\\) 个话题, 分配给 \\(z_{m n}\\); 增加计数 \\(n_{m k^{\\prime}}=n_{m k^{\\prime}}+1, n_m=n_m+1, n_{k^{\\prime} v}=n_{k^{\\prime} v}+1, n_{k^{\\prime}}=n_{k^{\\prime}}+1\\); 得到更新的两个计数矩阵 \\(N_{K \\times V}=\\left[n_{k v}\\right]\\) 和 \\(N_{M \\times K}=\\left[n_{m k}\\right]\\), 表示后验 概率分布 \\(p(\\mathbf{z} \\mid \\mathbf{w}, \\alpha, \\beta)\\) 的样本计数; 利用得到的样本计数, 计算模型参数 \\[ \\begin{aligned} \\theta_{m k} \u0026=\\frac{n_{m k}+\\alpha_k}{\\sum_{k=1}^K\\left(n_{m k}+\\alpha_k\\right)} \\\\\\\\ \\varphi_{k v} \u0026=\\frac{n_{k v}+\\beta_v}{\\sum_{v=1}^V\\left(n_{k v}+\\beta_v\\right)} \\end{aligned} \\] ","date":"2022-06-16","objectID":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/:4:8","tags":["NLP","主题模型"],"title":"主题模型","uri":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"训练与推断 有了LDA模型，我们的目标有两个： 估计模型中的参数\\(\\varphi_1, \\cdots, \\varphi_K\\)和\\(\\theta_1, \\cdots, \\theta_M\\); 对于新来的一篇doc，我们能够计算这篇文档的topic分布\\(\\theta_{new}\\)。 有了吉布斯采样公式就可以基于语料训练LDA模型，并应用训练得到的模型对新的文档进行topic语义分析，训练的过程就是通过Gibbs Samping获取语料中的（z,w）样本，而模型中的所有参数可以基于采样的样本进行估计。 训练流程如下： 随机初始化：对语料中的每篇文档的每个词w，随机赋一个topic编号z。 重新扫描语料库，对每个词按照吉布斯采样公式重新采样它的topic，在语料中进行更新。 重复以上语料库的重新采样过程直到吉布斯采样收敛。 统计语料库的topic-word共现频率矩阵，就是LDA的模型 由这个矩阵我们可以计算每一个\\(p(word\\mid topic)\\)概率，从而计算出模型参数\\(\\varphi_1, \\cdots, \\varphi_K\\)，也可以计算另一个参数\\(\\theta_1, \\cdots, \\theta_M\\)，只要在吉布斯抽样收敛后统计每篇文章的topic频率分布，就可以计算每一个\\(p(topic\\mid doc)\\)概率，由于它是和训练语料的每篇文章相关的，对于我们理解新的文档毫无用处，所以一般没有必要保留这个概率。 如何对新的文档进行推断呢？其实和训练过程完全相似，对于新的文档，认为\\(\\varphi_{kt}\\)是稳定不变的，是由训练语料得到的模型提供的。采样过程只估计该文档的topic分布\\(\\theta_{new}\\)就好了。 推断过程如下： 随机初始化：对当前文档的每个词w，随机的赋一个topic编号z； 重新扫描当前文档，按照吉布斯抽样公式，对每个词w，重新采样它的topic； 重复以上过程直到吉布斯采样收敛 统计文档中的topic分布，该分布就是\\(\\theta_{new}\\) ","date":"2022-06-16","objectID":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/:4:9","tags":["NLP","主题模型"],"title":"主题模型","uri":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"代码 实现了吉布斯推断的python代码： \"\"\" LDA implementation in Python @author: Michael Zhang \"\"\" import matplotlib.pyplot as plt import numpy as np import scipy class LDA(object): def __init__(self, tdm, T, alpha = 1., beta=1., iteration=100): \"\"\" tdm: the copus, of (D, Num_words_in_corpus), the value of each entry is the counts of corresponding words in this the corresponding document. e.g. tdm[d, w] = number of word w appears in document d. T: the number of topics \"\"\" self.tdm = tdm self.D, self.W = self.tdm.shape self.alpha= alpha # count for expected value for hyper parameter alpha of theta, i.e. document-topic distribution. self.beta = beta # count for expected value for hyper parameter beta topic-word distribution. self.T = T self.iteration = iteration # z must take in (d,w,i) as input, corresponding to # topic indicator for i-th obserevation of word w in doc d self.z = {} self.topic_word_matrix = np.zeros((self.T, self.W)) # initialize the topic-word matrix. self.doc_topic_matrix = np.zeros((self.D, self.T)) # initialize the documnet-topic matrix. self.topic_counts = np.zeros(self.T) # initialize the topic counter for after sampling process, should be sum of value in self.topic_word_matrix self.doc_counts = np.zeros(self.D) # initialize the doc counter for after sampling process, should be sum of value in self.doc_topic_matrix self.log_likelihood = np.zeros(self.iteration) # store the value of log likelihood at each iteration self._init_matrix() # @pysnooper.snoop('init.log') def _init_matrix(self): \"\"\" for all words 1. sample a topic randomly from T topics for each word 2. increment topic word count, self.topic_word_matrix 3. increment document topic count, self.doc_topic_matrix 4. update the topic indicator z. \"\"\" for d in range(self.D): doc = scipy.sparse.coo_matrix(self.tdm[d]) word_freq_topic = zip(doc.col, doc.data) for w, frequency in word_freq_topic: # (word, freq) for i in range(frequency): ############ Finish the following initialization steps ############# # 1. sample a topic randomly from T topics for each word topic = np.random.randint(self.T) # 2. increment topic word count, self.topic_word_matrix self.topic_word_matrix[topic, w] += 1 # 3. increment document topic count, self.doc_topic_matrix self.doc_topic_matrix[d, topic] += 1 # 4. update the topic indicator z. self.z[(d, w, i)] = topic # d: document ID; w: word ID: i: instance ID，即在d中第几个w self.topic_counts = self.topic_word_matrix.sum(axis=1) self.doc_counts = self.doc_topic_matrix.sum(axis=1) # @pysnooper.snoop('fit.log') def fit(self): for it in range(self.iteration): # iterate over all the documents for d in range(self.D): # iterate over all the words in d for w in self.tdm[d].indices: # iterate over number of times observed word w in doc d for i in range(self.tdm[d, w]): # we apply the hidden-varible method of Gibbs sampler, the hidden variable is z[(d,w,i)] self.doc_topic_matrix[d,self.z[(d,w,i)]] -= 1 self.doc_counts[d] -= 1 self.topic_word_matrix[self.z[(d,w,i)],w] -= 1 self.topic_counts[self.z[(d,w,i)]] -= 1 # estimation of phi and theta for the current corpus phi_hat = (self.topic_word_matrix[:,w] + self.beta) / (self.topic_counts + self.beta * self.W) theta_hat = (self.doc_topic_matrix[d,:] + self.alpha) / (self.doc_counts[d] + self.alpha * self.T) # calculate the full conditional distribution full_conditional = phi_hat * theta_hat # normalize full_conditional such that it summation equals to 1. full_conditional = full_conditional / full_conditional.sum() # sample a topic for i-th obserevation of word w in doc d based on full_conditional new_topic = np.random.multinomial(1, full_conditional).argmax() # update z, doc_topic_matrix, doc_counts, topic_word_matrix, topic_counts here. self.z[(d,w,i)] = new_topic self.doc_topic_matrix[d,self.z[(d,w,i)]] += 1 self.topic_word_matrix[self.z[(d,w,i)],w] += 1 self.doc_counts[d] += 1 self.topic_counts[self.z[(d,w,i)]] += 1 ############################################################ # Equation 2 log P(w|z) for each itera","date":"2022-06-16","objectID":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/:4:10","tags":["NLP","主题模型"],"title":"主题模型","uri":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"本质与使用条件 本质上说，主题模型根本上是实现文本数据的结构化，结构化的文档可以彼此比较和查询，实现传统的任务。 LDA主题模型本质上解决了两类问题： - 文档聚类 - 词汇聚类 主要价值在于： 1）文档的结构化，相比于传统的词袋模型达到了降维的效果 2）完成了文档的聚类和词汇的聚类，实现文本信息的抽象化分析，帮助分析者探索隐含的语义内容。 实践中数据要有以下性质才会有较好的结果： 文档足够多 文档足够长 词汇特征够多 词频足够大 ","date":"2022-06-16","objectID":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/:4:11","tags":["NLP","主题模型"],"title":"主题模型","uri":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"总结 历时好几周，终于完结了主题模型，主要是概率论没有学好，跟着推导的过程过于痛苦，不过也算是稍微理解了一点LDA，复述一下： LDA理解可以类比于PLSA，大体的思想都是根据文档生成主题分布，再根据主题分布和单词分布得到文档中的各个单词。不同的是LDA是贝叶斯派的思想，对于两种分布加入了狄利克雷先验概率。LDA的生成过程可以看成上帝掷骰子，从M个骰子中选取一个作为文本m的主题分布，从K个骰子中选取一个作为主题k的单词分布，（注意这里的多项分布的参数就是多项分布中的概率p，其服从狄利克雷分布，比如对于\\(\\theta_m\\)，它其实就是文本m生成不同主题k的概率\\(p(z\\mid d_m)\\)，是个K维的向量。对于\\(\\varphi_k\\)，是由主题k生成不同单词v的概率\\(p(w\\mid z_k)\\)，是个V维的向量。也就是根据狄利克雷分布采样得到的是一些概率，这些概率也是我们最终要求的参数，这些概率作为多项分布的参数再采样生成主题或者单词，还有就是\\(p(z_k\\mid d_m)\\)与\\(z_{mn}\\)的理解，前者就是相当于\\(\\theta_{mk}\\)，后者肯定是主题集合中的一个，不过是根据参数为\\(\\theta_m\\)的多项分布在位置n采样得到的。这就是LDA的整个的理解，当然模型的求解是使用吉布斯抽样的方法，与上面写的步骤不同。写这些是便于理解）。 由主题分布可以对文本的每个位置赋值一个主题，再根据主题-单词分布可以生成整个文本。一切的一切都是和PLSA一样，求两个分布，以至于可以生成我们的文档。LDA也可以得到文档的主题分布，得到了主题分布和单词分布可以应用于各种任务当中。具体可以参考《LDA漫游指南》。 现在知道了LDA是怎么一回事了，但还是感觉模模糊糊的，感觉如“通俗理解LDA主题模型”这篇文章开头所说的那样陷入了LDA的细枝末节中，所以写了一些主题，加深自己的印象与理解，经过代码的洗礼，又理解深入了一些，但感觉还没有掌握的很好，可能需要消化消化，那就先告一段落了。以后常看看就行。 ## 参考 https://zhuanlan.zhihu.com/p/374924140 https://www.cnblogs.com/gasongjian/p/7631978.html ","date":"2022-06-16","objectID":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/:5:0","tags":["NLP","主题模型"],"title":"主题模型","uri":"/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"Transformer \\[ -\\log \\frac{\\exp({\\operatorname{sim}\\left(\\mathbf{h}_i, \\mathbf{h}_i^{+}\\right) / \\tau})}{\\sum_{j=1}^N\\left(\\exp({\\operatorname{sim}\\left(\\mathbf{h}_i, \\mathbf{h}_j^{+}\\right) / \\tau})+\\exp({\\operatorname{sim}\\left(\\mathbf{h}_i, \\mathbf{h}_j^{-}\\right) / \\tau}\\right))} \\] ","date":"2022-06-08","objectID":"/transformer/:0:0","tags":["NLP","Transformer"],"title":"Transformer","uri":"/transformer/"},{"categories":["NLP"],"content":"背景 先从word2vec开始说起，word2vec可以看作是一个预训练模型，但是它有个问题就是它没有办法解决一词多义的问题，比如说bank这个词语，有银行的意思，但在某些语义下，它也有河岸的意思，但对于word2vec来说，它区别不了这两种含义，因为它们尽管上下文环境中出现的单词不同，但是在用语言模型训练的时候，不论什么上下文的句子经过word2vec，都是预测相同的单词bank，而同一个单词占的是同一行的参数空间，这导致两种不同的上下文信息都会编码到相同的word embedding空间里去。 而ELMo就解决了这个问题，它使用了双向的LSTM，具体的可以看ELMo,总之使用RNN作为特征提取器，解决了多义词的问题，但现在来看，RNN的特征提取的能力是远不如本文的Transformer的，为什么要介绍这些东西呢，这就是原因，Transformer出现后，取代了RNN和CNN的地位，成为了最流行的特征提取器，大火的GPT和BERT都与Transformer离不开关系。拿bank为例，RNN在读取整个句子之前不会理解bank的含义，也就是RNN的并行能力比较差，而在Transformer中，token之间会互相交互，也就是所谓的自注意力机制，直观地说，Transformer 的编码器可以被认为是一系列推理步骤（层）。在每一步中，token都会互相看着对方（这是我们需要注意的地方——self-attention），交换信息并尝试在整个句子的上下文中更好地理解对方。这发生在几个层（例如，6 个）中。 在每个解码器层中，前缀标记也通过自注意力机制相互交互。 下面就详细介绍一下。 ","date":"2022-06-08","objectID":"/transformer/:1:0","tags":["NLP","Transformer"],"title":"Transformer","uri":"/transformer/"},{"categories":["NLP"],"content":"self-attention 首先介绍一下最主要的self-attention，可以说是self-attention实现了上述的token之间交互的功能。 自注意力是模型的关键组成部分之一。注意 和自注意之间的区别在于，自注意在相同性质的表示之间运行：例如，某个层中的所有编码器状态。 形式上，这种直觉是通过查询键值注意来实现的。self-attention 中的每个输入标记都会收到三种表示，对应于它可以扮演的角色： query key value 进入正题： 作为我们想要翻译的输入语句“The animal didn’t cross the street because it was too tired”。句子中”it”指的是什么呢？“it”指的是”street” 还是“animal”？对人来说很简单的问题，但是对算法而言并不简单。 当模型处理单词“it”时，self-attention允许将“it”和“animal”联系起来。当模型处理每个位置的词时，self-attention允许模型看到句子的其他位置信息作辅助线索来更好地编码当前词。如果你对RNN熟悉，就能想到RNN的隐状态是如何允许之前的词向量来解释合成当前词的解释向量。Transformer使用self-attention来将相关词的理解编码到当前词中。 下面看一下self-attention是如何计算的： ","date":"2022-06-08","objectID":"/transformer/:2:0","tags":["NLP","Transformer"],"title":"Transformer","uri":"/transformer/"},{"categories":["NLP"],"content":"向量计算 第一步，根据编码器的输入向量，生成三个向量，比如，对每个词向量，生成query-vec, key-vec, value-vec，生成方法为分别乘以三个矩阵，这些矩阵在训练过程中需要学习。【注意：不是每个词向量独享3个matrix，而是所有输入共享3个转换矩阵；权重矩阵是基于输入位置的转换矩阵；有个可以尝试的点，如果每个词独享一个转换矩阵，会不会效果更厉害呢？】 注意到这些新向量的维度比输入词向量的维度要小（512–\u003e64），并不是必须要小的，是为了让多头attention的计算更稳定。 第二步，计算attention就是计算一个分值。对“Thinking Matchines”这句话，对“Thinking”（pos#1）计算attention 分值。我们需要计算每个词与“Thinking”的评估分，这个分决定着编码“Thinking”时（某个固定位置时），每个输入词需要集中多少关注度。 这个分，通过“Thing”对应query-vector与所有词的key-vec依次做点积得到。所以当我们处理位置#1时，第一个分值是q1和k1的点积，第二个分值是q1和k2的点积。这也就是所谓的注意力得分. 第三步和第四步，除以8(\\(=\\sqrt{dim_{key}}\\))，这样梯度会更稳定。然后加上softmax操作，归一化分值使得全为正数且加和为1。 softmax分值决定着在这个位置，每个词的表达程度（关注度）。很明显，这个位置的词应该有最高的归一化分数，但大部分时候总是有助于关注该词的相关的词。 第五步，将softmax分值与value-vec按位相乘。保留关注词的value值，削弱非相关词的value值。 第六步，将所有加权向量加和，产生该位置的self-attention的输出结果。 上述就是self-attention的计算过程，生成的向量流入前向网络。在实际应用中，上述计算是以速度更快的矩阵形式进行的。下面我们看下在单词级别的矩阵计算。 ","date":"2022-06-08","objectID":"/transformer/:2:1","tags":["NLP","Transformer"],"title":"Transformer","uri":"/transformer/"},{"categories":["NLP"],"content":"矩阵计算 第一步，计算query/key/value matrix，将所有输入词向量合并成输入矩阵\\(X\\)，并且将其分别乘以权重矩阵\\(W^q, W^k,W^v\\) 最后，鉴于我们使用矩阵处理，将步骤2~6合并成一个计算self-attention层输出的公式。 ","date":"2022-06-08","objectID":"/transformer/:2:2","tags":["NLP","Transformer"],"title":"Transformer","uri":"/transformer/"},{"categories":["NLP"],"content":"多头注意力机制 论文进一步增加了multi-headed的机制到self-attention上，在如下两个方面提高了attention层的效果： 多头机制扩展了模型集中于不同位置的能力。在上面的例子中，z1只包含了其他词的很少信息，仅由实际自己词决定。在其他情况下，比如翻译 “The animal didn’t cross the street because it was too tired”时，我们想知道单词”it”指的是什么。 多头机制赋予attention多种子表达方式。像下面的例子所示，在多头下有多组query/key/value-matrix，而非仅仅一组（论文中使用8-heads）。每一组都是随机初始化，经过训练之后，输入向量可以被映射到不同的子表达空间中。 如果我们计算multi-headed self-attention的，分别有八组不同的Q/K/V matrix，我们得到八个不同的矩阵。 这会带来点麻烦，前向网络并不能接收八个矩阵，而是希望输入是一个矩阵，所以要有种方式处理下八个矩阵合并成一个矩阵。 上述就是多头自注意机制的内容，我认为还仅是一部分矩阵，下面尝试着将它们放到一个图上可视化如下。 #### 代码 下面实现一下多头注意力机制，在原论文中，实现的方法如下： 也就是对每个W进行多头的设置，即为原维度/head，然后拼接后，再经过\\(hd_v\\times d_{model}\\)的转换又得到原来的维度，代码的实现不太一样，代码是W还是\\(d_{model}\\times d_{model}\\)的矩阵然后得到q,k,v之后再进行截断，实现如下。 class MultiHeadedAttention(nn.Module): def __init__(self, h, d_model, dropout=0.1) -\u003e None: # h为head，这里为8，d_model为embedding的维度，这里为512 super().__init__() assert d_model % h == 0 self.d_k = d_model // h # 64 self.h = h self.Q_Linear = nn.Linear(d_model, d_model) self.K_Linear = nn.Linear(d_model, d_model) self.V_Linear = nn.Linear(d_model, d_model) self.res_Linear = nn.Linear(d_model, d_model) self.attn = None self.dropout = nn.Dropout(p=dropout) def forward(self, query, key, value, mask=None): if mask is not None: mask = mask.unsqueeze(1) batch_size = query.size(0) query = self.Q_Linear(query).view(batch_size, -1, self.h, self.d_k) # (batch_size, seq_len, h, d_k)即(batch_size, seq_len, 8, 64) query = query.transpose(1, 2) # (batch_size, h, seq_len, d_k)即(batch_size, 8, seq_len, 64) key = self.K_Linear(key).view(batch_size, -1, self.h, self.d_k).transpose(1, 2) value = self.V_Linear(value).view(batch_size, -1, self.h, self.d_k).transpose(1, 2) x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout) # x为(batch_size, h, seq_len, d_k) # attn为(batch_size, h, seq_len1, seq_len2) x = x.transpose(1, 2).contiguous().view(batch_size, -1, self.h * self.d_k) # (batch_size, h, seq_len, d_k) -\u003e (batch_size, seq_len, h, d_k) -\u003e (batch_size, seq_len, h * d_k) = (batch_size, seq_len, 512) return self.res_Linear(x) ","date":"2022-06-08","objectID":"/transformer/:2:3","tags":["NLP","Transformer"],"title":"Transformer","uri":"/transformer/"},{"categories":["NLP"],"content":"Masked self-attention 在训练的时候，主要是消除后面的信息对预测的影响，因为decoder输入的是整个句子，也就是我们所谓的参考答案，而实际预测的时候就是预测后面的token，用不到后面的token，如果不mask掉，当前的token将看到“未来”，这不是我们想要的，因此必须要mask掉。 其实decoder里的sequence mask与encoder里的padding mask异曲同工，padding mask其实很简单，就是为了使句子长度一致进行了padding，而为了避免关注padding的位置，进行了mask，具体的做法就是将这些位置的值变成负无穷，这样softmax之后就接近于0了。 而sequence mask思想也差不多： 假设现在解码器的输入”\u003c s \u003e who am i \u003c e \u003e“在分别乘上一个矩阵进行线性变换后得到了Q、K、V，且Q与K作用后得到了注意力权重矩阵（此时还未进行softmax操作），如图17所示。 此时已经计算得到了注意力权重矩阵。由第1行的权重向量可知，在解码第1个时刻时应该将20%（严格来说应该是经过softmax后的值）的注意力放到’\u003c s \u003e’上，30%的注意力放到’who’上等等。不过此时有一个问题就是，模型在实际的预测过程中只是将当前时刻之前（包括当前时刻）的所有时刻作为输入来预测下一个时刻，也就是说模型在预测时是看不到当前时刻之后的信息。因此，Transformer中的Decoder通过加入注意力掩码机制来解决了这一问题。 当然还要进行softmax等计算。 在网上查了很多资料，说法都很不一样，不过我更倾向于这样的看法。而在预测的时候是用前面的输出结果作为输入的。 几张图帮助理解： 后面还有padding mask，所有的self attention都要用这个，因为pad的位置没有任何意义。 实践一下加深理解： 首先我们来定义模型： # 词典数为10， 词向量维度为8 embedding = nn.Embedding(10, 8) # 定义Transformer，注意一定要改成eval模型，否则每次输出结果不一样 transformer = nn.Transformer(d_model=8, batch_first=True).eval() 接下来定义我们的src和tgt： # Encoder的输入 src = torch.LongTensor([[0, 1, 2, 3, 4]]) # Decoder的输入 tgt = torch.LongTensor([[4, 3, 2, 1, 0]]) 然后我们将[4]送给Transformer进行预测，模拟推理时的第一步： transformer(embedding(src), embedding(tgt[:, :1]), # 这个就是用来生成阶梯式的mask的 tgt_mask=nn.Transformer.generate_square_subsequent_mask(1)) tensor([[[ 1.4053, -0.4680, 0.8110, 0.1218, 0.9668, -1.4539, -1.4427, 0.0598]]], grad_fn=\u003cNativeLayerNormBackward0\u003e) 然后我们将[4, 3]送给Transformer，模拟推理时的第二步： transformer(embedding(src), embedding(tgt[:, :2]), tgt_mask=nn.Transformer.generate_square_subsequent_mask(2)) tensor([[[ 1.4053, -0.4680, 0.8110, 0.1218, 0.9668, -1.4539, -1.4427, 0.0598], [ 1.2726, -0.3516, 0.6584, 0.3297, 1.1161, -1.4204, -1.5652, -0.0396]]], grad_fn=\u003cNativeLayerNormBackward0\u003e) 出的第一个向量和上面那个一模一样。 最后我们再将tgt一次性送给transformer，模拟训练过程： transformer(embedding(src), embedding(tgt), tgt_mask=nn.Transformer.generate_square_subsequent_mask(5)) tensor([[[ 1.4053, -0.4680, 0.8110, 0.1218, 0.9668, -1.4539, -1.4427, 0.0598], [ 1.2726, -0.3516, 0.6584, 0.3297, 1.1161, -1.4204, -1.5652, -0.0396], [ 1.4799, -0.3575, 0.8310, 0.1642, 0.8811, -1.3140, -1.5643, -0.1204], [ 1.4359, -0.6524, 0.8377, 0.1742, 1.0521, -1.3222, -1.3799, -0.1454], [ 1.3465, -0.3771, 0.9107, 0.1636, 0.8627, -1.5061, -1.4732, 0.0729]]], grad_fn=\u003cNativeLayerNormBackward0\u003e) 可以看到使用mask后就可以保证前面的结果都是不变的，不然如果没有mask则计算attention时因为计算注意力变化所以结果都会变化，这就是Mask self-attention的意义。 到这里self-attention就介绍完了 ","date":"2022-06-08","objectID":"/transformer/:2:4","tags":["NLP","Transformer"],"title":"Transformer","uri":"/transformer/"},{"categories":["NLP"],"content":"代码 def attention(query, key, value, mask=None, dropout=None): d_k = query.size(-1) scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k) # 最后两个维度相乘，即为scores，再scale一下。 if mask is not None: scores = scores.masked_fill(mask == 0, -1e9) # 将mask的位置的scores置为-1e9 # 实际上pad mask的时候，pad也会作为key与其它token对应的k,v计算score，pad mask只是消除pad作为k,v时候的影响。但在最后softmax的时候，将pad的损失值全部置为0 p_attn = F.softmax(scores, dim=-1) # 将scores进行softmax，得到p_attn，这里是在最后一个维度上softmax，因为对每个query的所有key进行softmax if dropout: p_attn = dropout(p_attn) return torch.matmul(p_attn, value), p_attn class MultiHeadedAttention(nn.Module): def __init__(self, h, d_model, dropout=0.1) -\u003e None: # h为head，这里为8，d_model为embedding的维度，这里为512 super().__init__() assert d_model % h == 0 self.d_k = d_model // h # 64 self.h = h self.Q_Linear = nn.Linear(d_model, d_model) self.K_Linear = nn.Linear(d_model, d_model) self.V_Linear = nn.Linear(d_model, d_model) self.res_Linear = nn.Linear(d_model, d_model) self.attn = None self.dropout = nn.Dropout(p=dropout) def forward(self, query, key, value, mask=None): if mask is not None: mask = mask.unsqueeze(1) batch_size = query.size(0) query = self.Q_Linear(query).view(batch_size, -1, self.h, self.d_k) # (batch_size, seq_len, h, d_k)即(batch_size, seq_len, 8, 64) query = query.transpose(1, 2) # (batch_size, h, seq_len, d_k)即(batch_size, 8, seq_len, 64) key = self.K_Linear(key).view(batch_size, -1, self.h, self.d_k).transpose(1, 2) value = self.V_Linear(value).view(batch_size, -1, self.h, self.d_k).transpose(1, 2) x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout) # x为(batch_size, h, seq_len, d_k) # attn为(batch_size, h, seq_len1, seq_len2) x = x.transpose(1, 2).contiguous().view(batch_size, -1, self.h * self.d_k) # (batch_size, h, seq_len, d_k) -\u003e (batch_size, seq_len, h, d_k) -\u003e (batch_size, seq_len, h * d_k) = (batch_size, seq_len, 512) return self.res_Linear(x) ","date":"2022-06-08","objectID":"/transformer/:2:5","tags":["NLP","Transformer"],"title":"Transformer","uri":"/transformer/"},{"categories":["NLP"],"content":"模型架构 下面是原始论文中的架构： self-attention上面已经讲的比较详细了，下面说一下其余的部分。 ","date":"2022-06-08","objectID":"/transformer/:3:0","tags":["NLP","Transformer"],"title":"Transformer","uri":"/transformer/"},{"categories":["NLP"],"content":"FFN(前馈网络) 除了注意力以外，每一层都有一个前馈网络：两个线性层之间具有ReLU非线性： \\[ FFN(x) = max(0, xW_1+b_1)W_2+b_2 \\] 在通过注意力机制查看其他令牌之后，模型使用 FFN 块来处理这些新信息。 class PositionwiseFeedForward(nn.Module): def __init__(self, d_model, d_ff, dropout=0.1): super().__init__() self.w_1 = nn.Linear(d_model, d_ff) self.w_2 = nn.Linear(d_ff, d_model) self.dropout = nn.Dropout(p=dropout) def forward(self, x): return self.w_2(self.dropout(F.relu(self.w_1(x)))) ","date":"2022-06-08","objectID":"/transformer/:3:1","tags":["NLP","Transformer"],"title":"Transformer","uri":"/transformer/"},{"categories":["NLP"],"content":"残差连接 残差连接非常简单（将块的输入添加到其输出），但同时也非常有用：它们缓解了通过网络的梯度流并允许堆叠很多层。解决了网络退化的问题。 在 Transformer 中，在每个注意力和 FFN 块之后使用残差连接。在上图中，残差显示为围绕一个块到黄色 “Add \u0026 Norm”层的箭头。在“Add \u0026 Norm”部分， “Add”部分代表残差连接。 ","date":"2022-06-08","objectID":"/transformer/:3:2","tags":["NLP","Transformer"],"title":"Transformer","uri":"/transformer/"},{"categories":["NLP"],"content":"Layer Norm “Add \u0026 Norm”层中的“Norm”部分 表示 Layer Normalization。它批量独立地标准化每个示例的向量表示 - 这样做是为了控制“流”到下一层。层归一化提高了收敛稳定性，有时甚至提高了质量。 这里的scale和bias都是可以训练的参数。 注意Layer Norm与Batch Norm是不同的，这里引用一下沐神的视频： 这是Batch Norm的切法，即对每个特征进行norm。 这是Layer norm的切法，即对每个样本进行norm。 为什么用layer norm而不用Batch norm呢？ 当你的样本长度变化比较大的时候，使用batch norm计算的均值和方差波动比较大，而且batch norm需要记录全局的均值和方差，当遇到新的测试样本的时候，由于长度的原因，之前的均值方差可能就效果不太好了。 但是如果使用layer norm 的话就没有那么多的问题，因为它是每个样本自己计算均值方差，不需要存在一个全局的均值方差，所以会稳定一点。 class LayerNorm(nn.Module): def __init__(self, features, eps=1e-6) -\u003e None: super().__init__() self.a_2 = nn.Parameter(torch.ones(features)) self.b_2 = nn.Parameter(torch.zeros(features)) self.eps = eps def forward(self, x): mean = x.mean(-1, keepdim=True) std = x.std(-1, keepdim=True) return self.a_2 * (x - mean) / (std + self.eps) + self.b_2 class SublayerConnection(nn.Module): def __init__(self, size, dropout) -\u003e None: super().__init__() self.norm = LayerNorm(size) self.dropout = nn.Dropout(p=dropout) def forward(self, x, sublayer): return x + self.dropout(sublayer(self.norm(x))) # 这里和论文不同，先norm再扔给sublayer（比如多头注意力、ffd）,理论上是self.norm(x+self.dropout(sublayer(x))) ","date":"2022-06-08","objectID":"/transformer/:3:3","tags":["NLP","Transformer"],"title":"Transformer","uri":"/transformer/"},{"categories":["NLP"],"content":"位置编码(position encoding) (Position Embedding是学习式，而Position Encoding为固定式) 请注意，由于 Transformer 不包含递归或卷积，它不知道输入标记(token)的顺序。因此，我们必须让模型明确地知道标记的位置。为此，我们有两组嵌入：用于标记（我们总是这样做）和用于位置（该模型所需的新嵌入）。那么令牌的输入表示是两个嵌入的总和：令牌和位置。 位置嵌入是可以学习的，但作者发现固定的嵌入不会影响质量。Transformer 中使用的固定位置编码是： \\[ PE_{pos,2i} = sin(\\frac{pos}{10000^{\\frac{2i}{d_{model}}}}) \\] \\[ PE_{pos,2i+1} = cos(\\frac{pos}{10000^{\\frac{2i}{d_{model}}}}) \\] 可以看到，每个词的维度都是512维，假设句子长度为10，则位置编码的计算如上图所示。 得到位置编码后，将位置编码与词嵌入简单相加即可。 #### 代码 class PositionalEncoding(nn.Module): def __init__(self, d_model, dropout, max_len=5000) -\u003e None: super().__init__() self.dropout = nn.Dropout(p=dropout) position_embedding = torch.zeros(max_len, d_model) position = torch.arange(0, max_len).unsqueeze(1) div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)) position_embedding[:, 0::2] = torch.sin(position * div_term) position_embedding[:, 1::2] = torch.cos(position * div_term) position_embedding = position_embedding.unsqueeze(0) # 增加一维预留batch size的位置，所以后面forward要在第二维上选取序列长度 self.register_buffer('PositionalEncoding', position_embedding) def forward(self, x): return self.dropout(x + Variable(self.PositionalEncoding[:, :x.size(1)], requires_grad=False)) 这里为了计算做了转换。 ### Padding Mask 对于输入序列一般我们都要进行padding补齐，也就是说设定一个统一长度N，在较短的序列后面填充0到长度为N。对于那些补零的数据来说，我们的attention机制不应该把注意力放在这些位置上，所以我们需要进行一些处理。具体的做法是，把这些位置的值加上一个非常大的负数(负无穷)，这样经过softmax后，这些位置的权重就会接近0。Transformer的padding mask实际上是一个张量，每个值都是一个Boolean，值为false的地方就是要进行处理的地方。 ","date":"2022-06-08","objectID":"/transformer/:3:4","tags":["NLP","Transformer"],"title":"Transformer","uri":"/transformer/"},{"categories":["NLP"],"content":"label smoothing(标签平滑) 神经网络会促使自身往正确标签和错误标签差值最大的方向学习，在训练数据较少，不足以表征所有的样本特征的情况下，会导致网络过拟合。 label smoothing可以解决上述问题，这是一种正则化策略，主要是通过soft one-hot来加入噪声，减少了真实样本标签的类别在计算损失函数时的权重，最终起到抑制过拟合的效果。 增加label smoothing后真实的概率分布有如下改变： 代码 class LabelSmoothing(nn.Module): # [标签平滑](../Deep%20Learning/训练trick/标签平滑.md)损失函数 def __init__(self, size, padding_idx, smoothing=0.0) -\u003e None: super().__init__() self.criterion = nn.KLDivLoss(size_average=False) self.padding_idx = padding_idx self.confidence = 1.0 - smoothing self.smoothing = smoothing self.size = size self.true_dist = None def forward(self, x, target): # x的shape为(batch.size * seq.len, target.vocab.size) # y的shape是(batch.size * seq.len) # x=logits，(seq.len, target.vocab.size) # 每一行，代表一个位置的词 # 类似于：假设seq.len=3, target.vocab.size=5 # x中保存的是log(prob) #x = tensor([[-20.7233, -1.6094, -0.3567, -2.3026, -20.7233], #[-20.7233, -1.6094, -0.3567, -2.3026, -20.7233], #[-20.7233, -1.6094, -0.3567, -2.3026, -20.7233]]) # target 类似于： # target = tensor([2, 1, 0])，torch.size=(3) assert x.size(1) == self.size true_dist = x.data.clone() # true_dist = tensor([[-20.7233, -1.6094, -0.3567, -2.3026, -20.7233], #[-20.7233, -1.6094, -0.3567, -2.3026, -20.7233], #[-20.7233, -1.6094, -0.3567, -2.3026, -20.7233]]) true_dist.fill_(self.smoothing / (self.size - 2)) # true_dist = tensor([[0.1333, 0.1333, 0.1333, 0.1333, 0.1333], #[0.1333, 0.1333, 0.1333, 0.1333, 0.1333], #[0.1333, 0.1333, 0.1333, 0.1333, 0.1333]]) # 注意，这里分母target.vocab.size-2是因为 # (1) 最优值 0.6要占一个位置； # (2) 填充词 \u003cblank\u003e 要被排除在外 # 所以被激活的目标语言词表大小就是self.size-2 true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence) # target.data.unsqueeze(1) -\u003e # tensor([[2], #[1], #[0]]); shape=torch.Size([3, 1]) # self.confidence = 0.6 # 根据target.data的指示，按照列优先(1)的原则，把0.6这个值 # 填入true_dist: 因为target.data是2,1,0的内容， # 所以，0.6填入第0行的第2列（列号，行号都是0开始） # 0.6填入第1行的第1列 # 0.6填入第2行的第0列： # true_dist = tensor([[0.1333, 0.1333, 0.6000, 0.1333, 0.1333], #[0.1333, 0.6000, 0.1333, 0.1333, 0.1333], #[0.6000, 0.1333, 0.1333, 0.1333, 0.1333]]) true_dist[:, self.padding_idx] = 0 # true_dist = tensor([[0.0000, 0.1333, 0.6000, 0.1333, 0.1333], #[0.0000, 0.6000, 0.1333, 0.1333, 0.1333], #[0.0000, 0.1333, 0.1333, 0.1333, 0.1333]]) # 设置true_dist这个tensor的第一列的值全为0 # 因为这个是填充词'\u003cblank\u003e'所在的id位置，不应该计入 # 目标词表。需要注意的是，true_dist的每一列，代表目标语言词表 #中的一个词的id mask = torch.nonzero(target.data == self.padding_idx) # mask = tensor([[2]]), 也就是说，最后一个词 2,1,0中的0， # 因为是'\u003cblank\u003e'的id，所以通过上面的一步，把他们找出来 # 如果不加上nonzero，那么mask的shape就是torch.Size([3]) if mask.dim() \u003e 0: true_dist.index_fill_(0, mask.squeeze(), 0.0) # 当target reference序列中有0这个'\u003cblank\u003e'的时候，则需要把 # 这一行的值都清空。 # 在一个batch里面的时候，可能两个序列长度不一，所以短的序列需要 # pad '\u003cblank\u003e'来填充，所以会出现类似于(2,1,0)这样的情况 # true_dist = tensor([[0.0000, 0.1333, 0.6000, 0.1333, 0.1333], # [0.0000, 0.6000, 0.1333, 0.1333, 0.1333], # [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]) self.true_dist = true_dist return self.criterion(x, Variable(true_dist, requires_grad=False)) # 这一步就是调用KL loss来计算 # x = tensor([[-20.7233, -1.6094, -0.3567, -2.3026, -20.7233], #[-20.7233, -1.6094, -0.3567, -2.3026, -20.7233], #[-20.7233, -1.6094, -0.3567, -2.3026, -20.7233]]) # true_dist=tensor([[0.0000, 0.1333, 0.6000, 0.1333, 0.1333], # [0.0000, 0.6000, 0.1333, 0.1333, 0.1333], # [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]) ","date":"2022-06-08","objectID":"/transformer/:3:5","tags":["NLP","Transformer"],"title":"Transformer","uri":"/transformer/"},{"categories":["NLP"],"content":"预测 预测过程与一般seq2seq不同的是，t时刻是将1到t-1时刻所有的预测结果作为序列进行预测，而seq2seq只是使用前一时刻的输出作为当前时刻的输入，这里困扰了我很久，实现了transformer代码后对比李沐老师的代码才理解。 其中seq2seq: transformer: 注意ys最后与之前的ys使用cat函数合并在一起。 ## 总结 Transformer还有很多的模型细节，以后遇到了再记录一下，在面试中很容易问到这些细节，因此可以参考面经边学习边记录，可以查缺补漏也可以学到新的东西。接下来把代码复现一下可以加深理解，并且提高自己的代码水平和实践能力。 ","date":"2022-06-08","objectID":"/transformer/:4:0","tags":["NLP","Transformer"],"title":"Transformer","uri":"/transformer/"},{"categories":["NLP"],"content":"一些问题 Transformer在哪里做了权重共享，为什么可以做权重共享？ Transformer在两个地方进行了权重共享： （1）Encoder和Decoder间的Embedding层权重共享； （2）Decoder中Embedding层和FC层权重共享。 对于（1），《Attention is all you need》中Transformer被应用在机器翻译任务中，源语言和目标语言是不一样的，但它们可以共用一张大词表，对于两种语言中共同出现的词（比如：数字，标点等等）可以得到更好的表示，而且对于Encoder和Decoder，嵌入时都只有对应语言的embedding会被激活，因此是可以共用一张词表做权重共享的。 论文中，Transformer词表用了bpe来处理，所以最小的单元是subword。英语和德语同属日耳曼语族，有很多相同的subword，可以共享类似的语义。而像中英这样相差较大的语系，语义共享作用可能不会很大。 但是，共用词表会使得词表数量增大，增加softmax的计算时间，因此实际使用中是否共享可能要根据情况权衡。 对于（2），Embedding层可以说是通过onehot去取到对应的embedding向量，FC层可以说是相反的，通过向量（定义为 x）去得到它可能是某个词的softmax概率，取概率最大（贪婪情况下）的作为预测值。 那哪一个会是概率最大的呢？在FC层的每一行量级相同的前提下，理论上和 x 相同的那一行对应的点积和softmax概率会是最大的。 因此，Embedding层和FC层权重共享，Embedding层中和向量 x 最接近的那一行对应的词，会获得更大的预测概率。实际上，Decoder中的Embedding层和FC层有点像互为逆过程。 通过这样的权重共享可以减少参数的数量，加快收敛。 ","date":"2022-06-08","objectID":"/transformer/:5:0","tags":["NLP","Transformer"],"title":"Transformer","uri":"/transformer/"},{"categories":["NLP"],"content":"为什么除以根号d 论文中的解释是：向量的点积结果会很大，将 softmax 函数 push 到梯度很小的区域，scaled 会缓解这种现象。 \\[\\frac{\\partial\\mathbf{y}}{\\partial\\mathbf{x}}=\\mathrm{diag}(\\mathbf{y})-\\mathbf{y}\\mathbf{y}^T\\] 当\\(\\mathbf{y} =\\)softmax\\(( \\mathbf{x} )\\)时，\\(\\mathbf{y}\\)对\\(\\mathbf{x}\\)的梯度为： 这是一个jacobi矩阵\\(^{+}\\),表示y的每一个元素对x每一个元素的导数是什么。 展开： \\[\\frac{\\partial\\mathbf{y}}{\\partial\\mathbf{x}}=\\begin{bmatrix}y_1\u00260\u0026\\cdots\u00260\\\\0\u0026y_2\u0026\\cdots\u00260\\\\\\vdots\u0026\\vdots\u0026\\ddots\u0026\\vdots\\\\0\u00260\u0026\\cdots\u0026y_d\\end{bmatrix}-\\begin{bmatrix}y_1^2\u0026y_1y_2\u0026\\cdots\u0026y_1y_d\\\\y_2y_1\u0026y_2^2\u0026\\cdots\u0026y_2y_d\\\\\\vdots\u0026\\vdots\u0026\\ddots\u0026\\vdots\\\\y_dy_1\u0026y_dy_2\u0026\\cdots\u0026y_d^2\\end{bmatrix}\\] 根据前面的讨论，当输入 \\(\\mathbf{x}\\) 的某一个元素较大时，softmax 会把大部分概率分布\\(^{+}\\)分配给最大的元 素，假设我们的输入数量级很大，那么就将产生一个接近 one-hot 的向量 \\[\\mathbf{y}\\approx[1,0,\\cdots,0]^\\top \\] 此时上面的矩阵变为如下形式 \\[\\frac{\\partial\\mathbf{y}}{\\partial\\mathbf{x}}\\approx\\begin{bmatrix}1\u00260\u0026\\cdots\u00260\\\\0\u00260\u0026\\cdots\u00260\\\\\\vdots\u0026\\vdots\u0026\\ddots\u0026\\vdots\\\\0\u00260\u0026\\cdots\u00260\\end{bmatrix}-\\begin{bmatrix}1\u00260\u0026\\cdots\u00260\\\\0\u00260\u0026\\cdots\u00260\\\\\\vdots\u0026\\vdots\u0026\\ddots\u0026\\vdots\\\\0\u00260\u0026\\cdots\u00260\\end{bmatrix}=\\mathbf{0}\\] 也就是所有的梯度都接近0 除以\\(\\sqrt{ d }\\)后就使x的分布更加平缓，从而防止梯度消失。 from scipy.special import softmax import numpy as np def test_gradient(dim, time_steps=50, scale=1.0): # Assume components of the query and keys are drawn from N(0, 1) independently q = np.random.randn(dim) ks = np.random.randn(time_steps, dim) x = np.sum(q * ks, axis=1) / scale # x.shape = (time_steps,) y = softmax(x) grad = np.diag(y) - np.outer(y, y)# softmax gradient(dy/dx) return np.max(np.abs(grad)) # the maximum component of gradients NUMBER_OF_EXPERIMENTS = 5 # results of 5 random runs without scaling print([test_gradient(100) for _ in range(NUMBER_OF_EXPERIMENTS)]) print([test_gradient(1000) for _ in range(NUMBER_OF_EXPERIMENTS)]) # results of 5 random runs with scaling print([test_gradient(100, scale=np.sqrt(100)) for _ in range(NUMBER_OF_EXPERIMENTS)]) print([test_gradient(1000, scale=np.sqrt(1000)) for _ in range(NUMBER_OF_EXPERIMENTS)]) 输出可看到下面的梯度比上面的梯度更大。 这时又有一个问题，为什么多分类的softmax+交叉熵不需要除以东西呢？这是因为交叉熵中有一个log，log_softmax的梯度和刚才算出来的不同，就算输入的某一个x过大也不会梯度消失。所以就又可以推断出softmax+MSE会导致梯度消失，因为MSE中没有Log，这是为什么分类任务不使用MSE损失函数的原因之一。 ### 为什么 Transformer 需要进行 Multi-head Attention 实验证明多头是必要的，8/16个头都可以取得更好的效果，但是超过16个反而效果不好。每个头关注的信息不同，但是头之间的差异随着层数增加而减少。并且不是所有头都有用，有工作尝试剪枝，可以得到更好的表现。 论文中提到模型分为多个头，形成多个子空间，每个头关注不同方面的信息。 那为什么每个头的维度要降呢? 一言蔽之的话，大概是：在不增加时间复杂度的情况下，同时，借鉴CNN多核的思想，在更低的维度，在多个独立的特征空间，更容易学习到更丰富的特征信息。 ### 为什么 Transformer 的 Embedding 最后要乘dmodel 具体的原因是，如果使用 Xavier 初始化，Embedding 的方差为 1/d_model，当d_model非常大时，矩阵中的每一个值都会减小。通过乘一个 dmodel 可以将方差恢复到1。 因为Position Encoding是通过三角函数算出来的，值域为[-1, 1]。所以当加上 Position Encoding 时，需要放大 embedding 的数值，否则规模不一致相加后会丢失信息。 因为 Bert 使用的是学习式的Embedding，所以 Bert 这里就不需要放大。 # 参考 Bert/Transformer 被忽视的细节（或许可以用来做面试题） - 知乎 (zhihu.com) ","date":"2022-06-08","objectID":"/transformer/:5:1","tags":["NLP","Transformer"],"title":"Transformer","uri":"/transformer/"},{"categories":["算法题"],"content":"最大子序和 https://leetcode-cn.com/problems/maximum-subarray/ 一开始直接暴力，结果tle了最后 class Solution: def maxSubArray(nums): res = -float('inf') for i in range(len(nums)): for j in range(i,len(nums)): res = max(res,sum(nums[i:j+1])) return res 这说明在leetcode尽量不要嵌套循环，大概率Tle class Solution: def maxSubArray(nums): for i in range(1,len(nums)): maxs = max(nums[i-1]+nums[i],nums[i]) nums[i] = maxs return max(nums) 最后巧妙地利用了替换的思想，将每次相加的值和当前比较，并将当前替换为较大的那个值，最后求整个列表的最大值。 ","date":"2022-06-08","objectID":"/%E6%9C%80%E5%A4%A7%E5%AD%90%E5%BA%8F%E5%92%8C/:0:0","tags":["算法题","最大子序和"],"title":"最大子序和","uri":"/%E6%9C%80%E5%A4%A7%E5%AD%90%E5%BA%8F%E5%92%8C/"},{"categories":["算法题"],"content":"使用最小花费爬楼梯 每日一题刷到的。 动态规划类型的题目，重点就是找状态转移方程，因为我不太熟练，对动态规划的题目做的比较少，所以WA了好几次。 class Solution: def minCostClimbingStairs(cost): res = [] #res[i]就是到第i阶梯时最小的花费 res.append(cost[0]) #到第一阶梯最小就是0+cost[0] res.append(cost[1]) #第二阶梯最小就是0+cost[1] #状态转移方程:res[i] = min(res[i-1],res[i-2])+cost[i] for i in range(2,len(cost)): res.append(min(res[i-1],res[i-2])+cost[i]) # return min(res[-1],res[-2]) 踏上第i级台阶有两种方法： 先踏上第i-2级台阶（最小总花费dp[i-2]），再直接迈两步踏上第i级台阶（花费cost[i]），最小总花费dp[i-2] + cost[i]； 先踏上第i-1级台阶（最小总花费dp[i-1]），再迈一步踏上第i级台阶（花费cost[i]），最小总花费dp[i-1] + cost[i]； 上述为引用的题解的说明，更加深了对动态规划的理解 ","date":"2022-06-01","objectID":"/%E4%BD%BF%E7%94%A8%E6%9C%80%E5%B0%8F%E8%8A%B1%E8%B4%B9%E7%88%AC%E6%A5%BC%E6%A2%AF/:0:0","tags":["算法题","使用最小花费爬楼梯"],"title":"使用最小花费爬楼梯","uri":"/%E4%BD%BF%E7%94%A8%E6%9C%80%E5%B0%8F%E8%8A%B1%E8%B4%B9%E7%88%AC%E6%A5%BC%E6%A2%AF/"},{"categories":["NLP","概率图模型"],"content":"CRF ","date":"2022-05-12","objectID":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/:0:0","tags":["NLP","概率图模型","马尔科夫网络","条件随机场"],"title":"条件随机场","uri":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"},{"categories":["NLP","概率图模型"],"content":"概率图模型与无向图 图是由结点和连接结点的边组成的集合。结点和边分别记作v和e，结点和边的集合分别记作V和E，图记作\\(G=(V, E)\\)。 无向图是指没有方向的图。 概率图模型是由图表示的概率分布。设有联合概率分布P(Y), Y是一组随机变量，由无向图\\(G=(V,E)\\)表示概率分布P(Y)，即在图G中，结点\\(v\\in V\\)表示一个随机变量\\(Y_v\\)，\\(Y=(Y_v)\\_{v\\in V}\\)，边e表示随机变量之间的依赖关系。 ","date":"2022-05-12","objectID":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/:1:0","tags":["NLP","概率图模型","马尔科夫网络","条件随机场"],"title":"条件随机场","uri":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"},{"categories":["NLP","概率图模型"],"content":"概率无向图模型 设有联合概率分布P(Y)，由无向图\\(G=(V,E)\\)表示，在图G中，结点表示随机变量，边表示随机变量之间的依赖关系。如果联合概率分布满足成对、局部或全局马尔科夫性，就称此联合概率分布称为概率无向图模型，或马尔科夫随机场。 ","date":"2022-05-12","objectID":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/:2:0","tags":["NLP","概率图模型","马尔科夫网络","条件随机场"],"title":"条件随机场","uri":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"},{"categories":["NLP","概率图模型"],"content":"因子分解 首先给出无向图的团和最大团的定义： 无向图G中任何两个结点均有边连接的结点子集称为团。若C是无向图G的一个团，并且不能再加进任何一个G的结点使其成为更大的团，则称此C为最大团。 将无向图模型的联合概率分布表示为其最大团上的随机变量的函数的乘积形式的操作，称为概率无向图模型的因子分解。 给定概率无向图模型, 设其无向图为 \\(G, C\\) 为 \\(G\\) 上的最大团, \\(Y_C\\) 表示 \\(C\\) 对应的 随机变量。那么概率无向图模型的联合概率分布 \\(P(Y)\\) 可写作图中所有最大团 \\(C\\) 上的 函数 \\(\\Psi_C\\left(Y_C\\right)\\) 的乘积形式, 即 \\[ P(Y)=\\frac{1}{Z} \\prod_C \\Psi_C\\left(Y_C\\right) \\] 其中, \\(Z\\) 是规范化因子 (normalization factor), 由式 \\[ Z=\\sum_Y \\prod_C \\Psi_C\\left(Y_C\\right) \\] 给出。规范化因子保证 \\(P(Y)\\) 构成一个概率分布。函数 \\(\\Psi_C\\left(Y_C\\right)\\) 称为势函数 (potential function)。这里要求势函数 \\(\\Psi_C\\left(Y_C\\right)\\) 是严格正的, 通常定义为指数函数: \\[ \\Psi_C\\left(Y_C\\right)=\\exp \\\\{-E\\left(Y_C\\right)\\\\\\} \\] ","date":"2022-05-12","objectID":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/:3:0","tags":["NLP","概率图模型","马尔科夫网络","条件随机场"],"title":"条件随机场","uri":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"},{"categories":["NLP","概率图模型"],"content":"条件随机场 条件随机场是指给定随机变量X的条件下，随机变量Y的马尔科夫随机场。一般的条件随机场主要是指线性链条件随机场，可以用于标注等问题。这里的\\(P(Y|X)\\)中，Y是输出变量，表示标注序列，X是输入变量，表示需要标注的观察序列。 ","date":"2022-05-12","objectID":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/:4:0","tags":["NLP","概率图模型","马尔科夫网络","条件随机场"],"title":"条件随机场","uri":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"},{"categories":["NLP","概率图模型"],"content":"一般的条件随机场 (条件随机场) 设 \\(X\\) 与 \\(Y\\) 是随机变量, \\(P(Y \\mid X)\\) 是在给定 \\(X\\) 的条件 下 \\(Y\\) 的条件概率分布。若随机变量 \\(Y\\) 构成一个由无向图 \\(G=(V, E)\\) 表示的马尔可夫 随机场, 即 \\[ P\\left(Y_v \\mid X, Y_w, w \\neq v\\right)=P\\left(Y_v \\mid X, Y_w, w \\sim v\\right) \\] 对任意结点 \\(v\\) 成立, 则称条件概率分布 \\(P(Y \\mid X)\\) 为条件随机场。式中 \\(w \\sim v\\) 表示在 图 \\(G=(V, E)\\) 中与结点 \\(v\\) 有边连接的所有结点 \\(w, w \\neq v\\) 表示结点 \\(v\\) 以外的所有结 点, \\(Y_v, Y_u\\) 与 \\(Y_w\\) 为结点 \\(v, u\\) 与 \\(w\\) 对应的随机变量。 ","date":"2022-05-12","objectID":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/:4:1","tags":["NLP","概率图模型","马尔科夫网络","条件随机场"],"title":"条件随机场","uri":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"},{"categories":["NLP","概率图模型"],"content":"线性链条件随机场 设\\(X=(X_1,X_2, \\dots, X_n), \\quad Y=(Y_1, Y_2, \\dots , Y_n)\\)均为线性链表示的随机变量序列，若在给定随机变量序列X的条件下，随机变量Y的条件概率分布\\(P(Y|X)\\)构成条件随机场，即满足马尔科夫性 \\[ P\\left(Y_i \\mid X, Y_1, \\cdots, Y_{i-1}, Y_{i+1}, \\cdots, Y_n\\right)=P\\left(Y_i \\mid X, Y_{i-1}, Y_{i+1}\\right) \\] \\(i=1,2, \\cdots, n\\) (在 \\(i=1\\) 和 \\(n\\) 时只考虑单边) 则称 \\(P(Y \\mid X)\\) 为线性链条件随机场。在标注问题中, \\(X\\) 表示输入观测序列, \\(Y\\) 表示对 应的输出标记序列或状态序列。 ","date":"2022-05-12","objectID":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/:4:2","tags":["NLP","概率图模型","马尔科夫网络","条件随机场"],"title":"条件随机场","uri":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"},{"categories":["NLP","概率图模型"],"content":"线性链条件随机场参数化形式 根据因子分解, 可以给出线性链条件随机场 \\(P(Y \\mid X)\\) 的因子分解式, 各因子是定 义在相邻两个结点 (最大团) 上的势函数。 (线性链条件随机场的参数化形式) 设 \\(P(Y \\mid X)\\) 为线性链条件随机 场, 则在随机变量 \\(X\\) 取值为 \\(x\\) 的条件下, 随机变量 \\(Y\\) 取值为 \\(y\\) 的条件概率具有如下 形式: \\[ P(y \\mid x)=\\frac{1}{Z(x)} \\exp \\left(\\sum_{i, k} \\lambda_k t_k\\left(y_{i-1}, y_i, x, i\\right)+\\sum_{i, l} \\mu_l s_l\\left(y_i, x, i\\right)\\right) \\] 其中, \\[ Z(x)=\\sum_y \\exp \\left(\\sum_{i, k} \\lambda_k t_k\\left(y_{i-1}, y_i, x, i\\right)+\\sum_{i, l} \\mu_l s_l\\left(y_i, x, i\\right)\\right) \\] 式中, \\(t_k\\) 和 \\(s_l\\) 是特征函数, \\(\\lambda_k\\) 和 \\(\\mu_l\\) 是对应的权值。 \\(Z(x)\\) 是规范化因子, 求和是在所 有可能的输出序列上进行的。 这两个式子是线性链条件随机场模型的基本形式, 表示给定输入序列 \\(x\\), 对输出序列 \\(y\\) 预测的条件概率。\\(t_k\\) 是定义在边上的特 征函数, 称为转移特征, 依赖于当前和前一个位置; \\(s_l\\) 是定义在结点上的特征函数, 称为状态特征, 依赖于当前位置。 \\(t_k\\) 和 \\(s_l\\) 都依赖于位置, 是局部特征函数。通常, 特 征函数 \\(t_k\\) 和 \\(s_l\\) 取值为 1 或 0 ; 当满足特征条件时取值为 1 , 否则为 0 。条件随机场完 全由特征函数 \\(t_k, s_l\\) 和对应的权值 \\(\\lambda_k, \\mu_l\\) 确定。 线性链条件随机场也是对数线性模型 (log linear model)。 ","date":"2022-05-12","objectID":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/:4:3","tags":["NLP","概率图模型","马尔科夫网络","条件随机场"],"title":"条件随机场","uri":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"},{"categories":["NLP","概率图模型"],"content":"条件随机场的简化形式 为简便起见, 首先将转移特征和状态特征及其权值用统一的符号表示。设有 \\(K_1\\) 个转移特征, \\(K_2\\) 个状态特征, \\(K=K_1+K_2\\), 记 \\[ f_k\\left(y_{i-1}, y_i, x, i\\right)= \\begin{cases}t_k\\left(y_{i-1}, y_i, x, i\\right), \u0026 k=1,2, \\cdots, K_1 \\\\\\\\ s_l\\left(y_i, x, i\\right), \u0026 k=K_1+l ; l=1,2, \\cdots, K_2\\end{cases} \\] 然后, 对转移与状态特征在各个位置 \\(i\\) 求和, 记作 \\[ f_k(y, x)=\\sum_{i=1}^n f_k\\left(y_{i-1}, y_i, x, i\\right), \\quad k=1,2, \\cdots, K \\] 用 \\(w_k\\) 表示特征 \\(f_k(y, x)\\) 的权值, 即 \\[ w_k= \\begin{cases}\\lambda_k, \u0026 k=1,2, \\cdots, K_1 \\\\\\\\ \\mu_l, \u0026 k=K_1+l ; l=1,2, \\cdots, K_2\\end{cases} \\] 于是, 条件随机场可表示为 \\[ \\begin{aligned} P(y \\mid x) \u0026=\\frac{1}{Z(x)} \\exp \\sum_{k=1}^K w_k f_k(y, x) \\\\\\\\ Z(x) \u0026=\\sum_y \\exp \\sum_{k=1}^K w_k f_k(y, x) \\end{aligned} \\] 若以 \\(w\\) 表示权值向量, 即 \\[ w=\\left(w_1, w_2, \\cdots, w_K\\right)^{\\mathrm{T}} \\] 以 \\(F(y, x)\\) 表示全局特征向量, 即 \\[ F(y, x)=\\left(f_1(y, x), f_2(y, x), \\cdots, f_K(y, x)\\right)^{\\mathrm{T}} \\] 则条件随机场可以写成向量 \\(w\\) 与 \\(F(y, x)\\) 的内积的形式: \\[ P_w(y \\mid x)=\\frac{\\exp (w \\cdot F(y, x))}{Z_w(x)} \\] 其中, \\[ Z_w(x)=\\sum_y \\exp (w \\cdot F(y, x)) \\] ","date":"2022-05-12","objectID":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/:4:4","tags":["NLP","概率图模型","马尔科夫网络","条件随机场"],"title":"条件随机场","uri":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"},{"categories":["NLP","概率图模型"],"content":"矩阵形式 对每个 标记序列引进特殊的起点和终点状态标记 \\(y_0=\\) start 和 \\(y_{n+1}=s t o p\\), 这时标注序列 的概率 \\(P_w(y \\mid x)\\) 可以通过矩阵形式表示并有效计算。 对观测序列 \\(x\\) 的每一个位置 \\(i=1,2, \\cdots, n+1\\), 由于 \\(y_{i-1}\\) 和 \\(y_i\\) 在 \\(m\\) 个标记中 取值, 可以定义一个 \\(m\\) 阶矩阵随机变量 \\[ M_i(x)=\\left[M_i\\left(y_{i-1}, y_i \\mid x\\right)\\right] \\] 矩阵随机变量的元素为 \\[ \\begin{aligned} \u0026M_i\\left(y_{i-1}, y_i \\mid x\\right)=\\exp \\left(W_i\\left(y_{i-1}, y_i \\mid x\\right)\\right) \\\\\\\\ \u0026W_i\\left(y_{i-1}, y_i \\mid x\\right)=\\sum_{k=1}^K w_k f_k\\left(y_{i-1}, y_i, x, i\\right) \\end{aligned} \\] 这里 \\(w_k\\) 和 \\(f_k\\) 分别由前面的式子给出, \\(y_{i-1}\\) 和 \\(y_i\\) 是标记随机变量 \\(Y_{i-1}\\) 和 \\(Y_i\\) 的取值。 这样, 给定观测序列 \\(x\\), 相应标记序列 \\(y\\) 的非规范化概率可以通过该序列 \\(n+1\\) 个矩阵的适当元素的乘积 \\(\\prod_{i=1}^{n+1} M_i\\left(y_{i-1}, y_i \\mid x\\right)\\) 表示。于是, 条件概率 \\(P_w(y \\mid x)\\) 是 \\[ P_w(y \\mid x)=\\frac{1}{Z_w(x)} \\prod_{i=1}^{n+1} M_i\\left(y_{i-1}, y_i \\mid x\\right) \\] 其中, \\(Z_w(x)\\) 为规范化因子, 是 \\(n+1\\) 个矩阵的乘积的 (start, stop) 元素, 即 \\[ Z_w(x)=\\left[M_1(x) M_2(x) \\cdots M_{n+1}(x)\\right]_{\\text {start,stop }} \\] 注意, \\(y_0=\\) start 与 \\(y_{n+1}=\\) stop 表示开始状态与终止状态, 规范化因子 \\(Z_w(x)\\) 是以 start 为起点 stop为终点通过状态的所有路径 \\(y_1 y_2 \\cdots y_n\\) 的非规范化概率 \\(\\prod_{i=1}^{n+1} M_i\\left(y_{i-1}, y_i \\mid x\\right)\\) 之和。 ","date":"2022-05-12","objectID":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/:4:5","tags":["NLP","概率图模型","马尔科夫网络","条件随机场"],"title":"条件随机场","uri":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"},{"categories":["NLP","概率图模型"],"content":"概率计算问题 与HMM类似，引入前向和后向变量，递归的计算概率和一些期望值。 ","date":"2022-05-12","objectID":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/:5:0","tags":["NLP","概率图模型","马尔科夫网络","条件随机场"],"title":"条件随机场","uri":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"},{"categories":["NLP","概率图模型"],"content":"前向-后向算法 对每个指标 \\(i=0,1, \\cdots, n+1\\), 定义前向向量 \\(\\alpha_i(x)\\) : \\[ \\alpha_0(y \\mid x)= \\begin{cases}1, \u0026 y=\\text { start } \\\\\\\\ 0, \u0026 \\text { 否则 }\\end{cases} \\] 递推公式为 \\[ \\alpha_i^{\\mathrm{T}}\\left(y_i \\mid x\\right)=\\alpha_{i-1}^{\\mathrm{T}}\\left(y_{i-1} \\mid x\\right)\\left[M_i\\left(y_{i-1}, y_i \\mid x\\right)\\right], \\quad i=1,2, \\cdots, n+1 \\] 又可表示为 \\[ \\alpha_i^{\\mathrm{T}}(x)=\\alpha_{i-1}^{\\mathrm{T}}(x) M_i(x) \\] \\(\\alpha_i\\left(y_i \\mid x\\right)\\) 表示在位置 \\(i\\) 的标记是 \\(y_i\\) 并且从 1 到 \\(i\\) 的前部分标记序列的非规范化概 率, \\(y_i\\) 可取的值有 \\(m\\) 个, 所以 \\(\\alpha_i(x)\\) 是 \\(m\\) 维列向量。 同样, 对每个指标 \\(i=0,1, \\cdots, n+1\\), 定义后向向量 \\(\\beta_i(x)\\) : \\[ \\begin{aligned} \\beta_{n+1}\\left(y_{n+1} \\mid x\\right) \u0026= \\begin{cases}1, \u0026 y_{n+1}=\\text { stop } \\\\\\\\ 0, \u0026 \\text { 否则 }\\end{cases} \\\\\\\\ \\beta_i\\left(y_i \\mid x\\right) \u0026=\\left[M_{i+1}\\left(y_i, y_{i+1} \\mid x\\right)\\right] \\beta_{i+1}\\left(y_{i+1} \\mid x\\right) \\end{aligned} \\] 又可表示为 \\[ \\beta_i(x)=M_{i+1}(x) \\beta_{i+1}(x) \\] \\(\\beta_i\\left(y_i \\mid x\\right)\\) 表示在位置 \\(i\\) 的标记为 \\(y_i\\) 并且从 \\(i+1\\) 到 \\(n\\) 的后部分标记序列的非规范化 概率。 ","date":"2022-05-12","objectID":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/:5:1","tags":["NLP","概率图模型","马尔科夫网络","条件随机场"],"title":"条件随机场","uri":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"},{"categories":["NLP","概率图模型"],"content":"概率计算 按照前向-后向向量的定义, 很容易计算标记序列在位置 \\(i\\) 是标记 \\(y_i\\) 的条件概率 和在位置 \\(i-1\\) 与 \\(i\\) 是标记 \\(y_{i-1}\\) 和 \\(y_i\\) 的条件概率: \\[ P\\left(Y_i=y_i \\mid x\\right)=\\frac{\\alpha_i^{\\mathrm{T}}\\left(y_i \\mid x\\right) \\beta_i\\left(y_i \\mid x\\right)}{Z(x)} \\] \\[ P\\left(Y_{i-1}=y_{i-1}, Y_i=y_i \\mid x\\right)=\\frac{\\alpha_{i-1}^{\\mathrm{T}}\\left(y_{i-1} \\mid x\\right) M_i\\left(y_{i-1}, y_i \\mid x\\right) \\beta_i\\left(y_i \\mid x\\right)}{Z(x)} \\] 其中, \\[ Z(x)=\\alpha_n^{\\mathrm{T}}(x) \\mathbf{1}=1 \\beta_1(x) \\] ","date":"2022-05-12","objectID":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/:5:2","tags":["NLP","概率图模型","马尔科夫网络","条件随机场"],"title":"条件随机场","uri":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"},{"categories":["NLP","概率图模型"],"content":"预测问题 ","date":"2022-05-12","objectID":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/:6:0","tags":["NLP","概率图模型","马尔科夫网络","条件随机场"],"title":"条件随机场","uri":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"},{"categories":["NLP","概率图模型"],"content":"维特比算法 还是使用维特比算法。 \\[ \\begin{aligned} y^* \u0026=\\arg \\max_y P_w(y \\mid x) \\\\\\\\ \u0026=\\arg \\max_y \\frac{\\exp (w \\cdot F(y, x))}{Z_w(x)} \\\\\\\\ \u0026=\\arg \\max_y \\exp (w \\cdot F(y, x)) \\\\\\\\ \u0026=\\arg \\max_y(w \\cdot F(y, x)) \\end{aligned} \\] 于是, 条件随机场的预测问题成为求非规范化概率最大的最优路径问题 \\[ \\max_y(w \\cdot F(y, x)) \\] 这里, 路径表示标记序列。其中, \\[ \\begin{aligned} w \u0026=\\left(w_1, w_2, \\cdots, w_K\\right)^{\\mathrm{T}} \\\\\\\\ F(y, x) \u0026=\\left(f_1(y, x), f_2(y, x), \\cdots, f_K(y, x)\\right)^{\\mathrm{T}} \\\\\\\\ f_k(y, x) \u0026=\\sum_{i=1}^n f_k\\left(y_{i-1}, y_i, x, i\\right), \\quad k=1,2, \\cdots, K \\end{aligned} \\] 注意, 这时只需计算非规范化概率, 而不必计算概率, 可以大大提高效率。为了求解最 优路径, 写成如下形式: \\[ \\max_y \\sum_{i=1}^n w \\cdot F_i\\left(y_{i-1}, y_i, x\\right) \\] 其中, \\[ F_i\\left(y_{i-1}, y_i, x\\right)=\\left(f_1\\left(y_{i-1}, y_i, x, i\\right), f_2\\left(y_{i-1}, y_i, x, i\\right), \\cdots, f_K\\left(y_{i-1}, y_i, x, i\\right)\\right)^{\\mathrm{T}} \\] 是局部特征向量。 下面叙述维特比算法。首先求出位置 1 的各个标记 \\(j=1,2, \\cdots, m\\) 的非规范化概率: \\[ \\delta_1(j)=w \\cdot F_1\\left(y_0=\\text { start, } y_1=j, x\\right), \\quad j=1,2, \\cdots, m \\] 一般地, 由递推公式, 求出到位置 \\(i\\) 的各个标记 \\(l=1,2, \\cdots, m\\) 的非规范化概率的最 大值, 同时记录非规范化概率最大值的路径 \\[ \\begin{gathered} \\delta_i(l)=\\max_{1 \\leqslant j \\leqslant m}\\left\\\\{\\delta_{i-1}(j)+w \\cdot F_i\\left(y_{i-1}=j, y_i=l, x\\right)\\right\\\\\\}, \\quad l=1,2, \\cdots, m \\\\\\\\ \\Psi_i(l)=\\arg \\max_{1 \\leqslant j \\leqslant m}\\left\\\\{\\delta_{i-1}(j)+w \\cdot F_i\\left(y_{i-1}=j, y_i=l, x\\right)\\right\\\\\\}, \\quad l=1,2, \\cdots, m \\end{gathered} \\] 直到 \\(i=n\\) 时终止。这时求得非规范化概率的最大值为 \\[ \\operatorname{max}_y(w \\cdot F(y, x))=\\max_{1 \\leqslant j \\leqslant m} \\delta_n(j) \\] 及最优路径的终点 \\[ y_n^* =\\arg \\max_{1 \\leqslant j \\leqslant m} \\delta_n(j) \\] 由此最优路径终点返回, \\[ y_i^* =\\Psi_{i+1}\\left(y_{i+1}^* \\right), \\quad i=n-1, n-2, \\cdots, 1 \\] 求得最优路径 \\(y^* =\\left(y_1^* , y_2^* , \\cdots, y_n^* \\right)^{\\mathrm{T}}\\) 。 综上所述, 得到条件随机场预测的维特比算法。 (条件随机场预测的维特比算法) 输入: 模型特征向量 \\(F(y, x)\\) 和权值向量 \\(w\\), 观测序列 \\(x=\\left(x_1, x_2, \\cdots, x_n\\right)\\); 输出: 最优路径 \\(y^* =\\left(y_1^* , y_2^* , \\cdots, y_n^* \\right)\\) 。 (1) 初始化 \\[ \\delta_1(j)=w \\cdot F_1\\left(y_0=\\operatorname{start}, y_1=j, x\\right), \\quad j=1,2, \\cdots, m \\] 递推。对 \\(i=2,3, \\cdots, n\\) \\[ \\begin{gathered} \\delta_i(l)=\\max_{1 \\leqslant j \\leqslant m}\\left\\\\{\\delta_{i-1}(j)+w \\cdot F_i\\left(y_{i-1}=j, y_i=l, x\\right)\\right\\\\\\}, \\quad l=1,2, \\cdots, m \\\\\\\\ \\Psi_i(l)=\\arg \\max_{1 \\leqslant j \\leqslant m}\\left\\\\{\\delta_{i-1}(j)+w \\cdot F_i\\left(y_{i-1}=j, y_i=l, x\\right)\\right\\\\\\}, \\quad l=1,2, \\cdots, m \\end{gathered} \\] （3）终止 \\[ \\begin{gathered} \\max_y(w \\cdot F(y, x))=\\max_{1 \\leqslant j \\leqslant m} \\delta_n(j) \\\\\\\\ y_n^* =\\arg \\max_{1 \\leqslant j \\leqslant m} \\delta_n(j) \\end{gathered} \\] 返回路径 \\[ y_i^* =\\Psi_{i+1}\\left(y_{i+1}^* \\right), \\quad i=n-1, n-2, \\cdots, 1 \\] 求得最优路径 \\(y^* =\\left(y_1^* , y_2^* , \\cdots, y_n^* \\right)\\_{\\text {。 }}\\) 自己的理解就是非规范化概率每个i代表时间步i，要对所有的\\(\\lambda_k t_k\\)和 \\(\\mu_ks_k\\) 进行筛选，找出符合条件的相加，这里要注意下标的理解。括号里的和HMM的类似，代表y的取值。 ","date":"2022-05-12","objectID":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/:6:1","tags":["NLP","概率图模型","马尔科夫网络","条件随机场"],"title":"条件随机场","uri":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"},{"categories":["NLP","概率图模型"],"content":"实例 这里使用维特比算法求解 ","date":"2022-05-12","objectID":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/:6:2","tags":["NLP","概率图模型","马尔科夫网络","条件随机场"],"title":"条件随机场","uri":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"},{"categories":["NLP","概率图模型"],"content":"参数学习问题 ","date":"2022-05-12","objectID":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/:7:0","tags":["NLP","概率图模型","马尔科夫网络","条件随机场"],"title":"条件随机场","uri":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"},{"categories":["NLP","概率图模型"],"content":"总结 ","date":"2022-05-12","objectID":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/:8:0","tags":["NLP","概率图模型","马尔科夫网络","条件随机场"],"title":"条件随机场","uri":"/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"},{"categories":["Machine Learning","集成学习","Boosting"],"content":"Boosting算法的工作机制是首先从训练集用初始权重训练出一个弱学习器1，根据弱学习的学习误差率表现来更新训练样本的权重，使得之前弱学习器1学习误差率高的训练样本点的权重变高，使得这些误差率高的点在后面的弱学习器2中得到更多的重视。然后基于调整权重后的训练集来训练弱学习器2.，如此重复进行，直到弱学习器数达到事先指定的数目T，最终将这T个弱学习器通过集合策略进行整合，得到最终的强学习器。 这段叙述里面有很多需要解决的东西，比如如何计算误差率，如何得到弱学习器权重系数，如何更新样本权重，如何结合。 ","date":"2022-04-27","objectID":"/adaboost/:0:0","tags":["Machine Learning","集成学习","Boosting","Adaboost"],"title":"Adaboost","uri":"/adaboost/"},{"categories":["Machine Learning","集成学习","Boosting"],"content":"Adaboost 先看一下adaboost的算法流程 将初始化样本的权重为\\(\\frac{1}{m}\\)，那么这个样本权重到底怎么用呢，主要是用于在构建弱分类器时计算弱学习器在训练集上的误差时使用，也就是计算误差： \\[ \\epsilon_t = \\sum_{i=1}^mP(h_t(x_i) \\neq y_i) =\\sum_{i=1}^m D_{ti}I(h_t(x_i)\\neq y_i) \\] 如果弱分类器为决策树的话，肯定要选择误差最小的划分作为最佳划分，最小的误差最为本轮弱分类器的误差。实际上样本权重不参与训练，只是通过样本权重动态调节模型的关注重点，即通过计算误差，影响决策树的划分，来调节模型的关注重点，这就是样本权重的作用。 然后计算弱学习器权重\\(\\alpha_t\\)，更新样本权重，对于分类错误的样本权重上升，对于分类正确的样本权重下调，再除以规范化因子，确保仍然是一个分布，一般就是\\(D_t\\)的和作为规范化因子，下一轮的模型就更注意划分错误的这些样本点。这样每一轮迭代都会得到弱分类器系数和弱分类器，这里具体的计算过程可以参考李航的《统计学习方法》，迭代完成以后，按照公式将权重与弱分类器相乘后相加，最后经过信号函数得到最终的分类结果。 ## 优点 Adaboost作为分类器时，分类精度很高 在Adaboost的框架下，可以使用各种回归分类模型来构建弱学习器，非常灵活。 作为简单的二元分类器时，构造简单，结果可理解。 不容易发生过拟合 ","date":"2022-04-27","objectID":"/adaboost/:1:0","tags":["Machine Learning","集成学习","Boosting","Adaboost"],"title":"Adaboost","uri":"/adaboost/"},{"categories":["Machine Learning","集成学习","Boosting"],"content":"缺点 对异常样本敏感，异常样本在迭代中可能会获得较高的权重，影响最终的强学习器的预测准确性。 ","date":"2022-04-27","objectID":"/adaboost/:2:0","tags":["Machine Learning","集成学习","Boosting","Adaboost"],"title":"Adaboost","uri":"/adaboost/"},{"categories":["Machine Learning","集成学习","Boosting"],"content":"另一种解释 上面叙述的是一般的Adaboost算法的解释，其实还有另外一种解释，就是adaboost为加法模型、损失函数为指数函数、学习算法为前向分步算法的二类分类学习方法。 那么什么是前向分步算法？ 输入: 训练数据集\\(T=\\{(x_1, y_1 ),(x_2, y_2), \\cdots,\\left(x_N, y_N\\right)\\}\\); 损失函数 \\(L(y, f(x))\\); 基函数集 \\(\\{b(x ; \\gamma)\\}\\); 输出: 加法模型 \\(f(x)\\) 。 初始化 \\(f_0(x)=0\\); 对 \\(m=1,2, \\cdots, M\\) 极小化损失函数 \\[ \\left(\\beta_m, \\gamma_m\\right)=\\arg \\min_{\\beta, \\gamma} \\sum_{i=1}^N L\\left(y_i, f_{m-1}\\left(x_i\\right)+\\beta b\\left(x_i ; \\gamma\\right)\\right) \\] 得到参数 \\(\\beta_m, \\gamma_m\\) 。 更新 \\[ f_m(x)=f_{m-1}(x)+\\beta_m b\\left(x ; \\gamma_m\\right) \\] 得到加法模型 \\[ f(x)=f_M(x)=\\sum_{m=1}^M \\beta_m b\\left(x ; \\gamma_m\\right) \\] 学过GBDT的话就感觉会很熟悉。实际上提升树和GBDT也都是使用的前向分步算法。 直接上结论吧，推导的感觉没有必要，毕竟都是boosting方法。具体证明的过程可以看李航老师的《统计学习方法》。 Adaboost算法是前向分步加法算法的特例，这时，模型是由基本分类器组成的加法模型，损失函数是指数函数。 ","date":"2022-04-27","objectID":"/adaboost/:3:0","tags":["Machine Learning","集成学习","Boosting","Adaboost"],"title":"Adaboost","uri":"/adaboost/"},{"categories":["Machine Learning","集成学习","Boosting"],"content":"总结 总是要写个总结的，adaboost一种boosting方法，就是不断迭代调整权重，最后将每一步的结果加权求和，可以说是一种典型的boosting的方法。 ","date":"2022-04-27","objectID":"/adaboost/:4:0","tags":["Machine Learning","集成学习","Boosting","Adaboost"],"title":"Adaboost","uri":"/adaboost/"},{"categories":["算法题"],"content":"分割等和子集 ","date":"2022-03-25","objectID":"/%E5%88%86%E5%89%B2%E7%AD%89%E5%92%8C%E5%AD%90%E9%9B%86/:0:0","tags":["算法题","分割等和子集"],"title":"分割等和子集","uri":"/%E5%88%86%E5%89%B2%E7%AD%89%E5%92%8C%E5%AD%90%E9%9B%86/"},{"categories":["算法题"],"content":"题目： https://leetcode-cn.com/problems/partition-equal-subset-sum/?utm_source=LCUS\u0026utm_medium=ip_redirect\u0026utm_campaign=transfer2china ","date":"2022-03-25","objectID":"/%E5%88%86%E5%89%B2%E7%AD%89%E5%92%8C%E5%AD%90%E9%9B%86/:1:0","tags":["算法题","分割等和子集"],"title":"分割等和子集","uri":"/%E5%88%86%E5%89%B2%E7%AD%89%E5%92%8C%E5%AD%90%E9%9B%86/"},{"categories":["算法题"],"content":"思路： 典型的01背包问题，利用套路框架做即可 注意做了优化，把原本的二维dp降低了一维 ","date":"2022-03-25","objectID":"/%E5%88%86%E5%89%B2%E7%AD%89%E5%92%8C%E5%AD%90%E9%9B%86/:2:0","tags":["算法题","分割等和子集"],"title":"分割等和子集","uri":"/%E5%88%86%E5%89%B2%E7%AD%89%E5%92%8C%E5%AD%90%E9%9B%86/"},{"categories":["算法题"],"content":"代码： class Solution: def canPartition(self, nums: List[int]) -\u003e bool: if sum(nums) % 2: return False s = sum(nums) // 2 dp = [False for _ in range(s+1)] dp[0] = True for i in range(1,len(nums)+1): for j in range(s,nums[i-1]-1,-1): # 容量 dp[j] = dp[j] or dp[j-nums[i-1]] # 用了or操作符 return dp[s] 更一般的套路，定义二维数组，然后二维dp # i代表前i个物品,j代表背包容量。 class Solution: def canPartition(self, nums: List[int]) -\u003e bool: if len(nums) \u003c= 1: return False if sum(nums) % 2: return False s = sum(nums) // 2 dp = [[False for _ in range(s+1)] for _ in range(len(nums)+1)] for i in range(len(nums)+1): dp[i][0] = True # 背包容量为0时 永远都是满的 所以为true for i in range(1,len(nums)+1): # 物品个数 for j in range(1,s+1): # 背包容量，最大为总和的一半，也就是需要求的 if j - nums[i-1] \u003c 0: # 如果容量小于当前物品的重量 dp[i][j] = dp[i-1][j] else: dp[i][j] = dp[i-1][j] or dp[i-1][j-nums[i-1]] if dp[i][s]: # 剪枝 return True return dp[len(nums)][s] '''首先，由于i是从 1 开始的，而数组索引是从 0 开始的，所以第i个物品的重量应该是nums[i-1]，这一点不要搞混。 dp[i - 1][j-nums[i-1]]也很好理解：你如果装了第i个物品，就要看背包的剩余重量j - nums[i-1]限制下是否能够被恰好装满。 换句话说，如果j - nums[i-1]的重量可以被恰好装满，那么只要把第i个物品装进去，也可恰好装满j的重量；否则的话，重量j肯定是装不满的。''' ","date":"2022-03-25","objectID":"/%E5%88%86%E5%89%B2%E7%AD%89%E5%92%8C%E5%AD%90%E9%9B%86/:3:0","tags":["算法题","分割等和子集"],"title":"分割等和子集","uri":"/%E5%88%86%E5%89%B2%E7%AD%89%E5%92%8C%E5%AD%90%E9%9B%86/"},{"categories":["面经"],"content":"kd树 knn算法就是用kd树实现的 ","date":"2022-03-21","objectID":"/kd%E6%A0%91/:0:0","tags":["面经","kd树"],"title":"kd树","uri":"/kd%E6%A0%91/"},{"categories":["面经"],"content":"二分查找 很简单 就不说了 ","date":"2022-03-21","objectID":"/kd%E6%A0%91/:1:0","tags":["面经","kd树"],"title":"kd树","uri":"/kd%E6%A0%91/"},{"categories":["面经"],"content":"BST 很简单 就不说了 ","date":"2022-03-21","objectID":"/kd%E6%A0%91/:2:0","tags":["面经","kd树"],"title":"kd树","uri":"/kd%E6%A0%91/"},{"categories":["面经"],"content":"多维数组 假设数组B为\\([[6, 2], [6, 3], [3, 5], [5, 0], [1, 2], [4, 9], [8, 1]]\\)，有一个元素x，我们要找到数组B中距离x最近的元素，应该如何实现呢？比较直接的想法是用数组B中的每一个元素与x求距离，距离最小的那个元素就是我们要找的元素。假设x = [1, 1]，那么用数组B中的所有元素与x求距离得到[5.0, 5.4, 4.5, 4.1, 1.0, 8.5, 7.0]，其中距离最小的是1，对应的元素是数组B中的[1, 2]，所以[1, 2]就是我们的查找结果。 ","date":"2022-03-21","objectID":"/kd%E6%A0%91/:3:0","tags":["面经","kd树"],"title":"kd树","uri":"/kd%E6%A0%91/"},{"categories":["面经"],"content":"kd-tree ","date":"2022-03-21","objectID":"/kd%E6%A0%91/:4:0","tags":["面经","kd树"],"title":"kd树","uri":"/kd%E6%A0%91/"},{"categories":["面经"],"content":"如何建立 你 1. 建立根节点； 选取方差最大的特征作为分割特征(或者根据深度选择) 选择该特征的中位数作为分割点； 将数据集中该特征小于中位数的传递给根节点的左儿子，大于中位数的传递给根节点的右儿子； 递归执行步骤2-4，直到所有数据都被建立到KD Tree的节点上为止。 不难看出，KD Tree的建立步骤跟BST是非常相似的，可以认为BST是KD Tree在一维数据上的特例。KD Tree的算法复杂度介于O(Log2(N))和O(N)之间。 ","date":"2022-03-21","objectID":"/kd%E6%A0%91/:5:0","tags":["面经","kd树"],"title":"kd树","uri":"/kd%E6%A0%91/"},{"categories":["面经"],"content":"为什么选择方差最大的维度 数据分割后分散的比较开，主要是为了减少回溯时间，减少子树的访问。 ","date":"2022-03-21","objectID":"/kd%E6%A0%91/:6:0","tags":["面经","kd树"],"title":"kd树","uri":"/kd%E6%A0%91/"},{"categories":["面经"],"content":"为什么选择中位数作为分割点 因为借鉴了BST，选取中位数，让左子树和右子树的数据数量一致，便于二分查找。 ","date":"2022-03-21","objectID":"/kd%E6%A0%91/:7:0","tags":["面经","kd树"],"title":"kd树","uri":"/kd%E6%A0%91/"},{"categories":["面经"],"content":"查找元素 从根节点出发进行查找，根据当前深度计算比较的特征维度，若目标节点的特征值小于当前节点的特征值则遍历左子树，否则遍历右子树 找到叶子结点后，将其暂时标记为当前最邻近的点 递归地向上回退，在回退时需要做： 如果当前节点与目标节点的距离更近，则更新最邻近节点为当前节点 如果当前节点对应特征与目标节点对应特征的值距离小于当前最小值时，进入当前节点的另一个子节点（因为刚刚从一个子节点遍历回来）进行查找（如果存在子节点的话），有可能存在更近的节点。否则的话继续向上回退。 回退到根节点结束。得到最邻近点。 class Node: def __init__(self, data, left=None, right=None): self.val = data self.left = left self.right = right class KDTree: def __init__(self, k): self.k = k def create_Tree(self, dataset, depth): if not dataset: return None mid_index = len(dataset) // 2 # 中位数索引 axis = depth % self.k # 选择的维度 sort_dataset = sorted(dataset, key=(lambda x: x[axis])) # 按照维度排序 mid_data = sort_dataset[mid_index] # 中位数索引对应的数据 cur_node = Node(mid_data) # 创建节点 left_data = sort_dataset[:mid_index] # 左子树数据 right_data = sort_dataset[mid_index+1:] # 右子树数据 cur_node.left = self.create_Tree(left_data, depth+1) # 递归创建左子树 cur_node.right = self.create_Tree(right_data, depth+1) # 递归创建右子树 # print(cur_node.val) return cur_node def search(self, tree, new_data): # kd树的搜索 self.near_node = None # 最近的节点 self.near_val = None # 最近的节点的值 def dfs(node, depth): if not node: return axis = depth % self.k # 当前深度对应选择的维度 if new_data[axis] \u003c node.val[axis]: # 如果新数据的维度值小于当前节点的维度值 dfs(node.left, depth+1) # 递归搜索左子树 else: dfs(node.right, depth+1) # 递归搜索右子树 # 到这就相当于到达了叶子节点 dist = self.distance(new_data, node.val) # 计算新数据与当前节点的距离 if not self.near_val or dist \u003c self.near_val: # 如果当前节点的距离小于最近的节点的距离 self.near_val = dist # 更新最近的节点的距离 self.near_point = node.val # 更新最近的节点的值 #判断是否要进入兄弟节点寻找 if abs(new_data[axis] - node.val[axis]) \u003c self.near_val: # 如果新数据的维度值与当前节点的维度值的差值小于最近的节点的距离，说明兄弟节点区域有可能存在更接近的值。 if new_data[axis] \u003c node.val[axis]: # 控制去兄弟节点而不是刚刚回溯来的节点。 dfs(node.right, depth+1) else: dfs(node.left, depth+1) dfs(tree, 0) return self.near_point def distance(self, point_1, point_2): res = 0 for i in range(self.k): res += (point_1[i] - point_2[i]) ** 2 return res ** 0.5 if __name__ == '__main__': data_set = [[2,3],[5,4],[9,6],[4,7],[8,1],[7,2]] new_data = [1,5] k = len(data_set[0]) kd_tree = KDTree(k) our_tree = kd_tree.create_Tree(data_set, 0) predict = kd_tree.search(our_tree, new_data) print('Nearest Point of {}: {}'.format(new_data,predict)) Nearest Point of [1, 5]: [2, 3] 借用一下别人画的解题过程 ## 参考 https://zhuanlan.zhihu.com/p/499241064#:~:text=kd%E6%A0%91%E7%94%A8%E4%BA%8E%E5%AF%B9k%E7%BB%B4,%E7%9A%84%E6%97%B6%E5%80%99%E9%9D%9E%E5%B8%B8%E8%80%97%E6%97%B6%E3%80%82 ","date":"2022-03-21","objectID":"/kd%E6%A0%91/:8:0","tags":["面经","kd树"],"title":"kd树","uri":"/kd%E6%A0%91/"},{"categories":["算法题"],"content":"最小公众前缀 leetcode上的简单题，最小公众前缀 有三种解法，一种常规，两种巧妙解法 # 最小公共前缀 #解1：常规解法 思路就是一个一个判断 先判断所有字符串第一个是否相同，不相同就返回，否则然后依次往后判断 def longestCommonPrefix1(strs): if len(strs) == 0: return '' if len(strs) == 1: return strs[0] minl=min([len(x) for x in strs]) #求最小长度 end = 0 while end \u003c minl: #判断是否到最小长度 for i in range(1,len(strs)): #以第一个字符串为基准 if strs[i][end] != strs[i-1][end]: #如果到end这里不再相等 则返回到end这里的字符串即最小公共前缀 return strs[0][:end] end+=1 return strs[0][:end] #常规方法容易想到 但是缺点是运行速度慢，从每次判断都要遍历所有字符串就可以看出 #解2: 通过ascii码来判断 #Python里字符串是可以比较的，按照ascII值排 def longestCommonPrefix2(strs): if not strs: return 0 s1 = max(strs) s2 = min(strs) #找出s1 s2的最小公共前缀即为整个列表的最小公共前缀 for i,s in enumerate(s2): if s1[i] != s: return s1[:i] return s2 #通过max 和 min 函数来找到列表里面最大最小的两个字符串 然后找到这两个字符串的最小公共前缀。 #解3：通过python语法糖 将每个字符串的每个对应字符串存为一组，用zip函数，比如说所有的字符串第一个存在一起，然后用set去重，如果留下了一个，则说明都重复了，则就是相同的 def longestCommonPrefix3(strs): if not strs: return 0 cc = list(map(set,zip(*strs))) #为什么用map呢 因为要对zip压缩后的每一个序列去重 res = '' #结果 for i,s in enumerate(cc): x = list(s) if len(x) \u003e 1: #如果长度大于1 说明有不一样的 则直接退出 break res += x[0] return res 如上！ ","date":"2022-03-20","objectID":"/%E6%9C%80%E5%B0%8F%E5%85%AC%E4%BC%97%E5%89%8D%E7%BC%80/:0:0","tags":["算法题","最小公众前缀"],"title":"最小公众前缀","uri":"/%E6%9C%80%E5%B0%8F%E5%85%AC%E4%BC%97%E5%89%8D%E7%BC%80/"},{"categories":["Machine Learning","回归算法"],"content":"参考：https://cuijiahua.com/blog/2017/12/ml_13_regtree_1.html ","date":"2022-03-16","objectID":"/%E6%A0%91%E5%9B%9E%E5%BD%92/:0:0","tags":["Machine Learning","回归算法","树回归"],"title":"树回归","uri":"/%E6%A0%91%E5%9B%9E%E5%BD%92/"},{"categories":["Machine Learning","回归算法"],"content":"1、ID3算法的弊端 回忆一下，决策树的树构建算法是ID3。ID3的做法是每次选取当前最佳的特征来分割数据，并按照该特征的所有可能取值来切分。也就是说，如果一个特征有4种取值，那么数据将被切分成4份。一旦按某特征切分后，该特征在之后的算法执行过程中将不会再起作用，所以有观点认为这种切分方式过于迅速。 除了切分过于迅速外，ID3算法还存在另一个问题，它不能直接处理连续型特征。只有事先将连续型特征离散化，才能在ID3算法中使用。但这种转换过程会破坏连续型变量的内在特性。 ","date":"2022-03-16","objectID":"/%E6%A0%91%E5%9B%9E%E5%BD%92/:1:0","tags":["Machine Learning","回归算法","树回归"],"title":"树回归","uri":"/%E6%A0%91%E5%9B%9E%E5%BD%92/"},{"categories":["Machine Learning","回归算法"],"content":"2、CART算法 与ID3算法相反，CART算法正好适用于连续型特征。CART算法使用二元切分法来处理连续型变量。而使用二元切分法则易于对树构建过程进行调整以处理连续型特征。具体的处理方法是：如果特征值大于给定值就走左子树，否则就走右子树。 CART算法有两步： 决策树生成：递归地构建二叉决策树的过程，基于训练数据集生成决策树，生成的决策树要尽量大；自上而下从根开始建立节点，在每个节点处要选择一个最好的属性来分裂，使得子节点中的训练集尽量的纯。不同的算法使用不同的指标来定义”最好”： 决策树剪枝：用验证数据集对已生成的树进行剪枝并选择最优子树，这时损失函数最小作为剪枝的标准。 决策树剪枝我们先不管，我们看下决策树生成。 在决策树的文章中，我们先根据信息熵的计算找到最佳特征切分数据集构建决策树。CART算法的决策树生成也是如此，实现过程如下： 使用CART算法选择特征 根据特征切分数据集合 构建树 ","date":"2022-03-16","objectID":"/%E6%A0%91%E5%9B%9E%E5%BD%92/:2:0","tags":["Machine Learning","回归算法","树回归"],"title":"树回归","uri":"/%E6%A0%91%E5%9B%9E%E5%BD%92/"},{"categories":["Machine Learning","回归算法"],"content":"推导 选择最优切分变量j与切分点s：遍历变量j，对规定的切分变量j扫描切分点s，选择使下式得到最小 值时的(j,s)对。其中Rm是被划分的输入空间， \\(\\mathrm{cm}\\) 是空间Rm对应的固定输出值。 \\[ \\min_{j, s}\\left[\\min_{c_{1}} \\sum_{x_{i} \\in R_{i}(j, s)}\\left(y_{i}-c_{1}\\right)^{2}+\\min_{c_{2}} \\sum_{x_{i} \\in R_{i}(j, s)}\\left(y_{i}-c_{1}\\right)^{2}\\right] \\] 用选定的(j,s)对，划分区域并决定相应的输出值 \\[ \\begin{gathered} R_{1}(j, s)={x \\mid x^{(j)} \\leq s}, R_{2}(j, s)={x \\mid x^{(j)}\u003es} \\\\\\\\ \\hat{c}_{m}=\\frac{1}{N_{m}} \\sum_{x_{i} \\in R_{m}(j, s)} y_{i} \\\\\\\\ x \\in R_{m}, m=1,2 \\end{gathered} \\] 继续对两个子区域调用上述步骤，将输入空间划分为 \\(M\\) 个区域R1,R2,..,Rm，生成决策树。 \\[ f(x)=\\sum_{m=1}^{M} \\hat{c}_{m} I\\left(x \\epsilon R_{m}\\right) \\] 当输入空间划分确定时，可以用平方误差来表示回归树对于训练数据的预测方法，用平方误差最小 的准则求解每个单元上的最优输出值。 ","date":"2022-03-16","objectID":"/%E6%A0%91%E5%9B%9E%E5%BD%92/:2:1","tags":["Machine Learning","回归算法","树回归"],"title":"树回归","uri":"/%E6%A0%91%E5%9B%9E%E5%BD%92/"},{"categories":["Machine Learning","回归算法"],"content":"实例 【机器学习】回归决策树-CSDN博客 ","date":"2022-03-16","objectID":"/%E6%A0%91%E5%9B%9E%E5%BD%92/:3:0","tags":["Machine Learning","回归算法","树回归"],"title":"树回归","uri":"/%E6%A0%91%E5%9B%9E%E5%BD%92/"},{"categories":["算法题"],"content":"搜索旋转排序数组 ","date":"2022-03-13","objectID":"/%E6%90%9C%E7%B4%A2%E6%97%8B%E8%BD%AC%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84/:0:0","tags":["算法题","搜索旋转排序数组"],"title":"搜索旋转排序数组","uri":"/%E6%90%9C%E7%B4%A2%E6%97%8B%E8%BD%AC%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84/"},{"categories":["算法题"],"content":"题目： https://leetcode-cn.com/problems/search-in-rotated-sorted-array/ ","date":"2022-03-13","objectID":"/%E6%90%9C%E7%B4%A2%E6%97%8B%E8%BD%AC%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84/:1:0","tags":["算法题","搜索旋转排序数组"],"title":"搜索旋转排序数组","uri":"/%E6%90%9C%E7%B4%A2%E6%97%8B%E8%BD%AC%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84/"},{"categories":["算法题"],"content":"思路： 明显的二分查找，不过不是有序数组了，而是部分有序，所以需要有判断 ","date":"2022-03-13","objectID":"/%E6%90%9C%E7%B4%A2%E6%97%8B%E8%BD%AC%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84/:2:0","tags":["算法题","搜索旋转排序数组"],"title":"搜索旋转排序数组","uri":"/%E6%90%9C%E7%B4%A2%E6%97%8B%E8%BD%AC%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84/"},{"categories":["算法题"],"content":"代码： class Solution(object): def search(self, nums, target): left, right = 0, len(nums) - 1 while left \u003c= right: mid = left + (right - left) // 2 if nums[mid] == target: return mid if nums[mid] \u003c nums[right]:#右边为升序 if nums[mid] \u003c target \u003c= nums[right]: left = mid + 1 else: right = mid if nums[left] \u003c= nums[mid]:#左边为升序 if nums[left] \u003c= target \u003c nums[mid]: right = mid else: left = mid + 1 return -1 ","date":"2022-03-13","objectID":"/%E6%90%9C%E7%B4%A2%E6%97%8B%E8%BD%AC%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84/:3:0","tags":["算法题","搜索旋转排序数组"],"title":"搜索旋转排序数组","uri":"/%E6%90%9C%E7%B4%A2%E6%97%8B%E8%BD%AC%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84/"},{"categories":["pandas"],"content":"pandas补充学习 推荐网站：http://joyfulpandas.datawhale.club/Content/Preface.html pandas核心操作手册：https://mp.weixin.qq.com/s/l1V5e726XixI0W3EDHx0Nw ","date":"2022-02-22","objectID":"/some_api/:0:0","tags":["pandas","learn_four"],"title":"learn_four","uri":"/some_api/"},{"categories":["pandas"],"content":"pd.join和pd.merge 可以说merge包含了join操作，merge支持两个df间行方向或列方向的拼接操作，默认列拼接，取交集，而join只是简化了merge的行拼接的操作 pandas的merge方法提供了一种类似于SQL的内存链接操作，官网文档提到它的性能会比其他开源语言的数据操作（例如R）要高效。 如果对于sql比较熟悉的话，merge也比较好理解。 merge的参数 on：列名，join用来对齐的那一列的名字，用到这个参数的时候一定要保证左表和右表用来对齐的那一列都有相同的列名。 left_on：左表对齐的列，可以是列名，也可以是和dataframe同样长度的arrays。 right_on：右表对齐的列，可以是列名，也可以是和dataframe同样长度的arrays。 left_index/ right_index: 如果是True的haunted以index作为对齐的key how：数据融合的方法。 sort：根据dataframe合并的keys按字典顺序排序，默认是，如果置false可以提高表现。 简单举一个刚刚在比赛中里面用到的例子 data = pd.merge(data1, data2, on=\"carid\", how=\"inner\") # 根据carid合并两个数据集 可以用pd.merge，也可以用dataframe.merge，更多的信息可以查阅官方API。 ## pd.concat 也是合并dataframe 用法： pd.concat([df1, df2]) # 纵向合并 pd.concat([df1, df2], axis=1) # 横向合并 参数 - ignore_index=True，重新设置合并后的dataframe对象的index值 - sort=False，列的顺序保持原样 - join : {“inner”, “outer”}，默认为outer。 ## pd.append # 语法结构 df.append(self, other, ignore_index=False, verify_integrity=False, sort=False) other 是它要追加的其他 DataFrame 或者类似序列内容 ignore_index 如果为 True 则重新进行自然索引 verify_integrity 如果为 True 则遇到重复索引内容时报错 sort 进行排序 ","date":"2022-02-22","objectID":"/some_api/:1:0","tags":["pandas","learn_four"],"title":"learn_four","uri":"/some_api/"},{"categories":["pandas"],"content":"同结构 将同结构的数据追加在原数据后面 ### 不同结构 没有的列会增加，没有的相应内容为空。 ### 可以合并追加多个 result = df1.append([df2, df3]) ","date":"2022-02-22","objectID":"/some_api/:1:1","tags":["pandas","learn_four"],"title":"learn_four","uri":"/some_api/"},{"categories":["pandas"],"content":"追加序列 s2 = pd.Series(['X0', 'X1', 'X2', 'X3'], index=['A', 'B', 'C', 'D']) result = df1.append(s2, ignore_index=True) ","date":"2022-02-22","objectID":"/some_api/:1:2","tags":["pandas","learn_four"],"title":"learn_four","uri":"/some_api/"},{"categories":["pandas"],"content":"追加字典列表 dicts = [{'A': 1, 'B': 2, 'C': 3, 'X': 4}, {'A': 5, 'B': 6, 'C': 7, 'Y': 8}] result = df1.append(dicts, ignore_index=True, sort=False) ","date":"2022-02-22","objectID":"/some_api/:1:3","tags":["pandas","learn_four"],"title":"learn_four","uri":"/some_api/"},{"categories":["pandas"],"content":"pd.rename DataFrame.rename(self, mapper=None, index=None, columns=None, axis=None, copy=True, inplace=False, level=None, errors=‘ignore’) 作用就是修改index或者columns的名字。使用时可以指定mapper，然后指定axis，默认axis=0，即修改index 也可以使用index=xxx,columns=xxx，同时进行修改。 ","date":"2022-02-22","objectID":"/some_api/:2:0","tags":["pandas","learn_four"],"title":"learn_four","uri":"/some_api/"},{"categories":["pandas"],"content":"pd.get_dummies 用于构造离散数据的独热编码 用法 training = pd.get_dummies(train_data, columns=[\"xxx\", \"xx\", \"x\"]) # 对xxx、xx、x这三列进行onehot编码 ","date":"2022-02-22","objectID":"/some_api/:3:0","tags":["pandas","learn_four"],"title":"learn_four","uri":"/some_api/"},{"categories":["pandas"],"content":"pd.melt 直观的看就是将宽数据转化为长数据。转化为variable-value这样的形式。 pandas.melt(frame, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None) 参数解释： frame:要处理的数据集。 id_vars:不需要被转换的列名。 value_vars:需要转换的列名，如果剩下的列全部都要转换，就不用写了。 var_name和value_name是自定义设置对应的列名。 col_level :如果列是MultiIndex，则使用此级别。 常常与seaborn的FacetGrid一起进行操作，示例： f = pd.melt(train_data, value_vars=numeric_features) g = sns.FacetGrid(f, col=\"variable\", col_wrap=2, sharex=False, sharey=False) # col_warp限制一行只有两个，sharx、sharey默认为True,与matplotlib.pyplot.subplots相反。 g = g.map(sns.distplot, \"value\") # 第一个参数可以自定义函数。 ","date":"2022-02-22","objectID":"/some_api/:4:0","tags":["pandas","learn_four"],"title":"learn_four","uri":"/some_api/"},{"categories":["pandas"],"content":"sns.pairplot seaborn一般与pandas的数据结合，因此不分开做笔记了。 根据官方文档，sns.pairplot是在数据集中绘制成对关系。用来展现变量两两之间的关系，比如线性、非线性、相关等等。 hue参数可以指定分类。与其它plot的hue参数一致。 一般都会使用参数diag_kind=\"kde\"，因为对角线上的变量x与y都是一样的，探究关系没有意义，因此展示核密度分布。 seaborn.pairplot(data, hue=None, hue_order=None, palette=None, vars=None, x_vars=None, y_vars=None, kind='scatter', diag_kind='hist', markers=None, size=2.5, aspect=1, dropna=True, plot_kws=None, diag_kws=None, grid_kws=None)¶ 数据指定： \u003e vars : 与data使用，否则使用data的全部变量。参数类型：numeric类型的变量list。 {x, y}_vars : 与data使用，否则使用data的全部变量。参数类型：numeric类型的变量list。 dropna : 是否剔除缺失值。参数类型：boolean, optional 特殊参数： \u003e kind : {‘scatter’, ‘reg’}, optional Kind of plot for the non-identity relationships. diag_kind : {‘hist’, ‘kde’}, optional。Kind of plot for the diagonal subplots. 基本参数： \u003e size : 默认 6，图的尺度大小（正方形）。参数类型：numeric hue : 使用指定变量为分类变量画图。参数类型：string (变量名) hue_order : list of strings Order for the levels of the hue variable in the palette palette : 调色板颜色 markers : 使用不同的形状。参数类型：list aspect : scalar, optional。Aspect * size gives the width (in inches) of each facet. {plot, diag, grid}_kws : 指定其他参数。参数类型：dicts ","date":"2022-02-22","objectID":"/some_api/:4:1","tags":["pandas","learn_four"],"title":"learn_four","uri":"/some_api/"},{"categories":["Machine Learning","分类算法"],"content":"线性判别分析(LDA) 线性判别分析，也就是LDA（与主题模型中的LDA区分开），现在常常用于数据的降维中，但从它的名字中可以看出来它也是一个分类的算法，而且属于硬分类，也就是结果不是概率，是具体的类别 ## 主要思想 1. 类内方差小 2. 类间方差大 ## 推导 这里以二类为例，即只有两个类别。 首先是投影，我们假定原来的数据是向量 \\(x\\)，那么顺着 \\(w\\) 方向的投影就是标量： \\[ z=w^T\\cdot x(=|w|\\cdot|x|\\cos\\theta) \\] 对第一点，相同类内部的样本更为接近，我们假设属于两类的试验样本数量分别是 \\(N_1\\)和 \\(N_2\\)，那么我们采用方差矩阵来表征每一个类内的总体分布，这里我们使用了协方差的定义，用 \\(S\\) 表示原数据的协方差： \\[ \\begin{align} C_1:Var_z[C_1]\u0026=\\frac{1}{N_1}\\sum\\limits_{i=1}^{N_1}(z_i-\\bar{z_{c1}})(z_i-\\bar{z_{c1}})^T\\nonumber\\\\\\\\\\\\\\\\ \u0026=\\frac{1}{N_1}\\sum\\limits_{i=1}^{N_1}(w^Tx_i-\\frac{1}{N_1}\\sum\\limits_{j=1}^{N_1}w^Tx_j)(w^Tx_i-\\frac{1}{N_1}\\sum\\limits_{j=1}^{N_1}w^Tx_j)^T\\nonumber\\\\\\\\\\\\\\\\ \u0026=w^T\\frac{1}{N_1}\\sum\\limits_{i=1}^{N_1}(x_i-\\bar{x_{c1}})(x_i-\\bar{x_{c1}})^Tw\\nonumber\\\\\\\\\\\\\\\\ \u0026=w^TS_1w\\\\\\\\\\\\\\\\ C_2:Var_z[C_2]\u0026=\\frac{1}{N_2}\\sum\\limits_{i=1}^{N_2}(z_i-\\bar{z_{c2}})(z_i-\\bar{z_{c2}})^T\\nonumber\\\\\\\\\\\\\\\\ \u0026=w^TS_2w \\end{align} \\] 所以类内距离为： \\[ \\begin{align} Var_z[C_1]+Var_z[C_2]=w^T(S_1+S_2)w \\end{align} \\] 对于第二点类间距离，我们可以用两类的均值表示这个距离： \\[ \\begin{align} (\\bar{z_{c1}}-\\bar{z_{c2}})^2\u0026=(\\frac{1}{N_1}\\sum\\limits_{i=1}^{N_1}w^Tx_i-\\frac{1}{N_2}\\sum\\limits_{i=1}^{N_2}w^Tx_i)^2\\nonumber\\\\\\\\\\\\\\\\ \u0026=(w^T(\\bar{x_{c1}}-\\bar{x_{c2}}))^2\\nonumber\\\\\\\\\\\\\\\\ \u0026=w^T(\\bar{x_{c1}}-\\bar{x_{c2}})(\\bar{x_{c1}}-\\bar{x_{c2}})^Tw \\end{align} \\] 合这两点，由于协方差是一个矩阵，于是我们用将这两个值相除来得到我们的损失函数，并最大化这个值： \\[ \\begin{align} \\hat{w}=\\mathop{argmax}\\limits_wJ(w)\u0026=\\mathop{argmax}\\limits_w\\frac{(\\bar{z_{c1}}-\\bar{z_{c2}})^2}{Var_z[C_1]+Var_z[C_2]}\\nonumber\\\\\\\\\\\\\\\\ \u0026=\\mathop{argmax}\\limits_w\\frac{w^T(\\bar{x_{c1}}-\\bar{x_{c2}})(\\bar{x_{c1}}-\\bar{x_{c2}})^Tw}{w^T(S_1+S_2)w}\\nonumber\\\\\\\\\\\\\\\\ \u0026=\\mathop{argmax}\\limits_w\\frac{w^TS_bw}{w^TS_ww} \\end{align} \\] 这样，我们就把损失函数和原数据集以及参数结合起来了。下面对这个损失函数求偏导，注意我们其实对w的绝对值没有任何要求，只对方向有要求，因此只要一个方程就可以求解了： \\[ \\begin{aligned} \u0026\\frac{\\partial}{\\partial w}J(w)=2S_bw(w^TS_ww)^{-1}-2w^TS_bw(w^TS_ww)^{-2}S_ww=0\\nonumber\\\\\\\\\\\\\\\\ \u0026\\Longrightarrow S_bw(w^TS_ww)=(w^TS_bw)S_ww\\nonumber\\\\\\\\\\\\\\\\ \u0026\\Longrightarrow w\\propto S_w^{-1}S_bw=S_w^{-1}(\\bar{x_{c1}}-\\bar{x_{c2}})(\\bar{x_{c1}}-\\bar{x_{c2}})^Tw\\propto S_w^{-1}(\\bar{x_{c1}}-\\bar{x_{c2}}) \\end{aligned} \\] 也就是说最后我们的结果就是\\(w=S_w^{-1}(\\bar{x_{c1}}-\\bar{x_{c2}})\\) 可以归一化求得单位的w值。 ","date":"2022-02-19","objectID":"/%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90/:0:0","tags":["Machine Learning","分类算法","线性判别分析"],"title":"线性判别分析","uri":"/%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90/"},{"categories":["Machine Learning","分类算法"],"content":"多类情况 前面的很容易类比二类的情况，现在的目标函数变成了： \\[ \\frac{W^TS_bW}{W^TS_wW} \\] 现在的问题就是这些都是矩阵，不能像上面那样直接优化，需要替换优化目标。 \\[ \\underbrace{arg\\;max}_W\\;\\;J(W) = \\frac{\\prod\\limits_{diag}W^TS_bW}{\\prod\\limits_{diag}W^TS_wW} \\] 其中 \\(\\prod_{diag}A\\)为A的主对角线元素的乘积,W为\\(n \\times d\\)的矩阵，n为原来的维度，d为映射到超平面的维度，则最终的目标就变成了： \\[ J(W) = \\frac{\\prod\\limits_{i=1}^dw_i^TS_bw_i}{\\prod\\limits_{i=1}^dw_i^TS_ww_i} = \\prod\\limits_{i=1}^d\\frac{w_i^TS_bw_i}{w_i^TS_ww_i} \\] 根据广式瑞利商，最大值是矩阵\\(S_w^{-1}S_b\\)的最大特征值,最大的d个值的乘积就是矩阵的 \\(S_w^{-1}S_b\\) 最大的d个特征值的乘积,此时对应的矩阵\\(W\\)为这最大的d个特征值对应的特征向量张成的矩阵。 ","date":"2022-02-19","objectID":"/%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90/:1:0","tags":["Machine Learning","分类算法","线性判别分析"],"title":"线性判别分析","uri":"/%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90/"},{"categories":["Machine Learning","分类算法"],"content":"总结 LDA是一种监督学习的降维技术，也就是说它的数据集的每个样本是有类别输出的。这点和PCA不同。PCA是不考虑样本类别输出的无监督降维技术。LDA的思想可以用一句话概括，就是“投影后类内方差最小，类间方差最大”。什么意思呢？ 我们要将数据在低维度上进行投影，投影后希望每一种类别数据的投影点尽可能的接近，而不同类别的数据的类别中心之间的距离尽可能的大。 实际上LDA除了可以用于降维以外，还可以用于分类。一个常见的LDA分类基本思想是假设各个类别的样本数据符合高斯分布，这样利用LDA进行投影后，可以利用极大似然估计计算各个类别投影数据的均值和方差，进而得到该类别高斯分布的概率密度函数。当一个新的样本到来后，我们可以将它投影，然后将投影后的样本特征分别带入各个类别的高斯分布概率密度函数，计算它属于这个类别的概率，最大的概率对应的类别即为预测类别。 LDA用于降维，和PCA有很多相同，也有很多不同的地方，因此值得好好的比较一下两者的降维异同点。 首先我们看看相同点： 1）两者均可以对数据进行降维。 2）两者在降维时均使用了矩阵特征分解的思想。 3）两者都假设数据符合高斯分布。 我们接着看看不同点： 1）LDA是有监督的降维方法，而PCA是无监督的降维方法 2）LDA降维最多降到类别数k-1的维数，而PCA没有这个限制。 3）LDA除了可以用于降维，还可以用于分类。 4）LDA选择分类性能最好的投影方向，而PCA选择样本点投影具有最大方差的方向。 ","date":"2022-02-19","objectID":"/%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90/:2:0","tags":["Machine Learning","分类算法","线性判别分析"],"title":"线性判别分析","uri":"/%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90/"},{"categories":["Machine Learning","分类算法"],"content":"代码 mean_list = [] for i in range(2): mean_list.append(np.mean(X_train[y_train==i], axis=0)) mean_list = np.array(mean_list) S_W = np.zeros((X_train.shape[1], X_train.shape[1])) # 类内散度矩阵 for c, mv in zip(range(2), mean_list): class_scatter = np.zeros((X_train.shape[1], X_train.shape[1])) for row in X_train[y_train==c]: row, mv = row.reshape(X_train.shape[1], -1), mv.reshape(X_train.shape[1], -1) class_scatter += (row-mv).dot((row-mv).T) S_W += class_scatter over_all_mean = np.mean(X_train, axis=0) S_B = np.zeros((X_train.shape[1], X_train.shape[1])) # 类间散度矩阵 for i, mean_vec in enumerate(mean_list): n = X_train[y_train==i, :].shape[0] mean_list_temp = mean_list[i, :].reshape(1, -1) over_all_mean = over_all_mean.reshape(X_train.shape[1], 1) S_B += n*(mean_vec-over_all_mean).dot((mean_vec-over_all_mean).T) eig_vals, eig_vecs = np.linalg.eig(np.linalg.inv(S_W).dot(S_B)) eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:, i]) for i in range(len(eig_vals))] eig_pairs = sorted(eig_pairs, key=lambda k: k[0], reverse=True) # eigv_sum = sum(eig_vals) # for i, j in enumerate(eig_pairs): # print('eigenvalue {0:}: {1:.2%}'.format(i + 1, (j[0] / eigv_sum).real)) # 根据百分比显示特征值，从而选取最大的n个特征值 W = np.hstack((eig_pairs[0][1].reshape(X_train.shape[1], 1), eig_pairs[1][1].reshape(X_train.shape[1], 1))) ","date":"2022-02-19","objectID":"/%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90/:3:0","tags":["Machine Learning","分类算法","线性判别分析"],"title":"线性判别分析","uri":"/%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90/"},{"categories":["Machine Learning","分类算法"],"content":"条件概率 \\(P(B|A) = \\frac{P(AB)}{P(A)}\\) ","date":"2022-02-16","objectID":"/bayes/:1:0","tags":["Machine Learning","分类算法","bayes"],"title":"bayes","uri":"/bayes/"},{"categories":["Machine Learning","分类算法"],"content":"乘法法则 如果P(A) \u003e 0 \\(P(AB) = P(A)P(B|A)\\) 如果\\(P(A_1 \\dots A_{n-1})\\) \u003e 0 则 \\[ \\begin{aligned} P(A_1A_2\\dots A_n) = P(A_1A_2\\dots A_{n-1})P(A_n | A_1A_2\\dots A_{n-1}) \\\\\\\\ = P(A_1)P(A_2|A_1)P(A_3|A_1A_2)\\dots P(A_n|A_1A_2\\dots A_{n-1}) \\end{aligned} \\] 其中第一步使用了乘法公式，然后再对前者继续使用乘法公式，以此类推，就可以得到最后的结果。 ","date":"2022-02-16","objectID":"/bayes/:2:0","tags":["Machine Learning","分类算法","bayes"],"title":"bayes","uri":"/bayes/"},{"categories":["Machine Learning","分类算法"],"content":"全概率公式(加法法则) \\[ P(A) = \\sum_{i=1}^n P(B_i)P(A\\lvert B_i) = \\sum_{i=1}^n P(AB_i) \\] 如果是连续变量则为 \\[ P(A) = \\int P(A,B) \\, dB \\] （加法规则与乘法规则结合是一些推导的基础，注意连续中的积分等同于离散中的连加） 特例为: \\[ P(A)=P(A\\lvert B)P(B) + P(A\\lvert \\bar{B})P(\\bar{B}) \\] 全概率公式的意义： 将复杂的事件A划分为较为简单的事件 \\[ AB_1,AB_2,\\ldots,AB_n \\] 再结合加法公式和乘法公式计算出A的概率 ## 贝叶斯公式 先引入一个小例子。 \\[ P(X=玩LOL)=0.6;\\\\\\\\ P(X=不玩LOL)=0.4 \\] 这个概率是根据统计得到或者根据自身经验给出的一个概率值，我们称之为先验概率(prior probability) 此外 \\[ P(Y=男性\\lvert X=玩LOL)=0.8,\\quad P(Y=小姐姐\\vert X=玩LOL)=0.2\\\\\\\\ P(Y=男性\\lvert X=不玩LOL)=0.2，\\quad P(Y=小姐姐\\vert X=不玩LOL)=0.8 \\] 求在已知玩家为男性的情况下，他是LOL玩家的概率是多少： 根据贝叶斯准则 \\[ P(X=玩LOL\\lvert Y=男性)=P(Y=男性\\lvert X=玩LOL)\\frac{P(X=玩LOL)}{[P(Y=男性\\lvert X=玩LOL)P(X=玩LOL)+P(Y=男性\\lvert X=不玩LOL)]P(X=不玩LOL)} \\] 分母为全概率公式 下面是贝叶斯公式的推导。 \\[ P(B\\lvert A)=\\frac{P(AB)}{P(A)}=\\frac{P(BA)}{P(A)}\\iff \\frac{P(B)P(A\\lvert B)}{\\displaystyle \\sum_{j=1}^n P(B_j)P(A\\lvert B_j)} \\] 贝叶斯公式的意义： 在事件A已经发生的条件下，贝叶斯公式可用来寻找导致A发生各种“原因”Bi的概率。 对于先验概率和后验概率来说， \\[ \\begin{aligned} P(B\\lvert A)为后验概率 \\\\\\\\ P(B)和P(A)为先验概率 \\\\\\\\ P(A\\vert B)为可能性 \\end{aligned} \\] ","date":"2022-02-16","objectID":"/bayes/:3:0","tags":["Machine Learning","分类算法","bayes"],"title":"bayes","uri":"/bayes/"},{"categories":["Machine Learning","分类算法"],"content":"介绍 朴素贝叶斯属于生成式模型， 其主要用于分类，属于是最简单的概率图模型，主要用到概率论中学到的贝叶斯公式，其中需要对模型进行假设，即贝叶斯假设。 ","date":"2022-02-16","objectID":"/bayes/:4:0","tags":["Machine Learning","分类算法","bayes"],"title":"bayes","uri":"/bayes/"},{"categories":["Machine Learning","分类算法"],"content":"贝叶斯假设 条件独立性假设(最简单的概率图模型(有向图))，目的是简化计算 ","date":"2022-02-16","objectID":"/bayes/:5:0","tags":["Machine Learning","分类算法","bayes"],"title":"bayes","uri":"/bayes/"},{"categories":["Machine Learning","分类算法"],"content":"推导 对于数据集\\(\\\\{(x_i, y_i)\\\\}^N_{i=1}\\)，\\(x_i \\in R^p , \\quad y_i \\in \\\\{ 0, 1\\\\}\\) \\[ \\begin{aligned} \\hat{y} \u0026= \\arg \\max(y|X) \\\\\\\\ \u0026 = \\arg \\max\\frac{P(X,y)}{P(X)} \\\\\\\\ \u0026 = \\arg \\max\\frac{P(y)P(X|y)}{P(X)} \\\\\\\\ \u0026 = \\arg \\max(y) P(X|y) \\\\\\\\ \u0026 = \\arg \\max(y)P(x_1,x_2,\\dots x_p| y) \\end{aligned} \\] 其中由于我们的条件独立性假设，因此\\(P(X|y)\\)可以写为\\(\\prod_{j=1}^pP(x_j|y)\\) 即最终的式子就是 \\[ \\hat{y} = \\arg \\max(y)\\prod_{j=1}^p P(x_j|y) \\] 这就是朴素贝叶斯的主要推导。 注意术语： \\(P(y)\\)为先验概率 \\(P(y|X)\\)为后验概率 \\(P(X,y)\\)为联合概率 MAP，即最大后验估计，选择有最高后验概率的类。 ","date":"2022-02-16","objectID":"/bayes/:6:0","tags":["Machine Learning","分类算法","bayes"],"title":"bayes","uri":"/bayes/"},{"categories":["Machine Learning","分类算法"],"content":"后验概率最大化的含义 （来自李航《统计学习方法》,比西瓜书上的更容易理解） ","date":"2022-02-16","objectID":"/bayes/:7:0","tags":["Machine Learning","分类算法","bayes"],"title":"bayes","uri":"/bayes/"},{"categories":["Machine Learning","分类算法"],"content":"极大似然估计 在朴素贝叶斯法中, 学习意味着估计 \\(P\\left(Y=c_{k}\\right)\\) 和 \\(P\\left(X^{(j)}=x^{(j)} \\mid Y=c_{k}\\right)\\) 。可以 应用极大似然估计法估计相应的概率。先验概率 \\(P\\left(Y=c_{k}\\right)\\) 的极大似然估计是 \\[ P\\left(Y=c_{k}\\right)=\\frac{\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right)}{N}, \\quad k=1,2, \\cdots, K \\] 设第 \\(j\\) 个特征 \\(x^{(j)}\\) 可能取值的集合为 \\(\\left\\{a_{j 1}, a_{j 2}, \\cdots, a_{j S_{j}}\\right\\}\\), 条件概率 \\(P\\left(X^{(j)}=a_{j l} \\mid Y=\\right.\\) \\(c_{k}\\) ) 的极大似然估计是 \\[ \\begin{aligned} \u0026P\\left(X^{(j)}=a_{j l} \\mid Y=c_{k}\\right)=\\frac{\\sum_{i=1}^{N} I\\left(x_{i}^{(j)}=a_{j l}, y_{i}=c_{k}\\right)}{\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right)} \\\\\\\\ \u0026j=1,2, \\cdots, n ; \\quad l=1,2, \\cdots, S_{j} ; \\quad k=1,2, \\cdots, K \\end{aligned} \\] 式中, \\(x_{i}^{(j)}\\) 是第 \\(i\\) 个样本的第 \\(j\\) 个特征; \\(a_{j l}\\) 是第 \\(j\\) 个特征可能取的第 \\(l\\) 个值; \\(I\\) 为指 示函数。 \\(S_j\\)为\\(x^{(j)}\\)的可能取值数，\\(K\\)为类别数。 ","date":"2022-02-16","objectID":"/bayes/:8:0","tags":["Machine Learning","分类算法","bayes"],"title":"bayes","uri":"/bayes/"},{"categories":["Machine Learning","分类算法"],"content":"拉普拉斯平滑 用极大似然估计可能会出现所要估计的概率值为 0 的情况。这时会影响到后验概 率的计算结果, 使分类产生偏差。解决这一问题的方法是采用贝叶斯估计。具体地, 条 件概率的贝叶斯估计是 \\[ P_{\\lambda}\\left(X^{(j)}=a_{j l} \\mid Y=c_{k}\\right)=\\frac{\\sum_{i=1}^{N} I\\left(x_{i}^{(j)}=a_{j l}, y_{i}=c_{k}\\right)+\\lambda}{\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right)+S_{j} \\lambda} \\] 式中 \\(\\lambda \\geqslant 0\\) 。等价于在随机变量各个取值的频数上赋予一个正数 \\(\\lambda\u003e0\\) 。当 \\(\\lambda=0\\) 时就 是极大似然估计。常取 \\(\\lambda=1\\), 这时称为拉普拉斯平滑 (Laplacian smoothing)。显然, 对任何 \\(l=1,2, \\cdots, S_{j}, k=1,2, \\cdots, K\\), 有 \\[ \\begin{aligned} \u0026P_{\\lambda}\\left(X^{(j)}=a_{j l} \\mid Y=c_{k}\\right)\u003e0 \\\\\\\\ \u0026\\sum_{l=1}^{S_{j}} P\\left(X^{(j)}=a_{j l} \\mid Y=c_{k}\\right)=1 \\end{aligned} \\] 同样, 先验概率的贝叶斯估计是 \\[ P_{\\lambda}\\left(Y=c_{k}\\right)=\\frac{\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right)+\\lambda}{N+K \\lambda} \\] ","date":"2022-02-16","objectID":"/bayes/:9:0","tags":["Machine Learning","分类算法","bayes"],"title":"bayes","uri":"/bayes/"},{"categories":["Machine Learning","分类算法"],"content":"文本分类 接下来是朴素贝叶斯在文本分类中的运用，这里以简单的二分类问题，情感分析为例。 ","date":"2022-02-16","objectID":"/bayes/:10:0","tags":["Machine Learning","分类算法","bayes"],"title":"bayes","uri":"/bayes/"},{"categories":["Machine Learning","分类算法"],"content":"如何定义几个概率？ \\(P(y=k)\\)很容易得到，可以只评估带有标签k的文档比例，即 \\[ P(y=k) = \\frac{N(y=k)}{\\sum_iN(y=i)} \\] \\(P(x|y=k)= P(x_1,x_2,\\dots, x_n | y=k)\\) 这里假设文档x被表示为一组特征，例如一组它的词\\((x_1,x_2,\\dots, x_n)\\) 这里需要两个假设，其中一个是上面提到的贝叶斯假设，即： - 条件独立假设：特征在给定类的情况下是独立的 - Bag of Words假设：词序无关紧要 直观地说，假设 每个单词出现在类别为k的文档中的概率不依赖上下文，因此得到： \\[ P(x|y=k) = P(x_1,x_2,\\dots,x_n|y=k) = \\prod_{t=1}^nP(x_t|y=k) \\] 概率\\(P(x_i|y=k)\\)为单词\\(x_i\\)出现在标签为k的文档中的频率，即 \\[ P(x_i|y=k) = \\frac{N(x_i, y=k)}{\\sum_{t=1}^{|V|}N(x_t,y=k)} \\] 但是有个问题就是有可能会出现\\(N(x_i, y=k)=0\\)的情况 这时就需要拉普拉斯平滑，即在所有的计数中都加入一个新的参数\\(\\delta\\)， \\[ P(x_i|y=k)=\\frac{ {\\delta} + N(x_i, y=k) }{\\sum\\limits_{t=1}^{|V|}( {\\delta} + N(x_t, y=k))} = \\frac{ {\\delta} + N(x_i, y=k) }{ {\\delta\\cdot |V|} + \\sum\\limits_{t=1}^{|V|} N(x_t, y=k)} , \\] 直观地说，朴素贝叶斯期望某些词作为类指示符。例如，对于情感分类标记 awesome、 brilliant、 great 将有更高的概率给定正面类别然后负面类别。 类似地，给定负类比正类 ，标记awful, boring, bad的概率更高。 在实践中，一般都是取log，单调性不变，变为\\(\\log(x, y=k) = \\log P(y=k) + \\sum \\log P(x_i|y=k)\\) ","date":"2022-02-16","objectID":"/bayes/:10:1","tags":["Machine Learning","分类算法","bayes"],"title":"bayes","uri":"/bayes/"},{"categories":["Machine Learning","分类算法"],"content":"补充：贝叶斯估计 易知\\(P(\\theta \\mid D)\\)称为后验概率，有三种估计\\(\\theta\\)的方法： 使用后验分布的密度函数最大值点作为\\(\\theta\\)的点估计的最大后验估计（MAP）。 使用后验分布的中位数作为\\(\\theta\\)的点估计的后验中位数估计（不常用）。 使用后验分布的均值作为\\(\\theta\\)的点估计的后验期望估计。 其中后验期望估计也就是贝叶斯估计。 贝叶斯估计是在MAP上做进一步拓展，不直接估计参数的值，而是允许参数服从一定的概率密度分布，先求出\\(\\theta\\)的后验分布\\(p(\\theta \\mid x)\\)，然后求出\\(\\theta\\)的期望值。 ","date":"2022-02-16","objectID":"/bayes/:11:0","tags":["Machine Learning","分类算法","bayes"],"title":"bayes","uri":"/bayes/"},{"categories":["pandas","api"],"content":"正为逆时针转，负为顺时针转。 import numpy as np mat = np.array([[1,3,5], [2,4,6], [7,8,9] ]) print mat, \"# orignal\" mat90 = np.rot90(mat, 1) print mat90, \"# rorate 90 \u003cleft\u003e anti-clockwise\" mat90 = np.rot90(mat, -1) print mat90, \"# rorate 90 \u003cright\u003e clockwise\" mat180 = np.rot90(mat, 2) print mat180, \"# rorate 180 \u003cleft\u003e anti-clockwise\" mat270 = np.rot90(mat, 3) print mat270, \"# rorate 270 \u003cleft\u003e anti-clockwise\" 直接复制的代码，python2，能看懂就行。 ","date":"2022-02-12","objectID":"/rot90/:0:0","tags":["pandas","api","rot90"],"title":"rot90","uri":"/rot90/"},{"categories":["比赛相关"],"content":"数据挖掘比赛 ","date":"2022-01-26","objectID":"/eda/:0:0","tags":["比赛相关","数据挖掘比赛"],"title":"数据挖掘比赛","uri":"/eda/"},{"categories":["比赛相关"],"content":"对赛题进行理解 ","date":"2022-01-26","objectID":"/eda/:1:0","tags":["比赛相关","数据挖掘比赛"],"title":"数据挖掘比赛","uri":"/eda/"},{"categories":["比赛相关"],"content":"数据分析 ","date":"2022-01-26","objectID":"/eda/:2:0","tags":["比赛相关","数据挖掘比赛"],"title":"数据挖掘比赛","uri":"/eda/"},{"categories":["比赛相关"],"content":"EDA目标 EDA的价值在于熟悉数据集，了解数据集，对数据集进行验证来确定所获得数据集可以用于接下来的机器学习或者深度学习使用。 当了解了数据集之后我们下一步就是要去了解变量间的相互关系以及变量与预测值之间的存在关系。 引导数据科学从业者进行数据处理以及特征工程的步骤,使数据集的结构和特征集让接下来的预测问题更加可靠。 完成对于数据的探索性分析，并对于数据进行一些图表或者文字总结并打卡。 ","date":"2022-01-26","objectID":"/eda/:2:1","tags":["比赛相关","数据挖掘比赛"],"title":"数据挖掘比赛","uri":"/eda/"},{"categories":["比赛相关"],"content":"主要操作 载入各种数据科学以及可视化库: 数据科学库 pandas、numpy、scipy； 可视化库 matplotlib、seabon； 其他； 载入数据： 载入训练集和测试集； 简略观察数据(head()+shape)； 数据总览: 通过describe()来熟悉数据的相关统计量 通过info()来熟悉数据类型 判断数据缺失和异常 查看每列的存在nan情况 异常值检测 了解预测值的分布 总体分布概况（无界约翰逊分布等） 查看skewness and kurtosis 查看预测值的具体频数 特征分为类别特征和数字特征，并对类别特征查看unique分布 数字特征分析 相关性分析 查看几个特征得 偏度和峰值 每个数字特征得分布可视化 数字特征相互之间的关系可视化 多变量互相回归关系可视化 类型特征分析 unique分布 类别特征箱形图可视化 类别特征的小提琴图可视化 类别特征的柱形图可视化类别 特征的每个类别频数可视化(count_plot) 用pandas_profiling生成数据报告 ","date":"2022-01-26","objectID":"/eda/:2:2","tags":["比赛相关","数据挖掘比赛"],"title":"数据挖掘比赛","uri":"/eda/"},{"categories":["比赛相关"],"content":"主要步骤 对于数据的初步分析（直接查看数据，或.sum(), .mean()，.descirbe()等统计函数）可以从：样本数量，训练集数量，是否有时间特征，是否是时许问题，特征所表示的含义（非匿名特征），特征类型（字符类似，int，float，time），特征的缺失情况（注意缺失的在数据中的表现形式，有些是空的有些是”NAN”符号等），特征的均值方差情况。 分析记录某些特征值缺失占比30%以上样本的缺失处理，有助于后续的模型验证和调节，分析特征应该是填充（填充方式是什么，均值填充，0填充，众数填充等），还是舍去，还是先做样本分类用不同的特征模型去预测。 对于异常值做专门的分析，分析特征异常的label是否为异常值（或者偏离均值较远或者事特殊符号）,异常值是否应该剔除，还是用正常值填充，是记录异常，还是机器本身异常等。 对于Label做专门的分析，分析标签的分布情况等。 进步分析可以通过对特征作图，特征和label联合做图（统计图，离散图），直观了解特征的分布情况，通过这一步也可以发现数据之中的一些异常值等，通过箱型图分析一些特征值的偏离情况，对于特征和特征联合作图，对于特征和label联合作图，分析其中的一些关联性。 记录自己之前没用到的东西 ### 数据的偏度和峰度 - 数据的偏度(skewness)：dataframe.skew() - 数据的峰度(kurtosis)：dataframe.kurt() ### log变换 一般要求预测值需要符合正态分布，因此需要先log变换一下 ### sns.pairplot 用来展现变量两两之间的关系，比如线性、非线性、相关 hue参数可以指定分类。 ","date":"2022-01-26","objectID":"/eda/:2:3","tags":["比赛相关","数据挖掘比赛"],"title":"数据挖掘比赛","uri":"/eda/"},{"categories":["比赛相关"],"content":"sns.heatmap 热度图，可以直观感受变量之间的相关程度。 更多的处理方法可以看pandas笔记 ","date":"2022-01-26","objectID":"/eda/:2:4","tags":["比赛相关","数据挖掘比赛"],"title":"数据挖掘比赛","uri":"/eda/"},{"categories":["比赛相关"],"content":"特征工程 ","date":"2022-01-26","objectID":"/eda/:3:0","tags":["比赛相关","数据挖掘比赛"],"title":"数据挖掘比赛","uri":"/eda/"},{"categories":["比赛相关"],"content":"主要步骤 异常处理： 通过箱线图（或 3-Sigma）分析删除异常值； BOX-COX 转换（处理有偏分布）； 长尾截断； 特征归一化/标准化： 标准化（转换为标准正态分布）； 归一化（抓换到 [0,1] 区间）； 针对幂律分布，可以采用公式：\\(log(\\frac{1+x}{1+median})\\) 数据分桶： 等频分桶； 等距分桶； Best-KS 分桶（类似利用基尼指数进行二分类）； 卡方分桶； 缺失值处理： 不处理（针对类似 XGBoost 等树模型）； 删除（缺失数据太多）； 插值补全，包括均值/中位数/众数/建模预测/多重插补/压缩感知补全/矩阵补全等； 分箱，缺失值一个箱； 特征构造： 构造统计量特征，报告计数、求和、比例、标准差等； 时间特征，包括相对时间和绝对时间，节假日，双休日等； 地理信息，包括分箱，分布编码等方法； 非线性变换，包括 log/ 平方/ 根号等； 特征组合，特征交叉； 仁者见仁，智者见智。 特征筛选： 过滤式（filter）：先对数据进行特征选择，然后在训练学习器，常见的方法有 Relief/方差选择发/相关系数法/卡方检验法/互信息法； 包裹式（wrapper）：直接把最终将要使用的学习器的性能作为特征子集的评价准则，常见方法有 LVM（Las Vegas Wrapper） ； 嵌入式（embedding）：结合过滤式和包裹式，学习器训练过程中自动进行了特征选择，常见的有 lasso 回归； 降维： PCA/LDA/LCA;本博客都有介绍 特征选择也是降维 ## 建模调参 ## 模型融合 ","date":"2022-01-26","objectID":"/eda/:3:1","tags":["比赛相关","数据挖掘比赛"],"title":"数据挖掘比赛","uri":"/eda/"},{"categories":["面经"],"content":"什么是前缀树？ 前缀树是N叉树的一种特殊形式。通常来说，一个前缀树是用来存储字符串的。前缀树的每一个节点代表一个字符串（前缀）。每一个节点会有多个子节点，通往不同子节点的路径上有着不同的字符。子节点代表的字符串是由节点本身的原始字符串，以及通往该子节点路径上所有的字符组成的。 在上图示例中，我们在节点中标记的值是该节点对应表示的字符串。例如，我们从根节点开始，选择第二条路径 ‘b’，然后选择它的第一个子节点 ‘a’，接下来继续选择子节点 ‘d’，我们最终会到达叶节点 “bad”。节点的值是由从根节点开始，与其经过的路径中的字符按顺序形成的。 值得注意的是，根节点表示空字符串。 前缀树的一个重要的特性是，节点所有的后代都与该节点相关的字符串有着共同的前缀。这就是前缀树名称的由来。 我们再来看这个例子。例如，以节点 “b” 为根的子树中的节点表示的字符串，都具有共同的前缀 “b”。反之亦然，具有公共前缀 “b” 的字符串，全部位于以 “b” 为根的子树中，并且具有不同前缀的字符串来自不同的分支。 前缀树有着广泛的应用，例如自动补全，拼写检查等等。 ","date":"2022-01-19","objectID":"/%E5%89%8D%E7%BC%80%E6%A0%91/:1:0","tags":["面经","前缀树"],"title":"前缀树","uri":"/%E5%89%8D%E7%BC%80%E6%A0%91/"},{"categories":["面经"],"content":"代码 import collections class TrieNode(object): # 定义节点 # Initialize your data structure here. def __init__(self): self.node = collections.defaultdict(TrieNode) self.char = \"\" self.is_word = False @property def data(self): return self.node def __getitem__(self, key): return self.node[key] def __str__(self) -\u003e str: return self.char __repr__ = __str__ class Trie(object): def __init__(self): \"\"\" Initialize your data structure here. \"\"\" self.root = TrieNode() def insert(self, word): \"\"\" Inserts a word into the trie. :type word: str :rtype: void \"\"\" node = self.root for chars in word: temp = node.char node = node[chars] # 因为defaultdict，如果不存在则自动生成键 node.char = temp + chars # 键可以视为路径上的字符，节点可以视为从根到当前节点表示的前缀或单词。 node.is_word = True # 这里很重要，用于search判断是否为完整的单词 def search(self, word): \"\"\" Returns if the word is in the trie. :type word: str :rtype: bool \"\"\" node = self.root for chars in word: if chars not in node.data.keys(): # 因为defaultdict所以不能判断value为None，要判断键是否存在 return False node = node[chars] # 判断单词是否是完整的存在在trie树中 return node.is_word def startsWith(self, prefix): \"\"\" Returns if there is any word in the trie that starts with the given prefix. :type prefix: str :rtype: bool \"\"\" node = self.root for chars in prefix: if chars not in node.data.keys(): # 和上面同理 return False node = node[chars] return True def get_all_words(self): # 获取所有的单词 q = [self.root] while q: node = q.pop(0) # 相当于一个队列 for child in node.data.values(): if child.is_word: yield child.char q.append(child) ","date":"2022-01-19","objectID":"/%E5%89%8D%E7%BC%80%E6%A0%91/:2:0","tags":["面经","前缀树"],"title":"前缀树","uri":"/%E5%89%8D%E7%BC%80%E6%A0%91/"},{"categories":["面经"],"content":"应用 前缀树在中文分词的应用，前缀树的实现和上面的可能不太一样，不过功能都是一样的，主要就是找句子中的词有没有出现在前缀树中。 from trie import Trie import time class TrieTokenizer(Trie): \"\"\" 基于字典树(Trie Tree)的中文分词算法 \"\"\" def __init__(self, dict_path): \"\"\" :param dict_path:字典文件路径 \"\"\" super(TrieTokenizer, self).__init__() self.dict_path = dict_path self.create_trie_tree() self.punctuations = \"\"\"！？｡＂＃＄％＆＇：（）＊＋，－／：；＜＝＞＠［＼］＾＿｀｛｜｝～｟｠｢｣､、〃》「」『』【】〔〕〖〗〘〙〚〛〜〝〞〟〰〾〿–—‘’‛“”„‟…‧﹏.\"\"\" def load_dict(self): \"\"\" 加载字典文件 词典文件内容如下，每行是一个词： AA制 ABC ABS AB制 AB角 :return: \"\"\" words = [] with open(self.dict_path, mode=\"r\", encoding=\"utf-8\") as file: for line in file: words.append(line.strip().encode('utf-8').decode('utf-8-sig')) return words def create_trie_tree(self): \"\"\" 遍历词典，创建字典树 :return: \"\"\" words = self.load_dict() for word in words: self.insert(word) def mine_tree(self, tree, sentence, trace_index): \"\"\" 从句子第trace_index个字符开始遍历查找词语，返回词语占位个数 :param tree: :param sentence: :param trace_index: :return: \"\"\" if trace_index \u003c= (len(sentence) - 1): if sentence[trace_index] in tree.data: trace_index = trace_index + 1 trace_index = self.mine_tree(tree.data[sentence[trace_index - 1]], sentence, trace_index) return trace_index def tokenize(self, sentence): tokens = [] sentence_len = len(sentence) while sentence_len != 0: trace_index = 0 # 从句子第一个字符开始遍历 trace_index = self.mine_tree(self.root, sentence, trace_index) if trace_index == 0: # 在字典树中没有找到以sentence[0]开头的词语 tokens.append(sentence[0:1]) # 当前字符作为分词结果 sentence = sentence[1:len(sentence)] # 重新遍历sentence sentence_len = len(sentence) else: # 在字典树中找到了以sentence[0]开头的词语，并且trace_index为词语的结束索引 tokens.append(sentence[0:trace_index]) # 命中词语作为分词结果 sentence = sentence[trace_index:len(sentence)] # sentence_len = len(sentence) return tokens def combine(self, token_list): \"\"\" TODO:对结果后处理：标点符号/空格/停用词 :param token_list: :return: \"\"\" flag = 0 output = [] temp = [] for i in token_list: if len(i) != 1: # 当前词语长度不为1 if flag == 0: output.append(i[::]) else: # ['该', '方法'] # temp=['该'] output.append(\"\".join(temp)) output.append(i[::]) temp = [] flag = 0 else: if flag == 0: temp.append(i) flag = 1 else: temp.append(i) return output if __name__ == '__main__': now = lambda: time.time() trie_cws = TrieTokenizer('data/32w_dic.txt') start = now() print(f\"Build Token Tree Time : {now() - start}\") sentence = '该方法的主要思想：词是稳定的组合，因此在上下文中，相邻的字同时出现的次数越多，就越有可能构成一个词。因此字与字相邻出现的概率或频率能较好地反映成词的可信度。' '可以对训练文本中相邻出现的各个字的组合的频度进行统计，计算它们之间的互现信息。互现信息体现了汉字之间结合关系的紧密程度。当紧密程 度高于某一个阈值时，' '便可以认为此字组可能构成了一个词。该方法又称为无字典分词。' tokens = trie_cws.tokenize(sentence) combine_tokens = trie_cws.combine(tokens) end = now() print(tokens) print(combine_tokens) print(f\"tokenize Token Tree Time : {end - start}\") ","date":"2022-01-19","objectID":"/%E5%89%8D%E7%BC%80%E6%A0%91/:3:0","tags":["面经","前缀树"],"title":"前缀树","uri":"/%E5%89%8D%E7%BC%80%E6%A0%91/"},{"categories":["Machine Learning","分类算法"],"content":"Logistic回归 ","date":"2022-01-15","objectID":"/logistic%E5%9B%9E%E5%BD%92/:0:0","tags":["Machine Learning","分类算法","Logistic回归"],"title":"Logistic回归","uri":"/logistic%E5%9B%9E%E5%BD%92/"},{"categories":["Machine Learning","分类算法"],"content":"线性回归 线性回归表达式： \\[ y = w^Tx+b \\] 广义回归模型： \\[ y = g^{-1}(w^Tx+b) \\] ","date":"2022-01-15","objectID":"/logistic%E5%9B%9E%E5%BD%92/:1:0","tags":["Machine Learning","分类算法","Logistic回归"],"title":"Logistic回归","uri":"/logistic%E5%9B%9E%E5%BD%92/"},{"categories":["Machine Learning","分类算法"],"content":"Sigmoid函数 在分类任务中，需要找到一个联系函数，即g，将线性回归的输出值与实际的标签值联系起来。因此可以使用Sigmoid函数 即： \\[ \\delta(z) = \\frac{1}{1+e^{-z}} \\] 对数几率其实是一种“sigmoid”函数，它将z值转化为一个接近 0 或 1 的 \\(y\\) 值: \\[ y=\\frac{1}{1+e^{-\\left(w^{T} x+b\\right)}} \\rightarrow \\operatorname{In} \\frac{y}{1-y}=w^{T} x+b \\] 若将y视为样本 \\(x\\) 作为正例的可能性，则1-y是其反例的可能性，两者的比值 \\(\\frac{y}{1-y}\\) 称为“几率”，反映了x作为正例的相对可能性，对几率取对 数则得到 \\(\\operatorname{In} \\frac{y}{1-y}\\) ，可以看出，上式其实是在用线性回归模型的预测结果去逼近真实标记的对数几率。所以该模型也被称作“对数几率回 归”。 ## 损失函数 \\[ J = -\\frac{1}{m}\\sum_{i=1}^my_i\\log(\\hat{y_i})+(1-y_i)\\log(1-\\hat{y}) \\] 实际上可以看作下面交叉熵损失函数形式在二分类问题上的形式： \\[ J = -\\frac{1}{m}\\sum_{i=1}^my_i\\log(\\hat{y_i}) \\] 这里的\\(y_i\\)与\\(\\hat{y_i}\\)都是向量，其长度就是类别的数量。其中\\(y_i\\)代表实际分布，形式上为onehot向量。\\(\\hat{y_i}\\)是概率分布，为预测的值。 其实这里可以想一下神经网络，对于sigmoid来说，输出层的神经元可以是一个，也可以是两个，如果是一个的话就可以用上面的形式，如果是两个的话可以用下面的这种形式。 也可以这样理解，对于softmax的这种形式，对于二分类我们可以拆分成这样 \\[ \\begin{cases} \\log \\hat{y_i}, \\quad y_i=1 \\\\\\\\ \\log (1-\\hat{y_i}), \\quad y_i=0 \\end{cases} \\] 再结合起来，这样就可以得到逻辑回归的损失函数的结果。 ## 与极大似然估计的关系 \\[ h(x;\\theta) = p(y=1|x;\\theta) = \\frac{1}{1+e^{-\\theta x+b}} \\] \\[ p(y=0|x;\\theta) = 1-p(y=1|x;\\theta) \\] 则对于单个样本： \\[ p(y|x;\\theta) = h(x;\\theta)^y(1-h(x;\\theta))^{(1-y)} \\] 接下来用极大似然估计估计出参数\\(\\theta\\) \\[ \\begin{aligned} L(\\theta) = \\prod_{i=1}^mp(y_i|x_i;\\theta)\\\\\\\\ =\\prod_{i=1}^mh(x_i;\\theta)^{y_i}(1-h(x_i;\\theta)) ^{1-y_i} \\end{aligned} \\] 则： \\[ l(\\theta) = \\ln L(\\theta) = \\sum_{i=1}^my_i\\ln (h(x_i;\\theta ))+(1-y_i)ln(1-h(x_i|\\theta)) \\] 极大这个函数，也就是最小化这个函数的负数，也就是上面的损失函数。 ","date":"2022-01-15","objectID":"/logistic%E5%9B%9E%E5%BD%92/:2:0","tags":["Machine Learning","分类算法","Logistic回归"],"title":"Logistic回归","uri":"/logistic%E5%9B%9E%E5%BD%92/"},{"categories":["Machine Learning","分类算法"],"content":"python实现 class LogisticRegression: def __init__(self): pass def sigmoid(self,a): res = [] for x in a: if x \u003e= 0: res.append(1/(1+np.exp(-x))) else: res.append(np.exp(x) / (np.exp(x) + 1)) return np.array(res) def train(self, X, y_true, n_iters=100, learning_rate=1): \"\"\" 根据给定的训练集X和y来训练逻辑回归 \"\"\" # 第零步：初始化参数 n_samples, n_features = X.shape #👆样本数m和特征量数n分别赋值为X的行数和列数 self.weights = np.zeros((n_features,1)) self.bias = 0 costs = [] for i in range(n_iters): # 第一步和第二步：计算输入的特征量和权值的线性组合，使用sigmoid函数 y_predict = self.sigmoid(np.dot(X,self.weights)+self.bias) # 第三步：计算代价值，用于之后计算代价函数值 cost = (-1/n_samples)*np.sum(y_true*np.log(y_predict+1e-5)+(1-y_true)*(np.log(1-y_predict+1e-5))) # 第四步：计算梯度 dw = (1/n_samples)*np.dot(X.T,(y_predict - y_true)) db = (1/n_samples)*np.sum(y_predict-y_true) # 第五步；更新参数 self.weights = self.weights - learning_rate * dw self.bias = self.bias - learning_rate * db costs.append(cost) if i%10 == 0: print(f\"Cost after iteration {i}:{cost}\") # return self.weights,self.bias,costs def predict(self,X): \"\"\" 对于测试集X，预测二元分类标签 \"\"\" y_predict = self.sigmoid(np.dot(X,self.weights)+self.bias) return np.array(y_predict) ","date":"2022-01-15","objectID":"/logistic%E5%9B%9E%E5%BD%92/:3:0","tags":["Machine Learning","分类算法","Logistic回归"],"title":"Logistic回归","uri":"/logistic%E5%9B%9E%E5%BD%92/"},{"categories":["pandas","api"],"content":"pd.melt ","date":"2022-01-12","objectID":"/melt/:0:0","tags":["pandas","api","melt"],"title":"melt","uri":"/melt/"},{"categories":["pandas","api"],"content":"用法 直观的看就是将宽数据转化为长数据。转化为variable-value这样的形式。 pandas.melt(frame, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None) 参数解释： frame:要处理的数据集。 id_vars:不需要被转换的列名。 value_vars:需要转换的列名，如果剩下的列全部都要转换，就不用写了。 var_name和value_name是自定义设置对应的列名。 col_level :如果列是MultiIndex，则使用此级别。 ## 实例 import pandas as pd df = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'}, 'B': {0: 1, 1: 3, 2: 5}, 'C': {0: 2, 1: 4, 2: 6} }) df ''' A B C 0 a 1 2 1 b 3 4 2 c 5 6 ''' pd.melt(df, id_vars=['A'], value_vars=['B']) ''' A variable value 0 a B 1 1 b B 3 2 c B 5 ''' pd.melt(df, id_vars=['A'], value_vars=['B', 'C']) ''' A variable value 0 a B 1 1 b B 3 2 c B 5 3 a C 2 4 b C 4 5 c C 6 ''' pd.melt(df, id_vars=['A'], value_vars=['B'], var_name='myVarName', value_name='myValueName') ''' A myVarName myValueName 0 a B 1 1 b B 3 2 c B 5 ''' pd.melt(df, id_vars=['A'], value_vars=['B', 'C'], ignore_index=False) ''' A variable value 0 a B 1 1 b B 3 2 c B 5 0 a C 2 1 b C 4 2 c C 6 ''' # 多重索引 df.columns = [list('ABC'), list('DEF')] df ''' A B C D E F 0 a 1 2 1 b 3 4 2 c 5 6 ''' # 选择最外层索引 pd.melt(df, col_level=0, id_vars=['A'], value_vars=['B']) ''' A variable value 0 a B 1 1 b B 3 2 c B 5 ''' # 选择内层索引 pd.melt(df, col_level=1, id_vars=['D'], value_vars=['E']) # 选择复合索引 pd.melt(df, id_vars=[('A', 'D')], value_vars=[('B', 'E')]) ''' (A, D) variable_0 variable_1 value 0 a B E 1 1 b B E 3 2 c B E 5 ''' ","date":"2022-01-12","objectID":"/melt/:1:0","tags":["pandas","api","melt"],"title":"melt","uri":"/melt/"},{"categories":["NLP"],"content":"预训练模型 ","date":"2022-01-03","objectID":"/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/:0:0","tags":["NLP","预训练模型"],"title":"预训练模型","uri":"/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"概述 预训练模型，则是使自然语言处理由原来的手工调参、依靠 ML 专家的阶段，进入到可以大规模、可复制的大工业施展的阶段。而且预训练模型从单语言、扩展到多语言、多模态任务。一路锐气正盛，所向披靡。 预训练通过自监督学习从大规模数据中获得与具体任务无关的预训练模型。体现某一个词在一个特定上下文中的语义表征。第二个步骤是微调，针对具体的任务修正网络。训练数据可以是文本、文本-图像对、文本-视频对。预训练模型的训练方法可使用自监督学习技术（如自回归的语言模型和自编码技术）。可训练单语言、多语言和多模态的模型。此类模型可经过微调之后，用于支持分类、序列标记、结构预测和序列生成等各项技术，并构建文摘、机器翻译、图片检索、视频注释等应用。 为什么我们要做预训练模型？首先，预训练模型是一种迁移学习的应用，利用几乎无限的文本，学习输入句子的每一个成员的上下文相关的表示，它隐式地学习到了通用的语法语义知识。第二，它可以将从开放领域学到的知识迁移到下游任务，以改善低资源任务，对低资源语言处理也非常有利。第三，预训练模型在几乎所有 NLP 任务中都取得了目前最佳的成果。最后，这个预训练模型+微调机制具备很好的可扩展性，在支持一个新任务时，只需要利用该任务的标注数据进行微调即可，一般工程师就可以实现。 ","date":"2022-01-03","objectID":"/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/:1:0","tags":["NLP","预训练模型"],"title":"预训练模型","uri":"/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"发展趋势 首先，第一个关键技术是 Transformer。它在 NLP 各个任务中都取得了优异的性能，它是预训练语言模型的核心网络。给定一句话或是一个段落作为输入，首先将输入序列中各个词转换为其对应的词向量，同时加上每一个词的位置向量，体现词在序列的位置。然后将这些词向量输入到多层 Transformer 网络中，通过自注意力（self-attention）机制来学习词与词之间的关系，编码其上下文信息，再通过一个前馈网络经过非线性变化，输出综合了上下文特征的各个词的向量表示。每一层 Transformer 网络主要由 Multi-head self-attention 层（多头自注意力机制）和前馈网络层两个子层构成。Multi-head self-attention 会并行地执行多个不同参数的 self-attention，并将各个 self-attention 的结果拼接作为后续网络的输入，self-attention 机制会在后面中做详细介绍。此后，我们得到了蕴含当前上下文信息的各个词的表示，然后网络会将其输入到前馈网络层以计算非线性层次的特征。 在每一层 Transformer 网络中，会将残差连接（residual connection）把自注意力机制前或者前馈神经网络之前的向量引入进来，以增强自注意力机制或者前馈网络的输出结果向量。并且还做一个 layer normalization，也就是通过归一化把同层的各个节点的多维向量映射到一个区间里面，这样各层节点的向量在一个区间里面。这两个操作加入在每个子层后，可更加平滑地训练深层次网络。 Transformer 可以用于编码，也可以用于解码。所谓解码就是根据一个句子的输入得到一个预想的结果，比如机器翻译（输入源语言句子，输出目标语言句子），或者阅读理解（输入文档和问题，输出答案）。解码时，已经解码出来的词要做一个自注意力机制，之后和编码得到的隐状态的序列再做一个注意力机制。这样可以做 N 层，然后通过一个线性层映射到词表的大小的一个向量。每个向量代表一个词表词的输出可能性，经过一个softmax 层得到每个词的输出概率。 接下来介绍一下 self-attention 机制，以一个 head 作为示例。假定当前输入包含三个词，给定其输入词向量或是其上一层 Transformer 网络的输出，将其通过三组线性变换，转换得到三组 queries、keys 和 values 向量。Query 和 key 向量用来计算两两词之间的得分，也就是其依赖关系，这个得分会同其对应的 value 向量做加权和，以得到每个词综合上下文信息的表示。给定当前第一个词的 query 向量，其首先同各个词的 key 向量通过点积操作得到这两个词的得分，这些得分用来表示这两个词的依赖或是相关程度。这些得分之后会根据 query 等向量的维度做一定比例的缩放，并将这些得分通过 softmax 操作做归一化。之后，各个得分会同其相对应的 value 向量相乘得到针对第一个词加权的各个 value 向量，这些加权的 value 向量最终相加以得到当前第一个词的上下文表示。 在得到第一个词的上下文表示后，给定第二个词的 query 向量，我们会重复之前的操作，计算当前 query 向量同各个词 key 向量的得分，对这些得分做 softmax 归一化处理，并将这些得分同其对应的 value 向量做加权和，以得到其编码上下文信息的表示。 第二个关键技术是自监督学习。在预训练的模型中，AR（自回归）LM 和 AE（自动编码器）是最常用的自监督学习方法，其中，自回归 LM 旨在利用前面的词序列预测下个词的出现概率（语言模型）。自动编码器旨在对损坏的输入句子，比如遮掩了句子某个词、或者打乱了词序等，重建原始数据。通过这些自监督学习手段来学习单词的上下文相关表示。 第三个关键技术就是微调。在做具体任务时，微调旨在利用其标注样本对预训练网络的参数进行调整。以我们使用基于 BERT（一种流行的预训练模型）为例来判断两个句子是否语义相同。输入是两个句子，经过 BERT 得到每个句子的对应编码表示，我们可以简单地用预训练模型的第一个隐节点预测分类标记判断两个句子是同义句子的概率，同时需要额外加一个线性层和 softmax 计算得到分类标签的分布。预测损失可以反传给 BERT 再对网络进行微调。当然也可以针对具体任务设计一个新网络，把预训练的结果作为其输入。 总体来讲，预训练模型发展趋势：第一，模型越来越大。比如 Transformer 的层数变化，从12层的 Base 模型到24层的 Large 模型。导致模型的参数越来越大，比如 GPT 110 M，到 GPT-2 是1.5 Billion，图灵是 17 Billion，而 GPT-3 达到了惊人的 175 Billion。一般而言模型大了，其能力也会越来越强，但是训练代价确实非常大。第二，预训练方法也在不断增加，从自回归 LM，到自动编码的各种方法，以及各种多任务训练等。第三，还有从语言、多语言到多模态不断演进。最后就是模型压缩，使之能在实际应用中经济的使用，比如在手机端。这就涉及到知识蒸馏和 teacher-student models，把大模型作为 teacher，让一个小模型作为 student 来学习，接近大模型的能力，但是模型的参数减少很多。 每个观点都可以看一下参考文章。 ","date":"2022-01-03","objectID":"/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/:2:0","tags":["NLP","预训练模型"],"title":"预训练模型","uri":"/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"深层表征阶段 在word embedding这篇文章里面，介绍了传统的词向量，也就是固定的词向量。本文将介绍deep contextualized词向量模型。也就是深层表征阶段。 两个伟大的想法： 编码的内容：从单词到上下文中的单词 （从 Word2Vec/GloVe/etc. 到 Cove/ELMo 的过渡） 用于下游任务：从仅替换特定任务模型中的词嵌入到替换整个特定任务模型 （从 Cove/ELMo 到 GPT/BERT 的过渡）。 具体的模型可以看本博客其余内容。 ","date":"2022-01-03","objectID":"/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/:3:0","tags":["NLP","预训练模型"],"title":"预训练模型","uri":"/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"参考 https://www.zhihu.com/question/327642286 https://zhuanlan.zhihu.com/p/115014536 ","date":"2022-01-03","objectID":"/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/:4:0","tags":["NLP","预训练模型"],"title":"预训练模型","uri":"/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"},{"categories":["pandas","api"],"content":"矩阵的反转，可以按照各个维度很好理解。 例子： cs_matrix = np.array([[ 4, 3, 2, 1, 0], [ 8, 7, 6, 5, 1], [11, 10, 9, 6, 2], [13, 12, 10, 7, 3], [14, 13, 11, 8, 4]]) np.flip(cs_matrix, 0) 变成了： np.flip(cs_matrix, 1) 变成了： ","date":"2022-01-01","objectID":"/flip/:0:0","tags":["pandas","api","flip"],"title":"flip","uri":"/flip/"},{"categories":["NLP"],"content":"ELMo 在Transformer中提到了ELMo解决了word2vec中存在的多义词问题，其使用双向的LSTM作为特征提取器，考虑了上下文的语义，所以可以解决多义词问题。这篇文章就详细介绍一下ELMo。 ElMo与CoVe很类似，不过它不是基于机器翻译模型，而是语言模型。仅仅通过用来自 LM 的嵌入替换词嵌入 (GloVe)，他们就在问答、共指解析、情感分析、命名实体识别等多项任务上获得了巨大的改进。 ","date":"2021-12-12","objectID":"/elmo/:0:0","tags":["NLP","ELMo"],"title":"ELMo","uri":"/elmo/"},{"categories":["NLP"],"content":"模型训练(char-CNN 之上的前向和后向 LSTM-LMs) 该模型非常简单，它由两层 LSTM 语言模型组成：前向和后向。使用这两种模型是为了使每个标记都可以具有两个上下文：左和右。 同样有趣的是作者如何获得初始单词表示（然后将其馈送到 LSTM）。让我们回想一下，在标准词嵌入层中，对于词汇表中的每个词，我们训练一个唯一的向量。在这种情况下， - 词嵌入不知道它们所包含的字符（例如，它们不知道单词represent, represents, represented, 和 representation在书面上是接近的） - OOV问题 为了解决这些问题，作者将单词表示为字符级网络的输出。正如我们从插图中看到的，这个 CNN 非常简单，由我们之前已经看到的组件组成：卷积、全局池化、highway connections和线性层。通过这种方式，单词表示通过构造知道它们的字符，我们甚至可以表示那些我们在训练中从未见过的单词。 ","date":"2021-12-12","objectID":"/elmo/:1:0","tags":["NLP","ELMo"],"title":"ELMo","uri":"/elmo/"},{"categories":["NLP"],"content":"获取表示 训练模型后，我们可以使用它来获取单词表示。为此，对于每个单词，我们结合来自前向和后向 LSTM 的相应层的表示。通过连接这些前向和后向向量，我们构建了一个“知道”左右上下文的单词表示。 总体而言，ELMo 表示具有三层： 第 0 层（嵌入） - 字符级 CNN 的输出； 第 1 层- 来自前向和后向 LSTM 的第 1 层的连接表示； 第 2 层- 来自前向和后向 LSTM 的第 2 层的连接表示； 这些层中的每一层都对不同类型的信息进行编码：第 0 层 - 仅单词级别，第 1 层和第 2 层 - 上下文中的单词。比较第 1 层和第 2 层，第 2 层可能包含更多高级信息：这些表示来自相应 LM 的更高层。 由于不同的下游任务需要不同种类的信息，ELMo 使用特定于任务的权重来组合来自三层的表示。这些是为每个下游任务学习的标量。得到的向量，即所有层表示的加权和，用于表示一个单词。 ","date":"2021-12-12","objectID":"/elmo/:2:0","tags":["NLP","ELMo"],"title":"ELMo","uri":"/elmo/"},{"categories":["NLP"],"content":"总结 CoVe和ELMo都用了上下文单词，解决了word2vec中多义词的问题。但他们主要是替换嵌入层，并保持特定于任务的模型架构几乎完好无损。这意味着例如，对于共指解决，必须使用为此任务设计的特定模型，用于词性标记 - 一些其他模型，用于问答 - 另一个非常特殊的模型等。对于这些任务中的每一个，专门研究它的研究人员不断改进特定于任务的模型架构。 与以前的模型相比，GPT/BERT 不是作为词嵌入的替代品，而是作为特定任务模型的替代品。在这个新设置中，首先使用大量未标记数据（纯文本）对模型进行预训练。然后，该模型在每个下游任务上进行微调。重要的是，现在在微调期间，您必须只使用任务感知输入转换（即以某种方式提供数据）， 而不是 修改模型架构。 ","date":"2021-12-12","objectID":"/elmo/:3:0","tags":["NLP","ELMo"],"title":"ELMo","uri":"/elmo/"},{"categories":["Machine Learning","集成学习"],"content":"Stacking ","date":"2021-11-25","objectID":"/stacking/:0:0","tags":["Machine Learning","集成学习","Stacking"],"title":"Stacking","uri":"/stacking/"},{"categories":["Machine Learning","集成学习"],"content":"思想简介 简单得理解，就是对于多个学习器，分别对结果进行预测，然后将预测的结果作为特征，再对结果进行预测。 上一张经典的图： 以这个5折stacking为例： 首先将所有数据集生成测试集和训练集（假如训练集为10000,测试集为2500行），那么上层会进行5折交叉检验，使用训练集中的8000条作为训练集，剩余2000行作为验证集（橙色）。 每次验证相当于使用了蓝色的8000条数据训练出一个模型，使用模型对验证集进行验证得到2000条数据，并对测试集进行预测，得到2500条数据，这样经过5次交叉检验，可以得到中间的橙色的\\(5\\times 2000\\)条验证集的结果(相当于每条数据的预测结果)，\\(5\\times 2500\\)条测试集的预测结果。 接下来会将验证集的\\(5\\times 2000\\)条预测结果拼接成10000行长的矩阵，标记为A1，而对于\\(5\\times 2500\\)行的测试集的预测结果进行加权平均，得到一个2500一列的矩阵，标记为B1。 上面得到一个基模型在数据集上的预测结果A1、B1,这样当我们对3个基模型进行集成的话，相于得到了A1、A2、A3、B1、B2、B3六个矩阵。 之后我们会将A1、A2、A3并列在一起成10000行3列的矩阵作为training data,B1、B2、B3合并在一起成2500行3列的矩阵作为testing data，让下层学习器基于这样的数据进行再训练。 再训练是基于每个基础模型的预测结果作为特征（三个特征），次学习器会学习训练如果往这样的基学习的预测结果上赋予权重w，来使得最后的预测最为准确。 ","date":"2021-11-25","objectID":"/stacking/:1:0","tags":["Machine Learning","集成学习","Stacking"],"title":"Stacking","uri":"/stacking/"},{"categories":["Machine Learning","集成学习"],"content":"伪代码 ","date":"2021-11-25","objectID":"/stacking/:2:0","tags":["Machine Learning","集成学习","Stacking"],"title":"Stacking","uri":"/stacking/"},{"categories":["Machine Learning","回归算法"],"content":"参考：https://cuijiahua.com/blog/2017/11/ml_11_regression_1.html ","date":"2021-11-25","objectID":"/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/:0:0","tags":["Machine Learning","回归算法","线性回归"],"title":"线性回归","uri":"/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"},{"categories":["Machine Learning","回归算法"],"content":"什么是回归？ 回归的目的是预测数值型的目标值。最直接的办法是依据输入写出一个目标值的计算公式。 HorsePower = 0.0015 * annualSalary - 0.99 * hoursListeningToPublicRadio 这就是所谓的回归方程（regression equation），其中的0.0015和-0.99称为回归系数（regression weights），求这些回归系数的过程就是回归。一旦有了这些回归系数，再给定输入，做预测就非常容易了。具体的做法是用回归系数乘以输入值，再将结果全部加在一起，就得到了预测值。 说到回归，一般都是指线性回归（linear regression），所以本文里的回归和线性回归代表同一个意思。线性回归意味着可以将输入项分别乘以一些常量，再将结果加起来得到输出。 这里的线性可以是对变量的线性，也可以是对参数的线性。比如\\(y=x^2\\)可以认为是一个线性函数。 ","date":"2021-11-25","objectID":"/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/:1:0","tags":["Machine Learning","回归算法","线性回归"],"title":"线性回归","uri":"/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"},{"categories":["Machine Learning","回归算法"],"content":"正规方程推导 将向量表达形式转为矩阵表达形式，则有 \\(J(\\theta)=\\frac{1}{2}(X \\theta-y)^{2}\\) ，其中 \\(X\\) 为 \\(m\\) 行 \\(n\\) 列的矩阵（ \\(m\\) 为样本个数， \\(n\\) 为特 征个数)， \\(\\theta\\) 为 \\(n\\) 行1列的矩阵， \\(y\\) 为 \\(m\\) 行1列的矩阵，对 \\(J(\\theta)\\) 进行如下变换 \\[ \\begin{aligned} \u0026J(\\theta)=\\frac{1}{2}(X \\theta-y)^{T}(X \\theta-y) \\\\\\\\ \u0026=\\frac{1}{2}\\left(\\theta^{T} X^{T}-y^{T}\\right)(X \\theta-y) \\\\\\\\ \u0026=\\frac{1}{2}\\left(\\theta^{T} X^{T} X \\theta-\\theta^{T} X^{T} y-y^{T} X \\theta-y^{T} y\\right) \\end{aligned} \\] 接下来对 \\(J(\\theta)\\) 偏导，需要用到以下几个矩阵的求导法则: \\[ \\begin{aligned} \u0026\\frac{d A B}{d B}=A^{T} \\\\\\\\ \u0026\\frac{d X^{T} A X}{d X}=2 A X \\end{aligned} \\] 所以有: \\[ \\begin{aligned} \u0026\\frac{\\partial J(\\theta)}{\\partial \\theta}=\\frac{1}{2}\\left(2 X^{T} X \\theta-X^{T} y-\\left(y^{T} X\\right)^{T}-0\\right) \\\\\\\\ \u0026=\\frac{1}{2}\\left(2 X^{T} X \\theta-X^{T} y-X^{T} y-0\\right) \\\\\\\\ \u0026=X^{T} X \\theta-X^{T} y \\\\\\\\ \u0026\\text { 令 } \\frac{\\partial J(\\theta)}{\\partial \\theta}=0 ｝ \\\\\\\\ {\\text { 则有 } \\theta=\\left(X^{T} X\\right)^{-1} X^{T} y} \\end{aligned} \\] 值得注意的是，上述公式中包含逆矩阵，也就是说，这个方程只在逆矩阵存在的时候使用，也即是这个矩阵是一个方阵，并且其行列式不为0。 除了这种方法，也可以使用最小二乘法来解决。 ","date":"2021-11-25","objectID":"/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/:2:0","tags":["Machine Learning","回归算法","线性回归"],"title":"线性回归","uri":"/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"},{"categories":["Machine Learning","回归算法"],"content":"局部加权线性回归 线性回归的一个问题是有可能出现欠拟合现象，因为它求的是具有小均方误差的无偏估 计。显而易见，如果模型欠拟合将不能取得好的预测效果。所以有些方法允许在估计中引入一 些偏差，从而降低预测的均方误差。 其中的一个方法是局部加权线性回归（Locally Weighted Linear Regression，LWLR）。 普通线性回归: \\[ \\min J_R=\\sum_{i=1}^m\\left(g\\left(x_i\\right)-y_i\\right)^2 \\] 局部加权线性回归: \\[ \\min J_{L R}=\\sum_{i=1}^m \\theta_i\\left(g\\left(x_i\\right)-y_i\\right)^2 \\] 这里唯一的区别是加入了权重 \\(\\theta\\), 采用之前的最小二乘法求解权数 \\(\\mathbf{w}\\) : \\[ \\hat{\\mathbf{w}}^* =\\arg \\min_{\\hat{\\mathbf{w}}} \\theta(\\mathbf{y}-\\mathbf{X} \\hat{\\mathbf{w}})^T(\\mathbf{y}-\\mathbf{X} \\hat{\\mathbf{w}}) \\] 在该方法中，我们给待预测点附近的每个点赋予一定的权重。与kNN一样，这种算法每次预测均需要事先选取出对应的数据子集。该算法解除回归系数W的形式如下： \\[ \\hat{w} = (X^T\\theta X)^{-1}X^T\\theta y \\] 其中W是一个矩阵，这个公式跟我们上面推导的公式的区别就在于W，它用来给每个店赋予权重。 LWLR使用”核”（与支持向量机中的核类似）来对附近的点赋予更高的权重。核的类型可以自由选择，最常用的核就是高斯核，高斯核对应的权重如下： \\[ \\theta(i,i) = exp\\left ( \\frac{ (x^{(i)}-x)^2}{-2k^2}\\right) \\] 这样就构造了一个只含对角元素的权重矩阵 \\(w\\) ，并且点xi与 \\(x\\) 越接近， \\(\\theta(i, i)\\) 的值越大，当 \\(x i\\) 与 \\(x\\) 非常接近时， \\(\\theta(i, i)\\) 的值趋于 1 ，我们再回头看之前的优化式: \\[ \\min J_{L R}=\\sum_{i=1}^m \\theta_i\\left(g\\left(x_i\\right)-y_i\\right)^2 \\] 对于一个数据点，与其靠近的点，权重大，与其相距较远的点，权重小，从而优化问题会有所偏倚，靠近的点对该数据点的回归拟合起较大作用，而相距较远的 点由于权数很小，造成的影响基本可以忽略不计，这样就等同于每个点的回归都是基于与其相距较近的点为基础，而忽略了较远的点，这也就是同部加权线性回归局部的由来，因为它着重考虑目标点同部的数据点为回归基础. 可以看到，加权函数只有一个系数，那就是分母上的 \\(k\\) ，当K取很小时， exp得到的很多值均趋于 0 ，此时只有很少一部分样本用于训练，而当k取很大时， exp的值 不会很快趋于 0 ，从而会有一大部分点用于训练，我们可以通过调整k的值，决定这个‘局部’的大小究竟是多大 如果数据的特征比样本点还多应该怎么办？如果矩阵有多重共线性怎么办？很显然，此时我们不能再使用上文的方法进行计算了，因为矩阵X不是满秩矩阵，非满秩矩阵在求逆时会出现问题。 解决的方法就是正则化。在线性回归中，正则化主要有L1正则化与L2正则化，L1正则化对应LASSO回归，L2正则化对应岭回归。 #!/usr/bin/env python #-*- coding:utf-8 -*- from numpy import * import matplotlib.pyplot as plt \"\"\" 打开一个用tab键分隔的文本文件 parameters: fileName -文件名 return: dataMat -数据矩阵 labelMat -目标值向量 \"\"\" def loadDataSet(fileName): numFeat = len(open(fileName).readline().split('\\t')) - 1 #得到列数，不包括最后一列，默认最后一列值为目标值 dataMat = []; labelMat = [] fr = open(fileName) for line in fr.readlines(): lineArr =[] curLine = line.strip().split('\\t') for i in range(numFeat): lineArr.append(float(curLine[i])) dataMat.append(lineArr) labelMat.append(float(curLine[-1])) return dataMat,labelMat \"\"\" 计算最佳拟合直线 parameters: xArr -给定的输入值 yArr -给定的输出值 return: ws -回归系数 \"\"\" def standRegres(xArr,yArr): xMat = mat(xArr); yMat = mat(yArr).T #将数据保存到矩阵中 #计算x.T *x xTx = xMat.T @ xMat #使用linalg.det()方法来判断它的行列式是否为零，即是否可逆 if linalg.det(xTx) == 0.0: return #使用最小二乘法计算w值 ws = linalg.inv(xTx) @ xMat.T @ yMat return ws \"\"\" 计算局部加权线性回归系数 parameters: testPoint -待预测数据 xArr -给定输入值 yArr -给定输出值 k -高斯核的k值，决定对附近的点赋予多大的权重 return: testPoint * ws -回归预测的估计值 \"\"\" def lwlr(testPoint, xArr, yArr, k=1.0): xMat = mat(xArr); yMat = mat(yArr).T #读入数据到矩阵 m = shape(xMat)[0] #创建对角权重矩阵，该矩阵为方阵，矩阵维数为样本点个数 theta = eye(m, m) #遍历整个数据集 for i, x in enumerate(xMat): #计算待预测数据与每个样本点的差值 x_i = (testPoint - x) @ (testPoint - x).T #计算每个样本点对应的权重值，随着样本点与待预测点距离的递增，权重将以指数级衰减 theta[i][i] = exp(x_i / (-2 * k ** 2)) #计算x.T θ x xT_theta_x = xMat.T @ theta @ xMat #判断矩阵是否可逆 if linalg.det(xT_theta_x) == 0: return #使用最小二乘法计算w值 ws = linalg.inv(xT_theta_x) @ (xMat.T @ (theta @ yMat)) return testPoint*ws \"\"\" 测试函数 parameters: testArr -测试数据集 xArr -给定输入值 yArr -给定输出值 k -高斯核的k值 return: yHat -预测值 \"\"\" def lwlrTest(testArr, xArr, yArr,k=1.0): m = shape(xArr)[0] yHat = zeros(m) for i in range(m): yHat[i] = lwlr(testArr[i],xArr,yArr,k) return yHat \"\"\" 计算预测误差的平方和 parameters: yArr -给定y值 yHatArr -预测y值 return: ((yArr-yHatArr)**2).sum() -误差矩阵 \"\"\" def rssError(yArr,yHatArr): return ((yArr-yHatArr)**2).sum() if __name__=='__main__': abX,abY = loadDataSet('linear_regression_abalone/abalone.txt') yHat01 = lwlrTest(abX[0:99],abX[0:99],abY[0:99],0.1) yHat1 = lwlrTest(abX[0:99],abX[0:99],abY[0:99],1) yHat10 = lwlrTest(abX[0:99],abX[0:99],abY[0:99],10) print(\"使用局部加权线性回归预测误差：\") print(\"核为0.1时：\",rssError(abY[0:99],yHat01.T)) print(\"核为1时：\",rssError(abY[0:99],yHat1.T)) print(\"核为10时：\",rssError(abY[0:99],yHat10.T)) yHat01 = lwlrTest(abX[100:199],abX[0:99],abY[0:99],0.1) yHat1 = lwlrTest(abX[100:199],abX[0:99],abY[0:99],1) yHat10 = lwlrTest(abX[100:199],abX[0:99],abY[0:99],10) print(\"使用局部加权线性回归预测误差在新数据上的表现：","date":"2021-11-25","objectID":"/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/:3:0","tags":["Machine Learning","回归算法","线性回归"],"title":"线性回归","uri":"/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"},{"categories":["Machine Learning","回归算法"],"content":"岭回归 岭回归即我们所说的L2正则线性回归，在一般的线性回归最小化均方误差的基础上增加了一个参数w的L2范数的罚项，从而最小化罚项残差平方和： \\[ min\\mid \\mid Xw-y \\mid\\mid_2^2 + \\lambda \\mid\\mid w\\mid\\mid_2^2 \\] 简单说来，岭回归就是在普通线性回归的基础上引入单位矩阵。回归系数的计算公式变形如下： \\[ \\hat{w} = (X^TX+\\lambda I)^{-1}X^Ty \\] 式中，矩阵I是一个mxm的单位矩阵，加上一个λI从而使得矩阵非奇异，进而能对矩阵求逆。 当\\(\\lambda\\)过小，则相当于原来的正规方程，会造成过拟合，而\\(\\lambda\\)过大时，模型的方差会更小，但偏差会变大，所以岭回归的关键是找到一个合理的\\(\\lambda\\)值来平衡模型的方差和偏差。 岭回归最先用来处理特征数多于样本数的情况，现在也用于在估计中加入偏差，从而得到更好的估计。这里通过引入λ来限制了所有w之和，通过引入该惩罚项，能够减少不重要的参数，这个技术在统计学中也可以叫做缩减（shrinkage）。 缩减方法可以去掉不重要的参数，因此能更好地裂解数据。此外，与简单的线性回归相比，缩减法能够取得更好的预测效果。 图绘制了回归系数与log(λ)的关系。在最左边，即λ最小时，可以得到所有系数的原始值（与线性回归一致）；而在右边，系数全部缩减成0；在中间部分的某个位置，将会得到最好的预测结果。想要得到最佳的λ参数，可以使用交叉验证的方式获得，文章的后面会继续讲解。 ","date":"2021-11-25","objectID":"/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/:4:0","tags":["Machine Learning","回归算法","线性回归"],"title":"线性回归","uri":"/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"},{"categories":["Machine Learning","回归算法"],"content":"Lasso Lasso对回归系数做了限定，对应的约束条件如下： \\[ \\sum_{k=1}^n|w_k| \\leq \\lambda \\] 而岭回归的约束条件如下： \\[ \\sum_{k=1}^nw_k^2 \\leq \\lambda \\] 唯一不同点在于，Lasso的约束条件用绝对值取代了平方和，虽然约束形式稍作变化，但结果大相径庭，细微的变化极大地增加了计算复杂度。所以用更简单的前向逐步回归来取代。 ","date":"2021-11-25","objectID":"/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/:5:0","tags":["Machine Learning","回归算法","线性回归"],"title":"线性回归","uri":"/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"},{"categories":["Machine Learning","回归算法"],"content":"前向逐步回归 前向逐步线性回归算法属于一种贪心算法，即每一步都尽可能减少误差。我们计算回归系数，不再是通过公式计算，而是通过每次微调各个回归系数，然后计算预测误差。那个使误差最小的一组回归系数，就是我们需要的最佳回归系数。 该算法的伪代码如下： 数据标准化，使其满足0均值和单位方差。 在每轮迭代中： 设置当前最小误差lowestError为正无穷 对每个特征 增大或缩小 改变一个系数得到新的W 计算新W下的误差 如果误差Error小于当前最小误差lowestError：设置Wbest等于当前的W 将W设置为新的Wbest ","date":"2021-11-25","objectID":"/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/:6:0","tags":["Machine Learning","回归算法","线性回归"],"title":"线性回归","uri":"/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"},{"categories":["Machine Learning","回归算法"],"content":"代码 使用的优化算法是梯度下降法，还有一个随机梯度下降 import numpy as np import matplotlib.pyplot as plt np.random.seed(42) w = np.array([2, 1, 4, 5, 3]) d = len(w) X = [] Y = [] for _ in range(1000000): x = np.random.randn(d) y = w.dot(x) + np.random.randn() X.append(x) Y.append(y) X = np.array(X) Y = np.array(Y) def mse(y_true, y_test): return ((y_true - y_test) ** 2) / len(y_true) def gradient(y_true, y_test): return 2 * (y_test - y_true) / len(y_true) def batch_gradient_descent(w, alpha, x, y): y_pred = x.dot(w) error = mse(y, y_pred).mean() grad = np.dot(x.T, gradient(y, y_pred)) w = w - alpha * grad return w, error def stochastic_gradient_descent(w, alpha, x, y, epoch): alpha_update = alpha for i in range(len(x)): y_pred = x[i].dot(w) grad = np.dot(x[i].T, (y_pred - y[i])) * 2 / len(x) w = w- alpha_update * grad alpha_update = alpha_update / (epoch+1) error = mse(y, x.dot(w)).mean() return w, error X_test = [] Y_test = [] for _ in range(10000): x = np.random.randn(d) y = w.dot(x) + np.random.randn() X_test.append(x) Y_test.append(y) X_test = np.array(X_test) Y_test = np.array(Y_test) def l2_mse(y_true, y_test, l, w): return ((y_true - y_test) ** 2) / len(y_true) + l * np.sum(w ** 2) def l2_gradient(y_true, y_test): return 2 * (y_test - y_true) / len(y_true) def batch_gradient_descent_with_l2(w, alpha, x, y, l): y_pred = x.dot(w) error = l2_mse(y, y_pred, l, w).mean() grad = np.dot(x.T, l2_gradient(y, y_pred)) w = w - alpha * grad - alpha * l * w *2 return w, error if __name__ == \"__main__\": train_loss = [] test_loss = [] print(\"Batch Gradient Descent\") for epoch in range(1000): w, error = batch_gradient_descent(w, 0.01, X, Y) # train y_pred = X_test.dot(w) error_test = mse(Y_test, y_pred).mean() # test if epoch % 100 == 0: print(\"Epoch: {}, TrainError: {}, TestError: {}\".format(epoch, error, error_test)) train_loss.append(error) test_loss.append(error_test) plt.plot(train_loss, label=\"Train-No-L2\") plt.legend() plt.xlabel(\"Epoch\") plt.ylabel(\"Loss\") plt.show() plt.plot(test_loss, label=\"Test-No-L2\") plt.xlabel(\"Epoch\") plt.ylabel(\"Loss\") plt.legend() plt.show() plt.plot(train_loss, label=\"Train-No-L2\") plt.plot(test_loss, label=\"Test-No-L2\") plt.legend() plt.show() # ============================================ train_loss = [] test_loss = [] print(\"Batch Gradient Descent with L2\") l = 0.0001 # lambda for epoch in range(1000): w, error = batch_gradient_descent_with_l2(w, 0.01, X, Y, l) # train y_pred = X_test.dot(w) error_test = l2_mse(Y_test, y_pred, l, w).mean() # test if epoch % 100 == 0: print(\"Epoch: {}, TrainError: {}, TestError: {}\".format(epoch, error, error_test)) train_loss.append(error) test_loss.append(error_test) plt.plot(train_loss, label=\"Train-L2\") plt.legend() plt.xlabel(\"Epoch\") plt.ylabel(\"Loss\") plt.show() plt.plot(test_loss, label=\"Test-L2\") plt.xlabel(\"Epoch\") plt.ylabel(\"Loss\") plt.legend() plt.show() plt.plot(train_loss, label=\"Train-L2\") plt.plot(test_loss, label=\"Test-L2\") plt.legend() plt.show() 其实很简单，就是数学公式的复现。 ## 总结 缩减方法（逐步线性回归或岭回归），就是将一些系数缩减成很小的值或者直接缩减为0。这样做，就增大了模型的偏差（减少了一些特征的权重），通过把一些特征的回归系数缩减到0，同时也就减少了模型的复杂度。消除了多余的特征之后，模型更容易理解，同时也降低了预测误差。 ","date":"2021-11-25","objectID":"/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/:7:0","tags":["Machine Learning","回归算法","线性回归"],"title":"线性回归","uri":"/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"},{"categories":["算法题"],"content":"计数质数 https://leetcode-cn.com/problems/count-primes/ 一开始直接暴力，隐约感觉会超时，果然不出我所料 class Solution: def countPrimes(self, n: int) -\u003e int: counts = 0 for i in range(n): if self.isprime(i): counts += 1 return counts def isprime(self,n): from itertools import count if n \u003c=1: return False for i in count(2): if i* i \u003e n: return True if n % i == 0: return False 我还特意用了itertools库，没想到还是超时了 ","date":"2021-11-19","objectID":"/%E8%AE%A1%E6%95%B0%E8%B4%A8%E6%95%B0/:0:0","tags":["算法题","计数质数"],"title":"计数质数","uri":"/%E8%AE%A1%E6%95%B0%E8%B4%A8%E6%95%B0/"},{"categories":["算法题"],"content":"埃氏筛 class Solution: def countPrimes(self, n: int) -\u003e int: res = [1] * n count = 0 for i in range(2, n): if res[i]: count += 1 for j in range(i*i, n, i): res[j] = 0 return count 埃氏筛的原理：从 2 开始，将每个质数的倍数都标记为合数。同样的，标记到 根号n停止。 假设一个数 i 为质数时，那么此时大于 i 且是 i 的倍数的数一定不是质数，例如 2i，3i…。那么我们将这些不是质数的数进行标记。 这里需要注意，标记应该从 i * i 开始，而不是 2 * i 开始。因为对于每个数 i 来说，枚举是从小到大的，此时前面数字的倍数都已经进行了标记。对于 i 而言，2∗i 也肯定会被在枚举数字 2 时进行标记，[2, i) 区间的数同理。 ","date":"2021-11-19","objectID":"/%E8%AE%A1%E6%95%B0%E8%B4%A8%E6%95%B0/:1:0","tags":["算法题","计数质数"],"title":"计数质数","uri":"/%E8%AE%A1%E6%95%B0%E8%B4%A8%E6%95%B0/"},{"categories":["算法题"],"content":"欧拉筛（线性筛） 具体的证明不说了，背板子就行 class Solution: def countPrimes(self, n: int) -\u003e int: if n \u003c= 1: return 0 is_prime = [True] * n is_prime[0] = is_prime[1] = False res = [] for i in range(2, n): if is_prime[i]: res.append(i) j = 0 while j \u003c len(res) and (tmp:=i*res[j]) \u003c n: is_prime[tmp] = False if i % res[j] == 0: # 如果res[j]为当前数的约数，则i*res[j+1]等后面的数必然会在后面的计算得到。就结束循环。这减少了重复计算。 break j += 1 return len(res) ","date":"2021-11-19","objectID":"/%E8%AE%A1%E6%95%B0%E8%B4%A8%E6%95%B0/:2:0","tags":["算法题","计数质数"],"title":"计数质数","uri":"/%E8%AE%A1%E6%95%B0%E8%B4%A8%E6%95%B0/"},{"categories":["Machine Learning","分类算法"],"content":"感知机算法 感知机印象中没有系统学习过但是是一个很简单的算法，最近看了一下李航老师的统计学习方法，发现感知机的思想和svm十分类似，并且比svm简单的多，不需要间隔最大，只需要分开就可以。同时老师在课堂上面讲的版本也有点不一样，主要是计算上的不同，本质还是一样的。然后就打算整理一下这一块。 ","date":"2021-11-16","objectID":"/%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%AE%97%E6%B3%95/:0:0","tags":["Machine Learning","分类算法","感知机算法"],"title":"感知机算法","uri":"/%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%AE%97%E6%B3%95/"},{"categories":["Machine Learning","分类算法"],"content":"感知机模型 假设输入空间（特征空间) 是 \\(\\mathcal{X} \\subseteq \\mathbf{R}^n\\), 输出空间是 \\(\\mathcal{Y}=\\\\{+1,-1\\\\}\\) 。输入 \\(x \\in \\mathcal{X}\\) 表示实例的特征向量, 对应于输入空间 (特征空间 ) 的点; 输出 \\(y \\in \\mathcal{Y}\\) 表示实例的类别。由输入空间到输出空间的如下函数 \\[ f(x)=\\operatorname{sign}(w \\cdot x+b) \\] 称为感知机。其中, \\(w\\) 和 \\(b\\) 为感知机模型参数, \\(w \\in \\mathbf{R}^n\\) 叫作权值 (weight) 或权值向 量 (weight vector), \\(b \\in \\mathbf{R}\\) 叫作偏置 (bias), \\(w \\cdot x\\) 表示 \\(w\\) 和 \\(x\\) 的内积。sign 是符号 函数, 即 \\[ \\operatorname{sign}(x)=\\left\\{\\begin{array}{cc} +1, \u0026 x \\geqslant 0 \\\\\\\\ -1, \u0026 x\u003c0 \\end{array}\\right. \\] ","date":"2021-11-16","objectID":"/%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%AE%97%E6%B3%95/:1:0","tags":["Machine Learning","分类算法","感知机算法"],"title":"感知机算法","uri":"/%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%AE%97%E6%B3%95/"},{"categories":["Machine Learning","分类算法"],"content":"损失函数 假设训练数据集是线性可分的, 感知机学习的目标是求得一个能够将训练集正实 例点和负实例点完全正确分开的分离超平面。为了找出这样的超平面, 即确定感知 机模型参数 \\(w, b\\), 需要确定一个学习策略, 即定义 (经验) 损失函数并将损失函数极 小化。 损失函数的一个自然选择是误分类点的总数。但是, 这样的损失函数不是参数 \\(w\\), \\(b\\) 的连续可导函数, 不易优化。损失函数的另一个选择是误分类点到超平面 \\(S\\) 的总距 离, 这是感知机所采用的。为此, 首先写出输入空间 \\(\\mathbf{R}^n\\) 中任一点 \\(x_0\\) 到超平面 \\(S\\) 的 距离: \\[ \\frac{1}{\\|w\\|}\\left|w \\cdot x_0+b\\right| \\] 这里, \\(\\|w\\|\\) 是 \\(w\\) 的 \\(L_2\\) 范数。 其次, 对于误分类的数据 \\(\\left(x_i, y_i\\right)\\) 来说, \\[ -y_i\\left(w \\cdot x_i+b\\right)\u003e0 \\] 成立。因为当 \\(w \\cdot x_i+b\u003e0\\) 时, \\(y_i=-1\\); 而当 \\(w \\cdot x_i+b\u003c0\\) 时, \\(y_i=+1\\) 。 因此, 误 分类点 \\(x_i\\) 到超平面 \\(S\\) 的距离是 \\[ -\\frac{1}{\\|w\\|} y_i\\left(w \\cdot x_i+b\\right) \\] 这样, 假设超平面 \\(S\\) 的误分类点集合为 \\(M\\), 那么所有误分类点到超平面 \\(S\\) 的总 距离为 \\[ -\\frac{1}{\\|w\\|} \\sum_{x_i \\in M} y_i\\left(w \\cdot x_i+b\\right) \\] 不考虑 \\(\\frac{1}{\\|w\\|}\\), 就得到感知机学习的损失函数。 即 \\[ L(w, b) = -\\sum_{x_i \\in M} y_i\\left(w \\cdot x_i+b\\right) \\] 使用梯度下降算法更新参数，对损失函数求导得到： \\[ \\begin{aligned} \u0026\\nabla_w L(w, b)=-\\sum_{x_i \\in M} y_i x_i \\\\\\\\ \u0026\\nabla_b L(w, b)=-\\sum_{x_i \\in M} y_i \\end{aligned} \\] 随机选取一个误分类点 \\(\\left(x_i, y_i\\right)\\), 对 \\(w, b\\) 进行更新: \\[ \\begin{gathered} w \\leftarrow w+\\eta y_i x_i \\\\\\\\ b \\leftarrow b+\\eta y_i \\end{gathered} \\] ## 算法流程 总结可得，感知机算法流程如下： 输入: 训练数据集 \\(T=\\left\\{\\left(x_1, y_1\\right),\\left(x_2, y_2\\right), \\cdots,\\left(x_N, y_N\\right)\\right\\\\\\}\\), 其中 \\(x_i \\in \\mathcal{X}=\\mathbf{R}^n, y_i \\in\\) \\(\\mathcal{Y}=\\\\{-1,+1\\\\}, i=1,2, \\cdots, N\\); 学习率 \\(\\eta(0\u003c\\eta \\leqslant 1)\\); 输出: \\(w, b\\); 感知机模型 \\(f(x)=\\operatorname{sign}(w \\cdot x+b)\\) 。 (1) 选取初值 \\(w_0, b_0\\); (2) 在训练集中选取数据 \\(\\left(x_i, y_i\\right)\\); (3) 如果 \\(y_i\\left(w \\cdot x_i+b\\right) \\leqslant 0\\), \\[ \\begin{aligned} \u0026w \\leftarrow w+\\eta y_i x_i \\\\\\\\ \u0026b \\leftarrow b+\\eta y_i \\end{aligned} \\] 转至 (2), 直至训练集中没有误分类点。 这很容易理解。就是求解最佳参数\\(w\\)和\\(b\\)，使用梯度下降算法，对于每个样本，如果其真实的标签与预测的结果符号不一致，也就是sign函数之前的结果不同号，则说明分类错误，则就需要更新参数，不断地继续更新直到所有的样本都分类正确。 ","date":"2021-11-16","objectID":"/%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%AE%97%E6%B3%95/:2:0","tags":["Machine Learning","分类算法","感知机算法"],"title":"感知机算法","uri":"/%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%AE%97%E6%B3%95/"},{"categories":["Machine Learning","分类算法"],"content":"另一种表达方式 感知器: 用数据训练线性模型 \\(g({x})={w}^T {x}+w_0\\) 增广的样本向量: \\[ {y}=\\left(1 ; x_1 ; x_2 ; \\ldots ; x_d\\right) \\] 增广的权向量: \\[ {\\alpha}=\\left(w_0 ; w_1 ; \\ldots ; w_d\\right) \\] 线性判别函数: \\[ g({y})={\\alpha}^T {y} \\] 决策规则: 如果 \\(g({y})\u003e0\\), 则 \\(y \\in \\omega_0\\); 如果 \\(g({y})\u003c0\\), 则 \\(y \\in \\omega_1\\) 若定义新变量 \\(y^{\\prime}\\), 使 \\[ y_i^{\\prime}=\\left\\{\\begin{array}{lll} y_i, \\text { 若 } \u0026 {y}_i \\in \\omega_0 \\\\ -{y}_i, \\text { 若 } \u0026 {y}_i \\in \\omega_1 \\end{array} \\quad i=1,2, \\ldots, m\\right. \\] 样本可分性条件变为：存在 \\(\\alpha\\), 使 \\[ {\\alpha}^T {y}_i^{\\prime}\u003e0, i=1,2, \\ldots, m \\] \\(y^{\\prime}\\) 称作规范化增广样本向量, 仍记作 \\(y\\) 。 可以用这样的形式定义损失函数为： \\[ J(\\alpha) = \\sum_{\\alpha^Ty_k \\leq 0} (-\\alpha^Ty_k) \\] 其中w和b合并为了\\(\\alpha\\)。\\(y_k\\)为原来的x加上了1用于与偏置b对应。 ","date":"2021-11-16","objectID":"/%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%AE%97%E6%B3%95/:3:0","tags":["Machine Learning","分类算法","感知机算法"],"title":"感知机算法","uri":"/%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%AE%97%E6%B3%95/"},{"categories":["Machine Learning","分类算法"],"content":"梯度下降迭代法求解 \\[ \\boldsymbol{\\alpha}(t+1)=\\boldsymbol{\\alpha}(t)-\\rho_t \\nabla J_P(\\boldsymbol{\\alpha}) \\] 下一时刻的权向量是把当前时刻的权向量向目标函数的负梯度方向调整一个修 正量, \\(\\rho_t\\) 为调整的步长 (“学习率”)。 \\[ \\nabla J_P(\\boldsymbol{\\alpha})=\\frac{\\partial J_P(\\boldsymbol{\\alpha})}{\\partial \\boldsymbol{\\alpha}}=\\sum_{\\alpha^T y_k \\leq 0}\\left(-y_k\\right) \\] 所以 \\[ \\alpha(t+1)=\\alpha(t)+\\rho_t \\sum_{\\alpha^T y_k \\leq 0} y_k \\] 即每次迭代时把错分的样本按照某个系数加到权向量上。 当没有错分样本时, 得到一个合适的解 $^* $ 。 ","date":"2021-11-16","objectID":"/%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%AE%97%E6%B3%95/:3:1","tags":["Machine Learning","分类算法","感知机算法"],"title":"感知机算法","uri":"/%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%AE%97%E6%B3%95/"},{"categories":["Machine Learning","分类算法"],"content":"固定增量法 （1）任意选择初始权向量 \\(\\alpha(0)\\); (2) 对样本 \\(y_j\\), 若 \\(\\alpha(t)^T y_j \\leq 0\\), 则 \\(\\alpha(t+1)=\\alpha(t)+y_j\\) (假设 \\(\\left.\\rho_t=1\\right)\\), 否则继 续; (3) 对所有样本重复 (2), 直至对所有的样本都有 \\(\\alpha(t)^T y_j\u003e0\\), 即 \\(J_P(\\boldsymbol{\\alpha})=0\\) 与梯度下降法的区别就是每次只对一个样本更新，可以这样理解： 原始的数据，对于第二类则增广之后取负数就可以理解为前面第一种表达的\\(y_i\\left(w \\cdot x_i+b\\right)\\)， 大于0则说明分类正确，否则说明分类错误，就需要更新参数。 ","date":"2021-11-16","objectID":"/%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%AE%97%E6%B3%95/:3:2","tags":["Machine Learning","分类算法","感知机算法"],"title":"感知机算法","uri":"/%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%AE%97%E6%B3%95/"},{"categories":["算法题"],"content":"最大数 ","date":"2021-11-08","objectID":"/%E6%9C%80%E5%A4%A7%E6%95%B0/:0:0","tags":["算法题","最大数"],"title":"最大数","uri":"/%E6%9C%80%E5%A4%A7%E6%95%B0/"},{"categories":["算法题"],"content":"题目： https://leetcode-cn.com/problems/largest-number/ ","date":"2021-11-08","objectID":"/%E6%9C%80%E5%A4%A7%E6%95%B0/:1:0","tags":["算法题","最大数"],"title":"最大数","uri":"/%E6%9C%80%E5%A4%A7%E6%95%B0/"},{"categories":["算法题"],"content":"思路： 一开始直接暴力搜索，把所有的情况都列举然后比较，结果超时了，最后利用了自定义排序的方法 ","date":"2021-11-08","objectID":"/%E6%9C%80%E5%A4%A7%E6%95%B0/:2:0","tags":["算法题","最大数"],"title":"最大数","uri":"/%E6%9C%80%E5%A4%A7%E6%95%B0/"},{"categories":["算法题"],"content":"代码： class Solution: def largestNumber(self, nums: List[int]) -\u003e str: class Comapre(str): def __lt__(self,other): return int(self+other) \u003e int(other+self) nums.sort(key=Comapre) return str(int(''.join(map(str,nums)))) 注意的是这里利用了自定义的比较类型，继承了str，也可以从functools里导入cmp_to_key方法来实现比较 python3之后不支持cmp，所用key函数并不直接比较任意两个原始元素，而是通过key函数把那些元素转换成一个个新的可比较对象，也就是元素的key，然后用元素的key代替元素去参与比较。如果原始元素本来就是可比较对象，比如数字、字符串，那么不考虑性能优化可以直接sort(key=lambda e: e)。不过这种基于key函数的设计倾向于每个元素的大小有个绝对标准，但有时却会出现单个元素并没有一个绝对的大小的情况，此时可以使用 functools.cmp_to_key构建基于多个元素的比较函数。 ","date":"2021-11-08","objectID":"/%E6%9C%80%E5%A4%A7%E6%95%B0/:3:0","tags":["算法题","最大数"],"title":"最大数","uri":"/%E6%9C%80%E5%A4%A7%E6%95%B0/"},{"categories":["Deep Learning","循环神经网络系列"],"content":" image.png image.png ","date":"2021-11-02","objectID":"/lstm/:0:0","tags":["Deep Learning","循环神经网络系列","LSTM"],"title":"LSTM","uri":"/lstm/"},{"categories":["算法题"],"content":"检查平衡性 ","date":"2021-10-27","objectID":"/%E6%A3%80%E6%9F%A5%E5%B9%B3%E8%A1%A1%E6%80%A7-1/:0:0","tags":["算法题","检查平衡性"],"title":"检查平衡性","uri":"/%E6%A3%80%E6%9F%A5%E5%B9%B3%E8%A1%A1%E6%80%A7-1/"},{"categories":["算法题"],"content":"题目： https://leetcode-cn.com/problems/check-balance-lcci/ ","date":"2021-10-27","objectID":"/%E6%A3%80%E6%9F%A5%E5%B9%B3%E8%A1%A1%E6%80%A7-1/:1:0","tags":["算法题","检查平衡性"],"title":"检查平衡性","uri":"/%E6%A3%80%E6%9F%A5%E5%B9%B3%E8%A1%A1%E6%80%A7-1/"},{"categories":["算法题"],"content":"思路： 算深度，然后作差是否大于1 ","date":"2021-10-27","objectID":"/%E6%A3%80%E6%9F%A5%E5%B9%B3%E8%A1%A1%E6%80%A7-1/:2:0","tags":["算法题","检查平衡性"],"title":"检查平衡性","uri":"/%E6%A3%80%E6%9F%A5%E5%B9%B3%E8%A1%A1%E6%80%A7-1/"},{"categories":["算法题"],"content":"代码： # Definition for a binary tree node. # class TreeNode: # def __init__(self, x): # self.val = x # self.left = None # self.right = None class Solution: def isBalanced(self, root: TreeNode) -\u003e bool: if self.maxdepth(root) \u003c 1: return True if abs(self.maxdepth(root.left) - self.maxdepth(root.right)) \u003e 1: return False return self.isBalanced(root.right) and self.isBalanced(root.left) def maxdepth(self,root): if not root: return 0 return 1 + max(self.maxdepth(root.right),self.maxdepth(root.left)) ","date":"2021-10-27","objectID":"/%E6%A3%80%E6%9F%A5%E5%B9%B3%E8%A1%A1%E6%80%A7-1/:3:0","tags":["算法题","检查平衡性"],"title":"检查平衡性","uri":"/%E6%A3%80%E6%9F%A5%E5%B9%B3%E8%A1%A1%E6%80%A7-1/"},{"categories":["算法题"],"content":"检查平衡性 ","date":"2021-10-27","objectID":"/%E6%A3%80%E6%9F%A5%E5%B9%B3%E8%A1%A1%E6%80%A7/:0:0","tags":["算法题","检查平衡性"],"title":"检查平衡性","uri":"/%E6%A3%80%E6%9F%A5%E5%B9%B3%E8%A1%A1%E6%80%A7/"},{"categories":["算法题"],"content":"题目： https://leetcode-cn.com/problems/check-balance-lcci/ ","date":"2021-10-27","objectID":"/%E6%A3%80%E6%9F%A5%E5%B9%B3%E8%A1%A1%E6%80%A7/:1:0","tags":["算法题","检查平衡性"],"title":"检查平衡性","uri":"/%E6%A3%80%E6%9F%A5%E5%B9%B3%E8%A1%A1%E6%80%A7/"},{"categories":["算法题"],"content":"思路： 算深度，然后作差是否大于1 ","date":"2021-10-27","objectID":"/%E6%A3%80%E6%9F%A5%E5%B9%B3%E8%A1%A1%E6%80%A7/:2:0","tags":["算法题","检查平衡性"],"title":"检查平衡性","uri":"/%E6%A3%80%E6%9F%A5%E5%B9%B3%E8%A1%A1%E6%80%A7/"},{"categories":["算法题"],"content":"代码： # Definition for a binary tree node. # class TreeNode: # def __init__(self, x): # self.val = x # self.left = None # self.right = None class Solution: def isBalanced(self, root: TreeNode) -\u003e bool: if self.maxdepth(root) \u003c 1: return True if abs(self.maxdepth(root.left) - self.maxdepth(root.right)) \u003e 1: return False return self.isBalanced(root.right) and self.isBalanced(root.left) def maxdepth(self,root): if not root: return 0 return 1 + max(self.maxdepth(root.right),self.maxdepth(root.left)) ","date":"2021-10-27","objectID":"/%E6%A3%80%E6%9F%A5%E5%B9%B3%E8%A1%A1%E6%80%A7/:3:0","tags":["算法题","检查平衡性"],"title":"检查平衡性","uri":"/%E6%A3%80%E6%9F%A5%E5%B9%B3%E8%A1%A1%E6%80%A7/"},{"categories":["NLP"],"content":"语言模型 语言模型是一个很大的主题，很多nlp的任务都是基于语言模型进行的，因此理解语言模型是很重要的。 语言模型简单说就是 计算一个句子在语言中出现的概率。 ","date":"2021-10-26","objectID":"/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/:0:0","tags":["NLP","语言模型"],"title":"语言模型","uri":"/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"数学表示 一个语言模型通常构建字符串s的概率分布p(s)，这里p(s)反应字符串s作为一个句子出现的概率。 对于一个由m个基元（可以是字、词或者短语）构成的句子\\(s=w_1,w_2, \\dots w_m\\)，其概率计算公式可以表示为(乘法公式，详见bayes)： \\[ p(s) = p(w_1)p(w_2\\mid w_1)p(w_3\\mid w_1, w_2)\\cdots p(w_m\\mid w_1w_2\\dots w_{m-1})= \\prod_{i=1}^mp(w_i\\mid w_1\\cdots,w_{i-1}) \\] 但是很明显这个计算复杂度是极大的。 ## 评价指标 语言模型的常用评价指标是困惑度（perplexity）：在一个测试数据上的perplexity越低，说明建模的效果越好。perplexity计算公式如下： 简单来说，困惑度就是刻画一个语言模型预测一个语言样本的能力，其实际上就是计算每一个词得到的概率倒数的几何平均，即模型预测下一个词的平均可选择数量。 在实际应用中通常使用log的形式，即： ","date":"2021-10-26","objectID":"/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/:1:0","tags":["NLP","语言模型"],"title":"语言模型","uri":"/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"统计语言模型 ","date":"2021-10-26","objectID":"/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/:2:0","tags":["NLP","语言模型"],"title":"语言模型","uri":"/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"n-gram 为了解决复杂度高的问题，因此引入马尔科夫假设，即当前词的预测概率只与之前n-1个词相关，基于此，语言模型可以修改如下： \\[ p(s) = p(w_1, w_2, \\dots, w_m) = \\prod_{i=1}^mp(w_i\\mid w_{i-n+1}, w_{i-1}) \\] 当n取1,2,3时，n-gram可以称为unigram、bigram、trigram。n越大复杂度越高。 n-gram model一般采用MLE进行参数估计： \\[ p(w_i\\mid w_{i-n+1}, \\cdots, w_{i-1}) = \\frac{C(w_{i-n+1}, \\cdots,w_{i-1}, w_i)}{C(w_{i-n+1}, \\cdots, w_{i-1})} \\] 即使训练语料再大，也存在参数为0的情况，这时候就需要引入数据平滑策略，其中最为常用的就是拉普拉斯平滑。 ","date":"2021-10-26","objectID":"/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/:2:1","tags":["NLP","语言模型"],"title":"语言模型","uri":"/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"拉普拉斯平滑 Add one 拉普拉斯平滑，即强制让所有的n-gram至少出现一次，只需要在分子和分母上分别做加法即可。这个方法的弊端是，大部分n-gram都是没有出现过的，很容易为他们分配过多的概率空间。 #### Add-K 在Add-one的基础上做了一点小改动，原本是加一，现在加上一个小于1的常数K K。但是缺点是这个常数仍然需要人工确定，对于不同的语料库K可能不同。 k取1时与add one 相同 ","date":"2021-10-26","objectID":"/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/:2:2","tags":["NLP","语言模型"],"title":"语言模型","uri":"/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP"],"content":"Kneser-Ney Smoothing 这是目前ngram模型效果最好的平滑方法。 ## 神经网络语言模型 具体可以看本博客有关神经网络语言模型的内容，NNLM是第一个出现的神经网络语言模型。 ","date":"2021-10-26","objectID":"/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/:2:3","tags":["NLP","语言模型"],"title":"语言模型","uri":"/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"},{"categories":["NLP","概率图模型","贝叶斯网络"],"content":"隐马尔科夫模型 ","date":"2021-10-25","objectID":"/hmm/:0:0","tags":["NLP","概率图模型","贝叶斯网络","HMM"],"title":"HMM","uri":"/hmm/"},{"categories":["NLP","概率图模型","贝叶斯网络"],"content":"介绍 HMM可以看做是处理序列模型的传统方法。 一般来说HMM解决三个问题： 评估观察序列概率。给定模型\\(\\lambda=(A,B,\\prod)\\)和观察序列\\(O=\\\\{o_1,o_2,\\dots,o_T\\\\}\\)，计算在模型\\(\\lambda\\)下观测序列O出现的概率\\(P(O\\lvert \\lambda)\\)，这个问题需要用到前向后向算法，属于三个问题中最简单的。 预测问题，也叫解码问题。即给定模型\\(\\lambda = (A,B,\\prod)\\)和观测序列\\(O=\\\\{o_1,o_2,\\dots,o_T\\\\}\\)，求在给定观测序列条件下，最可能出现的对应的状态序列，这个问题的求解需要用到基于动态规划的维特比算法，这个问题属于三个问题中复杂度居中的算法。 模型参数学习问题。即给定观测序列\\(O=\\\\{o_1,o_2,\\dots,o_T\\\\}\\)，估计模型\\(\\lambda = (A,B,\\prod)\\)的参数，使得该模型下观测序列的条件概率\\(P(O\\lvert\\lambda)\\)最大，这个问题的求解需要用到基于EM算法的鲍姆-韦尔奇算法。属于三个问题中最复杂的。 ","date":"2021-10-25","objectID":"/hmm/:1:0","tags":["NLP","概率图模型","贝叶斯网络","HMM"],"title":"HMM","uri":"/hmm/"},{"categories":["NLP","概率图模型","贝叶斯网络"],"content":"定义 设 \\(Q\\) 是所有可能的状态的集合, \\(V\\) 是所有可能的观测的集合: \\[ Q=\\left\\{q_1, q_2, \\cdots, q_N\\right\\}, \\quad V=\\left\\{v_1, v_2, \\cdots, v_M\\right\\} \\] 其中, \\(N\\) 是可能的状态数, \\(M\\) 是可能的观测数。 \\(I\\) 是长度为 \\(T\\) 的状态序列, \\(O\\) 是对应的观测序列: \\[ I=\\left(i_1, i_2, \\cdots, i_T\\right), \\quad O=\\left(o_1, o_2, \\cdots, o_T\\right) \\] \\(A\\) 是状态转移概率矩阵: \\[ A=\\left[a_{i j}\\right]_{N \\times N} \\] 其中, \\[ a_{i j}=P\\left(i_{t+1}=q_j \\mid i_t=q_i\\right), \\quad i=1,2, \\cdots, N ; \\quad j=1,2, \\cdots, N \\] 是在时刻 \\(t\\) 处于状态 \\(q_i\\) 的条件下在时刻 \\(t+1\\) 转移到状态 \\(q_j\\) 的概率。 \\(B\\) 是观测概率矩阵: \\[ B=\\left[b_j(k)\\right]_{N \\times M} \\] 其中, \\[ b_j(k)=P\\left(o_t=v_k \\mid i_t=q_j\\right), \\quad k=1,2, \\cdots, M ; \\quad j=1,2, \\cdots, N \\] 是在时刻 \\(t\\) 处于状态 \\(q_j\\) 的条件下生成观测 \\(v_k\\) 的概率。 \\(\\pi\\) 是初始状态概率向量: \\[ \\pi=\\left(\\pi_i\\right) \\] 其中, \\[ \\pi_i=P\\left(i_1=q_i\\right), \\quad i=1,2, \\cdots, N \\] 是时刻 \\(t=1\\) 处于状态 \\(q_i\\) 的概率。 隐马尔可夫模型由初始状态概率向量 \\(\\pi\\) 、状态转移概率矩阵 \\(A\\) 和观测概率矩阵 \\(B\\) 决定。 \\(\\pi\\) 和 \\(A\\) 决定状态序列, \\(B\\) 决定观测序列。因此, 隐马尔可夫模型 \\(\\lambda\\) 可以用三元 符号表示, 即 \\[ \\lambda=(A, B, \\pi) \\] \\(A, B, \\pi\\) 称为隐马尔可夫模型的三要素。 状态转移概率矩阵 \\(A\\) 与初始状态概率向量 \\(\\pi\\) 确定了隐藏的马尔可夫链, 生成不 可观测的状态序列。观测概率矩阵 \\(B\\) 确定了如何从状态生成观测, 与状态序列综合确 定了如何产生观测序列。 ","date":"2021-10-25","objectID":"/hmm/:2:0","tags":["NLP","概率图模型","贝叶斯网络","HMM"],"title":"HMM","uri":"/hmm/"},{"categories":["NLP","概率图模型","贝叶斯网络"],"content":"两个基本假设 齐次马尔可夫性假设, 即假设隐藏的马尔可夫链在任意时刻 \\(t\\) 的状态只依赖 于其前一时刻的状态, 与其他时刻的状态及观测无关, 也与时刻 \\(t\\) 无关: \\[ P\\left(i_t \\mid i_{t-1}, o_{t-1}, \\cdots, i_1, o_1\\right)=P\\left(i_t \\mid i_{t-1}\\right), \\quad t=1,2, \\cdots, T \\] 观测独立性假设, 即假设任意时刻的观测只依赖于该时刻的马尔可夫链的状 态, 与其他观测及状态无关: \\[ P\\left(o_t \\mid i_T, o_T, i_{T-1}, o_{T-1}, \\cdots, i_{t+1}, o_{t+1}, i_t, i_{t-1}, o_{t-1}, \\cdots, i_1, o_1\\right)=P\\left(o_t \\mid i_t\\right) \\] ","date":"2021-10-25","objectID":"/hmm/:3:0","tags":["NLP","概率图模型","贝叶斯网络","HMM"],"title":"HMM","uri":"/hmm/"},{"categories":["NLP","概率图模型","贝叶斯网络"],"content":"观测序列生成的过程 输入: 隐马尔可夫模型 \\(\\lambda=(A, B, \\pi)\\), 观测序列长度 \\(T\\); 输出: 观测序列 \\(O=\\left(o_1, o_2, \\cdots, o_T\\right)\\) 。 (1) 按照初始状态分布 \\(\\pi\\) 产生状态 \\(i_1\\); (2) 令 \\(t=1\\); (3) 按照状态 \\(i_t\\) 的观测概率分布 \\(b_{i_t}(k)\\) 生成 \\(o_t\\) : (4) 按照状态 \\(i_t\\) 的状态转移概率分布 \\(\\left\\{a_{i_t i_{t+1}}\\right\\}\\) 产生状态 \\(i_{t+1}, i_{t+1}=1,2, \\cdots, N\\); (5) 令 \\(t=t+1\\); 如果 \\(t\u003cT\\), 转步 (3); 否则, 终止。 ","date":"2021-10-25","objectID":"/hmm/:4:0","tags":["NLP","概率图模型","贝叶斯网络","HMM"],"title":"HMM","uri":"/hmm/"},{"categories":["NLP","概率图模型","贝叶斯网络"],"content":"概率计算问题 ","date":"2021-10-25","objectID":"/hmm/:5:0","tags":["NLP","概率图模型","贝叶斯网络","HMM"],"title":"HMM","uri":"/hmm/"},{"categories":["NLP","概率图模型","贝叶斯网络"],"content":"直接计算（复杂度太高） 给定模型 \\(\\lambda=(A, B, \\pi)\\) 和观测序列 \\(O=\\left(o_1, o_2, \\cdots, o_T\\right)\\), 计算观测序列 \\(O\\) 出现 的概率 \\(P(O \\mid \\lambda)\\) 。最直接的方法是按概率公式直接计算。通过列举所有可能的长度为 \\(T\\) 的状态序列 \\(I=\\left(i_1, i_2, \\cdots, i_T\\right)\\), 求各个状态序列 \\(I\\) 与观测序列 \\(O=\\left(o_1, o_2, \\cdots, o_T\\right)\\) 的联合概率 \\(P(O, I \\mid \\lambda)\\), 然后对所有可能的状态序列求和, 得到 \\(P(O \\mid \\lambda)\\) 。 状态序列 \\(I=\\left(i_1, i_2, \\cdots, i_T\\right)\\) 的概率是: \\[ P(I \\mid \\lambda)=\\pi_{i_1} a_{i_1 i_2} a_{i_2 i_3} \\cdots a_{i_{T-1} i_T} \\] 对固定的状态序列 \\(I=\\left(i_1, i_2, \\cdots, i_T\\right)\\), 观测序列 \\(O=\\left(o_1, o_2, \\cdots, o_T\\right)\\) 的概率是: \\[ P(O \\mid I, \\lambda)=b_{i_1}\\left(o_1\\right) b_{i_2}\\left(o_2\\right) \\cdots b_{i_T}\\left(o_T\\right) \\] \\(O\\) 和 \\(I\\) 同时出现的联合概率为 \\[ \\begin{aligned} P(O, I \\mid \\lambda) \u0026=P(O \\mid I, \\lambda) P(I \\mid \\lambda) \\\\\\\\ \u0026=\\pi_{i_1} b_{i_1}\\left(o_1\\right) a_{i_1 i_2} b_{i_2}\\left(o_2\\right) \\cdots a_{i_{T-1} i_T} b_{i_T}\\left(o_T\\right) \\end{aligned} \\] 然后, 对所有可能的状态序列 \\(I\\) 求和, 得到观测序列 \\(O\\) 的概率 \\(P(O \\mid \\lambda)\\), 即 \\[ \\begin{aligned} P(O \\mid \\lambda) \u0026=\\sum_I P(O \\mid I, \\lambda) P(I \\mid \\lambda) \\\\\\\\ \u0026=\\sum_{i_1, i_2, \\cdots, i_T} \\pi_{i_1} b_{i_1}\\left(o_1\\right) a_{i_1 i_2} b_{i_2}\\left(o_2\\right) \\cdots a_{i_{T-1} i_T} b_{i_T}\\left(o_T\\right) \\end{aligned} \\] 这种算法复杂度太高，计算量太大，有效算法为前向算法和后向算法。 ","date":"2021-10-25","objectID":"/hmm/:5:1","tags":["NLP","概率图模型","贝叶斯网络","HMM"],"title":"HMM","uri":"/hmm/"},{"categories":["NLP","概率图模型","贝叶斯网络"],"content":"前向算法 首先定义前向概率。 给定隐马尔可夫模型 \\(\\lambda\\), 定义到时刻 \\(t\\) 部分观测序列为 \\(o_1, o_2, \\cdots, o_t\\) 且状态为 \\(q_i\\) 的概率为前向概率, 记作 \\[ \\alpha_t(i)=P\\left(o_1, o_2, \\cdots, o_t, i_t=q_i \\mid \\lambda\\right) \\] 可以递推地求得前向概率 \\(\\alpha_t(i)\\) 及观测序列概率 \\(P(O \\mid \\lambda)\\) 。 (观测序列概率的前向算法) 输入: 隐马尔可夫慔型 \\(\\lambda\\), 观测序列 \\(O\\); 输出: 观测序列概率 \\(P(O \\mid \\lambda)\\) 。 (1) 初值 \\[ \\alpha_1(i)=\\pi_i b_i\\left(o_1\\right), \\quad i=1,2, \\cdots, N \\] （2）递推 对 \\(t=1,2, \\cdots, T-1\\), \\[ \\alpha_{t+1}(i)=\\left[\\sum_{j=1}^N \\alpha_t(j) a_{j i}\\right] b_i\\left(o_{t+1}\\right), \\quad i=1,2, \\cdots, N \\] 终止 \\[ P(O \\mid \\lambda)=\\sum_{i=1}^N \\alpha_T(i) \\] 前向算法, 步骤 (1) 初始化前向概率, 是初始时刻的状态 \\(i_1=q_i\\) 和观测 \\(o_1\\) 的 联合概率。步骤 (2) 是前向概率的递推公式, 计算到时刻 \\(t+1\\) 部分观测序列为 \\(o_1, o_2, \\cdots, o_t, o_{t+1}\\) 且在时刻 \\(t+1\\) 处于状态 \\(q_i\\) 的前向概率, 如图 \\(10.1\\) 所示。在式 (10.16) 的方括弧里, 既然 \\(\\alpha_t(j)\\) 是到时刻 \\(t\\) 观测到 \\(o_1, o_2, \\cdots, o_t\\) 并在时刻 \\(t\\) 处于状态 \\(q_j\\) 的前向概率, 那么乘积 \\(\\alpha_t(j) a_{j i}\\) 就是到时刻 \\(t\\) 观测到 \\(o_1, o_2, \\cdots, o_t\\) 并在时刻 \\(t\\) 处于 状态 \\(q_j\\) 而在时刻 \\(t+1\\) 到达状态 \\(q_i\\) 的联合概率。对这个乘积在时刻 \\(t\\) 的所有可能的 #### 统计学习方法中前向算法的例子 ### 后向算法 给定隐马尔可夫模型 \\(\\lambda\\), 定义在时刻 \\(t\\) 状态为 \\(q_i\\) 的条件下, 从 \\(t+1\\) 到 \\(T\\) 的部分观测序列为 \\(o_{t+1}, o_{t+2}, \\cdots, o_T\\) 的概率为后向概率, 记作 \\[ \\beta_t(i)=P\\left(o_{t+1}, o_{t+2}, \\cdots, o_T \\mid i_t=q_i, \\lambda\\right) \\] 可以用递推的方法求得后向概率 \\(\\beta_t(i)\\) 及观测序列概率 \\(P(O \\mid \\lambda)\\) 。 (观测序列概率的后向算法) 输入: 隐马尔可夫模型 \\(\\lambda\\), 观测序列 \\(O\\); 输出: 观测序列概率 \\(P(O \\mid \\lambda)\\) 。 (1) \\[ \\beta_T(i)=1, \\quad i=1,2, \\cdots, N \\] 对 \\(t=T-1, T-2, \\cdots, 1\\) \\[ \\beta_t(i)=\\sum_{j=1}^N a_{i j} b_j\\left(o_{t+1}\\right) \\beta_{t+1}(j), \\quad i=1,2, \\cdots, N \\] 后向算法到这一步只用到了第二个观测值，还有第一个观测值没有用到。 因此最后要乘上。 (3) \\[ P(O \\mid \\lambda)=\\sum_{i=1}^N \\pi_i b_i\\left(o_1\\right) \\beta_1(i) \\] ","date":"2021-10-25","objectID":"/hmm/:5:2","tags":["NLP","概率图模型","贝叶斯网络","HMM"],"title":"HMM","uri":"/hmm/"},{"categories":["NLP","概率图模型","贝叶斯网络"],"content":"结合 利用前向概率和后向概率的定义可以将观测序列概率 \\(P(O \\mid \\lambda)\\) 统一写成 \\[ P(O \\mid \\lambda)=\\sum_{i=1}^N \\sum_{j=1}^N \\alpha_t(i) a_{i j} b_j\\left(o_{t+1}\\right) \\beta_{t+1}(j), \\quad t=1,2, \\cdots, T-1 \\] 也可以写成： \\[ P(O\\mid \\lambda) = \\sum_{i=1}^N[\\alpha_t(i)\\beta_t(i)], \\quad t=1,2,\\cdots, T-1 \\] ","date":"2021-10-25","objectID":"/hmm/:5:3","tags":["NLP","概率图模型","贝叶斯网络","HMM"],"title":"HMM","uri":"/hmm/"},{"categories":["NLP","概率图模型","贝叶斯网络"],"content":"一些概率和期望问题 利用前向概率和后向概率, 可以得到关于单个状态和两个状态概率的计算公式。 1. 给定模型 \\(\\lambda\\) 和观测 \\(O\\), 在时刻 \\(t\\) 处于状态 \\(q_i\\) 的概率。记 \\[ \\gamma_t(i)=P\\left(i_t=q_i \\mid O, \\lambda\\right) \\] 可以通过前向后向概率计算。事实上， \\[ \\gamma_t(i)=P\\left(i_t=q_i \\mid O, \\lambda\\right)=\\frac{P\\left(i_t=q_i, O \\mid \\lambda\\right)}{P(O \\mid \\lambda)} \\] 由前向概率 \\(\\alpha_t(i)\\) 和后向概率 \\(\\beta_t(i)\\) 定义可知: \\[ \\alpha_t(i) \\beta_t(i)=P\\left(i_t=q_i, O \\mid \\lambda\\right) \\] 于是得到: \\[ \\gamma_t(i)=\\frac{\\alpha_t(i) \\beta_t(i)}{P(O \\mid \\lambda)}=\\frac{\\alpha_t(i) \\beta_t(i)}{\\sum_{j=1}^N \\alpha_t(j) \\beta_t(j)} \\] 给定模型 \\(\\lambda\\) 和观测 \\(O\\), 在时刻 \\(t\\) 处于状态 \\(q_i\\) 且在时刻 \\(t+1\\) 处于状态 \\(q_j\\) 的概 率。记 \\[ \\xi_t(i, j)=P\\left(i_t=q_i, i_{t+1}=q_j \\mid O, \\lambda\\right) \\] 可以通过前向后向概率计算: \\[ \\xi_t(i, j)=\\frac{P\\left(i_t=q_i, i_{t+1}=q_j, O \\mid \\lambda\\right)}{P(O \\mid \\lambda)}=\\frac{P\\left(i_t=q_i, i_{t+1}=q_j, O \\mid \\lambda\\right)}{\\sum_{i=1}^N \\sum_{j=1}^N P\\left(i_t=q_i, i_{t+1}=q_j, O \\mid \\lambda\\right)} \\] 而 \\[ P(i_t=q_i,i_{t+1}=q_j,O | \\lambda) = \\alpha_t(i)a_{ij}b_j(o_{t+1})\\beta_{t+1}(j) \\] 所以 \\[ \\xi_t(i, j)=\\frac{\\alpha_t(i) a_{i j} b_j\\left(o_{t+1}\\right) \\beta_{t+1}(j)}{\\sum_{i=1}^N \\sum_{j=1}^N \\alpha_t(i) a_{i j} b_j\\left(o_{t+1}\\right) \\beta_{t+1}(j)} \\] 将 \\(\\gamma_t(i)\\) 和 \\(\\xi_t(i, j)\\) 对各个时刻 \\(t\\) 求和, 可以得到一些有用的期望值。 在观测 \\(O\\) 下状态 \\(i\\) 出现的期望值: \\[ \\sum_{t=1}^T \\gamma_t(i) \\] （2）在观测 \\(O\\) 下由状态 \\(i\\) 转移的期望值: \\[ \\sum_{t=1}^{T-1} \\gamma_t(i) \\] 在观测 \\(O\\) 下由状态 \\(i\\) 转移到状态 \\(j\\) 的期望值: \\[ \\sum_{t=1}^{T-1} \\xi_t(i, j) \\] ","date":"2021-10-25","objectID":"/hmm/:6:0","tags":["NLP","概率图模型","贝叶斯网络","HMM"],"title":"HMM","uri":"/hmm/"},{"categories":["NLP","概率图模型","贝叶斯网络"],"content":"预测问题 ","date":"2021-10-25","objectID":"/hmm/:7:0","tags":["NLP","概率图模型","贝叶斯网络","HMM"],"title":"HMM","uri":"/hmm/"},{"categories":["NLP","概率图模型","贝叶斯网络"],"content":"近似算法 近似算法的想法是, 在每个时刻 \\(t\\) 选择在该时刻最有可能出现的状态 $i_t^* $, 从而得 到一个状态序列 \\(I^* =\\left(i_1^* , i_2^* , \\cdots, i_T^* \\right)\\), 将它作为预测的结果。 给定隐马尔可夫模型 \\(\\lambda\\) 和观测序列 \\(O\\), 在时刻 \\(t\\) 处于状态 \\(q_i\\) 的概率 \\(\\gamma_t(i)\\) 是 \\[ \\gamma_t(i)=\\frac{\\alpha_t(i) \\beta_t(i)}{P(O \\mid \\lambda)}=\\frac{\\alpha_t(i) \\beta_t(i)}{\\sum_{j=1}^N \\alpha_t(j) \\beta_t(j)} \\] 在每一时刻 \\(t\\) 最有可能的状态 $i_t^* $ 是 \\[ i_t^* =\\arg \\max_{1 \\leqslant i \\leqslant N}\\left[\\gamma_t(i)\\right], \\quad t=1,2, \\cdots, T \\] 从而得到状态序列 \\(I^* =\\left(i_1^* , i_2^* , \\cdots, i_T^* \\right)\\) 。 近似算法的优点是计算简单, 其缺点是不能保证预测的状态序列整体是最有可能 的状态序列, 因为预测的状态序列可能有实际不发生的部分。事实上, 上述方法得到 的状态序列中有可能存在转移概率为 0 的相邻状态, 即对某些 \\(i, j, a_{i j}=0\\) 时。尽管 如此, 近似算法仍然是有用的。 近似算法就是一种贪心的算法，每个时刻都取最有可能的状态，但整体序列并不一定是最优解。 ","date":"2021-10-25","objectID":"/hmm/:7:1","tags":["NLP","概率图模型","贝叶斯网络","HMM"],"title":"HMM","uri":"/hmm/"},{"categories":["NLP","概率图模型","贝叶斯网络"],"content":"维特比算法 维特比算法实际上是用动态规划解隐马尔科夫模型预测问题，用动态规划求解概率最大路径，一条路径对应着一条状态序列。 首先导入两个变量 \\(\\delta\\) 和 \\(\\Psi\\) 。定义在时刻 \\(t\\) 状态为 \\(i\\) 的所有单个路径 \\(\\left(i_1, i_2, \\cdots, i_t\\right)\\) 中概率最大值为 \\[ \\delta_t(i)=\\max_{i_1, i_2, \\cdots, i_{t-1}} P\\left(i_t=i, i_{t-1}, \\cdots, i_1, o_t, \\cdots, o_1 \\mid \\lambda\\right), \\quad i=1,2, \\cdots, N \\] 后面的部分与前向算法的部分有点类似。 由定义可得变量 \\(\\delta\\) 的递推公式: \\[ \\begin{aligned} \\delta_{t+1}(i) \u0026=\\max_{i_1, i_2, \\cdots, i_t} P\\left(i_{t+1}=i, i_t, \\cdots, i_1, o_{t+1}, \\cdots, o_1 \\mid \\lambda\\right) \\\\\\\\ \u0026=\\max_{1 \\leqslant j \\leqslant N}\\left[\\delta_t(j) a_{j i}\\right] b_i\\left(o_{t+1}\\right), \\quad i=1,2, \\cdots, N ; \\quad t=1,2, \\cdots, T-1 \\end{aligned} \\] 定义在时刻 \\(t\\) 状态为 \\(i\\) 的所有单个路径 \\(\\left(i_1, i_2, \\cdots, i_{t-1}, i\\right)\\) 中概率最大的路径的 第 \\(t-1\\) 个结点为 \\[ \\Psi_t(i)=\\arg \\max_{1 \\leqslant j \\leqslant N}\\left[\\delta_{t-1}(j) a_{j i}\\right], \\quad i=1,2, \\cdots, N \\] 可以简单理解为找到使得从t-1的j到t的i式子\\(\\delta_{t-1}(j)a_{ji}\\)最大的j，也就是说\\(\\Psi_t(i)\\)代表t-1时刻的最佳状态值，如果t时刻的最佳状态值是i的话，那么t-1时刻的最佳状态值就是\\(\\Psi_t(i)\\)，后面回溯要用到 下面介绍维特比算法。 输入: 模型 \\(\\lambda=(A, B, \\pi)\\) 和观测 \\(O=\\left(o_1, o_2, \\cdots, o_T\\right)\\); 输出: 最优路径 \\(I^* =\\left(i_1^* , i_2^* , \\cdots, i_T^* \\right)\\) 。 （1）初始化 \\[ \\begin{gathered} \\delta_1(i)=\\pi_i b_i\\left(o_1\\right), \\quad i=1,2, \\cdots, N \\\\\\\\ \\Psi_1(i)=0, \\quad i=1,2, \\cdots, N \\end{gathered} \\] 前者和前向算法的初始化是一样的。 递推。对 \\(t=2,3, \\cdots, T\\) \\[ \\begin{array}{ll} \\delta_t(i)=\\max_{1 \\leqslant j \\leqslant N}\\left[\\delta_{t-1}(j) a_{j i}\\right] b_i\\left(o_t\\right), \\quad i=1,2, \\cdots, N \\\\\\\\ \\Psi_t(i)=\\arg \\max_{1 \\leqslant j \\leqslant N}\\left[\\delta_{t-1}(j) a_{j i}\\right], \\quad i=1,2, \\cdots, N \\end{array} \\] 终止 \\[ \\begin{gathered} P^* =\\max_{1 \\leqslant i \\leqslant N} \\delta_T(i) \\\\\\\\ i_T^* =\\arg \\max_{1 \\leqslant i \\leqslant N}\\left[\\delta_T(i)\\right] \\end{gathered} \\] 这里得到的是最后一个时刻的最佳状态值，然后进行回溯。 最优路径回溯。对 \\(t=T-1, T-2, \\cdots, 1\\) \\[ i_t^* =\\Psi_{t+1}\\left(i_{t+1}^* \\right) \\] 求得最优路径 \\(I^* =\\left(i_1^* , i_2^* , \\cdots, i_T^* \\right)\\) 。 书上的例子 看一个例子就很容易理解了 #### 代码 def viterbi(obs, states, start_p, trans_p, emit_p): V = [{}] # 列表idx代表时间t，字典的键代表状态值，值代表概率 path = {} # 最佳路径 for y in states: V[0][y] = start_p[y] * emit_p[y].get(obs[0], 1e-5) path[y] = [0] # 都初始化为0 for t in range(1, len(obs)): V.append({}) for y in states: em_p = emit_p[y].get(obs[t], 1e-5) # 取出观测值对应的概率 (prob, state) = max([(V[t-1][y0]*trans_p[y0][y]*em_p, y0) for y0 in states]) V[t][y] = prob path[y] = path[y] + [state] # 记录路径，state是当前时间t状态为y时t-1的最佳状态，也就是从state转移到y的概率最大。如果最后时刻的最佳状态是y，则回溯从y开始，最后的状态也是y。 (prob, state) = max((V[len(obs)-1][y], y) for y in states) # 求最后时刻的最大概率和状态。 return path[state][1:] + [state] # 初始状态是0，所以去掉第一个0，再加上最后时刻的最大概率的状态，结果就是最佳路径。这里键对值的过程相当于回溯了。 A = { 0 : {0:0.5, 1:0.2, 2:0.3}, 1 : {0:0.3, 1:0.5, 2:0.2}, 2 : {0:0.2, 1:0.3, 2:0.5} } B = { 0: {'红': 0.5, '白': 0.5}, 1: {'红': 0.4, '白': 0.6}, 2: {'红': 0.7, '白': 0.3} } π = {0:0.2, 1:0.4, 2:0.4} viterbi(['红', '白', '红'], [0, 1, 2], π, A, B) 拿上面的例子进行实验，思路是完全按照李航老师书的思路来的。还是比较容易理解的，只是回溯的实现不太一样，这个严格来说不能叫做回溯。 ","date":"2021-10-25","objectID":"/hmm/:7:2","tags":["NLP","概率图模型","贝叶斯网络","HMM"],"title":"HMM","uri":"/hmm/"},{"categories":["NLP","概率图模型","贝叶斯网络"],"content":"学习算法 ","date":"2021-10-25","objectID":"/hmm/:8:0","tags":["NLP","概率图模型","贝叶斯网络","HMM"],"title":"HMM","uri":"/hmm/"},{"categories":["NLP","概率图模型","贝叶斯网络"],"content":"参考 《统计学习方法》李航 https://www.52nlp.cn/hmm-learn-best-practices-one-introduction https://www.cnblogs.com/pinard/p/6945257.html ","date":"2021-10-25","objectID":"/hmm/:9:0","tags":["NLP","概率图模型","贝叶斯网络","HMM"],"title":"HMM","uri":"/hmm/"},{"categories":["NLP"],"content":"What? TF-IDF(term frequency–inverse document frequency)是一种用于信息检索与数据挖掘的常用加权技术，常用于挖掘文章中的关键词，而且算法简单高效，常被工业用于最开始的文本数据清洗。 TF-IDF有两层意思，一层是”词频”（Term Frequency，缩写为TF），另一层是”逆文档频率”（Inverse Document Frequency，缩写为IDF）。 假设我们现在有一片长文叫做《量化系统架构设计》词频高在文章中往往是停用词，“的”，“是”，“了”等，这些在文档中最常见但对结果毫无帮助、需要过滤掉的词，用TF可以统计到这些停用词并把它们过滤。当高频词过滤后就只需考虑剩下的有实际意义的词。 但这样又会遇到了另一个问题，我们可能发现”量化”、“系统”、“架构”这三个词的出现次数一样多。这是不是意味着，作为关键词，它们的重要性是一样的？事实上系统应该在其他文章比较常见，所以在关键词排序上，“量化”和“架构”应该排在“系统”前面，这个时候就需要IDF，IDF会给常见的词较小的权重，它的大小与一个词的常见程度成反比。 当有TF(词频)和IDF(逆文档频率)后，将这两个词相乘，就能得到一个词的TF-IDF的值。某个词在文章中的TF-IDF越大，那么一般而言这个词在这篇文章的重要性会越高，所以通过计算文章中各个词的TF-IDF，由大到小排序，排在最前面的几个词，就是该文章的关键词。 ","date":"2021-10-24","objectID":"/tf-idf/:1:0","tags":["NLP","TF-IDF"],"title":"TF-IDF","uri":"/tf-idf/"},{"categories":["NLP"],"content":"步骤 第一步，计算词频： \\[ 词频(TF) = \\frac{某个词在文章中出现次数}{文章的总词数} \\] 第二步，计算逆文档频率： \\[ 逆文档频率(IDF) = log(\\frac{语料库的文档总数}{包含该词的文档数+1}) \\] 1.为什么+1？是为了处理分母为0的情况。假如所有的文章都不包含这个词，分子就为0，所以+1是为了防止分母为0的情况。 2.为什么要用log函数？log函数是单调递增，求log是为了归一化，保证反文档频率不会过大。 3.会出现负数？肯定不会，分子肯定比分母大。 第三步，计算TF-IDF： \\[ TF-IDF = 词频(TF) \\times 逆文档频率(IDF) \\] ","date":"2021-10-24","objectID":"/tf-idf/:2:0","tags":["NLP","TF-IDF"],"title":"TF-IDF","uri":"/tf-idf/"},{"categories":["NLP"],"content":"优缺点 TF-IDF的优点是简单快速，而且容易理解。缺点是有时候用词频来衡量文章中的一个词的重要性不够全面，有时候重要的词出现的可能不够多，而且这种计算无法体现位置信息，无法体现词在上下文的重要性。如果要体现词的上下文结构，那么你可能需要使用word2vec算法来支持。 ","date":"2021-10-24","objectID":"/tf-idf/:3:0","tags":["NLP","TF-IDF"],"title":"TF-IDF","uri":"/tf-idf/"},{"categories":["NLP"],"content":"代码 corpus = ['this is the first document', 'this is the second second document', 'and the third one', 'is this the first document'] words_list = list() for i in range(len(corpus)): words_list.append(corpus[i].split(' ')) ","date":"2021-10-24","objectID":"/tf-idf/:4:0","tags":["NLP","TF-IDF"],"title":"TF-IDF","uri":"/tf-idf/"},{"categories":["NLP"],"content":"手动实现 def manual(): from collections import Counter count_list = list() for i in range(len(words_list)): count = Counter(words_list[i]) count_list.append(count) import math def tf(word, count): return count[word] / sum(count.values()) def idf(word, count_list): n_contain = sum([1 for count in count_list if word in count]) return math.log(len(count_list) / (1 + n_contain)) def tf_idf(word, count, count_list): return tf(word, count) * idf(word, count_list) for i, count in enumerate(count_list): print(\"第 {} 个文档 TF-IDF 统计信息\".format(i + 1)) scores = {word : tf_idf(word, count, count_list) for word in count} sorted_word = sorted(scores.items(), key = lambda x : x[1], reverse=True) for word, score in sorted_word: print(\"\\tword: {}, TF-IDF: {}\".format(word, round(score, 5))) ","date":"2021-10-24","objectID":"/tf-idf/:4:1","tags":["NLP","TF-IDF"],"title":"TF-IDF","uri":"/tf-idf/"},{"categories":["NLP"],"content":"gensim def gensim_work(): from gensim import corpora # 赋给语料库中每个词(不重复的词)一个整数id dic = corpora.Dictionary(words_list) # 创建词典 new_corpus = [dic.doc2bow(words) for words in words_list] # 元组中第一个元素是词语在词典中对应的id，第二个元素是词语在文档中出现的次数 from gensim import models tfidf = models.TfidfModel(new_corpus) tfidf.save(\"tfidf.model\") # 载入模型 tfidf = models.TfidfModel.load(\"tfidf.model\") # 使用这个训练好的模型得到单词的tfidf值 res = [tfidf[temp] for temp in new_corpus] print(res) ","date":"2021-10-24","objectID":"/tf-idf/:4:2","tags":["NLP","TF-IDF"],"title":"TF-IDF","uri":"/tf-idf/"},{"categories":["NLP"],"content":"sklearn def sklearn_work(): from sklearn.feature_extraction.text import TfidfVectorizer vectorizer = TfidfVectorizer() tfidf = vectorizer.fit_transform(corpus) print(tfidf.toarray()) # 权重 print(vectorizer.get_feature_names()) # 单词 print(vectorizer.vocabulary_) # 词典 ","date":"2021-10-24","objectID":"/tf-idf/:4:3","tags":["NLP","TF-IDF"],"title":"TF-IDF","uri":"/tf-idf/"},{"categories":["pandas"],"content":"记录一下实训学到的内容 ","date":"2021-10-24","objectID":"/%E5%AE%9E%E8%AE%AD%E5%AD%A6%E4%B9%A0%E5%86%85%E5%AE%B9/:0:0","tags":["pandas","learn_three"],"title":"实训学习内容","uri":"/%E5%AE%9E%E8%AE%AD%E5%AD%A6%E4%B9%A0%E5%86%85%E5%AE%B9/"},{"categories":["pandas"],"content":"布尔索引 布尔索引不能使用and or not ，只能用\u0026 | ~ 因为只能用位操作符 ","date":"2021-10-24","objectID":"/%E5%AE%9E%E8%AE%AD%E5%AD%A6%E4%B9%A0%E5%86%85%E5%AE%B9/:1:0","tags":["pandas","learn_three"],"title":"实训学习内容","uri":"/%E5%AE%9E%E8%AE%AD%E5%AD%A6%E4%B9%A0%E5%86%85%E5%AE%B9/"},{"categories":["pandas"],"content":"花哨索引 arr = np.arange(32).reshape((8, 4)) arr array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]]) arr[[1, 5, 7, 2], [0, 3, 1, 2]] array([ 4, 23, 29, 10]) ","date":"2021-10-24","objectID":"/%E5%AE%9E%E8%AE%AD%E5%AD%A6%E4%B9%A0%E5%86%85%E5%AE%B9/:1:1","tags":["pandas","learn_three"],"title":"实训学习内容","uri":"/%E5%AE%9E%E8%AE%AD%E5%AD%A6%E4%B9%A0%E5%86%85%E5%AE%B9/"},{"categories":["pandas"],"content":"更常用的方式为 arr[[1, 5, 7, 2]][:, [0, 3, 1, 2]] # 行，列重置顺序 array([[ 4, 7, 5, 6], [20, 23, 21, 22], [28, 31, 29, 30], [ 8, 11, 9, 10]]) ","date":"2021-10-24","objectID":"/%E5%AE%9E%E8%AE%AD%E5%AD%A6%E4%B9%A0%E5%86%85%E5%AE%B9/:1:2","tags":["pandas","learn_three"],"title":"实训学习内容","uri":"/%E5%AE%9E%E8%AE%AD%E5%AD%A6%E4%B9%A0%E5%86%85%E5%AE%B9/"},{"categories":["pandas"],"content":"pandas.cut import pandas as pd import numpy as np cars = pd.read_csv(\"second_cars_info.csv\",encoding=\"gbk\") final_ = [cars.Sec_price.min()] + list(np.linspace(10,100,10)) + [cars.Sec_price.max()] pd.cut(cars[\"Sec_price\"],bins=final_).value_counts().sort_index() # 对区间进行排序 # labels参数给每个区间贴上标签 ","date":"2021-10-24","objectID":"/%E5%AE%9E%E8%AE%AD%E5%AD%A6%E4%B9%A0%E5%86%85%E5%AE%B9/:2:0","tags":["pandas","learn_three"],"title":"实训学习内容","uri":"/%E5%AE%9E%E8%AE%AD%E5%AD%A6%E4%B9%A0%E5%86%85%E5%AE%B9/"},{"categories":["pandas"],"content":".str的用法 可以对行列进行python字符串一样的操作 stud_alcoh[[\"Mjob\",'Fjob']].apply(lambda x:x.str.upper()) # 对Mjob Fjob两列变成大写 # 也可以用applymap stud_alcoh[[\"Mjob\",'Fjob']].applymap(lambda x:x.upper()) #区别就在于.str # 因为applymap只能对dataframe进行操作,apply可以对Dataframe和Series进行操作。 ","date":"2021-10-24","objectID":"/%E5%AE%9E%E8%AE%AD%E5%AD%A6%E4%B9%A0%E5%86%85%E5%AE%B9/:3:0","tags":["pandas","learn_three"],"title":"实训学习内容","uri":"/%E5%AE%9E%E8%AE%AD%E5%AD%A6%E4%B9%A0%E5%86%85%E5%AE%B9/"},{"categories":["pandas"],"content":"groupby与apply灵活运用 coffee = pd.read_excel(\"coffee.xlsx\") coffee.groupby(\"区域\").apply(lambda x:x[\"销售额\"].sum()) # 如果是DataFramegroupby对象调用apply，转换函数处理的就是每一个分组（dataframe） # 等价于 coffee.groupby(\"区域\")['销售额'].sum() 求各个区域的 销售总和、平均销售额、预计销售额与实际销售额的差异总和 def transfer(x_):# x_类型是dataframe res = pd.Series() res[\"销售总和\"] = x_[\"销售额\"].sum() res[\"平均销售额\"] = x_['销售额'].mean() res['差值'] = ( x_[\"销售额\"] - x_['预计销售额']).mean() return res # 返回的是一个series coffee.groupby(\"区域\").apply(transfer) 求出个区域中，高于该区域平均利润的记录 def transfer(x): # x(dataframe) mean_value = x[\"利润额\"].mean() condition = x[\"利润额\"] \u003e mean_value return x[condition] # dataframe c = coffee.groupby(\"区域\").apply(transfer) # 二维索引 # c.loc[(\"Central\",0)] ","date":"2021-10-24","objectID":"/%E5%AE%9E%E8%AE%AD%E5%AD%A6%E4%B9%A0%E5%86%85%E5%AE%B9/:4:0","tags":["pandas","learn_three"],"title":"实训学习内容","uri":"/%E5%AE%9E%E8%AE%AD%E5%AD%A6%E4%B9%A0%E5%86%85%E5%AE%B9/"},{"categories":["pandas"],"content":"groupby也可以嵌套 def top_3_data(x):# x 表示DataFrame 每个区域的数据集 res = x.groupby(\"产品名称\").sum().sort_values(\"销售额\",ascending=False).iloc[:3] return res coffee.groupby(\"区域\").apply(top_3_data) ","date":"2021-10-24","objectID":"/%E5%AE%9E%E8%AE%AD%E5%AD%A6%E4%B9%A0%E5%86%85%E5%AE%B9/:4:1","tags":["pandas","learn_three"],"title":"实训学习内容","uri":"/%E5%AE%9E%E8%AE%AD%E5%AD%A6%E4%B9%A0%E5%86%85%E5%AE%B9/"},{"categories":["pandas"],"content":"nlargest nsmallest 求每一列最大的几个多最小的几个，一般配合groupby和apply使用 ","date":"2021-10-24","objectID":"/%E5%AE%9E%E8%AE%AD%E5%AD%A6%E4%B9%A0%E5%86%85%E5%AE%B9/:5:0","tags":["pandas","learn_three"],"title":"实训学习内容","uri":"/%E5%AE%9E%E8%AE%AD%E5%AD%A6%E4%B9%A0%E5%86%85%E5%AE%B9/"},{"categories":["pandas"],"content":"pd.Grouper grouper = pd.Grouper(key=\"订单日期\",freq=\"M\") 按月进行分组 。freq=\"Y\"就是按年分组 def top_sale_month(x): #x 表示DataFrame 每个产品的数据集 grouper = pd.Grouper(key=\"订单日期\",freq=\"M\") return x.groupby(grouper).sum().nlargest(1,\"销售额\") coffee.groupby(\"产品名称\").apply(top_sale_month).reset_index() reset_index()方法就是按照原来的index显示，不然就是按照分组的结果展示 ## plt.xticks plt.yticks 可以理解为自定义x轴的坐标 plt.figure(figsize=(12,8)) width = 0.2 plt.bar(np.arange(4)+0,np.random.randint(3,10,(4)),color='r',width=width) plt.bar(np.arange(4)+width*1,np.random.randint(3,10,(4)),color='g',width=width) plt.bar(np.arange(4)+width*2,np.random.randint(3,10,(4)),color='b',width=width) plt.xticks(np.arange(4)+width/2,list(\"abcd\")) # 将0 1 2 3 替换为 a b c d plt.show() ","date":"2021-10-24","objectID":"/%E5%AE%9E%E8%AE%AD%E5%AD%A6%E4%B9%A0%E5%86%85%E5%AE%B9/:6:0","tags":["pandas","learn_three"],"title":"实训学习内容","uri":"/%E5%AE%9E%E8%AE%AD%E5%AD%A6%E4%B9%A0%E5%86%85%E5%AE%B9/"},{"categories":["pandas"],"content":"np.where np.where(condition, [x, y]),这里三个参数,其中必写参数是condition(判断条件),后边的x和y是可选参数.那么这三个参数都有怎样的要求呢? condition：array_like，bool,当为True时，产生x，否则产生y 情况1： np.where([[True, False], [True, True]], [[1, 2], [3, 4]], [[9, 8], [7, 6]]) 返回： array([[1, 8], [3, 4]]) 条件中第0个元素中的第0个元素是true,那么取x中的相对应元素1; 条件中第0个元素中的第1个元素是false,那么取y中的相对应元素8; 条件中第1个元素中的第0个元素是ture,那么取x中相对应的元素3; 条件中第1个元素中的第1个元素是ture,那么取x中相对应的元素4; 所以最后的结果中取出的元素是1,8,3,4. 情况2： x = np.arange(9.).reshape(3, 3) np.where(x\u003e5) # 返回的是索引 (array([2, 2, 2], dtype=int64), array([0, 1, 2], dtype=int64)) 第一个array是行坐标，第二个array为列坐标。 不想要索引想要具体的数值也很简单 x[np.where(x\u003e5)] array([6., 7., 8.]) np.where(x \u003c 5, x, -1) array([[ 0., 1., 2.], [ 3., 4., -1.], [-1., -1., -1.]]) 可见小于五的部分不变，大于5的则变成了-1 np.where常用于pandas的Series中。 ","date":"2021-10-24","objectID":"/%E5%AE%9E%E8%AE%AD%E5%AD%A6%E4%B9%A0%E5%86%85%E5%AE%B9/:7:0","tags":["pandas","learn_three"],"title":"实训学习内容","uri":"/%E5%AE%9E%E8%AE%AD%E5%AD%A6%E4%B9%A0%E5%86%85%E5%AE%B9/"},{"categories":["算法题"],"content":"平衡括号字符串的最少插入次数 ","date":"2021-10-19","objectID":"/%E5%B9%B3%E8%A1%A1%E6%8B%AC%E5%8F%B7%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E6%9C%80%E5%B0%91%E6%8F%92%E5%85%A5%E6%AC%A1%E6%95%B0/:0:0","tags":["算法题","平衡括号字符串的最少插入次数"],"title":"平衡括号字符串的最少插入次数","uri":"/%E5%B9%B3%E8%A1%A1%E6%8B%AC%E5%8F%B7%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E6%9C%80%E5%B0%91%E6%8F%92%E5%85%A5%E6%AC%A1%E6%95%B0/"},{"categories":["算法题"],"content":"题目： https://leetcode-cn.com/problems/minimum-insertions-to-balance-a-parentheses-string/ ","date":"2021-10-19","objectID":"/%E5%B9%B3%E8%A1%A1%E6%8B%AC%E5%8F%B7%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E6%9C%80%E5%B0%91%E6%8F%92%E5%85%A5%E6%AC%A1%E6%95%B0/:1:0","tags":["算法题","平衡括号字符串的最少插入次数"],"title":"平衡括号字符串的最少插入次数","uri":"/%E5%B9%B3%E8%A1%A1%E6%8B%AC%E5%8F%B7%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E6%9C%80%E5%B0%91%E6%8F%92%E5%85%A5%E6%AC%A1%E6%95%B0/"},{"categories":["算法题"],"content":"思路： 本题和前面的题属于同一系列的，都是平衡括号字符串，不过这个不是1:1 而是1:2 思路还是差不多，不过判断条件需要改变 ","date":"2021-10-19","objectID":"/%E5%B9%B3%E8%A1%A1%E6%8B%AC%E5%8F%B7%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E6%9C%80%E5%B0%91%E6%8F%92%E5%85%A5%E6%AC%A1%E6%95%B0/:2:0","tags":["算法题","平衡括号字符串的最少插入次数"],"title":"平衡括号字符串的最少插入次数","uri":"/%E5%B9%B3%E8%A1%A1%E6%8B%AC%E5%8F%B7%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E6%9C%80%E5%B0%91%E6%8F%92%E5%85%A5%E6%AC%A1%E6%95%B0/"},{"categories":["算法题"],"content":"代码： class Solution: def minInsertions(self, s: str) -\u003e int: res,temp = 0,0 for i in s: if i == '(': temp += 2 if temp % 2 == 1: res += 1 temp -= 1 if i == ')': temp -= 1 if temp == -1: res += 1 temp = 1 return res + temp 开始还是初始化，temp代表需求的右括号的数量 如果有左括号的话，则让右括号的需求+2 因为一个左对应两个右 这里有个难点，如果需求的是奇数的话，则应添加一个右括号，然后让需求减1 如果是右括号，则需求 减1 如果需求的成了-1 的话 则在左边补上左括号 res++ 此时还需要一个右括号，则temp再初始化为1 最后还是输出 Q:为什么最后不是 temp == -2 res += 1 temp=0 呢？ 看看这个例子: \")))))))\" 这是7个右括号，最后减到最后的话，temp是个负数，影响了最后的结果。 所以还是要用原来的那样，-1的时候就进行判断，不用考虑奇偶的问题了 ","date":"2021-10-19","objectID":"/%E5%B9%B3%E8%A1%A1%E6%8B%AC%E5%8F%B7%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E6%9C%80%E5%B0%91%E6%8F%92%E5%85%A5%E6%AC%A1%E6%95%B0/:3:0","tags":["算法题","平衡括号字符串的最少插入次数"],"title":"平衡括号字符串的最少插入次数","uri":"/%E5%B9%B3%E8%A1%A1%E6%8B%AC%E5%8F%B7%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E6%9C%80%E5%B0%91%E6%8F%92%E5%85%A5%E6%AC%A1%E6%95%B0/"},{"categories":["python"],"content":"可变与不可变 “-=”操作符会调用__isub__函数，而”-“操作符会调用__sub__函数，一般对于可变对象来说“-=”操作符会直接改变self自身。 import torch x1 = 1 x2 = 2 params = [x1, x2] for p in params: print(id(p), id(x1), id(x2)) p -= 4 print(id(p), id(x1), id(x2)) print(params) x1 = torch.Tensor([1]) x2 = torch.Tensor([2]) params = [x1, x2] for p in params: print(id(p), id(x1), id(x2)) p -= 4 print(id(p), id(x1), id(x2)) print(params) 9784896 9784896 9784928 9784768 9784896 9784928 9784928 9784896 9784928 9784800 9784896 9784928 [1, 2] 139752445458112 139752445458112 139752445458176 139752445458112 139752445458112 139752445458176 139752445458176 139752445458112 139752445458176 139752445458176 139752445458112 139752445458176 [tensor([-3.]), tensor([-2.])] 可以看到对于int类型，地址变换了，而torch类型，地址却没有变化。 p -= 4等价于p.sub_(4)。这个可变对象改变了自身。写成p = p - 4则会调用构造函数，并返回一个新的变量，也就不可能作用到原先的“可变对象”。 int类没有发生就地变化是因为它是一个不可变对象。 这是python “-” 与”-=“的一个坑 微妙的字符串 a = 'some_thing' b = 'some'+'_'+'thing' id(a),id(b) (1957716471920, 1957716471920) a = 'wtf' b = 'wtf' a is b True a = 'wtf!' b = 'wtf!' a is b False a,b = 'wtf!','wtf!' a is b True 'a'*20 is 'aaaaaaaaaaaaaaaaaaaa','a'*21 is 'aaaaaaaaaaaaaaaaaaaaa' (True, False) Cpython 在编译优化时, 某些情况下会尝试使用已经存在的不可变对象,成为字符串驻留 发生驻留之后, 许多变量可能指向内存中的相同字符串对象 所有长度为 0 和长度为 1 的字符串都被驻留. 字符串在编译时被实现 (‘wtf’ 将被驻留, 但是 ’‘.join([’w’, ’t’, ’f’] 将不会被驻留) 字符串中只包含字母，数字或下划线时将会驻留. 所以 ’wtf!’ 由于包含 ! 而未被驻留。 当在同一行将 a 和 b 的值设置为 “wtf!” 的时候, Python 解释器会创建一个新对象, 然后同时引用第二个变量. 常量折叠(constant folding) 是 Python 中的一种 窥孔优化(peephole optimization) 技术. 这意味着在编译时表达式 ‘a’*20 会被替换为 ‘aaaaaaaaaaaaaaaaaaaa’ 以减少运行时的时钟周期. 只有长度小于 20 的字符串才会发生常量折叠. a = 1 b = 1 a is b,id(a) == id(b) (True, True) is 是比较对象是否相同(is 表示对象标识符即 object identity)，即用 id() 函数查看的地址是否相同，如果相同则返回 True，如果不同则返回 False。is 不能被重载。 == 是比较两个对象的值是否相等，此操作符内部调用的是 _eq() 方法。所以 a==b 等效于a.___eq__(b)，所以 = 可以被重载 ","date":"2021-10-18","objectID":"/wtf/:1:0","tags":["python","WTF"],"title":"WTF","uri":"/wtf/"},{"categories":["python"],"content":"是时候来点蛋糕了! some_dict = {} some_dict[5.5] = 'ruby' some_dict[5.0] = 'javascript' some_dict[5] = 'python' print(some_dict[5.0]) python 5 == 5.0,hash(5) == hash(5.0) (True, True) Python 字典通过检查键值是否相等和比较哈希值来确定两个键是否相同. 具有相同值的不可变对象在Python中始终具有相同的哈希值 ","date":"2021-10-18","objectID":"/wtf/:2:0","tags":["python","WTF"],"title":"WTF","uri":"/wtf/"},{"categories":["python"],"content":"本质上,我们都一样 class WTF: pass print(WTF() == WTF(),WTF() is WTF()) print(hash(WTF()) == hash(WTF())) print(id(WTF()) == id(WTF())) False False True True 当调用 id 函数时, Python 创建了一个 WTF 类的对象并传给 id 函数. 然后 id 函数获取其id值 (也就是内存地址), 然后丢弃该对象. 该对象就被销毁了. 当我们连续两次进行这个操作时, Python会将相同的内存地址分配给第二个对象. 因为 (在CPython中) id 函数使用对象的内存地址作为对象的id值, 所以两个对象的id值是相同的. print(id(id(WTF())) == id(id(WTF()))) ##无论多少个ID都是True 原因就在上面 ##虽然id(id(WTF())) == id(id(WTF())) 但是id(WTF()) is id(WTF()) 返回True ##原因就是id这个函数调用的过程特殊性 print(id(WTF()) is id(WTF())) True False class WTF(object): def __init__(self): print(\"I\") def __del__(self): print(\"D\") WTF() is WTF() ##这时是两个对象一起创建，然后一起销毁，所以id不一样 I I D D False id(WTF()) == id(WTF()) ##这时候先创建一个销毁，然后再创建。对象销毁的顺序是造成所有不同之处的原因. I D I D True ","date":"2021-10-18","objectID":"/wtf/:3:0","tags":["python","WTF"],"title":"WTF","uri":"/wtf/"},{"categories":["python"],"content":"为什么？ some_string = \"wtf\" some_dict = {} for i, some_dict[i] in enumerate(some_string): pass some_dict Python 语法 中对 for 的定义是: {0: 'w', 1: 't', 2: 'f'} for_stmt: 'for' exprlist 'in' testlist ':' suite ['else' ':' suite] 其中 exprlist 指分配目标. 这意味着对可迭代对象中的每一项都会执行类似 {exprlist} = {next_value} 的操作. for i in range(4): print(i) i = 10 0 1 2 3 ","date":"2021-10-18","objectID":"/wtf/:4:0","tags":["python","WTF"],"title":"WTF","uri":"/wtf/"},{"categories":["python"],"content":"列表副本 list1 = [1,2,3,4,5] list2 = list1 list2[0] = 6 print(list1,list2) [6, 2, 3, 4, 5] [6, 2, 3, 4, 5] list1 = [1,2,3,4,5] list2 = list1[:] list2[0] = 6 print(list1,list2) [1, 2, 3, 4, 5] [6, 2, 3, 4, 5] ","date":"2021-10-18","objectID":"/wtf/:5:0","tags":["python","WTF"],"title":"WTF","uri":"/wtf/"},{"categories":["python"],"content":"执行时机差异 array = [1, 8, 15] g = (x for x in array if array.count(x) \u003e 0) ##这时候x为[1,8,15]的解包 ##而后面的array变成了下面的 array = [2, 8, 22] print(list(g)) [8] 在生成器表达式中, in 子句在声明时执行, 而条件子句则是在运行时执行. 所以在运行前, array 已经被重新赋值为 [2, 8, 22], 因此对于之前的 1, 8 和 15, 只有 count(8) 的结果是大于 0 的, 所以生成器只会生成 8. array_1 = [1,2,3,4] g1 = (x for x in array_1) array_1 = [1,2,3,4,5] array_2 = [1,2,3,4] g2 = (x for x in array_2) array_2[:] = [1,2,3,4,5] print(list(g1)) print(list(g2)) [1, 2, 3, 4] [1, 2, 3, 4, 5] 第二部分中 g1 和 g2 的输出差异则是由于变量 array_1 和 array_2 被重新赋值的方式导致的. 在第一种情况下, array_1 被绑定到新对象 [1,2,3,4,5], 因为 in 子句是在声明时被执行的， 所以它仍然引用旧对象 [1,2,3,4]. 在第二种情况下, 对 array_2 的切片赋值将相同的旧对象 [1,2,3,4] 原地更新为 [1,2,3,4,5]. 因此 g2 和 array_2 仍然引用同一个对象(这个对象现在已经更新为 [1,2,3,4,5]). ","date":"2021-10-18","objectID":"/wtf/:6:0","tags":["python","WTF"],"title":"WTF","uri":"/wtf/"},{"categories":["python"],"content":"出人意料的is a = 256 b = 256 a is b True a = 257 b = 257 ##256 是一个已经存在的对象, 而 257 不是 ##当你启动Python 的时候, -5 到 256 的数值就已经被分配好了. ##这些数字因为经常使用所以适合被提前准备好 a is b False a,b = 257,257 ##当 a 和 b 在同一行中使用相同的值初始化时，会指向同一个对象. print(a is b) print(id(a),id(b)) True 1957717387056 1957717387056 [] == [] True [] is [] ##两个空列表位于不同的内存地址 False ","date":"2021-10-18","objectID":"/wtf/:7:0","tags":["python","WTF"],"title":"WTF","uri":"/wtf/"},{"categories":["python"],"content":"一蹴即至! row = [\"\"] * 3 board = [row] * 3 board [['', '', ''], ['', '', ''], ['', '', '']] board[0][0] = 'X' board ##这是因为之前对row做乘法导致的 [['X', '', ''], ['X', '', ''], ['X', '', '']] ##如何避免这种情况？ board = [['']*3 for _ in range(3)] board[0][0] = 'X' board [['X', '', ''], ['', '', ''], ['', '', '']] ","date":"2021-10-18","objectID":"/wtf/:8:0","tags":["python","WTF"],"title":"WTF","uri":"/wtf/"},{"categories":["python"],"content":"麻烦的输出 funcs = [] res = [] for x in range(7): def func(): return x funcs.append(func) res.append(func()) func_res = [func() for func in funcs] print(func_res,res) [6, 6, 6, 6, 6, 6, 6] [0, 1, 2, 3, 4, 5, 6] power_x = [lambda x:x**i for i in range(11)] print([func(2) for func in power_x]) [1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024] 在循环内部定义一个函数时, 如果该函数在其主体中使用了循环变量, 则闭包函数将与循环变量绑定, 而不是它的值. 因此, 所有的函数都是使用最后分配给变量的值来进行计算的. ","date":"2021-10-18","objectID":"/wtf/:9:0","tags":["python","WTF"],"title":"WTF","uri":"/wtf/"},{"categories":["python"],"content":"连Python也知道爱是难言的 import this The Zen of Python, by Tim Peters Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. Readability counts. Special cases aren't special enough to break the rules. Although practicality beats purity. Errors should never pass silently. Unless explicitly silenced. In the face of ambiguity, refuse the temptation to guess. There should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you're Dutch. Now is better than never. Although never is often better than *right* now. If the implementation is hard to explain, it's a bad idea. If the implementation is easy to explain, it may be a good idea. Namespaces are one honking great idea -- let's do more of those! love = this this is love True love is True False love is False False love is not True or False True love is not True or False;love is love True ","date":"2021-10-18","objectID":"/wtf/:10:0","tags":["python","WTF"],"title":"WTF","uri":"/wtf/"},{"categories":["python"],"content":"三个引号 print('wtfpython''') wtfpython print(\"wtf\" \"python\") wtfpython ","date":"2021-10-18","objectID":"/wtf/:11:0","tags":["python","WTF"],"title":"WTF","uri":"/wtf/"},{"categories":["python"],"content":"布尔你咋了? mixed_list = [False, 1.0, \"some_string\", 3, True, [], False] integers_found_so_far = 0 booleans_found_so_far = 0 for item in mixed_list: if isinstance(item, int): integers_found_so_far += 1 elif isinstance(item, bool): booleans_found_so_far += 1 integers_found_so_far 4 booleans_found_so_far 0 another_dict = {} another_dict[True] = \"JavaScript\" another_dict[1] = \"Ruby\" another_dict[1.0] = \"Python\" another_dict[True] 'Python' 布尔值是 int 的子类 some_iterable = ('a', 'b') def some_func(val): return \"something\" [x for x in some_iterable] ['a', 'b'] [(yield x) for x in some_iterable] \u003cgenerator object \u003clistcomp\u003e at 0x000001CC6FFC3888\u003e list([(yield x) for x in some_iterable]) ['a', 'b'] list(((yield x) for x in some_iterable)) ['a', None, 'b', None] list(some_func((yield x)) for x in some_iterable) ['a', 'something', 'b', 'something'] ","date":"2021-10-18","objectID":"/wtf/:12:0","tags":["python","WTF"],"title":"WTF","uri":"/wtf/"},{"categories":["python"],"content":"消失的外部变量 e = 7 try: raise Exception() except Exception as e: pass print(e) ##error! ","date":"2021-10-18","objectID":"/wtf/:13:0","tags":["python","WTF"],"title":"WTF","uri":"/wtf/"},{"categories":["python"],"content":"从有到无 some_list = [1, 2, 3] some_dict = { \"key_1\": 1, \"key_2\": 2, \"key_3\": 3 } some_list = some_list.append(4) some_dict = some_dict.update({\"key_4\": 4}) some_list some_dict 大多数修改序列/映射对象的方法, 比如 list.append, dict.update, list.sort 等等. 都是原地修改对象并返回 None. 这样做的理由是, 如果操作可以原地完成, 就可以避免创建对象的副本来提高性能. ","date":"2021-10-18","objectID":"/wtf/:14:0","tags":["python","WTF"],"title":"WTF","uri":"/wtf/"},{"categories":["python"],"content":"迭代列表时删除元素 list_1 = [1, 2, 3, 4] list_2 = [1, 2, 3, 4] list_3 = [1, 2, 3, 4] list_4 = [1, 2, 3, 4] for idx, item in enumerate(list_1): del item for idx, item in enumerate(list_2): list_2.remove(item) for idx, item in enumerate(list_3[:]): list_3.remove(item) for idx, item in enumerate(list_4): list_4.pop(idx) list_1 ##没有修改list_1 [1, 2, 3, 4] list_2 ##每一次删除元素后 迭代的list_2也发生改变 比如第一次删除了1 list_2为[2,3,4]这时idx=1 所以下一个删除了3 [2, 4] list_3 ##迭代副本不会出现上述情况 [] list_4 [2, 4] ","date":"2021-10-18","objectID":"/wtf/:15:0","tags":["python","WTF"],"title":"WTF","uri":"/wtf/"},{"categories":["python"],"content":"循环变量泄露 for x in range(7): if x == 6: print(x, ': for x inside loop') print(x, ': x in global') 6 : for x inside loop 6 : x in global ## 这次我们先初始化x x = -1 for x in range(7): if x == 6: print(x, ': for x inside loop') print(x, ': x in global') 6 : for x inside loop 6 : x in global x = 1 print([x for x in range(5)]) print(x, ': x in global') [0, 1, 2, 3, 4] 1 : x in global ","date":"2021-10-18","objectID":"/wtf/:16:0","tags":["python","WTF"],"title":"WTF","uri":"/wtf/"},{"categories":["python"],"content":"当心默认的可变参数 def some_func(default_arg=[]): default_arg.append(\"some_string\") return default_arg some_func() ['some_string'] some_func() ['some_string', 'some_string'] some_func([]) ['some_string'] some_func() ['some_string', 'some_string', 'some_string'] Python中函数的默认可变参数并不是每次调用该函数时都会被初始化. 相反, 它们会使用最近分配的值作为默认值. 当我们明确的将 [] 作为参数传递给 some_func 的时候, 就不会使用 default_arg 的默认值, 所以函数会返回我们所期望的结果. some_func.__defaults__ (['some_string', 'some_string', 'some_string'],) 避免可变参数导致的错误的常见做法是将 None 指定为参数的默认值, 然后检查是否有值传给对应的参数. 例: def some_func(default_arg=None): if not default_arg: default_arg = [] default_arg.append(\"some_string\") return default_arg ","date":"2021-10-18","objectID":"/wtf/:17:0","tags":["python","WTF"],"title":"WTF","uri":"/wtf/"},{"categories":["python"],"content":"同人不同命 a = [1, 2, 3, 4] b = a a = a + [5, 6, 7, 8] a [1, 2, 3, 4, 5, 6, 7, 8] b [1, 2, 3, 4] a = [1, 2, 3, 4] b = a a += [5, 6, 7, 8] a [1, 2, 3, 4, 5, 6, 7, 8] b [1, 2, 3, 4, 5, 6, 7, 8] a += b 并不总是与 a = a + b 表现相同. 类实现 op= 运算符的方式 也许 是不同的, 列表就是这样做的. 表达式 a = a + [5,6,7,8] 会生成一个新列表, 并让 a 引用这个新列表, 同时保持 b 不变. 表达式 a += [5,6,7,8] 实际上是使用的是 “extend” 函数, 所以 a 和 b 仍然指向已被修改的同一列表. a_var = 'global variable' def a_func(): print(a_var, '[ a_var inside a_func() ]') a_func() print(a_var, '[ a_var outside a_func() ]') global variable [ a_var inside a_func() ] global variable [ a_var outside a_func() ] a_var = 'global value' def a_func(): a_var = 'local value' print(a_var, '[ a_var inside a_func() ]') a_func() print(a_var, '[ a_var outside a_func() ]') local value [ a_var inside a_func() ] global value [ a_var outside a_func() ] a_var = 'global value' def a_func(): global a_var a_var = 'local value' print(a_var, '[ a_var inside a_func() ]') print(a_var, '[ a_var outside a_func() ]') a_func() print(a_var, '[ a_var outside a_func() ]') global value [ a_var outside a_func() ] local value [ a_var inside a_func() ] local value [ a_var outside a_func() ] a_var = 'global value' def outer(): a_var = 'enclosed value' def inner(): a_var = 'local value' print(a_var) inner() outer() local value a_var = 'global variable' def len(in_var): print('called my len() function') l = 0 for i in in_var: l += 1 return l def a_func(in_var): len_in_var = len(in_var) print('Input variable is of length', len_in_var) a_func('Hello, World!') called my len() function Input variable is of length 13 a = 'global' def outer(): def len(in_var): print('called my len() function: ', end=\"\") l = 0 for i in in_var: l += 1 return l a = 'local' def inner(): global len nonlocal a a += ' variable' inner() print('a is', a) print(len(a)) outer() print(len(a)) print('a is', a) a is local variable called my len() function: 14 called my len() function 6 a is global ","date":"2021-10-18","objectID":"/wtf/:18:0","tags":["python","WTF"],"title":"WTF","uri":"/wtf/"},{"categories":["python"],"content":"大海捞针 x, y = (0, 1) if True else None, None x,y ((0, 1), None) ##正确做法 x,y = (0,1) if True else (None,None) x,y (0, 1) t = ('one', 'two') for i in t: print(i) t = ('one') for i in t: print(i) t = () print(t) one two o n e () ##明显上面的把t = ('one') t当成字符串了，正确做法如下 t = ('one',) ##注意逗号 for i in t: print(i) one ","date":"2021-10-18","objectID":"/wtf/:19:0","tags":["python","WTF"],"title":"WTF","uri":"/wtf/"},{"categories":["NLP"],"content":"共现矩阵 主要用于发现主题，解决词向量相近关系的表示 例如，语料库如下： - I like deep learning. - I like NLP. - I enjoy flying. 则共现矩阵如下(窗口大小为1) 例如：“I like”出现在第1，2句话中，一共出现2次，所以=2。 对称的窗口指的是，“like I”也是2次 将共现矩阵行(列)作为词向量表示后，可以知道like，enjoy都是在I附近且统计数目大约相等，他们意思相近。 ","date":"2021-10-15","objectID":"/%E5%85%B1%E7%8E%B0%E7%9F%A9%E9%98%B5/:0:0","tags":["NLP","共现矩阵"],"title":"共现矩阵","uri":"/%E5%85%B1%E7%8E%B0%E7%9F%A9%E9%98%B5/"},{"categories":["NLP"],"content":"代码 import numpy as np word2ind = {w:i for i,w in enumerate(words)} # word到key，words就是词汇表 M = np.zeros((num_words, num_words)) # num_words是词汇表的长度 for c in corpus: # 假设语料库是一个列表，元素为一段文本。遍历语料库 for idx, word in enumerate(c): # 遍历文本的每一个词，这里默认空格分词 for i in range(1, window_size+1): # 对窗口大 小进行遍历 left = idx - i # 自己与自己不算共现，所以这里要加减 right = idx + i if left \u003e= 0: # 左边元素 M[word2ind[word], word2ind[c[left]]] += 1 if right \u003c len(c): # 右边元素 M[word2ind[word], word2ind[c[right]]] += 1 ","date":"2021-10-15","objectID":"/%E5%85%B1%E7%8E%B0%E7%9F%A9%E9%98%B5/:1:0","tags":["NLP","共现矩阵"],"title":"共现矩阵","uri":"/%E5%85%B1%E7%8E%B0%E7%9F%A9%E9%98%B5/"},{"categories":["python"],"content":"两个数的交换 # a = 1 # b = 2 # temp = b # b = a # a = temp # print(a,b) a = 1 b = 2 a,b = b,a print(a,b) 2 1 ","date":"2021-10-10","objectID":"/skill/:1:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"格式化字符串 a = 17 name = \"wlb\" # print('%s is %d years old' % (name,a)) # print('{} is {} years old'.format(name,a)) print(f'{name} is {a} years old') #明显这个方法更简单 wlb is 17 years old ","date":"2021-10-10","objectID":"/skill/:2:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"yield与yield from def fib(n): a = 0 b = 1 for _ in range(n): yield a a,b = b,a+b for i in fib(10): print(i) #注释的内容与yield a效果相同，yield相当于使其成为一个迭代器 yield一个数后会立马传递出去，而return 要等列表都生成完毕后才会传出去 #他的优势在于一些耗时的操作 # 通过yield来进行dfs，由于没有实现__next__因此是个可迭代对象而不是一个迭代器 class Node: def __init__(self,value) -\u003e None: self._value = value self._node = [] def __repr__(self) -\u003e str: return f'Node({self._value})' def add_children(self,node:'Node') -\u003e 'Node': self._node.append(node) def __iter__(self): return iter(self._node) def dfs(self): yield self for i in self: yield from i.dfs() root = Node(0) children1 = Node(1) children2 = Node(2) root.add_children(children1) root.add_children(children2) children1.add_children(Node(3)) children1.add_children(Node(4)) children11 = Node(5) children2.add_children(children11) children11.add_children(Node(6)) for c in root.dfs(): print(c) from typing import Iterable def test_format(datas: Iterable[str], max_len: int): for data in datas: if len(data) \u003e max_len: yield data[:max_len] + '...' else: yield data print(list(test_format(['vllbc', 'test_for_this_function', 'good'],5))) # 把长度大于5的部分变成省略号 #子生成器 def average_gen(): total = 0 count = 0 average = 0 while True: new_num = yield average if new_num is None: break count += 1 total += new_num average = total/count return total,count,average # 委托生成器 def proxy_gen(): while True: total,count,average = yield from average_gen() # yield from后面是一个可迭代对象,此文后面的将多维数组转化为一维数组中flatten函数就用到了yield from，原理就是如果列表中一个元素是列表就yield from这个列表，否则就直接yield这个元素，也利用了递归的方法。如果子生成器退出while循环了，就执行return以获取返回值。 print(total,count,average) def main(): t = proxy_gen() next(t) print(t.send(10)) print(t.send(15)) print(t.send(20)) t.send(None) main() ","date":"2021-10-10","objectID":"/skill/:3:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"列表解析式 lists = [f\"http://www.baidu.com/page{n}\" for n in range(21)] lists#此方法在爬虫构造urls中非常常用 # lists = [f\"http://www.baidu.com/page{n}\" for n in range(21) if n%2==0] page偶数 # alp = \"abcdefghigklmnopqrstuvwxyz\" # ALP = [n.upper() for n in alp] 将小写转换为大写 ","date":"2021-10-10","objectID":"/skill/:4:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"enumerate lists = ['apple','banana','cat','dog'] for index,name in enumerate(lists): print(index,name) # 手动实现一下enumerate from typing import Iterable def enumerate_(Iterable:Iterable,start=0): yield from zip(range(start,start+len(Iterable)),Iterable) for i,item in enumerate_([1,2,3,4,5,6],9): print(i,item) ","date":"2021-10-10","objectID":"/skill/:5:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"字典的合并 dic1 = {'qq':1683070754, 'phone':123456789 } dic2 = { 'height':180, 'handsome':True } dic3 = {**dic1,**dic2} #合并两个字典 **叫做解包 #或者用dic1.update(dic2) 将dic2合并到dic1 相同键则dic2替代dic1 dic3 {'handsome': True, 'height': 180, 'phone': 123456789, 'qq': 1683070754} ","date":"2021-10-10","objectID":"/skill/:6:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"序列解包 name = \"wang lingbo\" xing,ming = name.split(\" \") #split返回一个序列，分别赋给xing 和ming print(xing,ming) #x,*y,z = [1,2,3,4,5] #x:1 z:5 y:[2,3,4] wang lingbo ","date":"2021-10-10","objectID":"/skill/:7:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"匿名函数lambda lists = [1,2,3,4,5,6] maps = map(lambda x:x*x,lists) print(maps) print(list(maps)) \u003cmap object at 0x000001911C8E03C8\u003e [1, 4, 9, 16, 25, 36] ","date":"2021-10-10","objectID":"/skill/:8:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"装饰器 def logging(level): def wapper(func): def inner_wapper(*args, **wbargs): print(f'{level} enter in {func.__name__}()') return func(*args, **wbargs) #不写return 也可以 return inner_wapper return wapper @logging('inner') def say(a): print('hello! {}'.format(a)) say('wlb') inner enter in say() hello! wlb import time def print_time(func): def wapper(*args,**wbargs): print(f'{func.__name__}()调用于{time.asctime(time.localtime(time.time()))}') return func(*args,**wbargs) #不写return 也可以 return wapper @print_time def my_name(name): print(f'look!{name}') my_name(\"wlb\") my_name()调用于Wed Dec 9 21:21:00 2020 look!wlb ","date":"2021-10-10","objectID":"/skill/:9:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"map、reduce、filter # map print(list(map(abs,[-1,-2,-3,-4,-5]))) #也可以自己定义函数或者用匿名函数 # reduce from functools import reduce #python3中需要从内置库导入 print(reduce(lambda x,y:x+y,list(map(int,str(131351412))))) # filter a = [1,2,3,4,5,6,7,8,9] new_a = filter(lambda x:x%2!=0,a) #filter就是筛选 list(new_a) # 这三个都是函数式编程中常用的函数 ","date":"2021-10-10","objectID":"/skill/:10:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"join() # lists = ['1','2','3','4','5'] # ''.join(lists) lists = [1,2,3,4,5] ''.join(list(map(str,lists))) #join只能是字符串列表，所以要map转换一下 '12345' ","date":"2021-10-10","objectID":"/skill/:11:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"将多维数组转换为一维 ab = [[1, 2, 3], [5, 8], [7, 8, 9]] print([i for item in ab for i in item]) #利用列表解析式 print(sum(ab, [])) # 利用sum函数 from functools import reduce print(reduce(lambda x,y:x+y,ab)) # 利用reduce from itertools import chain print(list(chain(*ab))) # 利用chain def flatten(items,ignore=(str,bytes)): for x in items: if isinstance(x,Iterable) and not isinstance(x,ignore): yield from flatten(x) else: yield x print(list(flatten(ab))) # 利用自己定义的函数 [1, 2, 3, 5, 8, 7, 8, 9] ","date":"2021-10-10","objectID":"/skill/:12:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"将一个列表倒序 lists = [2,4,3,2,5,4] lists[::-1] # list(reversed(lists)) ","date":"2021-10-10","objectID":"/skill/:13:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"随机生成密码 import random b = 8 t = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890' print(''.join(random.sample(t,b))) # 主要就是用sample这个方法来取多个随机值 0KmtEZSU ","date":"2021-10-10","objectID":"/skill/:14:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"断言 assert(True is True) #成功 print('yes') assert(True is False) #报错 print('no') yes ","date":"2021-10-10","objectID":"/skill/:15:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"合并列表 list1 = [1,2,31,13] list2 = [5,2,12,32] # list1.append(list2) # print(list1) #错误方法 list1.extend(list2) print(list1) #正确方法 [1, 2, 31, 13, 5, 2, 12, 32] a = [1,2,3,4,5] b = ['a','b','c','d','e'] fin = dict() for k,i in zip(a,b): fin[k] = i print(fin) # {1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e'} # 或者 d = {} for i,d[i] in zip(a,b): pass print(d) # {1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e'} 为什么？在WTFpython中有讲 # 或者 fin = dict(zip(a,b)) print(fin) # {1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e'} ","date":"2021-10-10","objectID":"/skill/:16:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"对list进行解包 lists = ['dog','cat','you'] print(*lists) #想对一个列表进行zip操作时，可以这样 print(list(zip(*lists))) def test(*args): print(\"args:\",args) test(*lists) dog cat you [('d', 'c', 'y'), ('o', 'a', 'o'), ('g', 't', 'u')] args:('dog','cat','you') ","date":"2021-10-10","objectID":"/skill/:17:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"对类的一些操作 class Test: x = 1 y = 2 print(Test.x,Test.y) #==\u003eprint(Test().x,Test().y) class Test: def __init__(self,x,y): self.x = x self.y = y test = Test(1,2) print(test.x,test.y) 1 2 1 2 class Test: def __init__(self,maxlen): self.maxlen = maxlen self.lists = [] def put(self,*args): for i in args: if len(self.lists) \u003c= self.maxlen: self.lists.append(i) else: break def get(self): return self.lists.pop() def empty(self): if len(self.lists) != 0: return False else: return True def __len__(self): return len(self.lists) def __del__(self): print(\"del this class\") def printfs(self): return self.lists test = Test(10) test.put(1,2,3,4,5,6) print(test.empty()) print(len(test)) print(test.printfs()) test.__del__() #直接调用test还存在，__del__是析构函数，垃圾回收时就会调用a print(test) #del test #print(test) 这时候就会报错，因为del将test这个对象直接删除了 False 6 [1, 2, 3, 4, 5, 6] del this class \u003c__main__.Test object at 0x0000021B7DF33EB0\u003e del this class ","date":"2021-10-10","objectID":"/skill/:18:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"一些内置函数 all([True,True,False]) #False all([True,True,True]) #True any([True,True,False]) #True any([True,False,False])#True any([False,False]) #False import random for i in iter(lambda:random.randint(1,10),5): print(i) #相当于 while True: x = random.randint(1,10) print(x) if x == 5: break iter(object[, sentinel]) sentinel为可选参数，若不传入，则object必须为可迭代对象，传入则必须为可调用对象,当可调用对象的返回值为sentinel抛出异常，但for循环会处理这个异常，这常常用于IO操作 ​ #这是cookbook里面的一个例子 import sys f = open('xxx/xxx.txt') for chunk in iter(lambda:f.read(10),''): n = sys.stdout.write(chunk) #深入理解一下 import random class Test: def __init__(self): self.lists = [1,23,2,4,1,421,412] def __call__(self): return random.choice(self.lists) for i in iter(Test(),1): print(i) #这是可以正常输出的，因为实例化Test后是个可调用对象，返回列表的随机值，当返回1时则循环结束，如果把__call__魔法方法去了后，则会报错，如果想要不使用魔法方法的话可以用匿名函数 import random class Test: def __init__(self): self.lists = [1,23,2,4,1,421,412] # def __call__(self): # return random.choice(self.lists) for i in iter(lambda:random.choice(Test().lists),1): print(i) #总之，吹爆cookbook ","date":"2021-10-10","objectID":"/skill/:19:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"functools.partial #先看演示 from functools import partial def add(a,b): return a + b addOne = partial(add,1) addOne(2) #3 addOne(4) #5 #大概意思就是利用partial将函数的一个参数固定住了 def partial(func,*wargs): def wapper(*kargs): args = list(wargs) print(f\"args:{args}\") print(f\"kargs:{kargs}\") args.extend(kargs) print(f\"last:{args}\") return func(*args) return wapper def add(a,b,c): return a + b + c addone = partial(add,1,2) #此时addone相当于wapper print(addone(3)) #调用wrapper 3为传入的kargs #输出： args:[1, 2] kargs:(3,) last:[1, 2, 3] 6 #上面是partial函数的简化版本 #很明显的闭包操作，很容易就可以理解 #当然也可以转换为装饰器操作 from functools import wraps from functools import wraps,partial def out_wapper(*wargs): def partialout(func): return partial(func,*wargs) # 这是使用partial原理的 # @wraps(func) # def wrapper(*kargs): # args = list(wargs) # print(f\"args:{args}\") # print(f\"kargs:{kargs}\") # args.extend(kargs) # print(f\"last:{args}\") # return func(*args) # return wrapper return partialout @out_wapper(1,2) def add(a,b,c): return a + b + c print(add(3)) #6 #明显装饰器要麻烦一点实现，不过毕竟是封装好的函数，以后直接用就可以，不过了解这些有助于提高思维水平 ","date":"2021-10-10","objectID":"/skill/:20:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"@classmethod和@staticmethod class A(object): bar = 1 def func1(self): print ('foo') @classmethod def func2(cls): print ('func2') print (cls.bar) cls().func1() # 调用 foo 方法 A.func2() # 不需要实例化 func2 1 foo class A(object): # 属性默认为类属性（可以给直接被类本身调用） num = \"类属性\" # 实例化方法（必须实例化类之后才能被调用） def func1(self): # self : 表示实例化类后的地址id print(\"func1\") print(self) # 类方法（不需要实例化类就可以被类本身调用） @classmethod def func2(cls): # cls : 表示没用被实例化的类本身 print(\"func2\") print(cls) print(cls.num) cls().func1() # 不传递传递默认self参数的方法（该方法也是可以直接被类调用的，但是这样做不标准） def func3(): print(\"func3\") print(A.num) # 属性是可以直接用类本身调用的 # A.func1() 这样调用是会报错：因为func1()调用时需要默认传递实例化类后的地址id参数，如果不实例化类是无法调用的 A.func2() A.func3() class A(object): def foo(self, x): print(\"executing foo(%s,%s)\" % (self, x)) print('self:', self) @staticmethod def static_foo(x): print(\"executing static_foo(%s)\" % x) 问题：@staticmethod修饰的方法函数与普通的类外函数，为什么不直接使用普通函数？ @staticmethod是把函数嵌入到类中的一种方式，函数就属于类，同时表明函数不需要访问这个类。通过子类的继承覆盖，能更好的组织代码。 from pydantic import BaseModel from typing import Sequence class Test(BaseModel): text: Sequence[str] @classmethod def create(cls,text: Sequence[str]) -\u003e \"Test\": # classmethod常用构造函数 return cls(text=text) def to_tuple(self) -\u003e \"Test\": return Test(text=tuple(self.text)) @classmethod def join(cls, *Tests): return cls.create(sum([i.text for i in Tests],[])) test = Test.create(list(\"Hello world\")) t2 = Test.create(list(\"NIHAO\")) print(Test.join(test, t2)) # text=['H', 'e', 'l', 'l', 'o', ' ', 'w', 'o', 'r', 'l', 'd', 'N', 'I', 'H', 'A', 'O'] ","date":"2021-10-10","objectID":"/skill/:21:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"用类实现装饰器 #先看这样的代码 类实现装饰器要求类必须是可调用的 import time import functools class DelayFunc: def __init__(self, duration, func): self.duration = duration self.func = func def __call__(self, *args, **kwargs): print(f'Wait for {self.duration} seconds...') time.sleep(self.duration) return self.func(*args, **kwargs) def eager_call(self, *args, **kwargs): print('Call without delay') return self.func(*args, **kwargs) def delay(duration): \"\"\"装饰器：推迟某个函数的执行。同时提供 .eager_call 方法立即执行 \"\"\" # 此处为了避免定义额外函数，直接使用 functools.partial 帮助构造 # DelayFunc 实例 return functools.partial(DelayFunc, duration) @delay(2) def add(a,b): print(a,b) add(1,2) #延迟两秒输出3 相当于delay(2)(add)(1,2) add.eager_call(1,2) #不延迟输出3 相当于delay(2)(add).eager_call(1,2) #额，当然，想更深入理解的话，也可以这么写 def delay(duration): def partial(func): return DelayFunc(duration,func) return partial # 上面的就相当于 partial(DelayFunc,duration),缺的func参数就是要修饰的函数 @delay(2) def add(a,b): return a + b print(add(1,2)) 与纯函数相比，我觉得使用类实现的装饰器在特定场景下有几个优势： 实现有状态的装饰器时，操作类属性比操作闭包内变量更符合直觉、不易出错 实现为函数扩充接口的装饰器时，使用类包装函数，比直接为函数对象追加属性更易于维护 更容易实现一个同时兼容装饰器与上下文管理器协议的对象 ","date":"2021-10-10","objectID":"/skill/:22:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"BaseModel from pydantic import BaseModel,AnyUrl class Test(BaseModel): # 继承后可以用类属性创建实例 url: AnyUrl data: str def __str__(self): return self.url + self.data kwargs = { 'url': 'https://www.baidu.com', 'data': '/search' } print(Test(**kwargs)) ","date":"2021-10-10","objectID":"/skill/:23:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"python类型注释 from pydantic import BaseModel from typing import Any class cout(): def __init__(self, cls: \"Test\", text: str) -\u003e None: self.cls = cls self.text = text def __str__(self): return f\"{self.cls} {self.text}\" #程序到cout时 Test类并没有定义，但最后Test在变量空间中，所以加上引号 class Test(BaseModel): def __str__(self) -\u003e str: return \"I am Test Class\" print(cout(cls=Test(), text=\"hello world!\")) ","date":"2021-10-10","objectID":"/skill/:24:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"namedtuple from collections import namedtuple Test = namedtuple(\"Test\", ['name', 'age', 'sex']) def test_for_test(name: str, year: int, sex: str) -\u003e \"Test\": return Test( name=name.title(), age=2021 - year, sex=sex ) name,age,sex = test_for_test('wlb', 2002, 'male') print(name, age, sex) ","date":"2021-10-10","objectID":"/skill/:25:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"@property from pydantic import BaseModel class Test(): def __init__(self, cls, n): self.cls = cls self.n = n @property def to_string_cls(self): return self.cls @property def to_strings(self): return self.n class Test_For(BaseModel): num: int def __str__(self): return str(self.num) __repr__ = __str__ test = Test(Test_For, 22) print(test.to_string_cls(num=1)) # 1 print(test.to_strings) # 22 ","date":"2021-10-10","objectID":"/skill/:26:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"在边界处思考 from typing import Iterable from pydantic import BaseModel,conint,ValidationError class NumberInput(BaseModel): num: conint(ge=0, le=100) def input_a_number(): while True: n = input(\"输入一个数\") try: n = NumberInput(num=n) except ValidationError as e: print(e) continue n = n.num break return n print(input_a_number()) #要求输入一个0-100的数 这样是不是很优雅 ","date":"2021-10-10","objectID":"/skill/:27:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"super()进阶 今天学习cookbook8-8子类中扩展property 先贴一下代码 class Person: def __init__(self, name): self.name = name # 有意思的是 这里的self.name是@property修饰的 这行代码调用name.setter # Getter function @property def name(self): return self._name # Setter function @name.setter def name(self, value): if not isinstance(value, str): raise TypeError('Expected a string') self._name = value # Deleter function @name.deleter def name(self): raise AttributeError(\"Can't delete attribute\") # 子类 class SubPerson(Person): @property def name(self): print('Getting name') return super().name @name.setter def name(self, value): print('Setting name to', value) super(SubPerson, SubPerson).name.__set__(self, value) @name.deleter def name(self): print('Deleting name') super(SubPerson, SubPerson).name.__delete__(self) 看到super(SubPerson, SubPerson)感到很疑惑，于是搜索资料大致搞明白了 通俗说默认的super(SubPerson,self) (直接写super()也可) 返回的是一个类的实例 \u003e 为了委托给之前定义的setter方法，需要将控制权传递给之前定义的name属性的 __set__() 方法。 不过，获取这个方法的唯一途径是使用类变量而不是实例变量来访问它。 这也是为什么我们要使用 super(SubPerson, SubPerson) 的原因。 从书中这句话可以看出 super(cls,cls)返回的是一个类 不是一个实例，super()的参数的作用就是用于定位位置 第一个cls必须是第二cls的父类或者二者相同，可以通过cls.__mro__查看继承顺序 比如在D里面super(A,D).__init__(self) 而__mro__ 为 (\u003cclass '__main__.D'\u003e, \u003cclass '__main__.A'\u003e, \u003cclass '__main__.B'\u003e, \u003cclass '__main__.C'\u003e, \u003cclass '__main__.Base'\u003e, \u003cclass 'object'\u003e) 那么就调用从A以后的类的__init__() 不过重点不在这里，重点是super(cls,cls)和super(cls,object)的区别 使用super(cls,cls)必须显示的传入self参数，即super(cls,cls).func(self,…)。总之其就是一个定位方法，别的作用我暂且不知。 ### 一个示例 class A: def say(self): print(\"I am A\") class B(A): def say(self): # super(B, B).say(self) super().say() class C(A): def say(self): print(\"I am C\") class D(B, C): def say(self): super().say() D().say() 上述的这段代码怎么修改D输出都是I am C，这是因为在B中super().say()相当于super(B,self).say()，而根据上述内容这是一个实例方法，其中self是D的实例，查看D的mro可以知道C在B的后面，所以根据super的作用，则会调用继承关系中B后面类的say方法，即C的say 方法，所以会得到匪夷所思的结果，将代码修改成注释的那样就可以解决这个问题，希望可以帮助理解。 ## dataclass from dataclasses import dataclass import random @dataclass(order=True) # 等于实现了各种比较方法例如=、\u003e、\u003c,排序函数都依赖比较两个对象 class A: n: int nums = [A(random.randint(1,10)) for _ in range(10)] nums = sorted(nums) print(nums, end='') x = '''hello''' print(x) dataclass可以自动添加__rapr__方法，不必自己实现 @dataclass(init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False) init：默认将生成 __init__ 方法。如果传入 False，那么该类将不会有 __init__ 方法。 repr：__repr__ 方法默认生成。如果传入 False，那么该类将不会有 __repr__ 方法。 eq：默认将生成 __eq__ 方法。如果传入 False，那么 __eq__ 方法将不会被 dataclass 添加，但默认为 object.__eq__。 order：默认将生成 __gt__、__ge__、__lt__、__le__ 方法。如果传入 False，则省略它们。 unsafe_hash：默认生成__hash__方法，用于构建可hashable的类 from dataclasses import dataclass @dataclass(unsafe_hash=True) class VisitRecordDC: first_name: str last_name: str phone_number: str # 跳过“访问时间”字段，不作为任何对比条件 date_visited: str = field(hash=False, compare=False) def find_potential_customers_v4(): return set(VisitRecordDC(**r) for r in users_visited_phuket) - \\ #求差集 set(VisitRecordDC(**r) for r in users_visited_nz) ","date":"2021-10-10","objectID":"/skill/:28:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"自定义format class Student: def __init__(self, name, age): self.name = name self.age = age def __format__(self, format_spec): if format_spec == 'long': return f'{self.name} is {self.age} years old.' elif format_spec == 'simple': return f'{self.name}({self.age})' raise ValueError('invalid format spec') vllbc = Student('vllbc', '18') print(f'{vllbc:simple}') print(f'{vllbc:long}') ","date":"2021-10-10","objectID":"/skill/:29:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"抽象类实践 import collections from abc import ABC, abstractmethod from typing import List customer = collections.namedtuple('customer', ['name', 'points']) class Goods(): def __init__(self, name: str, quantity: float, price: float) -\u003e None: self.name = name self.quantity = quantity self.price = price def total(self) -\u003e float: return self.quantity * self.price class Order(): def __init__(self, customer: customer, cart: List[Goods], prom=None) -\u003e None: self.customer = customer self.cart = cart self.prom = prom def total(self): if not hasattr(self, '__total'): self.__total = sum(i.total() for i in self.cart) return self.__total def due(self): if self.prom is None: discount = 0 else: discount = self.prom.discount(self) return self.total() - discount def __repr__(self) -\u003e str: return f'\u003cOrder total: {self.total():.2f} due: {self.due():.2f}\u003e' class Prom(ABC): # 抽象类 @abstractmethod def discount(self,order) -\u003e float: '''discount''' class discount1(Prom): def discount(self,order) -\u003e float: return order.total() * 0.05 if order.customer.points \u003e= 10000 else 0 john = customer(name='vllbc', points=100000) carts = [Goods(name='apple', quantity=5, price=10), Goods( name='banana', quantity=8, price=5), Goods(name='peach', quantity=4, price=8)] order = Order(customer=john, cart=carts,prom=discount1()) ","date":"2021-10-10","objectID":"/skill/:30:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"accumulate import itertools test_list = [i for i in range(1, 11)] for i in itertools.accumulate(test_list): print(i, end=\",\") # 1,3,6,10,15,21,28,36,45,55, print() for i in itertools.accumulate(test_list, lambda x, y: x * y): print(i, end=',') # 1,2,6,24,120,720,5040,40320,362880,3628800, ","date":"2021-10-10","objectID":"/skill/:31:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"异步装饰器 from functools import wraps import asyncio def decorator(func): @wraps(func) async def hello(*args, **kwargs): await asyncio.sleep(2) return await func(*args,**kwargs) return hello @decorator async def test(): print(\"hello\") asyncio.run(test()) ","date":"2021-10-10","objectID":"/skill/:32:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"bisect import bisect import time # BREAKPOINTS 必须是已经排好序的，不然无法进行二分查找 BREAKPOINTS = (1, 60, 3600, 3600 * 24) TMPLS = ( # unit, template (1, \"less than 1 second ago\"), (1, \"{units} seconds ago\"), (60, \"{units} minutes ago\"), (3600, \"{units} hours ago\"), (3600 * 24, \"{units} days ago\"), ) def from_now(ts): \"\"\"接收一个过去的时间戳，返回距离当前时间的相对时间文字描述 \"\"\" seconds_delta = int(time.time() - ts) unit, tmpl = TMPLS[bisect.bisect(BREAKPOINTS, seconds_delta)] # bisect类似于index方法，要是不存在会选择数值最接近的索引 return tmpl.format(units=seconds_delta // unit) ","date":"2021-10-10","objectID":"/skill/:33:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"contextlib from contextlib import contextmanager,ContextDecorator # contextmanager可以把一个函数变成一个上下文管理器，不需要自己去实现一个定义了__enter__和__exit__方法的类 @contextmanager def open_file(filename, methods=\"r\"): print(f\"打开了文件{filename}\") res_file = open(filename, mode=methods) # __enter__方法 这里也可以是自己定义的类 try: yield res_file # 相当于在__enter__方法里面返回self yield后面为空的话就不用as了 except Exception as e: print(\"有错误发生\", e) # __exit__方法里的错误处理 finally: res_file.close() # __exit__ with open_file(\"testvim.txt\") as fp: print(fp) ","date":"2021-10-10","objectID":"/skill/:34:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"读取大文件 from functools import partial def digits_(file,block_size=1024*8): # 分块读取 _read = partial(file.read, block_size) # 使用partial,也可以使用lambda:file.read(block_size) for line in iter(_read, \"\"): # 当读取完毕时退出 for s in line: if s.isdigit(): yield s # 使用yield def count_digits(fname): \"\"\"计算文件里包含多少个数字字符\"\"\" count = 0 with open(fname) as file: for _ in digits_(file=file): count+=1 return count ","date":"2021-10-10","objectID":"/skill/:35:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"__exit__、__enter__ # def __enter__(self): # 该方法将在进入上下文时调用 # return self # def __exit__(self, exc_type, exc_val, exc_tb): # 该方法将在退出上下文时调用 # exc_type, exc_val, exc_tb 分别表示该上下文内抛出的异常类型、异常值、错误栈 # __enter__()：主要执行一些环境准备工作，同时返回一资源对象。如果上下文管理器open(\"test.txt\")的__enter__()函数返回一个文件对象。 # __exit__()：完整形式为__exit__(type, value, traceback),这三个参数和调用sys.exec_info()函数返回值是一样的，分别为异常类型、异常信息和堆栈。如果*执行体语句*没有引发异常，则这三个参数均被设为None。否则，它们将包含上下文的异常信息。__exit__()方法返回True或False,分别指示被引发的异常有没有被处理，如果返回False，引发的异常将会被传递出上下文。如果__exit__()函数内部引发了异常，则会覆盖掉执行体的中引发的异常。处理异常时，不需要重新抛出异常，只需要返回False，with语句会检测__exit__()返回False来处理异常。 ","date":"2021-10-10","objectID":"/skill/:36:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"enum from enum import IntEnum class Test(IntEnum): X = 2 Y = 1 print(2 == Test.X) ","date":"2021-10-10","objectID":"/skill/:37:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"pydantic数据验证 from pydantic import BaseModel, conint, ValidationError # pydantic主要功能就是作数据验证 from typing import ( List, Union, Optional, Dict ) class Test(BaseModel): name: Optional[str] sex: Union[str, List[str]] d: Dict[str, int] id: conint(ge=1,le=10) try: test = Test(name='wlb', sex='male', d={'dict':1}, id=1) print(test.dict(), test.__annotations__) # {'name': 'wlb', 'sex': 'male', 'd': {'dict': 1}, 'id': 1} {'name': typing.Union[str, NoneType], 'sex': typing.Union[str, typing.List[str]], 'd': typing.Dict[str, int], 'id': \u003cclass '__main__.ConstrainedIntValue'\u003e} except ValidationError: print(\"数据错误\") ","date":"2021-10-10","objectID":"/skill/:38:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"islice from itertools import islice def test(): t = 0 while True: yield t t += 1 for i in islice(test(), 10, 21, 2): print(i) ","date":"2021-10-10","objectID":"/skill/:39:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"__iter__、__next__ class Range7: # 可迭代类型 只需要实现__iter__即可 def __init__(self,start,end) -\u003e None: self.start = start self.end = end def __iter__(self): return Range7iterator(self) class Range7iterator: #这是迭代器,一般的迭代器只能调用一次 def __init__(self,rangeobj) -\u003e None: self.rangeobj = rangeobj self.cur = rangeobj.start def __iter__(self): return self def __next__(self): while True: if self.cur \u003e self.rangeobj.end: raise StopIteration if self.is_7(self.cur): res = self.cur self.cur += 1 return res self.cur += 1 def is_7(self,num): if num == 0: return False return num%7==0 or \"7\" in str(num) for i in Range7(1,100): print(i,end=\" \") #可迭代对象不一定是迭代器，但迭代器一定是可迭代对象 # 对可迭代对象使用 iter() 会返回迭代器，迭代器则会返回它自身 # 每个迭代器的被迭代过程是一次性的，可迭代对象则不一定 # 可迭代对象只需要实现 __iter__ 方法，而迭代器要额外实现 __next__ 方法 ","date":"2021-10-10","objectID":"/skill/:40:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"求字典的最大值 prices = { 'ACME': 45.23, 'AAPL': 612.78, 'IBM': 205.55, 'HPQ': 37.20, 'FB': 10.75 } print(max(zip(prices.values(),prices.keys()))) print(max(prices.items(),key=lambda x:x[1])) print(max(prices,key=lambda k:prices[k])) ","date":"2021-10-10","objectID":"/skill/:41:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"注意循环变量 funcs = [] res = [] for x in range(7): def func(x=x): # 去掉x=x则出现[6,6,6,6,6,6] 在循环内部定义一个函数时, 如果该函数在其主体中使用了循环变量, 则闭包函数将与循环变量绑定, 而不是它的值. 因此, 所有的函数都是使用最后分配给变量的值来进行计算的. return x funcs.append(func) res.append(func()) func_res = [f() for f in funcs] print(func_res) def create_mult(): res = [] for i in range(5): def func(x, i=i): # 去掉i=i则全输出8，原因和上面一样 return x * i res.append(func) return res for cr in create_mult(): print(cr(2)) ","date":"2021-10-10","objectID":"/skill/:42:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"空对象模式 修改前 import decimal class CreateAccountError(Exception): \"\"\"Unable to create a account error\"\"\" class Account: \"\"\"一个虚拟的银行账号\"\"\" def __init__(self, username, balance): self.username = username self.balance = balance @classmethod def from_string(cls, s): \"\"\"从字符串初始化一个账号\"\"\" try: username, balance = s.split() balance = decimal.Decimal(float(balance)) except ValueError: raise CreateAccountError('input must follow pattern \"{ACCOUNT_NAME} {BALANCE}\"') if balance \u003c 0: raise CreateAccountError('balance can not be negative') return cls(username=username, balance=balance) def caculate_total_balance(accounts_data): \"\"\"计算所有账号的总余额 \"\"\" result = 0 for account_string in accounts_data: try: user = Account.from_string(account_string) except CreateAccountError: pass else: result += user.balance return result accounts_data = [ 'piglei 96.5', 'cotton 21', 'invalid_data', 'roland $invalid_balance', 'alfred -3', ] print(caculate_total_balance(accounts_data)) ","date":"2021-10-10","objectID":"/skill/:43:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"空对象模式简介 额外定义一个对象来表示None ","date":"2021-10-10","objectID":"/skill/:43:1","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"好处 它可以加强系统的稳固性，能有有效地防止空指针报错对整个系统的影响，使系统更加稳定。 它能够实现对空对象情况的定制化的控制，能够掌握处理空对象的主动权。 它并不依靠Client来保证整个系统的稳定运行。 它通过isNone对==None的替换，显得更加优雅，更加易懂。 import decimal class Account: \"\"\"一个虚拟的银行账号\"\"\" def __init__(self, username, balance): self.username = username self.balance = balance @classmethod def from_string(cls, s): \"\"\"从字符串初始化一个账号\"\"\" try: username, balance = s.split() balance = decimal.Decimal(float(balance)) except ValueError: # raise CreateAccountError('input must follow pattern \"{ACCOUNT_NAME} {BALANCE}\"') return NullAccount() if balance \u003c 0: return NullAccount() return cls(username=username, balance=balance) def caculate_total_balance(accounts_data): \"\"\"计算所有账号的总余额 \"\"\" return sum(Account.from_string(s).balance for s in accounts_data) class NullAccount: # 要返回的空对象 username = \"\" # 当发生错误时username的值 balance = 0 # 当发生错误时balance的值 def re_Null(): return NotImplementedError accounts_data = [ 'piglei 96.5', 'cotton 21', 'invalid_data', 'roland $invalid_balance', 'alfred -3', ] print(caculate_total_balance(accounts_data)) ","date":"2021-10-10","objectID":"/skill/:43:2","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"pathlib from pathlib import Path # 把txt文件重命名为csv文件 def unify_ext_with_pathlib(path): for fpath in Path(path).glob(\"*.txt\"): fpath.rename(fpath.with_suffix(\".csv\")) print(Path(\".\") / \"test_pathlib.py\") # Path类型可以使用/运算符 print(Path(\"testvim.txt\").read_text()) # 直接读取文件内容 # .resolve() 取绝对路径 # with_name() 修改文件名 with_suffix()修改后缀名 # 把当前目录下的文件批量重命名 # import os # from pathlib import Path # p = Path(\".\") # for filepath in p.glob(\"test_*.py\"): # name = filepath.with_name(str(filepath).replace(\"test_\",\"\")) # filepath.rename(name) ","date":"2021-10-10","objectID":"/skill/:44:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"单元测试 def say_hello(name=None): if name: return f\"hello {name}\" return \"hello world\" import unittest from typing import List class sayhellotest(unittest.TestCase): def setUp(self,nums:List[int] = 0): return super().setUp() def tearDown(self): return super().tearDown() def test_sayhello(self): rv = say_hello() self.assertEqual(rv,\"hello world\") def test_to_name(self): rv = say_hello(\"wlb\") self.assertEqual(rv,\"hello wlb\") if __name__ == '__main__': unittest.main() ","date":"2021-10-10","objectID":"/skill/:45:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"takewhile和dropwhile from itertools import dropwhile,takewhile # 你想遍历一个可迭代对象，但是它开始的某些元素你并不感兴趣，想跳过它们，用dropwhile with open('testvim.txt','r') as fp: for i in dropwhile(lambda i:i.startswith(\"#\"),fp): # 跳过前面#号开头的 print(i) with open(\"testvim.txt\",\"r\") as fp: for i in takewhile(lambda i:i.startswith(\"#\"),fp): # 遍历带#号开头的，遇到不是#号开头的就退出循环，可以当做break使用 # 相当于 if not i.startwith(\"#\"): break print(i) ","date":"2021-10-10","objectID":"/skill/:46:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"装饰器可以装饰方法 import random import wrapt # 为第三方库 def provide_number(min_num, max_num): @wrapt.decorator def wrapper(wrapped, instance, args, kwargs): # 参数含义： # # - wrapped：被装饰的函数或类方法 # - instance： # - 如果被装饰者为普通类方法，该值为类实例 # - 如果被装饰者为 classmethod 类方法，该值为类 # - 如果被装饰者为类/函数/静态方法，该值为 None # # - args：调用时的位置参数（注意没有 * 符号） # - kwargs：调用时的关键字参数（注意没有 ** 符号） # num = random.randint(min_num, max_num) # 无需关注 wrapped 是类方法或普通函数，直接在头部追加参数 args = (num,) + args return wrapped(*args, **kwargs) return wrapper @provide_number(1, 100) def print_random_number(num): print(num) class Foo: @provide_number(1, 100) def print_random_number(self, num): print(num) Foo().print_random_number() print_random_number() # 使用 wrapt 模块编写的装饰器，相比原来拥有下面这些优势： # 嵌套层级少：使用 @wrapt.decorator 可以将两层嵌套减少为一层 # 更简单：处理位置与关键字参数时，可以忽略类实例等特殊情况 # 更灵活：针对 instance 值进行条件判断后，更容易让装饰器变得通用 ","date":"2021-10-10","objectID":"/skill/:47:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"___getattribute__ ____getattribute__仅在新式类中可用，重载__getattrbute__方法对类实例的每个属性访问都有效。 class ClassA: x = 'a' def __init__(self): self.y = 'b' def __getattribute__(self, item): return '__getattribute__' if __name__ == '__main__': a = ClassA() # 使用实例直接访问存在的类属性时,会调用__getattribute__方法 # 输出结果 __getattribute__ print(a.x) # 使用实例直接访问实例存在的实例属性时,会调用__getattribute__方法 # 输出结果 __getattribute__ print(a.y) # 使用实例直接访问实例不存在的实例属性时,也会调用__getattribute__方法 # 输出结果 __getattribute__ print(a.z) 由于__getattr__只针对未定义属性的调用，所以它可以在自己的代码中自由地获取其他属性，而__getattribute__针对所有的属性运行，因此要十分注意避免在访问其他属性时，再次调用自身的递归循环。 当在__getattribute__代码块中，再次执行属性的获取操作时，会再次触发__getattribute__方法的调用，代码将会陷入无限递归，直到Python递归深度限制（重载__setter__方法也会有这个问题）。 示例代码（无限递归）： class ClassA: x = 'a' def __getattribute__(self, item): print('__getattribute__') return self.item if __name__ == '__main__': a = ClassA() a.x 运行结果引发异常。 同时，也没办法通过从__dict__取值的方式来避免无限递归 class ClassA: x = 'a' def __getattribute__(self, name): return self.__dict__[name] if __name__ == '__main__': a = ClassA() # 无限递归 a.x 为了避免无限递归，应该把获取属性的方法指向一个更高的超类，例如object（因为__getattribute__只在新式类中可用，而新式类所有的类都显式或隐式地继承自object，所以对于新式类来说，object是所有新式类的超类）。 修改代码（避免无限递归循环）： class ClassA: x = 'a' def __getattribute__(self, item): print('__getattribute__') return super().__getattribute__(self, item) if __name__ == '__main__': a = ClassA() print(a.x) 结果： __getattribute__ a ","date":"2021-10-10","objectID":"/skill/:48:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"___getattr__、__setattr__ 区别 getattribute 和 getattr，前者是任何通过 x.y 访问实例的属性时都会调用的特殊方法，而后者则是在正常访问形式下无法找到的情况下才会被调用。 class Chain(object): def __init__(self, path=''): self._path = path def __getattr__(self, path): return Chain('%s/%s' % (self._path, path)) def __str__(self): return self._path def users(self,name): return Chain(f\"{self._path}/users/{name}\") __repr__ = __str__ chain = Chain(\"vllbc\") print(chain.x.x.x.x.x) # out: vllbc/x/x/x/x/x 另外，当同时定义__getattribute__和__getattr__时，__getattr__方法不会再被调用，除非显示调用__getattr__方法或引发AttributeError异常。可以在__getattribute__中抛出异常来调用getattr。 ","date":"2021-10-10","objectID":"/skill/:49:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"__getitem__ ","date":"2021-10-10","objectID":"/skill/:50:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"元类 ''' 元类就是控制类的创建的类 ''' class ModelMetaclass(type): def __new__(cls, name, bases, attrs): if name == 'Model': return type.__new__(cls, name, bases, attrs) print(f\"found model {name}\") maps = dict() for k, v in attrs.items(): if isinstance(v, Field): print(f\"Found mapping {k} ==\u003e {v}\") maps[k] = v for k, v in maps.items(): attrs.pop(k) attrs['__mappings__'] = maps attrs['__table__'] = name return type.__new__(cls, name, bases, attrs) class Field(object): def __init__(self, name, column_type): self.name = name self.column_type = column_type def __str__(self): return '\u003c%s:%s\u003e' % (self.__class__.__name__, self.name) class StringField(Field): def __init__(self, name, column_type='TXT'): super().__init__(name, column_type) class IntegerField(Field): def __init__(self, name, column_type='INT'): super().__init__(name, column_type) class Model(dict, metaclass=ModelMetaclass): def __init__(self, **kw): super(Model, self).__init__(**kw) def __getattr__(self, key): try: return self[key] except KeyError: raise AttributeError(r\"'Model' object has no attribute '%s'\" % key) def __setattr__(self, key, value): self[key] = value def save(self): fields = [] params = [] args = [] for k, v in self.__mappings__.items(): fields.append(k) params.append('?') args.append(getattr(self, k, None)) sql = 'insert into %s (%s) values (%s)' % ( self.__table__, ','.join(fields), ','.join(params)) print('SQL: %s' % sql) print('ARGS: %s' % str(args)) class User(Model): # 定义类的属性到列的映射： id = IntegerField('id') name = StringField('username') email = StringField('email') password = StringField('password') # 创建一个实例： u = User(id=12345, name='Michael', email='test@orm.org', password='my-pwd') # 保存到数据库： u.save() ","date":"2021-10-10","objectID":"/skill/:51:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"关于hash # set中的元素要求必须是可哈希的，但set本身是不可哈希的 a = set([1,2,3,4]) a.add([1,2,3]) # 会报错，因为列表是不可哈希的 hash(a) # 会报错，因为set本身是不可哈希的 b = tuple([1,2,3,4]) # 元组本身是可哈希的 c = tuple([1,2,3,[4,5]]) # 如果元组里面有不可哈希的元素 那么整个元组也是不可哈希的了 # 在类中定义__hash__方法就可以变成可哈希的类，注意避免返回可能重复的hash值 class My_Hash: def __hash__(self) -\u003e int: return 111 # 还有简便的方法就是使用dataclass类，可以省时省力，本博客也有介绍。 ","date":"2021-10-10","objectID":"/skill/:52:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"处理列表越界 假如你请求的不是某一个元素，而是一段范围的切片。那么无论你指定的范围是否有效，程序都只会返回一个空列表 []，而不会抛出任何错误。 了解了这点后，你会发现像下面这种边界处理代码根本没有必要： def sum_list(l, limit): \"\"\"对列表的前 limit 个元素求和 \"\"\" # 如果 limit 过大，设置为数组长度避免越界 if limit \u003e len(l): limit = len(l) return sum(l[:limit]) 因为做切片不会抛出任何错误，所以不需要判断 limit 是否超出范围，直接做 sum 操作即可： def sum_list(l, limit): return sum(l[:limit]) ","date":"2021-10-10","objectID":"/skill/:53:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"or操作符 在很多场景下，我们可以利用 or 的特点来简化一些边界处理逻辑。看看下面这个例子： context = {} # 仅当 extra_context 不为 None 时，将其追加进 context 中 if extra_context: context.update(extra_context) # 等同于 context.update(extra_context or {}) 因为 a or b or c or … 这样的表达式，会返回这些变量里第一个布尔值为真的值，直到最后一个为止。 含义为当extra_context为None时，会返回{} ## 字典的键 在python里面，Python 字典通过检查键值是否相等和比较哈希值来确定两个键是否相同.具有相同值的不可变对象(可哈希)在Python中始终具有相同的哈希值。 注意: 具有不同值的对象也可能具有相同的哈希值（哈希冲突）。 下面这个例子 some_dict = {} some_dict[5.5] = \"Ruby\" some_dict[5.0] = \"JavaScript\" some_dict[5] = \"Python\" \u003e\u003e\u003e some_dict[5.5] \"Ruby\" \u003e\u003e\u003e some_dict[5.0] \"Python\" \u003e\u003e\u003e some_dict[5] \"Python\" 因为Python将 5 和 5.0 识别为 some_dict 的同一个键, 所以已有值 “JavaScript” 就被 “Python” 覆盖了. ","date":"2021-10-10","objectID":"/skill/:54:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["python"],"content":"类__init__参数快速赋给self def __init__(self, x=1) -\u003e None: super().__init__() self.__dict__.update(locals()) pass 即可，此时不需要self.x=x也可以直接使用self.x ","date":"2021-10-10","objectID":"/skill/:55:0","tags":["python","skill"],"title":"skill","uri":"/skill/"},{"categories":["算法题"],"content":"长度最小的子数组 ","date":"2021-09-30","objectID":"/%E9%95%BF%E5%BA%A6%E6%9C%80%E5%B0%8F%E7%9A%84%E5%AD%90%E6%95%B0%E7%BB%84/:0:0","tags":["算法题","长度最小的子数组"],"title":"长度最小的子数组","uri":"/%E9%95%BF%E5%BA%A6%E6%9C%80%E5%B0%8F%E7%9A%84%E5%AD%90%E6%95%B0%E7%BB%84/"},{"categories":["算法题"],"content":"题目： https://leetcode-cn.com/problems/minimum-size-subarray-sum/ ","date":"2021-09-30","objectID":"/%E9%95%BF%E5%BA%A6%E6%9C%80%E5%B0%8F%E7%9A%84%E5%AD%90%E6%95%B0%E7%BB%84/:1:0","tags":["算法题","长度最小的子数组"],"title":"长度最小的子数组","uri":"/%E9%95%BF%E5%BA%A6%E6%9C%80%E5%B0%8F%E7%9A%84%E5%AD%90%E6%95%B0%E7%BB%84/"},{"categories":["算法题"],"content":"思路： ​ 一开始想的是直接排序，然后从后面开始遍历，因为要求最小的 然后出错了，，，，， class Solution: def minSubArrayLen(self, s: int, nums: List[int]) -\u003e int: nums.sort() end = len(nums) - 1 while end \u003e 0: for i in range(end,-1,-1): if sum(nums[i:end+1]) \u003e= s: return len(nums[i:end+1]) end -= 1 return 0 在 213 [12,28,83,4,25,26,25,2,25,25,25,12] 出了错，结果试了一下排序后的列表 [2, 4, 12, 12, 25, 25, 25, 25, 25, 26, 28, 83] 结果居然是对的，说明是我的代码的问题，不应该排序 那么该怎么办呢 class Solution: def minSubArrayLen(self, s: int, nums: List[int]) -\u003e int: if not nums: return 0 left = 0 right = 0 res = float('inf') while right \u003c len(nums): while sum(nums[left:right+1]) \u003e= s: res = min(res, right-left +1) left += 1 else: right += 1 if res == float('inf'): return 0 return res 思路也差不多，也是用到了双指针。不过必须注意要判断最小的这个条件啊。 ","date":"2021-09-30","objectID":"/%E9%95%BF%E5%BA%A6%E6%9C%80%E5%B0%8F%E7%9A%84%E5%AD%90%E6%95%B0%E7%BB%84/:2:0","tags":["算法题","长度最小的子数组"],"title":"长度最小的子数组","uri":"/%E9%95%BF%E5%BA%A6%E6%9C%80%E5%B0%8F%E7%9A%84%E5%AD%90%E6%95%B0%E7%BB%84/"},{"categories":["Machine Learning","分类算法"],"content":"SVM ","date":"2021-09-20","objectID":"/svm/:0:0","tags":["Machine Learning","分类算法","SVM"],"title":"SVM","uri":"/svm/"},{"categories":["Machine Learning","分类算法"],"content":"kernel ","date":"2021-09-20","objectID":"/svm/:1:0","tags":["Machine Learning","分类算法","SVM"],"title":"SVM","uri":"/svm/"},{"categories":["Machine Learning","分类算法"],"content":"介绍 其实核函数和映射关系并不大，kernel可以看作是一个运算技巧。 一般认为，原本在低维线性不可分的数据集在足够高的维度存在线性可分的超平面。 围绕这个，那么我们所做的就是要在Feature Space套用原本在线性可分情况下的Input Space中使用过的优化方法，来找到那个Maximaizing Margin的超平面。原理机制一模一样，是二次规划，唯一不同是代入数据的不同，将原来的\\(x_i\\)替换成了高维空间中的\\(\\phi(x_i)\\)，这就是映射函数，映射到高维空间。 具体的技巧(trick)，就是简化计算二次规划中间的一步内积计算。也即中间步骤有一步必须求得\\(\\phi(x_i) \\phi(x_j)\\)，我们可以定义核函数\\(K(x_i,x_j) = \\phi(x_i)\\phi(x_j)\\)，这样我们不需要显式计算每一个\\(\\phi(x_i)\\)，甚至不需要知道它的形式，就可以直接计算结果出来。 也就是说，核函数、内积、相似度这三个词是等价的。因为inner product其实就是一种similarity的度量。核函数和映射是无关的。 ","date":"2021-09-20","objectID":"/svm/:1:1","tags":["Machine Learning","分类算法","SVM"],"title":"SVM","uri":"/svm/"},{"categories":["Machine Learning","分类算法"],"content":"例子 举一个例子： 考虑一个带有特征映射的二维输入空间 \\(\\chi \\subseteq \\mathbb{R}^{2}\\) : 特征映射二维到三维: \\(\\quad \\Phi: x=\\left(x_{1}, x_{2}\\right) \\rightarrow \\Phi(x)=\\left(x_{1}^{2}, x_{2}^{2}, \\sqrt{2} x_{1} x_{2}\\right) \\in F=\\mathbb{R}^{3}\\) 特征空间中的内积： \\[ \\begin{aligned} \\langle\\Phi(x), \\Phi(z)\\rangle \u0026=\\left\\langle\\left(x_{1}^{2}, x_{2}^{2}, \\sqrt{2} x_{1} x_{2}\\right),\\left(z_{1}^{2}, z_{2}^{2}, \\sqrt{2} z_{1} z_{2}\\right)\\right\\rangle \\\\\\\\ \u0026=x_{1}^{2} z_{1}^{2}+x_{2}^{2} z_{2}^{2}+2 x_{1} x_{2} z_{1} z_{2} \\\\\\\\ \u0026=\\left\\langle x_{1} z_{1}+x_{2} z_{2}\\right\\rangle^{2} \\\\\\\\ \u0026=\\langle x, z\\rangle^{2} \\end{aligned} \\] 根据上面可得，核函数\\(k(x,z) = \\langle x,z \\rangle^2=\\phi(x)^T \\phi(z)\\) 而这里为什么映射函数是这样的形式呢，其实可以是反推出来的，我也不知道，反正凑巧通过这种映射函数可以得到这个核函数。 ","date":"2021-09-20","objectID":"/svm/:1:2","tags":["Machine Learning","分类算法","SVM"],"title":"SVM","uri":"/svm/"},{"categories":["Machine Learning","分类算法"],"content":"常用核函数理解 以高斯核函数为例， \\[ \\kappa\\left(x_{1}, x_{2}\\right)=\\exp \\left(-\\frac{\\left|x_{1}-x_{2}\\right|^{2}}{2 \\sigma^{2}}\\right) \\] 我们假设 \\(\\sigma=1\\) ，则 \\[ \\begin{aligned} \\kappa\\left(x_{1}, x_{2}\\right) \u0026=\\exp \\left(-\\frac{\\left|x_{1}-x_{2}\\right|^{2}}{2 \\sigma^{2}}\\right) \\\\\\\\ \u0026=\\exp \\left(-\\left(x_{1}-x_{2}\\right)^{2}\\right) \\\\\\\\ \u0026=\\exp \\left(-x_{1}^{2}\\right) \\exp \\left(-x_{2}^{2}\\right) \\exp \\left(2 x_{1} x_{2}\\right) \\\\\\\\ \u0026 \\text { Taylor } \\\\\\\\ \u0026=\\exp \\left(-x_{1}^{2}\\right) \\exp \\left(-x_{2}^{2}\\right)\\left(\\sum_{i=0}^{\\infty} \\frac{\\left(2 x_{1} x_{2}\\right)^{i}}{i !}\\right) \\\\\\\\ \u0026=\\sum_{i=0}^{\\infty}\\left(\\exp \\left(-x_{1}^{2}\\right) \\exp \\left(-x_{2}^{2}\\right) \\sqrt{\\left.\\frac{2^{i}}{i !} \\sqrt{\\frac{2^{i}}{i !}} x_{1}^{i} x_{2}^{i}\\right)}\\right.\\\\\\\\ \u0026=\\sum_{i=0}^{\\infty}\\left(\\left[\\exp \\left(-x_{1}^{2}\\right) \\sqrt{\\frac{2^{i}}{i !}} x_{1}^{i}\\right]\\left[\\exp \\left(-x_{2}^{2}\\right) \\sqrt{\\frac{2^{i}}{i !}} x_{2}^{i}\\right]\\right) \\\\\\\\ \u0026=\\phi\\left(x_{1}\\right)^{T} \\phi\\left(x_{2}\\right) \\end{aligned} \\] w这不，已经有了定义的那种形式，对于 \\(\\phi(x)\\) ，由于 \\[ \\phi(x)=\\exp \\left(-x^{2}\\right) \\cdot\\left(1, \\sqrt{\\frac{2^{1}}{1 !}} x, \\sqrt{\\frac{2^{2}}{2 !}} x^{2}, \\cdots\\right) \\] 所以，可以映射到任何一个维度上。 ","date":"2021-09-20","objectID":"/svm/:1:3","tags":["Machine Learning","分类算法","SVM"],"title":"SVM","uri":"/svm/"},{"categories":["Machine Learning","分类算法"],"content":"核函数类别 其实常用的就那几个，高斯核函数最为常用。 ","date":"2021-09-20","objectID":"/svm/:1:4","tags":["Machine Learning","分类算法","SVM"],"title":"SVM","uri":"/svm/"},{"categories":["Machine Learning","分类算法"],"content":"参考 https://www.cnblogs.com/damin1909/p/12955240.html https://blog.csdn.net/mengjizhiyou/article/details/103437423 ","date":"2021-09-20","objectID":"/svm/:1:5","tags":["Machine Learning","分类算法","SVM"],"title":"SVM","uri":"/svm/"},{"categories":["Machine Learning","分类算法"],"content":"线性可分支持向量机 ","date":"2021-09-20","objectID":"/svm/:2:0","tags":["Machine Learning","分类算法","SVM"],"title":"SVM","uri":"/svm/"},{"categories":["Machine Learning","分类算法"],"content":"线性可分 在二维空间上，两类点被一条直线完全分开叫做线性可分。 ","date":"2021-09-20","objectID":"/svm/:2:1","tags":["Machine Learning","分类算法","SVM"],"title":"SVM","uri":"/svm/"},{"categories":["Machine Learning","分类算法"],"content":"最大间隔超平面 以最大间隔把两类样本分开的超平面，也称之为最大间隔超平面。 ","date":"2021-09-20","objectID":"/svm/:2:2","tags":["Machine Learning","分类算法","SVM"],"title":"SVM","uri":"/svm/"},{"categories":["Machine Learning","分类算法"],"content":"支持向量 样本中距离超平面最近的一些点，这些点叫做支持向量。 ","date":"2021-09-20","objectID":"/svm/:2:3","tags":["Machine Learning","分类算法","SVM"],"title":"SVM","uri":"/svm/"},{"categories":["Machine Learning","分类算法"],"content":"最优化问题 SVM 想要的就是找到各类样本点到超平面的距离最远，也就是找到最大间隔超平面。任意超平面可以用下面这个线性方程来描述： \\[ w^Tx+b=0 \\] 二维空间点(x,y)到直线\\(Ax+By+C=0\\)的距离公式为： \\[ \\frac{|Ax+By+C|}{\\sqrt{A^2+B^2}} \\] 扩展到n维空间中，\\(x=(x_1, x_2,\\dots, x_n)\\)到直线\\(w^Tx+b=0\\)的距离为： \\[ \\frac{|w^Tx+b|}{||w||} \\] 如图所示，根据支持向量的定义我们知道，支持向量到超平面的距离为 d，其他点到超平面的距离大于 d。 于是我们有这样的一个公式： 之后得到: 分母都是正数，因此可以令它为1。 合并得： 至此我们就可以得到最大间隔超平面的上下两个超平面： 每个支持向量到超平面的距离可以写为： 所以我们得到： 最大化这个距离： 这里乘上 2 倍也是为了后面推导，对目标函数没有影响。刚刚我们得到支持向量\\(y(w^Tx+b) = 1\\)，所以我们得到： \\[ \\max\\frac{2}{||w||} \\] 对目标进行转换： \\[ \\min\\frac{1}{2}||w||^2 \\] 所以得到的最优化问题是： ","date":"2021-09-20","objectID":"/svm/:2:4","tags":["Machine Learning","分类算法","SVM"],"title":"SVM","uri":"/svm/"},{"categories":["Machine Learning","分类算法"],"content":"对偶问题 拉格朗日乘数法、拉格朗日对偶和KKT条件 参考：https://zhuanlan.zhihu.com/p/38163970 给定约束优化问题： \\[ \\begin{aligned} \u0026\\min f(x) \\\\\\\\ \u0026 s.t. g(x) = 0 \\end{aligned} \\] 为方便分析，假设 f 与 g 是连续可导函数。Lagrange乘数法是等式约束优化问题的典型解法。定义Lagrangian函数 \\[ L(x, \\lambda) = f(x) + \\lambda g(x) \\] 其中 λ 称为Lagrange乘数。Lagrange乘数法将原本的约束优化问题转换成等价的无约束优化问题 计算 L 对 x 与 λ 的偏导数并设为零，可得最优解的必要条件： 接下来是不等式约束： \\[ \\begin{aligned} \u0026 \\min f(x) \\\\ \u0026 s.t. g(x) \\leq 0 \\end{aligned} \\] 据此我们定义可行域(feasible region)\\(K=x\\in R^n | g(x)\\leq 0\\)。设$x^* $为满足条件的最佳解，分情况讨论： \\(g(x^* ) \u003c 0\\)，最佳解位于K的内部，为内部解，这时的约束是无效的。 \\(g(x^* ) = 0\\)，最佳解落在K的边界，称为边界解，此时的约束是有效的。 这两种情况的最佳解具有不同的必要条件。 具有不同的必要条件： 内部解：在约束条件无效的情况下，\\(g(x)\\)不起作用，约束优化问题退化为无约束优化问题，因此$x^* \\(满足\\)= 0$ 边界解：在约束有效的情况下，约束不等式变为等式\\(g(x)=0\\)。此时拉格朗日函数在$x^* \\(的梯度为0，即\\)f = -g\\(，\\)f(x)\\(的极小值在边界取到，那么可行域内部的\\)f(x)\\(应该都是大于这个极小值，则\\)f(x)\\(的方向是可行域内部。而\\)g\\(的方向为可行域外部，因为约束条件是\\)g(x) \\(，也就是可行域外部都是\\)g(x) \u003e 0\\(，所以梯度方向就是指向函数增加的方向。说明两个函数的梯度方向相反，要想上面的等式成立，必须有\\)\\(，这就是对偶可行性。 因此，不论是内部解或边界解， \\)g(x)=0$ 恒成立 整合上述两种情况，最佳解的必要条件包括Lagrangian函数的定常方程式、原始可行性、对偶可行性，以及互补松弛性： 这就是KKT条件。 上面结果可推广至多个约束等式与约束不等式的情况。考虑标准约束优化问题(或称非线性规划)： 定义Lagrangian 函数 则KKT条件为 应用 已知svm优化的主要问题： 那么求解线性可分的 SVM 的步骤为： 步骤1： 构造拉格朗日函数： 步骤2： 利用强对偶性转化： 现对参数 w 和 b 求偏导数： 具体步骤： 在前面的步骤中即为： 我们将这个结果带回到函数中可得： 也就是说： 步骤3： 由上述过程需要满足KKT条件（\\(\\alpha\\)就是本文中的\\(\\lambda\\)）： 易得，当\\(\\lambda_i\\)大于0，则必有\\(y_if(x_i)=1\\),所对应的样本点是一个支持向量，即位于最大间隔边界上。 我们可以看出来这是一个二次规划问题，问题规模正比于训练样本数，我们常用 SMO(Sequential Minimal Optimization) 算法求解。 SMO(Sequential Minimal Optimization)，序列最小优化算法，其核心思想非常简单：每次只优化一个参数，其他参数先固定住，仅求当前这个优化参数的极值。我们来看一下 SMO 算法在 SVM 中的应用。 我们刚说了 SMO 算法每次只优化一个参数，但我们的优化目标有约束条件，没法一次只变动一个参数。所以我们选择了一次选择两个参数。具体步骤为： 选择两个需要更新的参数\\(\\lambda _i\\)和\\(\\lambda_j\\)，固定其他参数。于是我们有以下约束： 其中\\(c = -\\sum_{k\\neq i, j}\\lambda_ky_k\\)， 因此可以得出\\(\\lambda_j = \\frac{c-\\lambda_iy_i}{y_j}\\)，这样就相当于把目标问题转化成了仅有一个约束条件的最优化问题，仅有的约束是\\(\\lambda_i\u003e0\\) 对于仅有一个约束条件的最优化问题，我们完全可以在\\(\\lambda_i\\)上对优化目标求偏导，令导数为零，从而求出变量值\\(\\lambda_{inew}\\)，从而求出\\(\\lambda_{jnew}\\) 多次迭代直至收敛。 通过 SMO 求得最优解$^* $ 步骤4： 我们求偏导数时得到： 由上式可求得 w。 由于所有\\(\\lambda_i\u003e0\\)的点都是支持向量，可以随便找一个支持向量代入\\(y_s(w^Tx_s+b)=1\\)，求出b即可。 两边同时乘以\\(y_s\\)，最后得\\(b = y_s-wx_s\\) 为了更具鲁棒性，我们可以求得支持向量的均值： 步骤5： w 和 b 都求出来了，我们就能构造出最大分割超平面：\\(w^Tx+b=0\\) 分类决策函数：\\(f(x) = sign(w^Tx+b)\\) 将新样本点导入到决策函数中既可得到样本的分类。 ","date":"2021-09-20","objectID":"/svm/:2:5","tags":["Machine Learning","分类算法","SVM"],"title":"SVM","uri":"/svm/"},{"categories":["Machine Learning","分类算法"],"content":"线性支持向量机与软间隔 ","date":"2021-09-20","objectID":"/svm/:3:0","tags":["Machine Learning","分类算法","SVM"],"title":"SVM","uri":"/svm/"},{"categories":["Machine Learning","分类算法"],"content":"软间隔 在实际应用中，完全线性可分的样本是很少的，如果遇到了不能够完全线性可分的样本，我们应该怎么办？比如下面这个： 于是我们就有了软间隔，相比于硬间隔的苛刻条件，我们允许个别样本点出现在间隔带里面，即允许出现分类错误的样本： 我们允许部分样本点不满足约束条件： \\[ y_i(w^Tx_i+b) \\geq 1 \\] 则优化目标变成了 \\[ \\min_{w, b} \\frac{1}{2}\\|{w}\\|^{2}+C \\sum_{i=1}^{m} \\ell_{0 / 1}\\left(y_{i}\\left({w}^{\\mathrm{T}} {x}_{i}+b\\right)-1\\right), \\] 其中 \\(C\u003e0\\) 是一个常数, \\(\\ell_{0 / 1}\\) 是 “ \\(0 / 1\\) 损失函数” \\[ \\ell_{0 / 1}(z)= \\begin{cases}1, \u0026 \\text { if } z\u003c0 \\\\\\\\ 0, \u0026 \\text { otherwise. }\\end{cases} \\] 显然, 当 \\(C\\) 为无穷大时, \\(\\xi_i\\)必然无穷小，如此一来线性svm就又变成了线性可分svm，当\\(C\\)为有限值时，才会允许部分样本不遵循约束条件 然而, \\(\\ell_{0 / 1}\\) 非凸、非连续, 数学性质不太好, 使得不易直接求解. 于 是, 人们通常用其他一些函数来代替 \\(\\ell_{0 / 1}\\), 称为 “替代损失” (surrogate loss). 替代损失函数一般具有较好的数学性质, 如它们通常是凸的连续函数且是 \\(\\ell_{0 / 1}\\) 的上界. 给出了三种常用的替代损失函数: hinge 损失: \\(\\ell_{\\text {hinge }}(z)=\\max(0,1-z)\\); 指数损失(exponential loss): \\(\\ell_{\\exp }(z)=\\exp (-z)\\); 对率损失(logistic loss): \\(\\ell_{\\log }(z)=\\log (1+\\exp (-z))\\). 若采用 hinge 损失, 则变成 \\[ \\min_{w, b} \\frac{1}{2}\\|{w}\\|^{2}+C \\sum_{i=1}^{m} \\max\\left(0,1-y_{i}\\left({w}^{\\mathrm{T}} {x}_{i}+b\\right)\\right) \\] 为了度量这个间隔软到何种程度，我们为每个样本引入一个松弛变量\\(\\xi_i\\)，令\\(\\xi_i \\geq 0\\)，且\\(1-y_i(w^Tx_i+b)-\\xi_i\\leq 0\\)，如下图： ","date":"2021-09-20","objectID":"/svm/:3:1","tags":["Machine Learning","分类算法","SVM"],"title":"SVM","uri":"/svm/"},{"categories":["Machine Learning","分类算法"],"content":"优化目标与求解 优化目标： 步骤1： 构造拉格朗日函数： 步骤2： 分别求导，得出以下关系： 将这些关系带入拉格朗日函数中，得到： 则： 我们可以看到这个和硬间隔的一样，只是多了个约束条件。 然后使用SMO算法求$^* $ 软间隔KKT条件 其中\\(\\alpha\\)对应本文的\\(\\lambda\\)，\\(\\mu\\)对应本文的\\(\\mu\\) 因此由第三个式子得必有\\(\\lambda_i =0\\)或者\\(y_if(x_i) - 1+\\xi_i \\geq 0\\) \\(\\lambda_i=0\\)，则该样本对其没有任何影响。 \\(\\lambda_i \u003e 0\\)，则样本为支持向量。 若\\(\\lambda_i \u003cC\\),则\\(\\mu_i \u003e 0\\)，进而有\\(\\xi_i=0\\)，则样本恰在最大间隔边界上。也是支持向量。 若\\(\\lambda_i=C\\),则有\\(\\mu_i=0\\)，此时若\\(\\xi_i\\leq 1\\)，则样本落在最大间隔内部。若\\(\\xi_i\u003e1\\)则样本被错误分类。 再看一下下面这图就理解了。 步骤3： 然后我们通过上面两个式子求出 w 和 b，最终求得超平面 这边要注意一个问题，在间隔内的那部分样本点是不是支持向量？ 我们可以由求参数 w 的那个式子可看出，只要 \\(\\lambda_i \u003e 0\\)的点都能影响我们的超平面，因此都是支持向量。 ","date":"2021-09-20","objectID":"/svm/:3:2","tags":["Machine Learning","分类算法","SVM"],"title":"SVM","uri":"/svm/"},{"categories":["Machine Learning","分类算法"],"content":"非线性支持向量机 我们刚刚讨论的硬间隔和软间隔都是在说样本的完全线性可分或者大部分样本点的线性可分。 但我们可能会碰到的一种情况是样本点不是线性可分的，比如： 这种情况的解决方法就是：将二维线性不可分样本映射到高维空间中，让样本点在高维空间线性可分，比如： 对于在有限维度向量空间中线性不可分的样本，我们将其映射到更高维度的向量空间里，再通过间隔最大化的方式，学习得到支持向量机，就是非线性 SVM。 我们用 x 表示原来的样本点，用\\(\\phi(x)\\)表示 x 映射到特征新的特征空间后到新向量。那么分割超平面可以表示为: \\(f(x) = w\\phi(x)+b\\) 对于非线性 SVM 的对偶问题就变成了： 区别就在于优化目标中的内积。 ","date":"2021-09-20","objectID":"/svm/:4:0","tags":["Machine Learning","分类算法","SVM"],"title":"SVM","uri":"/svm/"},{"categories":["Machine Learning","分类算法"],"content":"核函数 我们不禁有个疑问：只是做个内积运算，为什么要有核函数的呢？ 这是因为低维空间映射到高维空间后维度可能会很大，如果将全部样本的点乘全部计算好，这样的计算量太大了。 但如果我们有这样的一核函数\\(k(x,y) = (\\phi(x), \\phi(y))\\)，x与y在特征空间中的内积，就等于它们在原始空间中通过函数\\(k(x,y)\\)计算的结果，我们就不需要知道映射函数和计算高维空间中的内积了。 有关内容看本文一开始对kernel的介绍。 ","date":"2021-09-20","objectID":"/svm/:4:1","tags":["Machine Learning","分类算法","SVM"],"title":"SVM","uri":"/svm/"},{"categories":["Machine Learning","分类算法"],"content":"总结 SVM是深度学习流行之前的首选分类方法，在许多任务上都有很好的效果，稍微修改后可以用于回归任务中。总结一下svm算法的优缺点。 ","date":"2021-09-20","objectID":"/svm/:5:0","tags":["Machine Learning","分类算法","SVM"],"title":"SVM","uri":"/svm/"},{"categories":["Machine Learning","分类算法"],"content":"优点 有严格的数学理论支持，可解释性强，不依靠统计方法，从而简化了通常的分类和回归问题； 能找出对任务至关重要的关键样本（即：支持向量）； 采用核技巧之后，可以处理非线性分类/回归任务； 最终决策函数只由少数的支持向量所确定，计算的复杂性取决于支持向量的数目，而不是样本空间的维数，这在某种意义上避免了“维数灾难”。 ","date":"2021-09-20","objectID":"/svm/:5:1","tags":["Machine Learning","分类算法","SVM"],"title":"SVM","uri":"/svm/"},{"categories":["Machine Learning","分类算法"],"content":"缺点 训练时间长。当采用 SMO 算法时，每次都需要挑选一对参数 当采用核技巧时，如果需要存储核矩阵，则空间复杂度为\\(O(N^2)\\) 模型预测时，预测时间与支持向量的个数成正比。当支持向量的数量较大时，预测计算复杂度较高。 ## 参考 https://zhuanlan.zhihu.com/p/77750026 ","date":"2021-09-20","objectID":"/svm/:5:2","tags":["Machine Learning","分类算法","SVM"],"title":"SVM","uri":"/svm/"},{"categories":["算法题"],"content":"字符串的排列 ","date":"2021-09-18","objectID":"/%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E6%8E%92%E5%88%97/:0:0","tags":["算法题","字符串的排列"],"title":"字符串的排列","uri":"/%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E6%8E%92%E5%88%97/"},{"categories":["算法题"],"content":"题目： https://leetcode-cn.com/problems/permutation-in-string/ ","date":"2021-09-18","objectID":"/%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E6%8E%92%E5%88%97/:1:0","tags":["算法题","字符串的排列"],"title":"字符串的排列","uri":"/%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E6%8E%92%E5%88%97/"},{"categories":["算法题"],"content":"思路： 滑动窗口加字典 ","date":"2021-09-18","objectID":"/%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E6%8E%92%E5%88%97/:2:0","tags":["算法题","字符串的排列"],"title":"字符串的排列","uri":"/%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E6%8E%92%E5%88%97/"},{"categories":["算法题"],"content":"代码： class Solution(object): def checkInclusion(self, s1, s2): counter1 = collections.Counter(s1) N = len(s2) left = 0 right = len(s1) - 1 counter2 = collections.Counter(s2[0:right]) while right \u003c N: counter2[s2[right]] += 1 if counter1 == counter2: return True counter2[s2[left]] -= 1 if counter2[s2[left]] == 0: del counter2[s2[left]] left += 1 right += 1 return False ","date":"2021-09-18","objectID":"/%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E6%8E%92%E5%88%97/:3:0","tags":["算法题","字符串的排列"],"title":"字符串的排列","uri":"/%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E6%8E%92%E5%88%97/"},{"categories":["pandas","api"],"content":"类似于pandas的apply，就是在某一维上进行定义的函数操作 apply_along_axis(func1d, axis, arr, *args, **kwargs) 官网的例子 def my_func(a): return (a[0] + a[-1]) * 0.5 b = np.array([[1,2,3], [4,5,6], [7,8,9]]) np.apply_along_axis(my_func, 0, b) # 结果 array([ 4., 5., 6.]) # 结果 array([ 2., 5., 8.]) ","date":"2021-09-03","objectID":"/apply_along_axis/:0:0","tags":["pandas","api","apply_along_axis"],"title":"apply_along_axis","uri":"/apply_along_axis/"},{"categories":["算法题"],"content":"采购方案 ","date":"2021-08-30","objectID":"/%E9%87%87%E8%B4%AD%E6%96%B9%E6%A1%88/:0:0","tags":["算法题","采购方案"],"title":"采购方案","uri":"/%E9%87%87%E8%B4%AD%E6%96%B9%E6%A1%88/"},{"categories":["算法题"],"content":"题目： https://leetcode-cn.com/problems/4xy4Wx/ ","date":"2021-08-30","objectID":"/%E9%87%87%E8%B4%AD%E6%96%B9%E6%A1%88/:1:0","tags":["算法题","采购方案"],"title":"采购方案","uri":"/%E9%87%87%E8%B4%AD%E6%96%B9%E6%A1%88/"},{"categories":["算法题"],"content":"思路： 题目很简单，思想就是双指针，感觉是个双指针的典型例子就写了下来 先对数组进行从小到大排序，然后双指针从两边移动，如果一直大于target就一直左移right 然后right - left就是所有成立的数目，再移动left 进行筛选 ","date":"2021-08-30","objectID":"/%E9%87%87%E8%B4%AD%E6%96%B9%E6%A1%88/:2:0","tags":["算法题","采购方案"],"title":"采购方案","uri":"/%E9%87%87%E8%B4%AD%E6%96%B9%E6%A1%88/"},{"categories":["算法题"],"content":"代码： class Solution: def purchasePlans(self, nums: List[int], target: int) -\u003e int: nums.sort() left = 0 right = len(nums) - 1 res = 0 while left \u003c right and left \u003c len(nums): while left \u003c right and nums[right] + nums[left] \u003e target: right -= 1 res += right - left left += 1 return res % (1000000007) ","date":"2021-08-30","objectID":"/%E9%87%87%E8%B4%AD%E6%96%B9%E6%A1%88/:3:0","tags":["算法题","采购方案"],"title":"采购方案","uri":"/%E9%87%87%E8%B4%AD%E6%96%B9%E6%A1%88/"},{"categories":["算法题"],"content":"位运算的一个应用 翻了翻以前用python刷leetcode的记录，最后刷的一道题是这样的 https://leetcode-cn.com/problems/single-number/ 叫只出现一次的数字，当时看题感觉非常简单啊！直接搞就行了 当时一开始我的做法是这样的 class Solution: def singleNumber(self, nums): for i in set(nums): if nums.count(i) ==1: return i 信心满满的提交，结果发现TLE了。。 然后看超时案例的输入，没有一个数字重复，也就是说我的set跟没有一样，所以说肯定不能这么做。 然后又想到了哈希表 class Solution: def singleNumber(self, nums): dic={} for num in nums: if num in dic.keys(): dic[num]+=1 else: dic[num]=1 for i in dic.keys(): if dic[i] ==1: return i 这样也算是AC了。本以为这个题就这么结束了，结果无意中看到了别的题解震惊了 代码数量比我短的多得多。 然后就认识到了位运算的魔力。。 先上代码： class Solution: def singleNumber(self, nums): a = 0 for i in nums: a^=i return a 简单的一个异或运算就达到了目的 真是太神奇了！ 找到相关资料 交换律：a ^ b ^ c \u003c=\u003e a ^ c ^ b 任何数于0异或为任何数 0 ^ n =\u003e n 相同的数异或为0: n ^ n =\u003e 0 也就是说相同的数就异或为0了，达到了去重的目的。 ","date":"2021-08-23","objectID":"/%E5%8F%AA%E5%87%BA%E7%8E%B0%E4%B8%80%E6%AC%A1%E7%9A%84%E6%95%B0%E5%AD%97/:0:0","tags":["算法题","只出现一次的数字"],"title":"只出现一次的数字","uri":"/%E5%8F%AA%E5%87%BA%E7%8E%B0%E4%B8%80%E6%AC%A1%E7%9A%84%E6%95%B0%E5%AD%97/"},{"categories":["NLP","概率图模型"],"content":"概率图模型概述 ","date":"2021-08-13","objectID":"/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B%E6%A6%82%E8%BF%B0/:0:0","tags":["NLP","概率图模型","概率图模型概述"],"title":"概率图模型概述","uri":"/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B%E6%A6%82%E8%BF%B0/"},{"categories":["面经"],"content":"B树 B树就是B-树，以前还以为这是两种树，现在才知道这俩就是一个东西。 ","date":"2021-08-07","objectID":"/b%E6%A0%91/:0:0","tags":["面经","B树"],"title":"B树","uri":"/b%E6%A0%91/"},{"categories":["面经"],"content":"基本概念 所有的叶子结点都出现在同一层上，并且不带信息(可以看做是外部结点或查找失败的结点，实际上这些结点不存在，指向这些结点的指针为空)。 每个结点包含的关键字个数有上界和下界。用一个被称为 B-树的 最小度数 的固定整数 t≥2 来表示这些界 ，其中 t 取决于磁盘块的大小： a.除根结点以外的每个结点必须至少有 t−1 个关键字。因此，除了根结点以外的每个内部结点有 t 个孩子。如果树非空，根结点至少有一个关键字。 每个结点至多包含 2t−1 个关键字。 一个包含x个关键字的结点有x+1个孩子。 一个结点中所有的关键字升序排列，两个关键字\\(k_1\\)和\\(k_2\\)之间的孩子结点的所有关键字key在\\((k_1, k_2)\\)的范围内。 其中最小度数和B树的阶不一样： 度：一个结点含有的子结点的个数称为该结点的度 阶：一棵树的最大孩子数 最小度minimum degree（t）：用来衡量结点的关键字数量范围 阶 order（m）：衡量B树中的结点的最大孩子数 关系如下： \\[ t = ceil(\\frac{m}{2}) \\quad m = 2t \\] 可以简单理解为最小度是孩子数的最小值，阶是孩子数的最大值。最小度-1是节点关键字数的最小值，阶-1是节点关键字数的最大值。 ","date":"2021-08-07","objectID":"/b%E6%A0%91/:1:0","tags":["面经","B树"],"title":"B树","uri":"/b%E6%A0%91/"},{"categories":["面经"],"content":"查找 查找很简单，对每个键中的索引进行比较然后查找就可以。 ","date":"2021-08-07","objectID":"/b%E6%A0%91/:2:0","tags":["面经","B树"],"title":"B树","uri":"/b%E6%A0%91/"},{"categories":["面经"],"content":"插入 伪代码： 初始化 x 作为根结点 当 x 不是叶子结点，执行如下操作： 找到 x 的下一个要被访问的孩子结点 y 如果 y 没有满，则将结点 y 作为新的 x 如果 y 已经满了，拆分 y ，结点 x 的指针指向结点 y 的两部分。 如果 k 比 y 中间的关键字小， 则将 y 的第一部分作为新的 x ，否则将 y 的第二部分作为新的 x ，当将 y 拆分后，将 y 中的一个关键字移动到它的父结点 x 当中。 当 x 是叶子结点时，第二步结束； 由于我们已经提前查分了所有结点，x 必定至少有一个额外的关键字空间，进行简单的插入即可。 ","date":"2021-08-07","objectID":"/b%E6%A0%91/:3:0","tags":["面经","B树"],"title":"B树","uri":"/b%E6%A0%91/"},{"categories":["面经"],"content":"删除 待删除的关键字 k 在结点 x 中，且 x 是叶子结点，删除关键字k 待删除的关键字 k 在结点 x 中，且 x 是内部结点，分一下三种情况 1). 如果位于结点 x 中的关键字 k 之前的第一个孩子结点 y 至少有 t 个关键字，则在孩子结点 y 中找到 k 的前驱结点 k0 ，递归地删除关键字 k0 ，并将结点 x 中的关键字 k 替换为 k0 直接前驱：当前关键字左侧指针 所指子树中“最右下”的元素 删除 B-树中的关键字 G ，G 的前一个孩子结点 y 为 [D、E、F] ，包含 3个关键字，满足情况一，关键字 G 的直接前驱为关键 F ，删除 F ，然后将 G 替换为 F . 2).y 所包含的关键字少于 t 个关键字，则检查结点 x 中关键字 k 的后一个孩子结点 z 包含的关键字的个数，如果 z 包含的关键字的个数至少为 t 个，则在 z 中找到关键字 k 的直接后继 K0 ,然后删除 K0 ，并将关键 k 替换为 K0 . 直接后继：当前关键字右侧指针 所指子树中“最左下”的元素 删除 B-树中的关键字 C , y 中包含的关键字的个数为 2 个，小于 t = 3 ,结点 [C、G、L] 中的 关键字 C 的后一个孩子 z 为 [D、E、F] 包含 3 个关键字，关键字 C 的直接后继为 D ，删除 D ，然后将 C 替换为 D . 3). 如果 y 和 z 都只包含 t -1 个关键字，合并关键字 k 和所有 z 中的关键字到 结点 y 中，结点 x 将失去关键字 k 和孩子结点 z，y 此时包含 2t -1 个关键字，释放结点 z 的空间并递归地从结点 y 中删除关键字 k. 删除关键字 C , 结点 y 包含 2 个关键字 ，结点 z 包含 2 个关键字，均等于 t - 1 = 2 个， 合并关键字 C 和结点 z 中的所有关键字到结点 y 当中： 之后直接删除C即可。 如果关键字 k 不在当前在内部结点 x 中，则确定必包含 k 的子树的根结点 x.c(i) （如果 k 确实在 B-树中）。如果 x.c(i) 只有 t - 1 个关键字，必须执行下面两种情况进行处理： 首先我们得确认什么是当前内部结点 x ，什么是 x.c(i) ,如下图所示， P 现在不是根结点，而是完整 B-树的一个子树的根结点： 1). x.c(i) 仅包含 t - 1 个关键字且 x.c(i) 的一个兄弟结点包含至少 t 个关键字，则将 x 的某一个关键字下移到 x.c(i) 中，将 x.c(i) 的相邻的左兄弟或右兄弟结点中的一个关键字上移到 x 当中，将该兄弟结点中相应的孩子指针移到 x.c(i) 中，使得 x.c(i) 增加一个额外的关键字。 我们以删除结点 [A、B] 中的结点 B 为例，上图中 x.c(i) 包含 2 个关键字，即 t - 1 个关键字， x.c(i) 的一个兄弟结点 [H、J、K] 包含 3 个关键字（满足至少 t 个关键字的要求），则将兄弟结点 [H、J、K] 中的关键字 H 向上移动到 x 中， 将 x 中的关键字 C 下移到 x.c(i) 中；删除关键字 B . 2).如果 x.c(i) 及 x.c(i) 的所有相邻兄弟都只包含 t - 1 个关键字，则将 x.c(i) 与 一个兄弟合并，即将 x 的一个关键字移动至新合并的结点，使之成为该结点的中间关键字，将合并后的结点作为新的 x 结点 . 以此图为例： 上面的图标明了相应的 x 及 x.c(i) ，我们以删除关键字 D 为例，此时当前内部结点 x 不包含关键字 D , 确定是第三种情况，我们可以确认关键 D 一定在结点 x 的第一个孩子结点所在的子树中，结点 x 的第一个孩子结点所在子树的跟结点为 x.c(i) 即 [C、L] . 其中 结点 [C、L] 及其相邻的兄弟结点 [T、W] 都只包含 2 个结点（即 t - 1) ，则将 [C、L] 与 [T、W] 合并，并将结点 x 当中仅有的关键字 P 合并到新结点中；然后将合并后的结点作为新的 x 结点，递归删除关键字 D ，发现D 此时在叶子结点 y 中，直接删除，就是 1. 的情况。 ","date":"2021-08-07","objectID":"/b%E6%A0%91/:4:0","tags":["面经","B树"],"title":"B树","uri":"/b%E6%A0%91/"},{"categories":["算法题"],"content":"和为s的连续正数序列 ","date":"2021-08-06","objectID":"/%E5%92%8C%E4%B8%BAs%E7%9A%84%E8%BF%9E%E7%BB%AD%E6%AD%A3%E6%95%B0%E5%BA%8F%E5%88%97/:0:0","tags":["算法题","和为s的连续正数序列"],"title":"和为s的连续正数序列","uri":"/%E5%92%8C%E4%B8%BAs%E7%9A%84%E8%BF%9E%E7%BB%AD%E6%AD%A3%E6%95%B0%E5%BA%8F%E5%88%97/"},{"categories":["算法题"],"content":"题目: https://leetcode-cn.com/problems/he-wei-sde-lian-xu-zheng-shu-xu-lie-lcof/ ","date":"2021-08-06","objectID":"/%E5%92%8C%E4%B8%BAs%E7%9A%84%E8%BF%9E%E7%BB%AD%E6%AD%A3%E6%95%B0%E5%BA%8F%E5%88%97/:1:0","tags":["算法题","和为s的连续正数序列"],"title":"和为s的连续正数序列","uri":"/%E5%92%8C%E4%B8%BAs%E7%9A%84%E8%BF%9E%E7%BB%AD%E6%AD%A3%E6%95%B0%E5%BA%8F%E5%88%97/"},{"categories":["算法题"],"content":"思路： 滑动窗口即可，滑动窗口就是选取数组的一部分来进行操作，left 和 right只能向右移动 ","date":"2021-08-06","objectID":"/%E5%92%8C%E4%B8%BAs%E7%9A%84%E8%BF%9E%E7%BB%AD%E6%AD%A3%E6%95%B0%E5%BA%8F%E5%88%97/:2:0","tags":["算法题","和为s的连续正数序列"],"title":"和为s的连续正数序列","uri":"/%E5%92%8C%E4%B8%BAs%E7%9A%84%E8%BF%9E%E7%BB%AD%E6%AD%A3%E6%95%B0%E5%BA%8F%E5%88%97/"},{"categories":["算法题"],"content":"代码： class Solution: def findContinuousSequence(self, target: int) -\u003e List[List[int]]: res = [] left,right = 1,2 while left \u003c= target // 2: # 优化 减少时间复杂度 if sum(range(left,right+1)) \u003c target: # 小于target 右指针移动 right += 1 elif sum(range(left,right+1)) \u003e target: # 大于target 左指针移动 left += 1 else: res.append(list(range(left,right+1))) # 相等的话 两个指针都移动 right += 1 left += 1 return res ","date":"2021-08-06","objectID":"/%E5%92%8C%E4%B8%BAs%E7%9A%84%E8%BF%9E%E7%BB%AD%E6%AD%A3%E6%95%B0%E5%BA%8F%E5%88%97/:3:0","tags":["算法题","和为s的连续正数序列"],"title":"和为s的连续正数序列","uri":"/%E5%92%8C%E4%B8%BAs%E7%9A%84%E8%BF%9E%E7%BB%AD%E6%AD%A3%E6%95%B0%E5%BA%8F%E5%88%97/"},{"categories":["算法题"],"content":"合并区间 ","date":"2021-08-03","objectID":"/%E5%90%88%E5%B9%B6%E5%8C%BA%E9%97%B4/:0:0","tags":["算法题","合并区间"],"title":"合并区间","uri":"/%E5%90%88%E5%B9%B6%E5%8C%BA%E9%97%B4/"},{"categories":["算法题"],"content":"题目： ​ https://leetcode-cn.com/problems/merge-intervals/ ","date":"2021-08-03","objectID":"/%E5%90%88%E5%B9%B6%E5%8C%BA%E9%97%B4/:1:0","tags":["算法题","合并区间"],"title":"合并区间","uri":"/%E5%90%88%E5%B9%B6%E5%8C%BA%E9%97%B4/"},{"categories":["算法题"],"content":"思路： ​ 一开始思路想的是，根据每一个区间的left排序后，然后比较每一个数，再向前更新，然后写了半天，一直WA，感觉这个思路不太行了 ","date":"2021-08-03","objectID":"/%E5%90%88%E5%B9%B6%E5%8C%BA%E9%97%B4/:2:0","tags":["算法题","合并区间"],"title":"合并区间","uri":"/%E5%90%88%E5%B9%B6%E5%8C%BA%E9%97%B4/"},{"categories":["算法题"],"content":"代码： ​ 先贴上错误的代码： class Solution: def merge(self, res: List[List[int]]) -\u003e List[List[int]]: if not res: return [] res.sort(key=lambda i:i[0]) n = len(res) - 1 for i in range(0,n): if res[i][1] \u003c res[i+1][0]: continue else: res[i+1] = [res[i][0],max(res[i][1],res[i+1][1])] res[i] = res[i-1] ress = [] for i in res: if i not in ress: ress.append(i) return ress 在[[1,4],[0,2],[3,5]] ​ 出错了 输出： [[3,5],[0,5]] 预期结果： [[0,5]] 应该是思路的错误 后来觉得不应该在原数组上操作 又改了如下，终于过了 class Solution: def merge(self, intervals: List[List[int]]) -\u003e List[List[int]]: if not intervals: return [] intervals.sort(key=lambda i:i[0]) res = [] for i in intervals: if len(res) == 0 or res[-1][1] \u003c i[0]: res.append(i) else: res[-1][1] = max(res[-1][1],i[1]) return res 这个思路就是先创造一个空数组res 然后如果数组为空或者题设的条件不成立的时候，把原数组的值加进去，要是条件成立的话，则将目前区间的right改为目前区间的right和原数组的right之间的最大值，预防[[1,4],[2,3]]这种情况。注意这个也是按left排序的 我上面代码的思路和这个是一样的，看来类似的题目尽量不要在原数组上面操作，除非题目要求 ","date":"2021-08-03","objectID":"/%E5%90%88%E5%B9%B6%E5%8C%BA%E9%97%B4/:3:0","tags":["算法题","合并区间"],"title":"合并区间","uri":"/%E5%90%88%E5%B9%B6%E5%8C%BA%E9%97%B4/"},{"categories":["Machine Learning","降维算法"],"content":"SVD奇异值分解 参考：https://www.cnblogs.com/pinard/p/6251584.html ","date":"2021-07-16","objectID":"/svd/:0:0","tags":["Machine Learning","降维算法","SVD"],"title":"SVD","uri":"/svd/"},{"categories":["Machine Learning","降维算法"],"content":"特征值与特征向量 首先回顾特征值与特征向量\\(Ax=\\lambda x\\) \\(\\lambda\\) 是矩阵A的一个特征值，x是矩阵A的特征值\\(\\lambda\\)对应的特征向量。 求出特征值与特征向量可以将矩阵A进行特征分解。如果求出了A的n个特征值，以及这n个特征值所对应的特征向量\\({w_1,w_2,\\dots,w_n}\\)，如果这n个特征向量线性无关，则矩阵A就可以用下式进行表示： \\[ A = W\\sum W^{-1} \\] 其中W为这n个特征向量所张成的\\(n\\times n\\)维矩阵，\\(\\sum\\)为这n个特征值为主对角线的矩阵。 我们一般会把n个特征向量标准化，即\\(w_i^Tw_i=1\\)，此时W的n个特征向量为标准正交基，满足\\(W^TW=I\\)，即\\(W^T=W^{-1}\\)，也就是说W为酉矩阵。 这样特征分解表达式可以写为\\(A=W\\sum W^T\\) 特征分解要求A必须为方阵，如果行列不相同则使用SVD进行分解。 ","date":"2021-07-16","objectID":"/svd/:1:0","tags":["Machine Learning","降维算法","SVD"],"title":"SVD","uri":"/svd/"},{"categories":["Machine Learning","降维算法"],"content":"SVD 假设A为一个\\(m\\times n\\)的矩阵，那么定义A的SVD为： \\[ A = U\\sum V^T \\] 其中U是一个\\(m\\times n\\)的矩阵，\\(\\sum\\)是一个\\(m\\times n\\)的矩阵，除了主对角线上的元素全为0，主对角线上的每个元素成为奇异值，V是一个\\(n\\times n\\)的矩阵，U和V都是酉矩阵。 先得到\\(m\\times m\\)的方阵\\(AA^T\\),然后进行特征值分解，\\((AA^T)u_i=\\lambda_iu_i\\) 将\\(AA^T\\)的所有特征向量张成一个\\(m\\times m\\)的矩阵U，就是SVD公式里面的U矩阵了。 后得到\\(n\\times n\\)的方阵\\(A^TA\\),然后进行特征值分解，\\((A^TA)v_i=\\lambda_iv_i\\) 将\\(A^TA\\)的所有特征向量张成一个\\(n\\times n\\)的矩阵V，就是SVD公式里面的V矩阵了。 特征值和奇异值满足以下关系\\(\\sigma_i = \\sqrt{\\lambda_i}\\)，意思就是我们可以通过求\\(A^TA\\)的特征值取平方根来求奇异值。 ","date":"2021-07-16","objectID":"/svd/:2:0","tags":["Machine Learning","降维算法","SVD"],"title":"SVD","uri":"/svd/"},{"categories":["NLP"],"content":"词嵌入 ","date":"2021-07-16","objectID":"/word-embedding/:0:0","tags":["NLP","Word Embedding"],"title":"Word Embedding","uri":"/word-embedding/"},{"categories":["NLP"],"content":"介绍 词嵌入是自然语言处理（NLP）中语言模型与表征学习技术的统称。概念上而言，它是指把一个维数为所有词的数量的高维空间嵌入到一个维数低得多的连续向量空间中，每个单词或词组被映射为实数域上的向量。 词嵌入的方法包括人工神经网络、对词语同现矩阵降维、概率模型以及单词所在上下文的显式表示等。 在底层输入中，使用词嵌入来表示词组的方法极大提升了NLP中语法分析器和文本情感分析等的效果。 以上是百度百科中对词嵌入的定义。本文只介绍传统的词向量，也就是固定的词向量。deep contextualized词向量模型在本博客预训练模型内容里面。词嵌入也可以称为词表征(word representation)，可以粗略得把它分为三个阶段： 一、特征工程阶段，以词袋模型为典型代表。 二、浅层表证阶段，以word2vec为典型代表。 三、深层表征阶段，以基于transformer的Bert为典型代表。 本文介绍了一、二两部分内容 ","date":"2021-07-16","objectID":"/word-embedding/:1:0","tags":["NLP","Word Embedding"],"title":"Word Embedding","uri":"/word-embedding/"},{"categories":["NLP"],"content":"语言模型 一句话，语言模型是这样一个模型：对于任意的词序列，它能够计算出这个序列是一句话的概率。 具体的详见本博客有关语言模型的文章。 为什么要介绍语言模型，因为NLP的做预训练一般选择用语言模型任务来做的。 语言模型主要有： N-gram LM、FeedForward Neural Network LM、RNN LM和GPT系列 本文会涉及到Neural Network LM，其本质是一个语言模型，词向量只是其在训练过程中的一个副产物。 ","date":"2021-07-16","objectID":"/word-embedding/:2:0","tags":["NLP","Word Embedding"],"title":"Word Embedding","uri":"/word-embedding/"},{"categories":["NLP"],"content":"特征工程阶段(基于计数的方法) ","date":"2021-07-16","objectID":"/word-embedding/:3:0","tags":["NLP","Word Embedding"],"title":"Word Embedding","uri":"/word-embedding/"},{"categories":["NLP"],"content":"One-Hot 最简单的方法是将单词表示为 one-hot 向量：对于词汇表中的第 i 个单词，向量在第 i 个维度上具有 1，在其余维度上具有 0。在机器学习中，这是表示分类特征的最简单方法。 One-Hot的缺点很明显，它对自己代表的词一无所知，没有捕捉到词的意义。 ","date":"2021-07-16","objectID":"/word-embedding/:3:1","tags":["NLP","Word Embedding"],"title":"Word Embedding","uri":"/word-embedding/"},{"categories":["NLP"],"content":"词袋模型 即无视词语的顺序，只关心出现的次数，以下都属于词袋模型。在文本匹配领域也有类似的字面意义的匹配。本博客有相关内容。 ### TFIDF 权重也可以作为词向量表示。也可以计算文本相似度等，本博客有相关内容。 ","date":"2021-07-16","objectID":"/word-embedding/:3:2","tags":["NLP","Word Embedding"],"title":"Word Embedding","uri":"/word-embedding/"},{"categories":["NLP"],"content":"共现矩阵 详见本博客共现矩阵 ### PPMI 详见本博客互信息相关博文。 中文名字为正点互信息，公式如下 \\[ PPMI(w, c) = max(0, PMI(w, c)) \\\\\\\\ PMI(w, c) = log\\frac{P(w,c)}{P(w)P(c)} = log \\frac{N(w,c)|(w,c)|}{N(w)N(c)} \\] 事实证明，word2vec被证明可以隐式逼近PMI矩阵的因式分解。 『Neural Word Embedding as Implicit Matrix Factorization』这篇论文就详细讨论了这个问题。 ","date":"2021-07-16","objectID":"/word-embedding/:3:3","tags":["NLP","Word Embedding"],"title":"Word Embedding","uri":"/word-embedding/"},{"categories":["NLP"],"content":"主题模型 这个更是重量级，见本博客。 ","date":"2021-07-16","objectID":"/word-embedding/:3:4","tags":["NLP","Word Embedding"],"title":"Word Embedding","uri":"/word-embedding/"},{"categories":["NLP"],"content":"浅层表征阶段(基于推理的方法) ","date":"2021-07-16","objectID":"/word-embedding/:4:0","tags":["NLP","Word Embedding"],"title":"Word Embedding","uri":"/word-embedding/"},{"categories":["NLP"],"content":"NNLM 介绍 先来张经典的图片 这就是大名鼎鼎的神经网络语言模型（其它的语言模型详见本博客语言模型部分） 学习任务是输入某个句中单词\\(W_t=i\\)前面句子的t-1个单词，要求网络正确预测单词\\(W_t=i\\)，即最大化： \\[ P(W_t=i | W_1, W_2, \\dots W_{(t-1)}; \\theta) \\] 前面任意单词 \\(W_i\\)用Onehot编码（比如：0001000）作为原始单词输入，之后乘以矩阵Q后获得向量 \\(C(W_i)\\)，每个单词的 \\(C(W_i)\\) 拼接，上接隐层，然后接softmax去预测后面应该后续接哪个单词。 这个\\(C(W_i)\\)是什么？ 这其实就是单词对应的Word Embedding值，那个矩阵Q包含V行，V代表词典大小，每一行内容代表对应单词的Word embedding值。只不过Q的内容也是网络参数，需要学习获得，训练刚开始用随机值初始化矩阵Q，当这个网络训练好之后，矩阵Q的内容被正确赋值，每一行代表一个单词对应的Word embedding值。 所以你看，通过这个网络学习语言模型任务，这个网络不仅自己能够根据上文预测后接单词是什么，同时获得一个副产品，就是那个矩阵Q，这就是单词的Word Embedding是被如何学会的。 参数解释 训练样本(Context(w), w),w是语料C的每一个词，Context(w)为取其前n-1个词 投影层向量\\(X_w\\): 将该训练样本(Context(w), w)的前n-1个词的词向量首尾拼接在一起，这里的词向量可以用独热编码表示。\\(X_w\\)的形状为 \\((n-1)\\times m\\)，这里的m为词汇表的所有词的个数。 隐藏层向量\\(Z_w\\): \\[ Z_w = tanh(WX_w+p) \\] 输出层向量\\(y_w\\): 维度为N=|D|,即词典D中词的个数。 \\[ y_w = Uz_w + q \\] 在对\\(y_w\\)做softmax后，\\(y_w\\)的分量就表示当前词是w的概率 \\[ p(w|Context(w)) = \\frac{e^{y_w,iw}}{\\sum_{i-1}^N e^{y^{w, i}} } \\] 优点与缺点 NNLM相对于N-grams语言模型，有以下优点： 词语与词语间的相似度可以通过词向量来体现 基于词向量的模型自带『平滑化』功能，无需额外处理。 当然也有缺点，缺点就是计算量太大。 下面就重点介绍一下word2vec，相比于NNLM来说这是专门训练词向量的一种工具，而词向量对于NNLM来说只是一个副产物，其本质还是一个语言模型。 代码 代码来自https://github.com/graykode/nlp-tutorial import torch import torch.nn as nn import torch.optim as optim def make_batch(): input_batch = [] target_batch = [] for sen in sentences: word = sen.split() # space tokenizer input = [word_dict[n] for n in word[:-1]] # create (1~n-1) as input target = word_dict[word[-1]] # create (n) as target, We usually call this 'casual language model' input_batch.append(input) target_batch.append(target) return input_batch, target_batch # Model class NNLM(nn.Module): def __init__(self): super(NNLM, self).__init__() self.C = nn.Embedding(n_class, m) self.H = nn.Linear(n_step * m, n_hidden, bias=False) self.d = nn.Parameter(torch.ones(n_hidden)) self.U = nn.Linear(n_hidden, n_class, bias=False) self.W = nn.Linear(n_step * m, n_class, bias=False) self.b = nn.Parameter(torch.ones(n_class)) def forward(self, X): X = self.C(X) # X : [batch_size, n_step, m] X = X.view(-1, n_step * m) # [batch_size, n_step * m] tanh = torch.tanh(self.d + self.H(X)) # [batch_size, n_hidden] output = self.b + self.W(X) + self.U(tanh) # [batch_size, n_class] return output if __name__ == '__main__': n_step = 2 # number of steps, n-1 in paper n_hidden = 2 # number of hidden size, h in paper m = 2 # embedding size, m in paper sentences = [\"i like dog\", \"i love coffee\", \"i hate milk\"] word_list = \" \".join(sentences).split() # ['i', 'like', 'dog', 'dog', 'i', 'love', 'coffee', 'i', 'hate', 'milk'] word_list = list(set(word_list)) # ['i', 'like', 'dog', 'love', 'coffee', 'hate', 'milk'] word_dict = {w: i for i, w in enumerate(word_list)} # {'i':0, 'like':1, 'dog':2, 'love':3, 'coffee':4, 'hate':5, 'milk':6} number_dict = {i: w for i, w in enumerate(word_list)} # {0:'i', 1:'like', 2:'dog', 3:'love', 4:'coffee', 5:'hate', 6:'milk'} n_class = len(word_dict) # number of Vocabulary, just like |V|, in this task n_class=7 model = NNLM() criterion = nn.CrossEntropyLoss() optimizer = optim.Adam(model.parameters(), lr=0.001) input_batch, target_batch = make_batch() input_batch = torch.LongTensor(input_batch) target_batch = torch.LongTensor(target_batch) # Training for epoch in range(5000): optimizer.zero_grad() output = model(input_batch) # output : [batch_size, n_class], target_batch : [batch_size] loss = criterion(output, target_batch) if (epoch + 1) % 1000 == 0: print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss)) loss.backward() optimizer.step() # Predict predict = model(input_batch).data.argmax(1, keepdim=True) # Test print([sen.split()[:2] for sen in sentences], '-\u003e', [number_dict[n.item()] for n in predict.squeeze()]) ","date":"2021-07-16","objectID":"/word-embedding/:4:1","tags":["NLP","Word Embedding"],"title":"Word Embedding","uri":"/word-embedding/"},{"categories":["NLP"],"content":"word2vec Word2Vec是从大量文本语料中以无监督的方式学习语义知识的一种模型，它被大量地用在自然语言处理（NLP）中。那么它是如何帮助我们做自然语言处理呢？Word2Vec其实就是通过学习文本来用词向量的方式表征词的语义信息，即通过一个嵌入空间使得语义上相似的单词在该空间内距离很近。Embedding其实就是一个映射，将单词从原先所属的空间映射到新的多维空间中，也就是把原先词所在空间嵌入到一个新的空间中去。 Word2Vec和NNLM不一样，NNLM的主要任务是要学习一个解决语言模型任务的网络结构，语言模型就是要看到上文预测下文，而word embedding只是无心插柳的一个副产品。但是Word2Vec目标不一样，它单纯就是要word embedding的，这是主产品，所以它完全可以随性地这么去训练网络。 (skip-gram与CBOW只是word2vec的变体。) 训练思路 Word2Vec 是一个模型，其参数是词向量。这些参数针对某个目标进行迭代优化。目标迫使词向量“知道”一个词可能出现的上下文：训练向量以预测相应词的可能上下文。正如您从分布假设中所记得的那样，如果向量“知道”上下文，它们就“知道”单词的含义。 获取一个巨大的文本语料库； 使用滑动窗口浏览文本，一次移动一个单词。在每一步，都有一个中心词和上下文词（此窗口中的其他词）； 对于中心词，计算上下文词的概率； 调整向量以增加这些概率。 推导 以Skip-grams模型为例，首先清楚几个概念，中心词、背景词（上下文词）、负采样词。中心词就是我们的输入，因为skip-grams相当于在一句话中扣去一个词，然后用这个词预测这句话的其余词。形式上给人的感觉就是一对多，这里的一句话其实不是一句话，是我们设定的窗口大小，比如一句话”I miss you very much”， 设置中心词为you，窗口大小为1，那么背景词就是”miss”和”very”。那么对于我们的模型来说，miss和very就是正例，就是我们的预测值(sigmoid后)的值接近于1的，而其余的词就是负例，就是使其值接近于0的。所以负采样就是从这些负例中随机抽取一些负例，不然每次都要计算单词表中所有单词的sigmoid值，这个计算量很大，而使用负采样就大大缩小了计算量。 目标函数：负似然对数 对于每个位置\\(t=1,\\dots, T\\)，在文本语料库中，Word2Vec在给定中心词的m大小窗口内预测上下文词\\(w_t\\): \\[ Likelihood=L(\\theta)=\\prod_{t=1}^T\\prod_{-m\\leq j\\leq m, j\\neq0} P(w_{t+j} | w_t, \\theta) \\] 目标函数\\(J(\\theta)\\)为平均负对数似然 \\[ Loss = J(\\theta) = -\\frac{1}{T}\\sum_{t=1}^T\\sum_{-m\\leq j\\leq m, j\\neq0} logP(w_{t+j}|w_t, \\theta) \\] 对于每个单词w我们都有两个向量： \\(v_w\\)当w是中心词 \\(u_w\\)当w时背景词 因为word2vec是一个专门训练词向量的神经网络，输入为onehot向量，经过第一层W的计算得到隐藏层，就相当于查表，数值为中心词的词向量，然后再与第二层的W计算得到输出，输出的维度和输入的维度相同，因此输出层的结果在计算上就是\\(u_c^Tv_w\\)。即输入层对应的中心词的词向量*输出层对应背景词的词向量，再经过softmax就是对应背景词的概率。 训练完毕后，我们只使用\\(v_w\\)，即只使用从输入层到隐藏层的权重。 对于中心词w，上下文词c的概率为： \\[ P(c|w) = \\frac{exp(u_c^Tv_w)}{\\sum_{o\\in V}exp(u_o^Tv_w)} \\] 这就是softmax函数。 训练 \\(\\theta^{new} = \\theta^{old} - \\alpha \\nabla_\\theta J(\\theta)\\) 一次进行一次更新，每次更新都是针对一对中心词和其中一个背景词。损失函数： \\[ Loss = J(\\theta) = -\\frac{1}{T}logL(\\theta)= -\\frac{1}{T}\\sum_{t=1}^T\\sum_{-m\\leq j\\leq m, j\\neq0} logP(w_{t+j}|w_t, \\theta)\\\\\\\\=\\frac{1}{T}\\sum_{t=1}^T\\sum_{-m\\leq j\\leq m, j\\neq0}J_{t,j}(\\theta). \\] 其中\\(J_{t,j}(\\theta) = -logP(w_{t+j}|w_t, \\theta)\\) 以”I miss you very much”这句话为例子，中心词为”you”，其中一个背景词为miss，则损失项为 \\[ J_{t,j}(\\theta) = -logP(miss|you) = -log\\frac{exp(u_{miss}^Tv_{you})}{\\sum_{o\\in V}exp(u_o^Tv_{you})} = \\\\\\\\-u_{miss}^Tv_{you}+log\\sum_{o\\in V} exp(u_o^Tv_{you}) \\] 这是中心词对应其中一个背景词的损失函数，如果要求总的损失，则将所有背景词的损失相加，然后将所有样本的损失求平均，就是上面的Loss。其实这就是交叉熵损失函数，是个多分类问题，预测的target相当于miss对应的数字，也就是序列值，具体的pytorch代码为 loss = (-output_layer[:, Y] + torch.log(torch.sum(torch.exp(output_layer), dim=1))).mean() 这里的output_layer就是神经网络的输出层，注意这里的都是对batch操作，这里求出的loss是这个batch上最终的loss，而不是一对中心词与背景词的loss。理解了这个简单的word2vec模型就算理解了。 下面求一下梯度： 注意这里的c为center word, o为上下文词 \\[ \\frac{\\partial logP(w_o|w_c)}{\\partial v_c} = \\frac{\\partial}{\\partial v_c}log\\frac{exp(u_0^Tv_c)}{\\sum_{i=1}^{|V|}exp(u_i^Tv_c)}\\\\\\\\= \\frac{\\partial}{\\partial v_c}log\\, exp(u_o^Tv_c) - \\frac{\\partial}{\\partial v_c}log\\sum_{i=1}^{|V|}exp(u_i^Tv_c) \\] 左边的： \\[ \\frac{\\partial}{\\partial v_c}log\\, exp(u_o^Tv_c)=\\frac{\\partial}{\\partial v_c}u_o^Tv_c=u_o \\] 第二部分推导 \\[ \\begin{aligned} \\frac{\\partial}{\\partial {v}_{c}} \\log \\sum_{i=1}^{|V|} \\exp \\left({u}_{i}^{T} {v}_{c}\\right) \u0026=\\frac{1}{\\sum_{i=1}^{|V|} \\exp \\left({u}_{i}^{T} {v}_{c}\\right)} \\cdot \\frac{\\partial}{\\partial {v}_{c}} \\sum_{x=1}^{|V|} \\exp \\left({u}_{x}^{T} {v}_{c}\\right) \\\\\\\\ \u0026=\\frac{1}{A} \\cdot \\sum_{x=1}^{|V|} \\frac{\\partial}{\\partial {v}_{c}} \\exp \\left({u}_{x}^{T} {v}_{c}\\right) \\\\\\\\ \u0026=\\frac{1}{A} \\cdot \\sum_{x=1}^{|V|} \\exp \\left({u}_{x}^{T} {v}_{c}\\right) \\frac{\\partial}{\\partial {v}_{c}} {u}_{x}^{T} {v}_{c} \\\\\\\\ \u0026=\\frac{1}{\\sum_{i=1}^{|V|} \\exp \\left({u}_{i}^{T} {v}_{c}\\right)} \\sum_{x=1}^{|V|} \\exp \\left({u}_{x}^{T} {v}_{c}\\right) {u}_{x} \\\\\\\\ \u0026=\\sum_{x=1}^{|V|} \\frac{\\exp \\left({u}_{x}^{T} {v}_{c}\\right)}{\\sum_{i=1}^{|V|} \\exp \\left({u}_{i}^{T} {v}_{c}\\right)} {u}_{x} \\\\\\\\ \u0026=\\sum_{x=1}^{|V|} P\\left(w_{x} \\mid w_{c}\\right) {u}_{x} \\end{aligned} \\] 综上所述 \\[ \\frac{\\partial \\log P\\left(w_{o} \\mid w_{c}\\right)}{\\partial {v}_{c}}={u}_{o}-\\sum_{j \\in V} P\\left(w_{j} \\mid w_{c}\\right) {u}_{j} \\] 通过上面计算得到梯度后，我们可以使用随机梯度下降来不断迭代模型参数\\(v_c\\)","date":"2021-07-16","objectID":"/word-embedding/:4:2","tags":["NLP","Word Embedding"],"title":"Word Embedding","uri":"/word-embedding/"},{"categories":["NLP"],"content":"GloVe GloVe 模型是基于计数的方法和预测方法（例如 Word2Vec）的组合。模型名称 GloVe 代表“Global Vectors”，体现了它的思想：该方法利用 语料库中的全局信息来学习向量。 正如我们之前看到的，最简单的基于计数的方法使用共现计数来衡量单词 w 和上下文c之间的关联：\\(N(w,c)\\)。 GloVe 也使用这些计数来构建损失函数： \\[ J(\\theta) = \\sum_{w,c\\in V}f(N(w,c)) \\cdot(u_c^Tv_w+b_c+\\bar{b_w}-logN(w,c)^2) \\] 其中： \\[ f(x) = \\begin{cases} (\\frac{x}{x_{max}})^{0.75}, \\quad if \\;x \u003c x_{max} \\\\\\\\ 1, \\quad if \\; x\\geq x_{max} \\end{cases} \\] 具体的推导可以看这个博客：https://www.cnblogs.com/Lee-yl/p/11172255.html 可以看到GloVe并没有使用神经网络的方法。 与 Word2Vec 类似，我们也有不同的 中心词和上下文词向量——这些是我们的参数。此外，该方法对每个词向量都有一个标量偏置项。 特别有趣的是 GloVe 控制稀有词和频繁词影响的方式：每对 ( w , c ) 的损失以如下方式加权 罕见事件受到惩罚， 非常频繁的事件不会被过度加权。 ","date":"2021-07-16","objectID":"/word-embedding/:4:3","tags":["NLP","Word Embedding"],"title":"Word Embedding","uri":"/word-embedding/"},{"categories":["NLP"],"content":"关于word embedding word embedding只能通过语言模型的训练获取吗？ 不是的；事实上任何NLP任务都可以在训练过程中获取word embedding，甚至特定任务下的word embedding在特定任务中的使用效果还会更好（如基于fasttext的文本分类任务）。之所以我们平时提及的word embedding均是在语言模型任务中产生，私以为主要有这么几个原因：a).语言模型是无监督任务，存在海量训练语料，无需标注成本；b).语言模型任务本身要求较高，训练过程中可以学习大量的语义知识，进而生成高质的word representation。 如何评估word embedding好坏？ 有两种方式：第一种，把word embedding融入现有系统中，看其对系统性能的提升；第二，从语言学的角度对word embedding进行分析，如相似度、语义偏移等。更细节的可以参考这里。 ## 参考 参考： https://blog.csdn.net/malefactor/article/details/83961886 https://www.zybuluo.com/Dounm/note/591752 https://lena-voita.github.io/nlp_course/word_embeddings.html https://wmathor.com/index.php/archives/1430/ https://zhuanlan.zhihu.com/p/27234078 Rong X . word2vec Parameter Learning Explained[J]. Computer Science, 2014. ","date":"2021-07-16","objectID":"/word-embedding/:5:0","tags":["NLP","Word Embedding"],"title":"Word Embedding","uri":"/word-embedding/"},{"categories":["算法题"],"content":"三数之和 ","date":"2021-07-16","objectID":"/%E4%B8%89%E6%95%B0%E4%B9%8B%E5%92%8C/:0:0","tags":["算法题","三数之和"],"title":"三数之和","uri":"/%E4%B8%89%E6%95%B0%E4%B9%8B%E5%92%8C/"},{"categories":["算法题"],"content":"题目： https://leetcode-cn.com/problems/3sum/solution/ ","date":"2021-07-16","objectID":"/%E4%B8%89%E6%95%B0%E4%B9%8B%E5%92%8C/:1:0","tags":["算法题","三数之和"],"title":"三数之和","uri":"/%E4%B8%89%E6%95%B0%E4%B9%8B%E5%92%8C/"},{"categories":["算法题"],"content":"思路： ​ 第一眼看就想到了用双指针，注意重复数值的处理问题，算是一个滑动窗口问题 ","date":"2021-07-16","objectID":"/%E4%B8%89%E6%95%B0%E4%B9%8B%E5%92%8C/:2:0","tags":["算法题","三数之和"],"title":"三数之和","uri":"/%E4%B8%89%E6%95%B0%E4%B9%8B%E5%92%8C/"},{"categories":["算法题"],"content":"代码： class Solution: def threeSum(self, nums: List[int]) -\u003e List[List[int]]: res = [] if len(nums) \u003c 3: return [] nums.sort() for i, num in enumerate(nums): if num \u003e 0: return res if i \u003e 0 and nums[i] == nums[i-1]: continue left, right = i+1, len(nums) - 1 while left \u003c right: temp = nums[i] + nums[left] + nums[right] if temp == 0: res.append([nums[i], nums[left], nums[right]]) while left \u003c right and nums[right-1] == nums[right]: right -= 1 while left \u003c right and nums[left+1] == nums[left]: left += 1 left += 1 right -= 1 if temp \u003e 0: right -=1 if temp \u003c 0: left += 1 return res ","date":"2021-07-16","objectID":"/%E4%B8%89%E6%95%B0%E4%B9%8B%E5%92%8C/:3:0","tags":["算法题","三数之和"],"title":"三数之和","uri":"/%E4%B8%89%E6%95%B0%E4%B9%8B%E5%92%8C/"},{"categories":["Machine Learning","性能指标"],"content":"# ROC曲线 了解什么是ROC曲线和AUC之前，要先了解什么是混淆矩阵。 混淆矩阵中有着Positive、Negative、True、False的概念，其意义如下： 称预测类别为1的为Positive（阳性），预测类别为0的为Negative（阴性）。 预测正确的为True（真），预测错误的为False（伪）。 因此有了True Postive Rate、False Postive Rate两个概念 \\(TPRate = \\frac{TP}{TP+FN}\\) \\(FPRate = \\frac{FP}{FP+TN}\\) TPRate的意义是所有真实类别为1的样本中，预测类别为1的比例。 FPRate的意义是所有真实类别为0的样本中，预测类别为1的比例。 按照定义，AUC即ROC曲线下的面积，而ROC曲线的横轴是FPRate，纵轴是TPRate，当二者相等时，即y=x，如下图: 这样的分类器和瞎猜没啥区别，我们可以看成AUC的最小值为0.5。 而我们希望分类器达到的效果是：对于真实类别为1的样本，分类器预测为1的概率（即TPRate），要大于真实类别为0而预测类别为1的概率（即FPRate），即y＞x。这是理所当然的，分类器肯定要分对的嘛。 我们知道，在二分类（0，1）的模型中，一般我们最后的输出是一个概率值，表示结果是1的概率。那么我们最后怎么决定输入的x是属于0或1呢？我们需要一个 阈值，超过这个阈值则归类为1，低于这个阈值就归类为0。 所以，不同的阈值会导致分类的结果不同，也就是混淆矩阵不一样了，FPR和TPR也就不一样了。所以当阈值从0开始慢慢移动到1的过程，就会形成很多对(FPR, TPR)的值，将它们画在坐标系上，就是所谓的ROC曲线了。 看这张图： 当阈值选取为0.5时，阈值右边的视为 预测为正例 ，阈值左边的视为 预测为负例 。由于准确度为\\(\\frac{TP+TN}{all}\\)，因此可得此时的准确度为90%。 看这张图： 阈值设定为0.6，即右边视为 预测为正例 ，红色的为实际为正例，蓝色的为实际为负例，因此很容易得到FP=0，因为阈值右边没有蓝色区域，可以这么理解。 当蓝色区域与红色区域基本重叠时，ROC曲线就和接近y=x这条线了。 其实，AUC表示的是正例排在负例前面的概率 我们知道阈值可以取不同，也就是说，分类的结果会受到阈值的影响。如果使用AUC的话，因为阈值变动考虑到了，所以评估的效果更好。 最后说说AUC的优势，AUC的计算方法同时考虑了分类器对于正例和负例的分类能力，在样本不平衡的情况下，依然能够对分类器作出合理的评价。 ","date":"2021-06-26","objectID":"/roc%E6%9B%B2%E7%BA%BF/:1:0","tags":["Machine Learning","性能指标","ROC曲线"],"title":"ROC曲线","uri":"/roc%E6%9B%B2%E7%BA%BF/"},{"categories":["Machine Learning","性能指标"],"content":"AUC计算 ","date":"2021-06-26","objectID":"/roc%E6%9B%B2%E7%BA%BF/:2:0","tags":["Machine Learning","性能指标","ROC曲线"],"title":"ROC曲线","uri":"/roc%E6%9B%B2%E7%BA%BF/"},{"categories":["算法题"],"content":"删除排序数组中的重复项 ","date":"2021-06-22","objectID":"/%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E9%A1%B9/:0:0","tags":["算法题","删除排序数组中的重复项"],"title":"删除排序数组中的重复项","uri":"/%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E9%A1%B9/"},{"categories":["算法题"],"content":"删除排序数组中的重复项1 ","date":"2021-06-22","objectID":"/%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E9%A1%B9/:1:0","tags":["算法题","删除排序数组中的重复项"],"title":"删除排序数组中的重复项","uri":"/%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E9%A1%B9/"},{"categories":["算法题"],"content":"题目： ​ https://leetcode-cn.com/problems/remove-duplicates-from-sorted-array/ ","date":"2021-06-22","objectID":"/%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E9%A1%B9/:1:1","tags":["算法题","删除排序数组中的重复项"],"title":"删除排序数组中的重复项","uri":"/%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E9%A1%B9/"},{"categories":["算法题"],"content":"思路： ​ 双指针，定义 nums[0...i] 为为非重复数列，遍历整个数列不断的维护这个定义 ","date":"2021-06-22","objectID":"/%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E9%A1%B9/:1:2","tags":["算法题","删除排序数组中的重复项"],"title":"删除排序数组中的重复项","uri":"/%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E9%A1%B9/"},{"categories":["算法题"],"content":"代码： ​ class Solution: def removeDuplicates(self, nums: List[int]) -\u003e int: start = 0 for i in range(len(nums)): if nums[i] != nums[start]: start += 1 nums[i],nums[start] = nums[start],nums[i] return start + 1 ","date":"2021-06-22","objectID":"/%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E9%A1%B9/:1:3","tags":["算法题","删除排序数组中的重复项"],"title":"删除排序数组中的重复项","uri":"/%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E9%A1%B9/"},{"categories":["算法题"],"content":"删除排序数组中的重复项2 ","date":"2021-06-22","objectID":"/%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E9%A1%B9/:2:0","tags":["算法题","删除排序数组中的重复项"],"title":"删除排序数组中的重复项","uri":"/%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E9%A1%B9/"},{"categories":["算法题"],"content":"题目： ​ https://leetcode-cn.com/problems/remove-duplicates-from-sorted-array-ii/ ","date":"2021-06-22","objectID":"/%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E9%A1%B9/:2:1","tags":["算法题","删除排序数组中的重复项"],"title":"删除排序数组中的重复项","uri":"/%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E9%A1%B9/"},{"categories":["算法题"],"content":"思路： ​ 也是利用双指针，一个指针用于遍历数组元素，一个指针指向要拷贝赋值的索引位置 ","date":"2021-06-22","objectID":"/%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E9%A1%B9/:2:2","tags":["算法题","删除排序数组中的重复项"],"title":"删除排序数组中的重复项","uri":"/%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E9%A1%B9/"},{"categories":["算法题"],"content":"代码： ​ class Solution: def removeDuplicates(self, nums: List[int]) -\u003e int: if len(nums) \u003c= 2: #长度小于等于2时 return len(nums) count = 1 #用于重复的计数 j = 1 #指向多余重复的元素 for i in range(1,len(nums)): if nums[i] == nums[i-1]: count += 1 #重复了就加一 if count \u003e 2: #如果重复两次以上就pass掉，等着被替换 pass else: nums[j] = nums[i] j += 1 else: nums[j] = nums[i] #如果不相等了 把多余重复的那个替换掉了 count = 1 #重置计数 j += 1 return j 这是一种思路比较清晰的写法 ","date":"2021-06-22","objectID":"/%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E9%A1%B9/:2:3","tags":["算法题","删除排序数组中的重复项"],"title":"删除排序数组中的重复项","uri":"/%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E9%A1%B9/"},{"categories":["python"],"content":"import threading import time ","date":"2021-06-13","objectID":"/asyncio/:0:0","tags":["python","asyncio"],"title":"asyncio","uri":"/asyncio/"},{"categories":["python"],"content":"多线程例子 def spider(): #..... time.sleep(0.02) def main1(): for i in range(100): spider() def main2(): thread_list = [] for i in range(100): thread = threading.Thread(target = spider) thread.start() thread_list.append(thread) for t in thread_list: t.join() if __name__ == \"__main__\": start = time.time() main1() end = time.time() print(\"time1 :{:.4f}\".format(end-start)) start = time.time() main2() end = time.time() print(\"time2 :{:4f}\".format(end-start)) time1 :2.0523 time2 :0.037929 ","date":"2021-06-13","objectID":"/asyncio/:1:0","tags":["python","asyncio"],"title":"asyncio","uri":"/asyncio/"},{"categories":["python"],"content":"yield def fib(n): a,b = 0,1 while b\u003cn: a,b = b,a+b yield a print(fib(100)) for i in fib(100): print(i) \u003cgenerator object fib at 0x000002B1A7AA1E60\u003e 1 1 2 3 5 8 13 21 34 55 89 ","date":"2021-06-13","objectID":"/asyncio/:2:0","tags":["python","asyncio"],"title":"asyncio","uri":"/asyncio/"},{"categories":["python"],"content":"协程 GEN_CREATED 创建完成，等待执行 GEN_RUNNING 解释器正在执行 GEN_SUSPENDED 在 yield 表达式处暂停 GEN_CLOSE 执行结束，生成器停止 import inspect def generator(): i = \"激活生成器\" while True: try: value = yield i except ValueError: print(\"OVER\") i = value g = generator() print(inspect.getgeneratorstate(g)) #查看状态 next(g) # next(g)相当于g.send(None) 可以用后面的语句来预缴携程 GEN_CREATED '激活生成器' inspect.getgeneratorstate(g) #查看生成器状态 'GEN_SUSPENDED' g.send(\"hello world\") 'hello world' 暂停状态的生成器可以使用 send 方法发送数据，此方法的参数就是 yield 表达式的值，也就是 yield 表达式等号前面的 value 变量的值变成 ‘Hello Shiyanlou’，继续向下执行完一次 while 循环，变量 i 被赋值，继续运行下一次循环，yield 表达式弹出变量 i g.throw(ValueError) #抛出异常 结束 OVER 'hello world' g.close() inspect.getgeneratorstate(g) #关闭了 'GEN_CLOSED' ","date":"2021-06-13","objectID":"/asyncio/:3:0","tags":["python","asyncio"],"title":"asyncio","uri":"/asyncio/"},{"categories":["python"],"content":"预激协程 from functools import wraps def corcut(func): @wraps(func) def wrapper(*args,**kw): g = func(*args,**kw) next(g) return g return wrapper @corcut #装饰器 def generator(): i = \"激活生成器\" while True: try: value = yield i except ValueError: print(\"OVER\") i = value g = generator() print(inspect.getgeneratorstate(g)) #此时已经用装饰器将生成器激活了 GEN_SUSPENDED @corcut def generator(): l = [] while True: value = yield if value == \"CLOSE\": break l.append(value) return l g = generator() for i in ['a','b','CLOSE']: try: g.send(i) except StopIteration as e: value = e.value value ['a', 'b'] ","date":"2021-06-13","objectID":"/asyncio/:4:0","tags":["python","asyncio"],"title":"asyncio","uri":"/asyncio/"},{"categories":["python"],"content":"yield from用法 from itertools import chain c = chain({'one','two','three'},list(\"abc\")) for i in c: print(i) three two one a b c def chains1(*args): for i in args: for n in i: yield n def chains2(*args): for i in args: yield from i #i为可迭代对象，避免嵌套循环 c1 = chains1({\"one\",\"two\",\"three\"},list(\"abc\")) for i in c1: print(i) print(\"\\n\") c2 = chains2({\"one\",\"two\",\"three\"},list(\"abc\")) for i in c2: print(i) three two one a b c three two one a b c ","date":"2021-06-13","objectID":"/asyncio/:5:0","tags":["python","asyncio"],"title":"asyncio","uri":"/asyncio/"},{"categories":["python"],"content":"转移控制权 from functools import wraps from faker import Faker import time def corout(func): @wraps(func) def wapper(*args,**kw): g = func(*args,**kw) next(g) return g return wapper # 子生成器 def generator(): l = [] while True: i = yield if i == \"CLOSE\": break l.append(i) return sorted(l) # 委托生成器 @corout def generator2(): while True: l = yield from generator() print(\"排序后的列表\",l) print(\"-----------------\") # 客户端 if __name__ == \"__main__\": fake = Faker().country_code nest_country = [[fake() for i in range(3)] for j in range(3)] for country in nest_country: print('国家代号列表：', country) c = generator2() for i in country: c.send(i) c.send(\"CLOSE\") 国家代号列表： ['AM', 'ZA', 'BG'] 排序后的列表 ['AM', 'BG', 'ZA'] ----------------- 国家代号列表： ['UG', 'BE', 'SI'] 排序后的列表 ['BE', 'SI', 'UG'] ----------------- 国家代号列表： ['SC', 'KI', 'KI'] 排序后的列表 ['KI', 'KI', 'SC'] ----------------- yield显然不只是用来减小循环次数的，引用一下《流畅的python》中关于yield from 的意义： - 子生成器产出的值都直接传给委派生成器的调用方（即客户端代码）。 - 使用 send() 方法发给委派生成器的值都直接传给子生成器。如果发送的值是 None，那么会调用子生成器的 next() 方法。如果发送的值不是 None，那么会调用子生成器的 send() 方法。如果调用的方法抛出 StopIteration 异常，那么委派生成器恢复运行。任何其他异常都会向上冒泡，传给委派生成器。 - 生成器退出时，生成器（或子生成器）中的 return expr 表达式会触发 StopIteration(expr) 异常抛出。 - yield from 表达式的值是子生成器终止时传给 StopIteration异常的第一个参数。 为什么yield可以转移控制权，可以看一下这一段伪代码： 注意这里的6是委托生成器向子生成器发送_s，而_s是调用方向委托生成器发送的，发送后得到结果_y，并在下一个循环yield即抛出给调用方。 ## asyncio模块 import time import asyncio def one(): start = time.time() @asyncio.coroutine #1 def do_something(): #2 print(\"start ------\") time.sleep(0.1) #3 print(\"doing something\") loop = asyncio.get_event_loop() #4 coroutine = do_something() #5 loop.run_until_complete(coroutine) #6 end = time.time() print(\"消耗时间:{:.4f}\".format(end-start))#7 one() start ------ doing something 消耗时间:0.1012 代码说明： 1、使用协程装饰器创建协程函数 2、协程函数 3、模拟 IO 操作 4、创建事件循环。每个线程中只能有一个事件循环，get_event_loop 方法会获取当前已经存在的事件循环，如果当前线程中没有，新建一个 5、调用协程函数获取协程对象 6、将协程对象注入到事件循环，协程的运行由事件循环控制。事件循环的 run_until_complete 方法会阻塞运行，直到任务全部完成。协程对象作为 run_until_complete 方法的参数，loop 会自动将协程对象包装成任务来运行。后面我们会讲到多个任务注入事件循环的情况 7、打印程序运行耗时 import time import asyncio def two(): start = time.time() @asyncio.coroutine def do_something(): print(\"start ------\") time.sleep(0.1) print(\"doing something\") loop = asyncio.get_event_loop() coroutine = do_something() task = loop.create_task(coroutine) #1 print(\"task是不是Task的示例？\",isinstance(task,asyncio.Task)) #2 print(\"task state\",task._state) #3 loop.run_until_complete(task) #4 print(\"take state\",task._state) end = time.time() print(\"消耗时间:{:.4f}\".format(end-start)) two() task是不是Task的示例？ True task state PENDING start ------ doing something take state FINISHED 消耗时间:0.1013 1、事件循环的 create_task 方法可以创建任务，另外 asyncio.ensure_future 方法也可以创建任务，参数须为协程对象 2、task 是 asyncio.Task 类的实例，为什么要使用协程对象创建任务？因为在这个过程中 asyncio.Task 做了一些工作，包括预激协程、协程运行中遇到某些异常时的处理 **3、task 对象的 _state 属性保存当前任务的运行状态，任务的运行状态有 PENDING 和 FINISHED 两种** 4、将任务注入事件循环，阻塞运行 ","date":"2021-06-13","objectID":"/asyncio/:6:0","tags":["python","asyncio"],"title":"asyncio","uri":"/asyncio/"},{"categories":["python"],"content":"async / await import functools def three(): start = time.time() #@asyncio.coroutine async def do_something(): #1 print(\"start doing\") time.sleep(0.1) print(\"done\") def callback(name,task): #2 print(\"call back:{}\".format(name)) print(\"call back:{}\".format(task._state)) loop = asyncio.get_event_loop() coroutine = do_something() task = loop.create_task(coroutine) task.add_done_callback(functools.partial(callback, 'vllbc')) #3 loop.run_until_complete(task) end = time.time() print(\"total time {:.4f}\".format(end-start)) three() start doing done call back:vllbc call back:FINISHED total time 0.1013 代码说明： 1、使用 async 关键字替代 asyncio.coroutine 装饰器创建协程函数 2、回调函数，协程终止后需要顺便运行的代码写入这里，回调函数的参数有要求，最后一个位置参数须为 task 对象 3、task 对象的 add_done_callback 方法可以添加回调函数，注意参数必须是回调函数，这个方法不能传入回调函数的参数，这一点需要通过 functools 模块的 partial 方法解决，将回调函数和其参数 name 作为 partial 方法的参数，此方法的返回值就是偏函数，偏函数可作为 task.add_done_callback 方法的参数 def four(): start = time.time() async def do_something(name,t): print(\"start !\u003e\u003e\",name) await asyncio.sleep(t) #1 print('Stop coroutine', name) return 'Coroutine {} OK'.format(name) #2 loop = asyncio.get_event_loop() coroutine1 = do_something('wlb',3) #3 coroutine2 = do_something('yyh',1) task1 = loop.create_task(coroutine1) #4 task2 = loop.create_task(coroutine2) gather = asyncio.gather(task1,task2) #5 loop.run_until_complete(gather) print(\"task1\",task1.result()) print(\"task2\",task2.result()) #result = loop.run_until_complete(gather) #这里result就是两个返回值组成的列表 即['task1 Coroutine wlb OK','task2 Coroutine yyh OK'] end = time.time() print(\"total time:{:.4f}\".format(end-start)) four() start !\u003e\u003e wlb start !\u003e\u003e yyh Stop coroutine yyh Stop coroutine wlb task1 Coroutine wlb OK task2 Coroutine yyh OK total time:3.0022 代码说明： 1、await 关键字等同于 Python 3.4 中的 yield from 语句，后面接协程对象。asyncio.sleep 方法的返回值为协程对象，这一步为阻塞运行。asyncio.sleep 与 time.sleep 是不同的，前者阻塞当前协程，即 corowork 函数的运行，而 time.sleep 会阻塞整个线程，所以这里必须用前者，阻塞当前协程，CPU 可以在线程内的其它协程中执行 2、协程函数的 return 值可以在协程运行结束后保存到对应的 task 对象的 result 方法中 3、创建两个协程对象，在协程内部分别阻塞 3 秒和 1 秒 4、创建两个任务对象 5、将任务对象作为参数，asyncio.gather 方法创建任务收集器。注意，asyncio.gather 方法中参数的顺序决定了协程的启动顺序 6、将任务收集器作为参数传入事件循环的 run_until_complete 方法，阻塞运行，直到全部任务完成 7、任务结束后，事件循环停止，打印任务的 result 方法返回值，即协程函数的 return 值 到这一步，大家应该可以看得出，上面的代码已经是异步编程的结构了，在事件循环内部，两个协程是交替运行完成的。简单叙述一下程序协程部分的运行过程： -\u003e 首先运行 task1 -\u003e 打印 [corowork] Start coroutine ONE -\u003e 遇到 asyncio.sleep 阻塞 -\u003e 释放 CPU 转到 task2 中执行 -\u003e 打印 [corowork] Start coroutine TWO -\u003e 再次遇到 asyncio.sleep 阻塞 -\u003e 这次没有其它协程可以运行了，只能等阻塞结束 -\u003e task2 的阻塞时间较短，阻塞 1 秒后先结束，打印 [corowork] Stop coroutine TWO -\u003e 又过了 2 秒，阻塞 3 秒的 task1 也结束了阻塞，打印 [corowork] Stop coroutine ONE -\u003e 至此两个任务全部完成，事件循环停止 -\u003e 打印两个任务的 result -\u003e 打印程序运行时间 -\u003e 程序全部结束 ","date":"2021-06-13","objectID":"/asyncio/:7:0","tags":["python","asyncio"],"title":"asyncio","uri":"/asyncio/"},{"categories":["python"],"content":"await的理解 从上文中也可以看到await其实是从yield from中转变过来的，当在代码中看到await时，可以知道当前协程要去运行await后面的任务，此时控制权回到了event loop手中，去执行其它的任务，当前面的任务完成了以后，则转去执行前面await后面的代码。注意当await直接跟一个coroutline时，此时相当于去yield from，会卡在那里，并不会实现真正的异步，所以要先将coroutline变为task或者future就可以直接await。 ## 异步编程 ","date":"2021-06-13","objectID":"/asyncio/:7:1","tags":["python","asyncio"],"title":"asyncio","uri":"/asyncio/"},{"categories":["python"],"content":"一个买土豆的例子 import asyncio import random # potato类 class Potato: # 生成土豆 @classmethod def make(cls, num, *args, **kws): potatos = [] for i in range(num): potatos.append(cls.__new__(cls, *args, **kws)) return potatos all_potatos = Potato.make(5) ## 这是一个异步生成器，可以用async for迭代，nums为想买的数量。 async def take_photos(nums): count = 0 while True: # 如果没有土豆了，挂起当前任务请求生成土豆任务。 if len(all_potatos) == 0: await askfor_photos() else: photo = all_potatos.pop() # 如果有土豆将土豆抛出去 yield photo count += 1 if count == nums : break async def askfor_photos(): await asyncio.sleep(2) all_potatos.append(Potato.make(5)) async def buy_photos(): bucket = [] async for p in take_photos(50): bucket.append(p) print(f\"Go photo {id(p)}\") loop = asyncio.get_event_loop() loop.run_until_complete(buy_photos()) ","date":"2021-06-13","objectID":"/asyncio/:7:2","tags":["python","asyncio"],"title":"asyncio","uri":"/asyncio/"},{"categories":["python"],"content":"requests例子 import asyncio import requests import time # 相当于委托生成器 async def result(url): res = await request_url(url) print(url, res) # 相当于子生成器 async def request_url(url): res = requests.get(url) print(url) await asyncio.sleep(2) print(\"execute_time:\", time.time() - start) return res url_list = [\"https://www.csdn.net/\", \"https://vllbc.top/\", \"https://www.baidu.com/\", ] # 以下相当于调用方 start = time.time() print(f\"start_time:{start}\\n\") task = [result(url) for url in url_list] loop = asyncio.get_event_loop() loop.run_until_complete(asyncio.wait(task)) endtime = time.time() - start print(\"\\nendtime:\", time.time()) print(\"all_execute_time:\", endtime) ","date":"2021-06-13","objectID":"/asyncio/:7:3","tags":["python","asyncio"],"title":"asyncio","uri":"/asyncio/"},{"categories":["算法题"],"content":"移除元素 还是以前刷过的题 https://leetcode-cn.com/problems/remove-element/ 以前的思路早忘了 然后我重新做了一下，一开始就一行代码 class Solution: def removeElement(self, nums: List[int], val: int) -\u003e int: return len(list(filter(lambda x:x!=val,nums))) ​ 然后发现输出和正确输出不一样。于是看了了下面的提示，然后改了改 class Solution: def removeElement(self, nums: List[int], val: int) -\u003e int: for i in range(nums.count(val)): nums.remove(val) return len(nums) 但这算不上叫算法，利用双指针做法如下： class Solution: def removeElement(self, nums: List[int], val: int) -\u003e int: left = 0 for i in range(len(nums)): if nums[i] != val: nums[left], nums[i] = nums[i], nums[left] left += 1 return left ","date":"2021-06-12","objectID":"/%E7%A7%BB%E9%99%A4%E5%85%83%E7%B4%A0/:0:0","tags":["算法题","移除元素"],"title":"移除元素","uri":"/%E7%A7%BB%E9%99%A4%E5%85%83%E7%B4%A0/"},{"categories":["NLP"],"content":"参考：https://blog.csdn.net/asialee_bird/article/details/96894533 TextRank算法是一种基于图的用于关键词抽取和文档摘要的排序算法，由谷歌的网页重要性排序算法PageRank算法改进而来，它利用一篇文档内部的词语间的共现信息(语义)便可以抽取关键词，它能够从一个给定的文本中抽取出该文本的关键词、关键词组，并使用抽取式的自动文摘方法抽取出该文本的关键句。 ","date":"2021-05-20","objectID":"/textrank/:0:0","tags":["NLP","TextRank"],"title":"TextRank","uri":"/textrank/"},{"categories":["NLP"],"content":"PageRank算法 PageRank算法通过计算网页链接的数量和质量来粗略估计网页的重要性，算法创立之初即应用在谷歌的搜索引擎中，对网页进行排名。 PageRank算法的核心思想如下： （1）链接数量：如果一个网页被越多的其他网页链接，说明这个网页越重要，即该网页的PR值（PageRank值）会相对较高； （2）链接质量：如果一个网页被一个越高权值的网页链接，也能表明这个网页越重要，即一个PR值很高的网页链接到一个其他网页，那么被链接到的网页的PR值会相应地因此而提高。 ","date":"2021-05-20","objectID":"/textrank/:1:0","tags":["NLP","TextRank"],"title":"TextRank","uri":"/textrank/"},{"categories":["NLP"],"content":"TextRank算法 TextRank算法的基本思想是将文档看作一个词的网络，该网络中的链接表示词与词之间的语义关系。 TextRank算法主要包括：关键词抽取、关键短语抽取、关键句抽取。 ","date":"2021-05-20","objectID":"/textrank/:2:0","tags":["NLP","TextRank"],"title":"TextRank","uri":"/textrank/"},{"categories":["NLP"],"content":"（1）关键词抽取（keyword extraction） 关键词抽取是指从文本中确定一些能够描述文档含义的术语的过程。对关键词抽取而言，用于构建顶点集的文本单元可以是句子中的一个或多个字；根据这些字之间的关系（比如：在一个框中同时出现）构建边。根据任务的需要，可以使用语法过滤器（syntactic filters）对顶点集进行优化。语法过滤器的主要作用是将某一类或者某几类词性的字过滤出来作为顶点集。 ","date":"2021-05-20","objectID":"/textrank/:2:1","tags":["NLP","TextRank"],"title":"TextRank","uri":"/textrank/"},{"categories":["NLP"],"content":"（2）关键短语抽取（keyphrase extration） 关键词抽取结束后，我们可以得到的N个关键词，在原始文本中相邻的关键词构成关键短语。因此，从get_keyphrases函数的源码中我们可以看到，它先调用get_keywords抽取关键词，然后分析关键词是否存在相邻的情况，最后确定哪些是关键短语。 ","date":"2021-05-20","objectID":"/textrank/:2:2","tags":["NLP","TextRank"],"title":"TextRank","uri":"/textrank/"},{"categories":["NLP"],"content":"（3）关键句抽取（sentence extraction） 句子抽取任务主要针对的是自动摘要这个场景，将每一个sentence作为一个顶点，根据两个句子之间的内容重复程度来计算他们之间的“相似度”，以这个相似度作为联系，由于不同句子之间相似度大小不一致，在这个场景下构建的是以相似度大小作为edge权重的有权图。 ","date":"2021-05-20","objectID":"/textrank/:2:3","tags":["NLP","TextRank"],"title":"TextRank","uri":"/textrank/"},{"categories":["python"],"content":"matplotlib.pyplot学习 ","date":"2021-05-02","objectID":"/pyplot/:0:0","tags":["python","pyplot"],"title":"pyplot","uri":"/pyplot/"},{"categories":["python"],"content":"绘图标记 import matplotlib.pyplot as plt import numpy as np ypoints = np.array([1,3,4,5,8,9,6,1,3,4,5,2,4]) plt.plot(ypoints, marker = 'o') # \"o\"代表实心圆 plt.show() maker可用的符号如下： ","date":"2021-05-02","objectID":"/pyplot/:1:0","tags":["python","pyplot"],"title":"pyplot","uri":"/pyplot/"},{"categories":["python"],"content":"fmt参数 fmt = '[marker][line][color]' 例如 o:r，o 表示实心圆标记，: 表示虚线，r 表示颜色为红色。 ","date":"2021-05-02","objectID":"/pyplot/:2:0","tags":["python","pyplot"],"title":"pyplot","uri":"/pyplot/"},{"categories":["python"],"content":"线类型 线的类型可以使用 linestyle 参数来定义，简写为 ls。 ","date":"2021-05-02","objectID":"/pyplot/:3:0","tags":["python","pyplot"],"title":"pyplot","uri":"/pyplot/"},{"categories":["python"],"content":"线的宽度 线的宽度可以使用 linewidth 参数来定义，简写为 lw，值可以是浮点数，如：1、2.0、5.67 等。 ","date":"2021-05-02","objectID":"/pyplot/:3:1","tags":["python","pyplot"],"title":"pyplot","uri":"/pyplot/"},{"categories":["python"],"content":"颜色类型 ","date":"2021-05-02","objectID":"/pyplot/:4:0","tags":["python","pyplot"],"title":"pyplot","uri":"/pyplot/"},{"categories":["python"],"content":"线的颜色 线的颜色可以使用 color 参数来定义，简写为 c。 ","date":"2021-05-02","objectID":"/pyplot/:4:1","tags":["python","pyplot"],"title":"pyplot","uri":"/pyplot/"},{"categories":["python"],"content":"标记大小与颜色 我们可以自定义标记的大小与颜色，使用的参数分别是： markersize，简写为 ms：定义标记的大小。 markerfacecolor，简写为 mfc：定义标记内部的颜色。 markeredgecolor，简写为 mec：定义标记边框的颜色。 import matplotlib.pyplot as plt import numpy as np ypoints = np.array([6, 2, 13, 10]) plt.plot(ypoints, marker = 'o', ms = 20) plt.show() ","date":"2021-05-02","objectID":"/pyplot/:4:2","tags":["python","pyplot"],"title":"pyplot","uri":"/pyplot/"},{"categories":["python"],"content":"Matplotlib 轴标签和标题 我们可以使用 xlabel() 和 ylabel() 方法来设置 x 轴和 y 轴的标签。 import numpy as np import matplotlib.pyplot as plt x = np.array([1, 2, 3, 4]) y = np.array([1, 4, 9, 16]) plt.plot(x, y) plt.xlabel(\"x - label\") plt.ylabel(\"y - label\") plt.show() ","date":"2021-05-02","objectID":"/pyplot/:5:0","tags":["python","pyplot"],"title":"pyplot","uri":"/pyplot/"},{"categories":["python"],"content":"标题 我们可以使用 title() 方法来设置标题 也可以自定义字体样式，通过传入fontdict参数 import matplotlib.pyplot as plt import numpy as np font = {\"color\":\"blue\",\"size\":20} ypoints = np.array([1,3,4,5,8,9,6,1,3,4,5,2,4]) plt.plot(ypoints,marker=\"o\",color=\"r\",linestyle=\"-.\") plt.title(\"test\",fontdict=font) plt.xlabel(\"x\",fontdict=font) plt.ylabel(\"y\",fontdict=font) plt.show() ","date":"2021-05-02","objectID":"/pyplot/:5:1","tags":["python","pyplot"],"title":"pyplot","uri":"/pyplot/"},{"categories":["python"],"content":"Matplotlib 网格线 我们可以使用 pyplot 中的 grid() 方法来设置图表中的网格线。 grid() 方法语法格式如下： matplotlib.pyplot.grid(b=None, which='major', axis='both', ) 参数说明： b：可选，默认为 None，可以设置布尔值，true 为显示网格线，false 为不显示，如果设置 **kwargs 参数，则值为 true。 which：可选，可选值有 ‘major’、‘minor’ 和 ‘both’，默认为 ‘major’，表示应用更改的网格线。 axis：可选，设置显示哪个方向的网格线，可以是取 ‘both’（默认），‘x’ 或 ‘y’，分别表示两个方向，x 轴方向或 y 轴方向。 **kwargs：可选，设置网格样式，可以是 color=‘r’, linestyle=‘-’ 和 linewidth=2，分别表示网格线的颜色，样式和宽度。 以下实例添加一个简单的网格线，并设置网格线的样式，格式如下： grid(color = 'color', linestyle = 'linestyle', linewidth = number) 参数说明： color：’b’ 蓝色，‘m’ 洋红色，‘g’ 绿色，‘y’ 黄色，‘r’ 红色，‘k’ 黑色，‘w’ 白色，‘c’ 青绿色，‘#008000’ RGB 颜色符串。 linestyle：’‐’ 实线，‘‐‐’ 破折线，‘‐.’ 点划线，‘:’ 虚线。 linewidth：设置线的宽度，可以设置一个数字。 ","date":"2021-05-02","objectID":"/pyplot/:6:0","tags":["python","pyplot"],"title":"pyplot","uri":"/pyplot/"},{"categories":["python"],"content":"Matplotlib 绘制多图 我们可以使用 pyplot 中的 subplot() 和 subplots() 方法来绘制多个子图。 subpot() 方法在绘图时需要指定位置，subplots() 方法可以一次生成多个，在调用时只需要调用生成对象的 ax 即可。 ","date":"2021-05-02","objectID":"/pyplot/:7:0","tags":["python","pyplot"],"title":"pyplot","uri":"/pyplot/"},{"categories":["python"],"content":"subplot subplot(nrows, ncols, index, **kwargs) subplot(pos, **kwargs) subplot(**kwargs) subplot(ax) 以上函数将整个绘图区域分成 nrows 行和 ncols 列，然后从左到右，从上到下的顺序对每个子区域进行编号 1…N ，左上的子区域的编号为 1、右下的区域编号为 N，编号可以通过参数 index 来设置。 设置 numRows ＝ 1，numCols ＝ 2，就是将图表绘制成 1x2 的图片区域, 对应的坐标为： (1, 1), (1, 2) 设置 numRows ＝ 2，numCols ＝ 2，就是将图表绘制成 2x2 的图片区域, 对应的坐标为： (1, 1), (1, 2) (2, 1), (2, 2) ","date":"2021-05-02","objectID":"/pyplot/:7:1","tags":["python","pyplot"],"title":"pyplot","uri":"/pyplot/"},{"categories":["python"],"content":"subplots() subplots() 方法语法格式如下： matplotlib.pyplot.subplots(nrows=1, ncols=1, *, sharex=False, sharey=False, squeeze=True, subplot_kw=None, gridspec_kw=None, **fig_kw) 参数说明： nrows：默认为 1，设置图表的行数。 ncols：默认为 1，设置图表的列数。 sharex、sharey：设置 x、y 轴是否共享属性，默认为 false，可设置为 ‘none’、‘all’、‘row’ 或 ‘col’。 False 或 none 每个子图的 x 轴或 y 轴都是独立的，True 或 ‘all’：所有子图共享 x 轴或 y 轴，‘row’ 设置每个子图行共享一个 x 轴或 y 轴，‘col’：设置每个子图列共享一个 x 轴或 y 轴。 squeeze：布尔值，默认为 True，表示额外的维度从返回的 Axes(轴)对象中挤出，对于 N1 或 1N 个子图，返回一个 1 维数组，对于 N*M，N\u003e1 和 M\u003e1 返回一个 2 维数组。如果设置为 False，则不进行挤压操作，返回一个元素为 Axes 实例的2维数组，即使它最终是1x1。 subplot_kw：可选，字典类型。把字典的关键字传递给 add_subplot() 来创建每个子图。 gridspec_kw：可选，字典类型。把字典的关键字传递给 GridSpec 构造函数创建子图放在网格里(grid)。 **fig_kw：把详细的关键字参数传给 figure() 函数。 常用技巧 x = np.linspace(0, 2*np.pi, 400) y = np.sin(x**2) fig, axs = plt.subplots(2, 2) for i in axs.flatten(): # axs.flatten()将二维数组变为一维，方便循环。 i.plot(x, y) ","date":"2021-05-02","objectID":"/pyplot/:7:2","tags":["python","pyplot"],"title":"pyplot","uri":"/pyplot/"},{"categories":["python"],"content":"Matplotlib 散点图 我们可以使用 pyplot 中的 scatter() 方法来绘制散点图。 scatter() 方法语法格式如下： matplotlib.pyplot.scatter(x, y, s=None, c=None, marker=None, cmap=None, norm=None, vmin=None, vmax=None, alpha=None, linewidths=None, *, edgecolors=None, plotnonfinite=False, data=None, **kwargs) 参数说明： x，y：长度相同的数组，也就是我们即将绘制散点图的数据点，输入数据。 s：点的大小，默认 20，也可以是个数组，数组每个参数为对应点的大小。 c：点的颜色，默认蓝色 ‘b’，也可以是个 RGB 或 RGBA 二维行数组。 marker：点的样式，默认小圆圈 ‘o’。 cmap：Colormap，默认 None，标量或者是一个 colormap 的名字，只有 c 是一个浮点数数组的时才使用。如果没有申明就是 image.cmap。 norm：Normalize，默认 None，数据亮度在 0-1 之间，只有 c 是一个浮点数的数组的时才使用。 vmin，vmax：：亮度设置，在 norm 参数存在时会忽略。 alpha：：透明度设置，0-1 之间，默认 None，即不透明。 linewidths：：标记点的长度。 edgecolors：：颜色或颜色序列，默认为 ‘face’，可选值有 ‘face’, ‘none’, None。 plotnonfinite：：布尔值，设置是否使用非限定的 c ( inf, -inf 或 nan) 绘制点。 **kwargs：：其他参数。 设置颜色条需要使用 cmap 参数，默认值为 ‘viridis’，之后颜色值设置为 0 到 100 的数组。 如果要显示颜色条，需要使用 plt.colorbar() 方法： ","date":"2021-05-02","objectID":"/pyplot/:8:0","tags":["python","pyplot"],"title":"pyplot","uri":"/pyplot/"},{"categories":["python"],"content":"Matplotlib 柱形图 我们可以使用 pyplot 中的 bar() 方法来绘制柱形图。 bar() 方法语法格式如下： matplotlib.pyplot.bar(x, height, width=0.8, bottom=None, *, align='center', data=None, **kwargs) 参数说明： x：浮点型数组，柱形图的 x 轴数据。 height：浮点型数组，柱形图的高度。 width：浮点型数组，柱形图的宽度。 bottom：浮点型数组，底座的 y 坐标，默认 0。 align：柱形图与 x 坐标的对齐方式，‘center’ 以 x 位置为中心，这是默认值。 ‘edge’：将柱形图的左边缘与 x 位置对齐。要对齐右边缘的条形，可以传递负数的宽度值及 align=‘edge’。 **kwargs：：其他参数。 垂直方向的柱形图可以使用 barh() 方法来设置： ","date":"2021-05-02","objectID":"/pyplot/:9:0","tags":["python","pyplot"],"title":"pyplot","uri":"/pyplot/"},{"categories":["python"],"content":"Matplotlib 饼图 我们可以使用 pyplot 中的 pie() 方法来绘制饼图。 pie() 方法语法格式如下： matplotlib.pyplot.pie(x, explode=None, labels=None, colors=None, autopct=None, pctdistance=0.6, shadow=False, labeldistance=1.1, startangle=0, radius=1, counterclock=True, wedgeprops=None, textprops=None, center=0, 0, frame=False, rotatelabels=False, *, normalize=None, data=None)[source] 参数说明： x：浮点型数组，表示每个扇形的面积。 explode：数组，表示各个扇形之间的间隔，默认值为0。 labels：列表，各个扇形的标签，默认值为 None。 colors：数组，表示各个扇形的颜色，默认值为 None。 autopct：设置饼图内各个扇形百分比显示格式，%d%% 整数百分比，%0.1f 一位小数， %0.1f%% 一位小数百分比， %0.2f%% 两位小数百分比。 labeldistance：标签标记的绘制位置，相对于半径的比例，默认值为 1.1，如 \u003c1则绘制在饼图内侧。 pctdistance：：类似于 labeldistance，指定 autopct 的位置刻度，默认值为 0.6。 shadow：：布尔值 True 或 False，设置饼图的阴影，默认为 False，不设置阴影。 radius：：设置饼图的半径，默认为 1。 startangle：：起始绘制饼图的角度，默认为从 x 轴正方向逆时针画起，如设定 =90 则从 y 轴正方向画起。 counterclock：布尔值，设置指针方向，默认为 True，即逆时针，False 为顺时针。 wedgeprops ：字典类型，默认值 None。参数字典传递给 wedge 对象用来画一个饼图。例如：wedgeprops={‘linewidth’:5} 设置 wedge 线宽为5。 textprops ：字典类型，默认值为：None。传递给 text 对象的字典参数，用于设置标签（labels）和比例文字的格式。 center ：浮点类型的列表，默认值：(0,0)。用于设置图标中心位置。 frame ：布尔类型，默认值：False。如果是 True，绘制带有表的轴框架。 rotatelabels ：布尔类型，默认为 False。如果为 True，旋转每个 label 到指定的角度。 ","date":"2021-05-02","objectID":"/pyplot/:10:0","tags":["python","pyplot"],"title":"pyplot","uri":"/pyplot/"},{"categories":["Machine Learning"],"content":"范数的定义 \\[ {\\lVert x \\rVert}_p := \\left(\\sum_{i=1}^n{\\lvert x_i\\rvert}^p\\right)^{\\frac{1}{p}} \\] ","date":"2021-05-01","objectID":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/:1:0","tags":["Machine Learning","机器学习的一些概念"],"title":"机器学习的一些概念","uri":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/"},{"categories":["Machine Learning"],"content":"标准化与归一化 ","date":"2021-05-01","objectID":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/:2:0","tags":["Machine Learning","机器学习的一些概念"],"title":"机器学习的一些概念","uri":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/"},{"categories":["Machine Learning"],"content":"定义 归一化和标准化都是对数据做变换的方式，将原始的一列数据转换到某个范围，或者某种形态。 \u003e归一化：将一列数据变化到某个固定区间(范围)中，通常，这个区间是[0, 1]，广义的讲，可以是各种区间，比如映射到[0，1]一样可以继续映射到其他范围，图像中可能会映射到[0,255]，其他情况可能映射到[-1,1]； 标准化：将数据变换为均值为0，标准差为1的分布。切记，并非一定是正态的； 中心化：还有一种处理叫做中心化，也叫零均值处理，就是将每个原始数据减去这些数据的均值。 ","date":"2021-05-01","objectID":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/:2:1","tags":["Machine Learning","机器学习的一些概念"],"title":"机器学习的一些概念","uri":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/"},{"categories":["Machine Learning"],"content":"差异 归一化会严格限定变换后的数据的范围，标准化没有严格的区间，变换后的数据没有范围，只是其均值为0，标注差为1. 归一化对数据的缩放比例只与极值有关，而标准化缩放比例与所有的数据都有关。 ","date":"2021-05-01","objectID":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/:2:2","tags":["Machine Learning","机器学习的一些概念"],"title":"机器学习的一些概念","uri":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/"},{"categories":["Machine Learning"],"content":"标准化、归一化的好处 统计建模中，如回归模型，自变量\\(X\\)的量纲不一致导致了回归系数无法直接解读或者错误解读；需要将\\(X\\)都处理到统一量纲下，这样才可比； 机器学习任务和统计学任务中有很多地方要用到“距离”的计算，比如PCA，比如KNN，比如kmeans等等，假使算欧式距离，不同维度量纲不同可能会导致距离的计算依赖于量纲较大的那些特征而得到不合理的结果； 参数估计时使用梯度下降，在使用梯度下降的方法求解最优化问题时， 归一化/标准化后可以加快梯度下降的求解速度，即提升模型的收敛速度。 ","date":"2021-05-01","objectID":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/:2:3","tags":["Machine Learning","机器学习的一些概念"],"title":"机器学习的一些概念","uri":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/"},{"categories":["Machine Learning"],"content":"决策边界 所谓决策边界就是能够把样本正确分类的一条边界，主要有线性决策边界(linear decision boundaries)和非线性决策边界(non-linear decision boundaries)。注意：决策边界是假设函数的属性，由参数决定，而不是由数据集的特征决定。下面主要举一些例子，形象化的来说明线性决策边界和非线性决策边界。 ","date":"2021-05-01","objectID":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/:3:0","tags":["Machine Learning","机器学习的一些概念"],"title":"机器学习的一些概念","uri":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/"},{"categories":["Machine Learning"],"content":"方差与偏差 当我们的模型表现不佳时，通常是出现两种问题，一种是 高偏差 问题，另一种是 高方差 问题。识别它们有助于选择正确的优化方式，所以我们先来看下 偏差 与 方差 的意义。 偏差: 描述模型输出结果的期望与样本真实结果的差距。 方差: 描述模型对于给定值的输出稳定性。 就像打靶一样，偏差描述了我们的射击总体是否偏离了我们的目标，而方差描述了射击准不准。接下来让我们通过各种情况下 训练集 和 交叉验证集 的 误差 曲线来直观地理解 高偏差 与 高方差 的意义。 对于 多项式回归，当次数选取较低时，我们的 训练集误差 和 交叉验证集误差 都会很大；当次数选择刚好时，训练集误差 和 交叉验证集误差 都很小；当次数过大时会产生过拟合，虽然 训练集误差 很小，但 交叉验证集误差 会很大（ 关系图如下 ） 对于 正则化 参数，使用同样的分析方法，当参数比较小时容易产生过拟合现象，也就是高方差问题。而参数比较大时容易产生欠拟合现象，也就是高偏差问题。 偏差和方差与数据噪声之和就是模型的泛化能力 模型的期望预测（这里x指所有的样本，期望预测为该模型的所有预测结果的期望。也可以表示有多个模型同时对x一个样本进行预测，期望预测为所有模型预测的期望）： 样本数相同的不同训练集产生的方差（可以理解为测试集预测结果与训练集输出期望之间的方差，也可以直接理解为一个模型中所有的预测与预测期望之间的平方差）： 噪声（这里的噪声为人工标注的错误。）： 期望输出与真实标记的差别称为偏差(也有两种理解，一种是多模型的预测期望与真实值之间的偏差，还有一种就直接是单模型的预测输出（因为单模型的预测期望就是它的输出了）与真实值之间的平方差就可以记为偏差的平方，其实这里应理解为多模型的情况 泛化误差也就是期望风险。 ","date":"2021-05-01","objectID":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/:4:0","tags":["Machine Learning","机器学习的一些概念"],"title":"机器学习的一些概念","uri":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/"},{"categories":["Machine Learning"],"content":"参考 参考1 参考2 ","date":"2021-05-01","objectID":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/:4:1","tags":["Machine Learning","机器学习的一些概念"],"title":"机器学习的一些概念","uri":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/"},{"categories":["Machine Learning"],"content":"改进策略 [高方差] 采集更多的样本数据，(参考正规方程) [高方差] 减少特征数量，去除非主要的特征 [高偏差] 引入更多的相关特征 [高偏差] 采用多项式特征 [高偏差] 减小正则化参数 λ [高方差] 增加正则化参数 λ ","date":"2021-05-01","objectID":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/:4:2","tags":["Machine Learning","机器学习的一些概念"],"title":"机器学习的一些概念","uri":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/"},{"categories":["Machine Learning"],"content":"学习曲线 无论你是要检查你的学习算法是否正常工作或是要改进算法的表现，学习曲线 都是一个十分直观有效的工具。学习曲线 的横轴是样本数，纵轴为 训练集 和 交叉验证集 的 误差 ","date":"2021-05-01","objectID":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/:5:0","tags":["Machine Learning","机器学习的一些概念"],"title":"机器学习的一些概念","uri":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/"},{"categories":["Deep Learning","损失函数"],"content":"Softmax理解 主要记录了在使用softmax这个函数中遇到的一些问题，比较基础，但确实困扰了一段时间。 在学习word2vec中, 使用的一般都是如下的损失函数： \\[ \\begin{aligned} Loss = J(\\theta) = -\\frac{1}{T}logL(\\theta)= -\\frac{1}{T}\\sum_{t=1}^T\\sum_{-m\\leq j\\leq m, j\\neq0} logP(w_{t+j}|w_t, \\theta) \\\\\\\\ =\\frac{1}{T}\\sum_{t=1}^T\\sum_{-m\\leq j\\leq m, j\\neq0}J_{t,j}(\\theta). \\end{aligned} \\] \\[ \\begin{aligned} J_{t,j}(\\theta) = -logP(miss|xwh) = -log\\frac{exp(u_{miss}^Tv_{xwh})}{\\sum_{o\\in V}exp(u_o^Tv_{xwh})} = \\\\\\\\ -u_{miss}^Tv_{xwh}+log\\sum_{o\\in V} exp(u_o^Tv_{xwh}) \\end{aligned} \\] 但是说起交叉熵往往是下面的式子： \\[ L = -\\sum_{c=1}^Cy_clog(p_c) \\] 在学习的时候就疑惑，这两种形式有什么区别与联系呢，最近看到一篇文章正好解答了这个疑惑。 下面给出结论： 第一种形式是只针对正确类别的对应点输出，将这个位置的softmax即概率最大化，而第二种形式是直接衡量真实分布和实际输出之间的距离，因为交叉熵就是由KL散度变形得来的。 ","date":"2021-04-30","objectID":"/%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/:0:0","tags":["Deep Learning","损失函数","交叉熵损失函数"],"title":"交叉熵损失函数","uri":"/%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"},{"categories":["Deep Learning","损失函数"],"content":"交叉熵 ","date":"2021-04-30","objectID":"/%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/:1:0","tags":["Deep Learning","损失函数","交叉熵损失函数"],"title":"交叉熵损失函数","uri":"/%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"},{"categories":["Deep Learning","损失函数"],"content":"信息量 一条信息的信息量大小和它的不确定性有很大的关系。一句话如果需要很多外部信息才能确定，我们就称这句话的信息量比较大。 将信息的定义为下： \\(I(x_0) = -log(p(x_0))\\) ","date":"2021-04-30","objectID":"/%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/:1:1","tags":["Deep Learning","损失函数","交叉熵损失函数"],"title":"交叉熵损失函数","uri":"/%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"},{"categories":["Deep Learning","损失函数"],"content":"熵 信息量是对于单个事件来说的，但是实际情况一件事有很多种发生的可能，比如掷骰子有可能出现6种情况，明天的天气可能晴、多云或者下雨等等。熵是表示随机变量不确定的度量，是对所有可能发生的事件产生的信息量的期望。公式如下： \\[ H(X) = -\\sum_{i=1}^np(x_i)log(p(x_i)) \\] ### 相对熵 相对熵也称之为KL散度，用于衡量对于同意随机变量x的两个分布p(x)和q(x)之间的差异。在机器学习中，p(x)通常描述样本的真实分布，例如[1, 0, 0, 0]表示样本属于第一类，而q(x)常常用于表示预测的分布，例如[0.7, 0.1, 0.1, 0.1] KL散度的定义公式如下： \\[ D_{KL}(p||q) = \\sum_{i=1}^np(x_i)log(\\frac{p(x_i)}{q(x_i)}) \\] KL越小则说明二者越接近 ### 交叉熵 将KL散度变形 \\[ D_{KL}(p||q) = \\sum_{i=1}^np(x_i)log(p(x_i)) -\\sum_{i=1}^np(x_i)log(q(x_i)) = -H(p(x)) - \\sum_{i=1}^np(x_i)log(q(x_i)) \\] 后半部分就是我们的交叉熵，常常用于评估predict和label之间的差别。 ## 理解 以一个三分类的问题来说，假设真实分布为[0, 1, 0]，则对于第二个式子来说 \\[ L = -\\sum_{c=1}^Cy_clog(p_c) = -0 \\times log(p_0) - 1\\times log(p_1) - 0\\times log(p_3) = -log(p_1) \\] 对于第一个式子就是 \\[ loss_1 = -log(\\frac{e^{z_1}}{\\sum_{c=1}^C e^{z_c}}) = -log(p_1) = -z_1+log\\sum_{c=1}^Ce^{z_c} \\] 所以说实际上这俩是一样的，只是出发点不一样。在skip-gram中，使用的就是第一种式子，对它来说，正确的类别就是背景词，就直接将背景词的概率最大，即损失函数最小。 loss = (-output_layer[:, Y] + torch.log(torch.sum(torch.exp(output_layer), dim=1))).mean() 这行代码就是对第一个式子的实现，需要注意的是所有的操作都是基于batch的。负采样的形式有一些不同，这里不再讨论，到这里我才终于稍稍理解了softmax这个函数。 ","date":"2021-04-30","objectID":"/%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/:1:2","tags":["Deep Learning","损失函数","交叉熵损失函数"],"title":"交叉熵损失函数","uri":"/%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"},{"categories":["Deep Learning","损失函数"],"content":"与二分类的联系 具体的说二分类就是两个类别，可以使用上述的方法定义，对于正类和负类都用不同的概率表示，也可以只计算正类，负类就等于1-正类，上述出现的y都是向量的形式，对于二分类，向量的长度就是2，就可以直接展开，最后的结果就是熟知的损失函数的形式。 ","date":"2021-04-30","objectID":"/%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/:2:0","tags":["Deep Learning","损失函数","交叉熵损失函数"],"title":"交叉熵损失函数","uri":"/%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"},{"categories":["Deep Learning","损失函数"],"content":"参考 https://zhuanlan.zhihu.com/p/105722023 ","date":"2021-04-30","objectID":"/%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/:3:0","tags":["Deep Learning","损失函数","交叉熵损失函数"],"title":"交叉熵损失函数","uri":"/%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"},{"categories":["算法题"],"content":"验证二叉搜索树 https://leetcode-cn.com/problems/validate-binary-search-tree/ # Definition for a binary tree node. # class TreeNode: # def __init__(self, val=0, left=None, right=None): # self.val = val # self.left = left # self.right = right class Solution: def isValidBST(self, root: TreeNode) -\u003e bool: return self.search(root,-(232),232) def search(self,root,mins,maxs): if root == None: return True if root.val \u003e mins and root.val \u003c maxs: pass else: return False return all([self.search(root.left,mins,root.val),self.search(root.right,root.val,maxs)]) 最后用了个all 也是简洁了代码 ","date":"2021-04-22","objectID":"/%E9%AA%8C%E8%AF%81%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/:0:0","tags":["算法题","验证二叉搜索树"],"title":"验证二叉搜索树","uri":"/%E9%AA%8C%E8%AF%81%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/"},{"categories":["Deep Learning","循环神经网络系列"],"content":"回看博客，发现深度学习的笔记空荡荡，才发觉一直没有详细得进行笔记，但也感觉确实没有什么可以记录的东西，都是一些网络和模型，具体的trick倒是记录了一些，不过为了博客的美观，还是写一些东西吧，最主要的还是一些小知识。 (MLP就不记录了) RNN其实很类似于一个自回归模型，用历史观测预测下一个观测，我们可以假设不适用所有的历史预测下一个，而是部分的历史，也就是说序列满足马尔科夫条件，而RNN，即循环神经网络，就符合一阶马尔科夫模型，即当前观测仅仅与前一个的观测有关，模型图如下： ","date":"2021-04-21","objectID":"/rnn/:0:0","tags":["Deep Learning","循环神经网络系列","RNN"],"title":"RNN","uri":"/rnn/"},{"categories":["工具"],"content":"范围+文本对象 ","date":"2021-04-20","objectID":"/vim/:0:0","tags":["vim","工具"],"title":"vim","uri":"/vim/"},{"categories":["工具"],"content":"范围 内部：i ，意指 inner 外部：a ，英文单词 a，一个的意思 ","date":"2021-04-20","objectID":"/vim/:1:0","tags":["vim","工具"],"title":"vim","uri":"/vim/"},{"categories":["工具"],"content":"文本对象 ( 或 ) ：一对 () b ：一对 () { 或 } ：一对 {} B ：一对 {} [ 或 ] ：一对 [] \u003c 或 \u003e ：一对 \u003c\u003e t ：tag （HTML 或 XML）标签 ' 或 ' ：一对 '' \" 或 \" ：一对 \"\" ` 或 ` ：一对 `` w ：一个单词 s ：一个句子；以 . ! ? 结尾即为一个句子 p ：一个段落；以一个换行符间隔即为一个段落(一般用于对函数体操作) 比如i'代表'内部，iw代表光标所在单词，注意到，加上了范围i或者a，则原本的w含义也发生了变化，注意这是两个东西，原本的w为一个移动，而这里的w代表文本对象即单词。 move ","date":"2021-04-20","objectID":"/vim/:2:0","tags":["vim","工具"],"title":"vim","uri":"/vim/"},{"categories":["工具"],"content":"some easy hjkl，左下上右 wbeWBE，单词级别 0和$，行首和行尾 ^和g _，行首和行尾，但不算空白字符 H和L，页面相关，基本就是映射到^和g _ %括号匹配 ","date":"2021-04-20","objectID":"/vim/:3:0","tags":["vim","工具"],"title":"vim","uri":"/vim/"},{"categories":["工具"],"content":"search 光标移到要搜索的单词，*向下查找，#向上查找 /向下模糊搜索，?向上模糊搜索，配合n和N f + 字符：自左往右移动光标到下一个匹配的字符中 F + 字符：自右往左移动光标到下一个匹配的字符中 t + 字符：自左往右移动光标到下一个匹配的字符的前一个字符中 T + 字符：自右往左移动光标到下一个匹配的字符的后一个字符中 ;：重复执行上一个搜索命令 ,： 与上一个命令方向相反地执行上一个搜索命令 动词 ","date":"2021-04-20","objectID":"/vim/:4:0","tags":["vim","工具"],"title":"vim","uri":"/vim/"},{"categories":["工具"],"content":"some easy d: 删除 c: 删除并进入insert模式 y: 复制 ys, ds, cs，vim-surround插件，对应添加括号，删除括号，修改括号 .重复上一个命令 u撤销上条命令 p粘贴剪切板内容 r替换 ","date":"2021-04-20","objectID":"/vim/:5:0","tags":["vim","工具"],"title":"vim","uri":"/vim/"},{"categories":["工具"],"content":"g+？整理 g : 定位到上次编辑位置 g c 注释 g h 弹出变量或者函数的详细信息 gu和gU 小写或大写，g u u和g U U整行小写大写 g b 多选相同的word gg文件首，G文件尾 3G或3gg或:3，跳到第3行 数量词 1234567...表示命令执行的次数。 结合起来吧 ","date":"2021-04-20","objectID":"/vim/:6:0","tags":["vim","工具"],"title":"vim","uri":"/vim/"},{"categories":["工具"],"content":"动词 + move d h，删除前一个字符 d w，删除字符到下一个单词开头 d tV，删除字符到下一个v字符前面 d 2fb，删除字符到第二个b，且包括这个b，等同于2 dfb ","date":"2021-04-20","objectID":"/vim/:7:0","tags":["vim","工具"],"title":"vim","uri":"/vim/"},{"categories":["工具"],"content":"动词 + （范围） +文本对象 ys w'，给当前到下一个单词前添加'号 ds '，删除包裹的符号 cs [(，将[]修改为() yssb，整行添加括号，重复两次代表对行操作，b在前面介绍说了是文本对象，代表括号。 ysiw'，出现了两个文本对象，第一个与前面的i结合为iw代表单词，第二个文本对象代表即位要添加的引号，注意和第一条的区别，w所代表的不同。 gUw，大写直到下一个单词前，是动词+move，gUiw，大写光标所在单词，是动词+范围+文本对象。 ","date":"2021-04-20","objectID":"/vim/:8:0","tags":["vim","工具"],"title":"vim","uri":"/vim/"},{"categories":["Deep Learning","损失函数"],"content":"L1 Loss 也称为Mean Absolute Error，即平均绝对误差（MAE），它衡量的是预测值与真实值之间距离的平均误差幅度，作用范围为0到正无穷。 优点： 对离群点（Outliers）或者异常值更具有鲁棒性。 缺点： 由图可知其在0点处的导数不连续，使得求解效率低下，导致收敛速度慢；而对于较小的损失值，其梯度也同其他区间损失值的梯度一样大，所以不利于网络的学习。 ","date":"2021-04-19","objectID":"/smooth-l1-loss/:1:0","tags":["Deep Learning","损失函数","Smooth L1 Loss"],"title":"Smooth L1 Loss","uri":"/smooth-l1-loss/"},{"categories":["Deep Learning","损失函数"],"content":"L2 Loss 也称为Mean Squred Error，即均方差（MSE），它衡量的是预测值与真实1值之间距离的平方和，作用范围同为0到正无穷。 优点： 收敛速度快，能够对梯度给予合适的惩罚权重，而不是“一视同仁”，使梯度更新的方向可以更加精确。 缺点： 对异常值十分敏感，梯度更新的方向很容易受离群点所主导，不具备鲁棒性。 提一嘴，真的不理解鲁棒性这个翻译的含义，后来才知道是音译，真的是，毒害了多少人。。理解成稳定性就行。 ","date":"2021-04-19","objectID":"/smooth-l1-loss/:2:0","tags":["Deep Learning","损失函数","Smooth L1 Loss"],"title":"Smooth L1 Loss","uri":"/smooth-l1-loss/"},{"categories":["Deep Learning","损失函数"],"content":"Smooth L1 Loss 以上两种方法都有各自的优缺点，大部分的情况下其实二者都不使用，因此需要新的损失函数。即平滑的L1损失（SLL)。 SLL通过综合L1和L2损失的优点，在0点处附近采用了L2损失中的平方函数，解决了L1损失在0点处梯度不可导的问题，使其更加平滑易于收敛。此外，在|x|\u003e1的区间上，它又采用了L1损失中的线性函数，使得梯度能够快速下降。 通过对这三个损失函数进行求导可以发现，L1损失的导数为常数，如果不及时调整学习率，那么当值过小时，会导致模型很难收敛到一个较高的精度，而是趋向于一个固定值附近波动。反过来，对于L2损失来说，由于在训练初期值较大时，其导数值也会相应较大，导致训练不稳定。最后，可以发现Smooth L1在训练初期输入数值较大时能够较为稳定在某一个数值，而在后期趋向于收敛时也能够加速梯度的回传，很好的解决了前面两者所存在的问题。 ","date":"2021-04-19","objectID":"/smooth-l1-loss/:3:0","tags":["Deep Learning","损失函数","Smooth L1 Loss"],"title":"Smooth L1 Loss","uri":"/smooth-l1-loss/"},{"categories":["算法题"],"content":"无重叠区间 https://leetcode-cn.com/problems/non-overlapping-intervals/ 利用了贪心 移除的数目就是总数目减去条件成立的数目 class Solution: def eraseOverlapIntervals(self, intervals: List[List[int]]) -\u003e int: if len(intervals) == 0: return 0 res = 0 mins = -float(\"inf\") for i in sorted(intervals,key=lambda i:i[1]): if i[0] \u003e= mins: res += 1 mins = i[1] return len(intervals) - res 注意是根据end进行排序的，引用别人的解释@HONGYANG 比如你一天要参加几个活动，这个活动开始的多早其实不重要，重要的是你结束的多早，早晨7点就开始了然后一搞搞一天，那你今天也就只能参加这一个活动；但如果这个活动开始的不早，比如9点才开始，但是随便搞搞10点就结束了，那你接下来就还有大半天的时间可以参加其他活动。 这就是为啥要着眼于end，而不是start。 贪心就是考虑当前最优解 ","date":"2021-04-16","objectID":"/%E6%97%A0%E9%87%8D%E5%8F%A0%E5%8C%BA%E9%97%B4/:0:0","tags":["算法题","无重叠区间"],"title":"无重叠区间","uri":"/%E6%97%A0%E9%87%8D%E5%8F%A0%E5%8C%BA%E9%97%B4/"},{"categories":["算法题"],"content":"对角线遍历 ","date":"2021-04-13","objectID":"/%E5%AF%B9%E8%A7%92%E7%BA%BF%E9%81%8D%E5%8E%86/:0:0","tags":["算法题","对角线遍历"],"title":"对角线遍历","uri":"/%E5%AF%B9%E8%A7%92%E7%BA%BF%E9%81%8D%E5%8E%86/"},{"categories":["算法题"],"content":"题目： ​ https://leetcode-cn.com/problems/diagonal-traverse/ ","date":"2021-04-13","objectID":"/%E5%AF%B9%E8%A7%92%E7%BA%BF%E9%81%8D%E5%8E%86/:1:0","tags":["算法题","对角线遍历"],"title":"对角线遍历","uri":"/%E5%AF%B9%E8%A7%92%E7%BA%BF%E9%81%8D%E5%8E%86/"},{"categories":["算法题"],"content":"思路： ​ 每个对角线的两索引之和是一样的 ","date":"2021-04-13","objectID":"/%E5%AF%B9%E8%A7%92%E7%BA%BF%E9%81%8D%E5%8E%86/:2:0","tags":["算法题","对角线遍历"],"title":"对角线遍历","uri":"/%E5%AF%B9%E8%A7%92%E7%BA%BF%E9%81%8D%E5%8E%86/"},{"categories":["算法题"],"content":"代码： class Solution: def findDiagonalOrder(self, matrix: List[List[int]]) -\u003e List[int]: if not matrix: return [] hashs = collections.defaultdict(list) row, col = len(matrix), len(matrix[0]) for i in range(row): for j in range(col): hashs[j + i].append(matrix[i][j]) res = [] flag = True for k, v in sorted(hashs.items()): if flag: res.extend(v[::-1]) else: res.extend(v) flag = not flag return res 注意flag的作用 ","date":"2021-04-13","objectID":"/%E5%AF%B9%E8%A7%92%E7%BA%BF%E9%81%8D%E5%8E%86/:3:0","tags":["算法题","对角线遍历"],"title":"对角线遍历","uri":"/%E5%AF%B9%E8%A7%92%E7%BA%BF%E9%81%8D%E5%8E%86/"},{"categories":["Machine Learning","降维算法"],"content":"主成分分析(PCA) 主成分分析（Principal components analysis，以下简称PCA）是最重要的降维方法之一。在数据压缩消除冗余和数据噪音消除等领域都有广泛的应用。注意的是PCA属于无监督学习。 PCA降维的原则是投影方差最大。 使用PCA时如果有不同种类的数据，PCA会把这些数据混合在一起降维。 PCA顾名思义，就是找出数据里最主要的方面，用数据里最主要的方面来代替原始数据。具体的，假如我们的数据集是n维的，共有m个数据(x(1),x(2),…,x(m))。我们希望将这m个数据的维度从n维降到n’维，希望这m个n’维的数据集尽可能的代表原始数据集。我们知道数据从n维降到n’维肯定会有损失，但是我们希望损失尽可能的小。那么如何让这n’维的数据尽可能表示原来的数据呢？ ","date":"2021-04-12","objectID":"/pca/:0:0","tags":["Machine Learning","降维算法","PCA"],"title":"PCA","uri":"/pca/"},{"categories":["Machine Learning","降维算法"],"content":"协方差矩阵 在统计学中，方差是用来度量单个随机变量的离散程度，而协方差则一般用来刻画两个随机变量的相似程度，其中，方差的计算公式为: \\[ \\sigma_x^2 = \\frac{1}{n}\\sum_{i=1}^n(x-\\bar{x})^2 \\] 协方差的公式为: \\[ \\sigma(x,y) = \\frac{1}{n-1}\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y}) \\] 根据方差的定义，给定d个随机变量\\(x_k,k=1,2,\\dots,d\\)，这些随机变量的方差为 \\[ \\sigma(x_k,x_k) = \\frac{1}{n-1}\\sum_{i=1}^n(x_{ki}-\\bar{x_k})^2,k=1,2,\\dots,d \\] 因此可以求出两两之间的协方差 \\[ \\sigma(x_m,x_k) = \\frac{1}{n-1}\\sum_{i=1}^n(x_{mi}-\\bar{x_m})(x_{ki}-\\bar{x_k}) \\] 因此，协方差矩阵为 \\[ \\sum = \\begin{bmatrix} \\sigma(x_1,x_1) \u0026 \\cdots \u0026 \\sigma(x_1,x_d) \\\\\\\\ \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\\\\ \\sigma(x_d,x_1) \u0026 \\cdots \u0026 \\sigma(x_d,x_d) \\end{bmatrix} \\] ","date":"2021-04-12","objectID":"/pca/:1:0","tags":["Machine Learning","降维算法","PCA"],"title":"PCA","uri":"/pca/"},{"categories":["Machine Learning","降维算法"],"content":"拉格朗日乘数法优化 设原始数据矩阵 X 对应的协方差矩阵为 C，而 P 是一组基按行组成的矩阵，设 Y=PX，则 Y 为 X 对 P 做基变换后的数据。设 Y 的协方差矩阵为 D，我们推导一下 D 与 C 的关系： \\[ D = \\frac{1}{m}YY^T \\\\\\\\ =\\frac{1}{m}(PX)(PX)^T \\\\\\\\ =\\frac{1}{m}PXX^TP^T \\\\\\\\ =P(\\frac{1}{m}XX^T)P^T \\\\\\\\ =PCP^T \\] 我们令P=\\(w^T\\),令原本的协方差为A，于是我们有优化目标如下： \\[ \\begin{cases} \\max{w^TAw} \\\\\\\\ s.t. w^Tw = 1 \\end{cases} \\] 然后构造拉格朗日函数： \\[ L(w) = w^TAw + \\lambda(1-w^Tw) \\] 对w求导： \\[ Aw = \\lambda w \\] 则方差\\(D(x) = w^TAw = \\lambda w^Tw = \\lambda\\) 于是我们发现，x 投影后的方差就是协方差矩阵的特征值。我们要找到最大方差也就是协方差矩阵最大的特征值，最佳投影方向就是最大特征值所对应的特征向量，次佳就是第二大特征值对应的特征向量，以此类推。 ","date":"2021-04-12","objectID":"/pca/:2:0","tags":["Machine Learning","降维算法","PCA"],"title":"PCA","uri":"/pca/"},{"categories":["Machine Learning","降维算法"],"content":"对角矩阵 由上文知道，协方差矩阵 C 是一个是对称矩阵，在线性代数中实对称矩阵有一系列非常好的性质： 实对称矩阵不同特征值对应的特征向量必然正交。 设特征向量\\(\\lambda\\) 重数为 r，则必然存在 r 个线性无关的特征向量对应于 \\(\\lambda\\) ，因此可以将这 r 个特征向量单位正交化。 实对称矩阵一定可以对角化 由上面两条可知，一个 n 行 n 列的实对称矩阵一定可以找到 n 个单位正交特征向量，设这 n 个特征向量为 \\(e_1,e_2,\\cdots,e_n\\)，我们将其按列组成矩阵： \\(E=(e_1,e_2,\\cdots,e_n)\\)。 对于协方差矩阵C有以下结论: \\[ E^TCE = \\begin{bmatrix} \\lambda_1 \\\\\\\\ \u0026\\lambda_2 \\\\\\\\ \u0026\u0026 \\ddots \\\\\\\\ \u0026\u0026\u0026 \\lambda_n \\end{bmatrix} \\] 注：因为E为正交矩阵，则\\(E^{-1}\\) = \\(E^T\\) ,这个过程成为相似对角化，\\(\\lambda_n\\)为C的特征值，对应的特征向量为\\(e_n\\) 这都是线代的基础知识。 ","date":"2021-04-12","objectID":"/pca/:3:0","tags":["Machine Learning","降维算法","PCA"],"title":"PCA","uri":"/pca/"},{"categories":["Machine Learning","降维算法"],"content":"SVD 复制一下将协方差矩阵写成中心化的形式： \\[ \\begin{align}S\u0026=\\frac{1}{N}\\sum\\limits_{i=1}^N(x_i-\\overline{x})(x_i-\\overline{x})^T\\nonumber\\\\\\\\ \u0026=\\frac{1}{N}(x_1-\\overline{x},x_2-\\overline{x},\\cdots,x_N-\\overline{x})(x_1-\\overline{x},x_2-\\overline{x},\\cdots,x_N-\\overline{x})^T\\nonumber\\\\\\\\ \u0026=\\frac{1}{N}(X^T-\\frac{1}{N}X^T\\mathbb{I}_{N1}\\mathbb{I}_{N1}^T)(X^T-\\frac{1}{N}X^T\\mathbb{I}_{N1}\\mathbb{I}_{N1}^T)^T\\nonumber\\\\\\\\ \u0026=\\frac{1}{N}X^T(E_N-\\frac{1}{N}\\mathbb{I}_{N1}\\mathbb{I}_{1N})(E_N-\\frac{1}{N}\\mathbb{I}_{N1}\\mathbb{I}_{1N})^TX\\nonumber\\\\\\\\ \u0026=\\frac{1}{N}X^TH_NH_N^TX\\nonumber\\\\\\\\ \u0026=\\frac{1}{N}X^TH_NH_NX=\\frac{1}{N}X^THX \\end{align} \\] 对中心化后的数据集进行奇异值分解： \\[ HX=U\\Sigma V^T,U^TU=E_N,V^TV=E_p,\\Sigma:N\\times p \\] 于是： \\[ S=\\frac{1}{N}X^THX=\\frac{1}{N}X^TH^THX=\\frac{1}{N}V\\Sigma^T\\Sigma V^T \\] 因此，我们直接对中心化后的数据集进行 SVD，就可以得到特征值\\(\\Sigma^2\\)和特征向量 \\(V\\)，在新坐标系中的坐标就是： \\[ HX\\cdot V \\] ## 步骤 总结一下 PCA 的算法步骤： 设有 m 条 n 维数据。 对所有的样本进行中心化： \\(x^{(i)} = x^{(i)}-\\frac{1}{m}\\sum_{j=1}^mx^{(j)}\\) 计算样本的协方差矩阵 \\(XX^T\\) 对矩阵\\(XX^T\\)进行特征值分解 4）取出最大的n’个特征值对应的特征向量\\((w_1,w_2,...,w_{n′})\\), 将所有的特征向量标准化后，组成特征向量矩阵W。 5）对样本集中的每一个样本\\(x^{(i)}\\),转化为新的样本\\(z^{(i)}=W^Tx^{(i)}\\) 6) 得到输出样本集\\(D^′=(z^{(1)},z^{(2)},...,z^{(m)})\\) ","date":"2021-04-12","objectID":"/pca/:4:0","tags":["Machine Learning","降维算法","PCA"],"title":"PCA","uri":"/pca/"},{"categories":["Machine Learning","降维算法"],"content":"实例 假设我们的数据集有10个二维数据(2.5,2.4), (0.5,0.7), (2.2,2.9), (1.9,2.2), (3.1,3.0), (2.3, 2.7), (2, 1.6), (1, 1.1), (1.5, 1.6), (1.1, 0.9)，需要用PCA降到1维特征。 首先我们对样本中心化，这里样本的均值为(1.81, 1.91),所有的样本减去这个均值向量后，即中心化后的数据集为(0.69, 0.49), (-1.31, -1.21), (0.39, 0.99), (0.09, 0.29), (1.29, 1.09), (0.49, 0.79), (0.19, -0.31), (-0.81, -0.81), (-0.31, -0.31), (-0.71, -1.01)。 现在我们开始求样本的协方差矩阵。 然后求出特征值\\((0.0490833989,1.28402771)\\)，对应的特征向量为 \\((0.735178656,0.677873399)^T\\),\\((−0.677873399,−0.735178656)^T\\)，,由于最大的k=1个特征值为1.28402771,对于的k=1个特征向量为\\((−0.677873399,−0.735178656)^T\\). 则我们的W=\\((−0.677873399,−0.735178656)^T\\)。 们对所有的数据集进行投影\\(z^{(i)}=W^Tx^{(i)}\\)，得到PCA降维后的10个一维数据集为：(-0.827970186， 1.77758033， -0.992197494， -0.274210416， -1.67580142， -0.912949103， 0.0991094375， 1.14457216, 0.438046137， 1.22382056) ","date":"2021-04-12","objectID":"/pca/:5:0","tags":["Machine Learning","降维算法","PCA"],"title":"PCA","uri":"/pca/"},{"categories":["Machine Learning","降维算法"],"content":"性质 缓解维度灾难：PCA 算法通过舍去一部分信息之后能使得样本的采样密度增大（因为维数降低了），这是缓解维度灾难的重要手段； 降噪：当数据受到噪声影响时，最小特征值对应的特征向量往往与噪声有关，将它们舍弃能在一定程度上起到降噪的效果； 过拟合：PCA 保留了主要信息，但这个主要信息只是针对训练集的，而且这个主要信息未必是重要信息。有可能舍弃了一些看似无用的信息，但是这些看似无用的信息恰好是重要信息，只是在训练集上没有很大的表现，所以 PCA 也可能加剧了过拟合； 特征独立：PCA 不仅将数据压缩到低维，它也使得降维之后的数据各特征相互独立； ","date":"2021-04-12","objectID":"/pca/:6:0","tags":["Machine Learning","降维算法","PCA"],"title":"PCA","uri":"/pca/"},{"categories":["Machine Learning","降维算法"],"content":"代码 # 手动实现PCA算法 import numpy as np def pca(data): \"\"\" 主成分分析 :param data: 数据集 :return: \"\"\" # 数据集的行数 num_data, num_feat = data.shape # 对每一列的数据进行平均值的计算 mean_vec = np.mean(data, axis=0) # 对数据集中每一行的数据进行平均值的计算 data_mean_centered = data - mean_vec # 计算协方差矩阵 sigma = np.dot(data_mean_centered.T, data_mean_centered) / num_data # 计算特征值和特征向量 eig_val, eig_vec = np.linalg.eig(sigma) # 对特征值进行排序 eig_pairs = [(np.abs(eig_val[i]), eig_vec[:, i]) for i in range(len(eig_val))] eig_pairs.sort(key=lambda x: x[0], reverse=True) # 要降维的维数，这里以2为例。将特征向量以列向量形式拼合。 matrix_w = np.hstack([eig_pairs[i][1].reshape(-1, 1) for i in range(2)]) # 将原始数据进行投影。 res = data.dot(matrix_w) print(res) pca(np.array([[1, 2, 5], [3, 4, 6], [5, 6, 9], [3, 2 ,5]])) [[ 4.78637704 -1.46926342] [ 7.62278435 -0.82094287] [11.68194836 -0.79767573] [ 5.77746434 0.2656909 ]] 参考文章 https://zhuanlan.zhihu.com/p/77151308 https://www.cnblogs.com/pinard/p/6239403.html ","date":"2021-04-12","objectID":"/pca/:7:0","tags":["Machine Learning","降维算法","PCA"],"title":"PCA","uri":"/pca/"},{"categories":["NLP"],"content":"Bert BERT 的模型架构非常简单，你已经知道它是如何工作的：它只是 Transformer 的编码器。新的是训练目标和 BERT 用于下游任务的方式。 我们如何使用纯文本训练（双向）编码器？我们只知道从左到右的语言建模目标，但它仅适用于每个标记只能使用以前的标记（并且看不到未来）的解码器。BERT 的作者提出了其他未标记数据的训练目标。在讨论它们之前，让我们先看看 BERT 作为 Transformer 编码器的输入。 训练输入：带有特殊标记的句子对 在训练中，BERT 看到用特殊的标记分隔符 [SEP] 分隔的句子对。为了让模型轻松区分这些句子，除了标记和位置嵌入之外，它还使用了段嵌入。 另一个特殊标记是 [CLS] 。顾名思义，它就是表示整个句子的类别的token。在训练中，它用于我们接下来会看到的 NSP 目标。一旦模型被训练，它就会被用于下游任务。 ","date":"2021-04-08","objectID":"/bert/:0:0","tags":["NLP","BERT"],"title":"BERT","uri":"/bert/"},{"categories":["NLP"],"content":"预训练目标：NSP Next Sentence Prediction (NSP) 目标是一个二元分类任务。根据特殊标记[CLS] 的最后一层表示 ，该模型预测这两个句子是否是某些文本中的连续句子。 输入： [CLS] 这个人去了 [MASK] 商店 [SEP] 他买了一加仑 [MASK] 牛奶 [SEP] 标签： isNext 输入： [CLS] 男子去了 [MASK] 商店 [SEP] 企鹅 [MASK] 正在飞行##less 鸟 [SEP] 标签： notNext 该任务教模型理解句子之间的关系。正如我们稍后将看到的，这将使 BERT 能够用于需要某种推理的复杂任务。 ","date":"2021-04-08","objectID":"/bert/:1:0","tags":["NLP","BERT"],"title":"BERT","uri":"/bert/"},{"categories":["NLP"],"content":"预训练目标：MLM（掩蔽语言模型） BERT 有两个训练目标，其中最重要的是 Masked Language Modeling (MLM) 目标。对于 MLM 目标，在步骤中会发生以下情况： 选择一些标记 （每个标记以 15% 的概率被选中） 替换这些选定的标记 （使用特殊标记 [MASK] (p=80%)，随机标记 (p=10%)，原始标记（保持不变）(p=10%)） 预测原始标记（计算损失） 其思想来自于完形填空，也借鉴了CBOW的思想。 MLM 仍然是语言建模：目标是根据文本的某些部分预测句子/文本中的一些标记。为了更清楚，让我们将 MLM 与标准的从左到右的语言建模目标进行比较 在每一步，标准的从左到右的 LMs 根据之前的标记预测下一个标记。这意味着最终表示，即来自最终层的用于预测的表示，仅编码先前的上下文，即它们 看不到未来。 不同的是，MLM可以一次看到整个文本，但有些标记被破坏了：这就是 BERT 是双向的原因。请注意，为了让 ELMo 知道左右上下文，作者必须训练两个不同的单向 LM(即双向LSTM)，然后将它们的表示连接起来。在 BERT 中，我们不需要这样做：一个模型就足够了。 注意一些细节，在代码实现的时候，注意特殊的标记如[SEP][CLS] 等不要替换， 还有[PAD] ","date":"2021-04-08","objectID":"/bert/:2:0","tags":["NLP","BERT"],"title":"BERT","uri":"/bert/"},{"categories":["NLP"],"content":"数据集构建代码 class BERTDataset(Dataset): def __init__(self, corpus_path, vocab, seq_len, encoding=\"utf-8\", corpus_lines=None, on_memory=True): self.vocab = vocab self.seq_len = seq_len self.on_memory = on_memory self.corpus_lines = corpus_lines self.corpus_path = corpus_path self.encoding = encoding with open(corpus_path, \"r\", encoding=encoding) as f: if self.corpus_lines is None and not on_memory: for _ in tqdm.tqdm(f, desc=\"Loading Dataset\", total=corpus_lines): self.corpus_lines += 1 if on_memory: self.lines = [line[:-1].split(\"\\t\") for line in tqdm.tqdm(f, desc=\"Loading Dataset\", total=corpus_lines)] # 一行有两个句子，分隔符是\\t self.corpus_lines = len(self.lines) if not on_memory: self.file = open(corpus_path, \"r\", encoding=encoding) self.random_file = open(corpus_path, \"r\", encoding=encoding) for _ in range(random.randint(self.corpus_lines if self.corpus_lines \u003c 1000 else 1000)): self.random_file.__next__() def __len__(self): return self.corpus_lines def __getitem__(self, item): t1, t2, is_next_label = self.random_sent(item) # is_next_label: 1 or 0，1代表t2是相邻句子，0代表不是相邻句子 t1_random, t1_label = self.random_word(t1) # mlm任务 t2_random, t2_label = self.random_word(t2) # [CLS] tag = SOS tag, [SEP] tag = EOS tag t1 = [self.vocab.sos_index] + t1_random + [self.vocab.eos_index] t2 = t2_random + [self.vocab.eos_index] t1_label = [self.vocab.pad_index] + t1_label + [self.vocab.pad_index] t2_label = t2_label + [self.vocab.pad_index] segment_label = ([1 for _ in range(len(t1))] + [2 for _ in range(len(t2))])[:self.seq_len] bert_input = (t1 + t2)[:self.seq_len] # 截断 bert_label = (t1_label + t2_label)[:self.seq_len] padding = [self.vocab.pad_index for _ in range(self.seq_len - len(bert_input))] #pad bert_input.extend(padding), bert_label.extend(padding), segment_label.extend(padding) output = {\"bert_input\": bert_input, \"bert_label\": bert_label, \"segment_label\": segment_label, \"is_next\": is_next_label} return {key: torch.tensor(value) for key, value in output.items()} def random_word(self, sentence): # 对sent token进行mask并返回mask后的label tokens = sentence.split() output_label = [] for i, token in enumerate(tokens): prob = random.random() if prob \u003c 0.15: prob /= 0.15 # 80% randomly change token to mask token if prob \u003c 0.8: tokens[i] = self.vocab.mask_index # 10% randomly change token to random token elif prob \u003c 0.9: tokens[i] = random.randrange(len(self.vocab)) # 10% randomly change token to current token else: tokens[i] = self.vocab.stoi.get(token, self.vocab.unk_index) output_label.append(self.vocab.stoi.get(token, self.vocab.unk_index)) # 被mask掉的token作为label else: tokens[i] = self.vocab.stoi.get(token, self.vocab.unk_index) output_label.append(0) # label为0，这样计算loss时不用考虑，因为可以设置nn.NLLLoss(ignore_index=0) return tokens, output_label def random_sent(self, index): # 根据idx选择某对句子并随机返回相邻或不相邻的句子。 t1, t2 = self.get_corpus_line(index) # output_text, label(isNotNext:0, isNext:1) if random.random() \u003e 0.5: return t1, t2, 1 else: return t1, self.get_random_line(), 0 def get_corpus_line(self, item): # 通过item idx选择某对句子 if self.on_memory: return self.lines[item][0], self.lines[item][1] else: line = self.file.__next__() if line is None: self.file.close() self.file = open(self.corpus_path, \"r\", encoding=self.encoding) line = self.file.__next__() t1, t2 = line[:-1].split(\"\\t\") return t1, t2 def get_random_line(self): # 随机选一行 if self.on_memory: return self.lines[random.randrange(len(self.lines))][1] line = self.file.__next__() if line is None: self.file.close() self.file = open(self.corpus_path, \"r\", encoding=self.encoding) for _ in range(random.randint(self.corpus_lines if self.corpus_lines \u003c 1000 else 1000)): self.random_file.__next__() line = self.random_file.__next__() return line[:-1].split(\"\\t\")[1] ","date":"2021-04-08","objectID":"/bert/:3:0","tags":["NLP","BERT"],"title":"BERT","uri":"/bert/"},{"categories":["NLP"],"content":"微调 ","date":"2021-04-08","objectID":"/bert/:4:0","tags":["NLP","BERT"],"title":"BERT","uri":"/bert/"},{"categories":["NLP"],"content":"分类 对于分类任务直接取第一个[CLS] token的final hidden state，然后加一层权重后softmax输出。 \\[ P = softmax(CW^T) \\] ","date":"2021-04-08","objectID":"/bert/:4:1","tags":["NLP","BERT"],"title":"BERT","uri":"/bert/"},{"categories":["NLP"],"content":"其它任务 其它任务需要一些调整 ","date":"2021-04-08","objectID":"/bert/:4:2","tags":["NLP","BERT"],"title":"BERT","uri":"/bert/"},{"categories":["NLP"],"content":"适配器(Adapter) 到目前为止，我们只考虑了将知识从预训练模型（例如 BERT）转移到下游任务的标准方法：微调。“微调”意味着您采用预训练模型并以相当小的学习率训练您感兴趣的任务（例如，情感分类）。这意味着首先，您更新整个（大型）模型，其次，对于每个任务，您需要微调预训练模型的单独副本。最后，对于几个下游任务，您最终会得到很多大型模型 - 这是非常低效的！ Apdater-Bert的想法是将task-specific layer放在预训练模型中间，也就是加入Adapter结构，然后冻结住预训练模型参数，最后我们fientuning的时候，只更新Apdater、layerNorm以及与具体任务相关的layer的参数。具体结构图如下： 左图是Adapter-BERT中的transformer layer，我们可以看到每一个transformer layer增加了两个Adapter layer，分别加在LayerNorm之前，当然了，在进行LayerNorm之前，我们需要进行讲Apdater layer的输出进行残差连接。 右图是Adapter layer的具体结构示意 \u003e这里为什么要用残差连接？主要是因为当初始化的时候，权重都很小，残差连接可以保证模型输出与预训练模型相同。 ","date":"2021-04-08","objectID":"/bert/:5:0","tags":["NLP","BERT"],"title":"BERT","uri":"/bert/"},{"categories":["NLP"],"content":"总结 总之BERT就只有这么多新的特性，或者说创新，但是它一经问世就成为了新的霸主，可见效果之好，BERT还有很多细节上的问题，后面看到或者学习到的时候会继续记录下来。 ## 一些问题 ","date":"2021-04-08","objectID":"/bert/:6:0","tags":["NLP","BERT"],"title":"BERT","uri":"/bert/"},{"categories":["NLP"],"content":"为什么 Bert 的三个 Embedding 可以进行相加？ 因为三个 embedding 相加等价于三个原始 one-hot 的拼接再经过一个全连接网络。和拼接相比，相加可以节约模型参数。 引用苏建林老师的话： \u003e Embedding的数学本质，就是以one hot为输入的单层全连接。 也就是说，世界上本没什么Embedding，有的只是one hot。 假设 token Embedding 矩阵维度是 [4,768]；position Embedding 矩阵维度是 [3,768]；segment Embedding 矩阵维度是 [2,768]。 对于一个字，假设它的 token one-hot 是[1,0,0,0]；它的 position one-hot 是[1,0,0]；它的 segment one-hot 是[1,0]。 那这个字最后的 word Embedding，就是上面三种 Embedding 的加和。 如此得到的 word Embedding，和concat后的特征：[1,0,0,0,1,0,0,1,0]，再过维度为 [4+3+2,768] = [9, 768] 的全连接层，得到的向量其实就是一样的。 ","date":"2021-04-08","objectID":"/bert/:6:1","tags":["NLP","BERT"],"title":"BERT","uri":"/bert/"},{"categories":["NLP"],"content":"transformers中bert模型的输出 ","date":"2021-04-08","objectID":"/bert/:6:2","tags":["NLP","BERT"],"title":"BERT","uri":"/bert/"},{"categories":["工具"],"content":"常用命令 ","date":"2021-04-04","objectID":"/git/:1:0","tags":["git","工具"],"title":"git","uri":"/git/"},{"categories":["工具"],"content":"diff image.png git diff：当工作区有改动，临时区为空，diff的对比是“工作区”与最后一次commit提交的仓库的共同文件”；当工作区有改动，临时区不为空，diff对比的是“工作区”与“暂存区”的共同文件”。 git diff --cached：显示暂存区与最后一次commit的改动。 git diff \u003c分支1\u003e \u003c分支2\u003e 显示两个分支最后一次commit的改动。 ","date":"2021-04-04","objectID":"/git/:1:1","tags":["git","工具"],"title":"git","uri":"/git/"},{"categories":["工具"],"content":"init git init初始化一个仓库 ","date":"2021-04-04","objectID":"/git/:1:2","tags":["git","工具"],"title":"git","uri":"/git/"},{"categories":["工具"],"content":"add git add .将除.gitignore中声明的所有文件加入暂存区 也可以git add 特定文件，将文件加入暂存区。 ","date":"2021-04-04","objectID":"/git/:1:3","tags":["git","工具"],"title":"git","uri":"/git/"},{"categories":["工具"],"content":"commit image.png git commit -m \"提交说明\" 提交到工作区 git commit --amend 修改上次的提交记录 ","date":"2021-04-04","objectID":"/git/:1:4","tags":["git","工具"],"title":"git","uri":"/git/"},{"categories":["工具"],"content":"push git push 提交到远程库。可以指定分支提交 比如：git push origin main 指定为main分支 ","date":"2021-04-04","objectID":"/git/:1:5","tags":["git","工具"],"title":"git","uri":"/git/"},{"categories":["工具"],"content":"pull git pull 将改动拉倒本地库，并合并，默认为Merge合并 如果加上rebase参数则合并方式变为rebase合并。 ","date":"2021-04-04","objectID":"/git/:1:6","tags":["git","工具"],"title":"git","uri":"/git/"},{"categories":["工具"],"content":"log git log 查看提交历史 git log --oneline简洁输出 ","date":"2021-04-04","objectID":"/git/:1:7","tags":["git","工具"],"title":"git","uri":"/git/"},{"categories":["工具"],"content":"branch git branch xxx 建立分支xxx 然后用git checkout xxx 切换到分支xxx 或者用git checkout -b xxx 完成同样的操作 ","date":"2021-04-04","objectID":"/git/:1:8","tags":["git","工具"],"title":"git","uri":"/git/"},{"categories":["工具"],"content":"checkout image.png git checkout 回退版本即head分离 但master不变 checkout可以切换分支，也可以head分离，但是分支的位置不变，但后面的reset和revert都会改变分支 ","date":"2021-04-04","objectID":"/git/:1:9","tags":["git","工具"],"title":"git","uri":"/git/"},{"categories":["工具"],"content":"reset git reset --hard HEAD^回退一个版本（master也改变） git reset --hard HEAD~n 回退n个版本 git reset --hard xxxxxx xxxxxx为版本号 即为git log显示的每一个版本号 一般为前六位 reset的参数有三种，其作用如下： 最危险但最常用的就是hard。soft也常用来修改某个提交，只修改提交，之后再进行提交即可达到修改的目的。 ","date":"2021-04-04","objectID":"/git/:1:10","tags":["git","工具"],"title":"git","uri":"/git/"},{"categories":["工具"],"content":"revert git revert命令用于撤消对仓库提交历史的更改。其他“撤消”命令，例如 git checkout 和 git reset，将HEAD和分支引用指针移动到指定的提交。git revert也需要一个指定的提交，但是，它并不会将 ref 指针移动到这个提交。revert 操作将采用反转指定的提交的更改，并创建一个新的“还原提交”。然后更新 ref 指针以指向新的还原提交，使其成为分支的HEAD。(创建一个新的commit结点) ","date":"2021-04-04","objectID":"/git/:1:11","tags":["git","工具"],"title":"git","uri":"/git/"},{"categories":["工具"],"content":"merge git merge 比如在master分支里 执行git merge xxx 将xxx分支合并到master中，一般项目开发，一人一个分支，最后提交的时候合并再提交。不过更推荐用git rebase方法，这样合并后的分支更加直观。一般是进行三方合并。 ","date":"2021-04-04","objectID":"/git/:1:12","tags":["git","工具"],"title":"git","uri":"/git/"},{"categories":["工具"],"content":"branch 最常用的就是创建和删除分支 git branch -f master~3将分支强制回退三个版本，但head不动 ","date":"2021-04-04","objectID":"/git/:1:13","tags":["git","工具"],"title":"git","uri":"/git/"},{"categories":["工具"],"content":"cherry-pick 当需要另一个分支的所有改动时，用git merge，但当需要部分改动时候，要用git cherry-pick xxx xxx为哈希值或者分支名，指定为分支名时候，将分支的最新改动合并过来 ","date":"2021-04-04","objectID":"/git/:1:14","tags":["git","工具"],"title":"git","uri":"/git/"},{"categories":["工具"],"content":"rebase 当不知道提交的哈希值时，可以用git rebase -i HEAD~x 来可视化管理，可以调整提交的顺序，可以删除不想要的提交，或合并提交 这是线性化的自动的 cherry-pick git rebase xx1 xx2将xx2分支上的提交记录放到xx1后面 此外活用git rebase -i ,进行可视化的操作。 ### fetch git fetch获取远程仓库的数据，不会改变你本地仓库的状态，不会更新你的master,也没有更改你的本地磁盘文件，可以理解为单纯的下载操作。而git pull相当于git fetch + git merge即抓取后合并 ","date":"2021-04-04","objectID":"/git/:1:15","tags":["git","工具"],"title":"git","uri":"/git/"},{"categories":["工具"],"content":"reflog git reflog 查看操作记录，这个操作可以撤销不小心用git reset回退版本的操作 ","date":"2021-04-04","objectID":"/git/:1:16","tags":["git","工具"],"title":"git","uri":"/git/"},{"categories":["工具"],"content":"stash 它会保存当前工作进度，会把暂存区和工作区的改动保存到一个未完结变更的堆栈中；执行完这个命令后，在运行 git status 命令，就会发现当前是一个干净的工作区，没有任何改动。 git stash 是本地的，不会上传到服务器上； 可以通过使用git stash save 'message...'可以添加一些注释。 image.png ","date":"2021-04-04","objectID":"/git/:1:17","tags":["git","工具"],"title":"git","uri":"/git/"},{"categories":["工具"],"content":"底层内容 这几天系统学习了一下git的底层内容，通透了很多，记录一些。贴一下原博客：https://www.lzane.com/tech/git-internal/ 首先看一个图 首先要明确有四种object，第一种是记录文件内容，第二种是记录目录结构，第三种是记录提交信息，第四种是记录tag信息，第四种无关紧要。 从下面开始看，最下面记录的文件内容，注意只记录文件内容，不包括文件名等其它内容。是一个blob类型的节点，将文件的内容信息经过SHA1哈希算法得到对应的哈希值作为这个object在Git仓库中的唯一身份证。 然后再往上的三角形记录的是仓库的目录结构，它将当前的目录结构打了一个快照。从它储存的内容来看可以发现它储存了一个目录结构（类似于文件夹），以及每一个文件（或者子文件夹）的权限、类型、对应的身份证（SHA1值）、以及文件名。 再往上就是记录的提交的信息，它储存的是一个提交的信息，包括对应目录结构的快照tree的哈希值，上一个提交的哈希值，提交的作者以及提交的具体时间，最后是该提交的信息。 还有分支的信息和Head。HEAD、分支和普通的Tag可以理解为一个指针，指向对应commit的sha1值。 仓库有三个分区：工作目录、index索引区域、Git仓库。 当文件被修改后，只是工作目录发生了改变，其余两个是没有任何变化的。当运行git add xxx命令后，即将xxx文件加入了索引区域，此时新建了一个blob object，并且将原来指向xxx指向了新建的blob Object，记住索引索引的是add的所有文件，这时运行git commit，会生成一个tree object，然后创建commit object，将分支等信息指向新的commit。注意每次commit都是储存的全新的文件快照而不是变更部分。 ","date":"2021-04-04","objectID":"/git/:2:0","tags":["git","工具"],"title":"git","uri":"/git/"},{"categories":["工具"],"content":"合并策略 ","date":"2021-04-04","objectID":"/git/:3:0","tags":["git","工具"],"title":"git","uri":"/git/"},{"categories":["工具"],"content":"Fast-forward(没有分叉) image.png ","date":"2021-04-04","objectID":"/git/:3:1","tags":["git","工具"],"title":"git","uri":"/git/"},{"categories":["工具"],"content":"Recursive(最常用最重要) Recursive是Git分支合并策略中最重要也是最常用的策略，是Git在合并两个有分叉的分支时的默认行为。其算法可以简单描述为：递归寻找路径最短的唯一共同祖先节点，然后以其为base节点进行递归三向合并。 那怎么保证Git能够找到正确的合并base节点，尽可能的减少冲突呢？答案就是，Git在寻找路径最短的共同祖先节点时，如果满足条件的祖先节点不唯一，那么Git会继续递归往下寻找直至唯一。不唯一的多个祖先节点做一个临时的三向合并节点。 Recursive策略已经被大量的场景证明它是一个尽量减少冲突的合并策略，我们可以看到有趣的一点是，对于两个合并分支的中间节点（如上图节点4，5），只参与了base的计算，而最终真正被三向合并拿来做合并的节点，只包括末端以及base节点。 需要注意Git只是使用这些策略尽量的去帮你减少冲突，如果冲突不可避免，那Git就会提示冲突，需要手工解决。（也就是真正意义上的冲突）。 ### Ours \u0026 Theirs ### Octopus ## 参考 图解Git (marklodato.github.io) 这才是真正的Git——Git内部原理 - LZANE | 李泽帆（靓仔） 这才是真正的Git——分支合并 - LZANE | 李泽帆（靓仔） ","date":"2021-04-04","objectID":"/git/:3:2","tags":["git","工具"],"title":"git","uri":"/git/"},{"categories":["算法题"],"content":"编辑距离 ","date":"2021-04-03","objectID":"/%E7%BC%96%E8%BE%91%E8%B7%9D%E7%A6%BB/:0:0","tags":["算法题","编辑距离"],"title":"编辑距离","uri":"/%E7%BC%96%E8%BE%91%E8%B7%9D%E7%A6%BB/"},{"categories":["算法题"],"content":"定义 编辑距离(Edit Distance)是针对两个字符串S1和S2的差异程度进行量化，计算方式是看至少需要多少次的处理才能将S1变成S2（和S2变成S1是等价的），用 EditDis(S1,S2)表示。 其中处理的方式有三种： 1.插入一个字符 2.删除一个字符 3.替换一个字符 这是严格意义上的距离，满足”距离三公理”： 1.对称性，EditDis(S1,S2) = EditDis(S2,S1) 2.非负性，EditDis(S1,S2) \u003e= 0, 当且仅当S1=S2时，等号成立 3.三角不等式，EditDis(S1,S2) + EditDis(S1,S3) \u003e= EditDis(S2,S3) ","date":"2021-04-03","objectID":"/%E7%BC%96%E8%BE%91%E8%B7%9D%E7%A6%BB/:1:0","tags":["算法题","编辑距离"],"title":"编辑距离","uri":"/%E7%BC%96%E8%BE%91%E8%B7%9D%E7%A6%BB/"},{"categories":["算法题"],"content":"动态规划求解 令 S1.substr(i)表示 S1前i个字符构成的子串，S2.substr(j)表示S2前j个字符构成的子串 \\(dp[i][j]\\)表示S1.substr(i)和S2.substr(j)的编辑距离。 注意，这句话的另一层含义是：当我们计算出了EditDis(S1,S2)则默认了S1.substr(i)已经通过三种处理方式变成了S2.substr(j)。 所以，当我们计算\\(dp[i+1][j+1]\\)时，我们可以利用\\(dp[i][j]\\)，\\(dp[i+1][j]\\)，\\(dp[i][j+1]\\)的信息。 ","date":"2021-04-03","objectID":"/%E7%BC%96%E8%BE%91%E8%B7%9D%E7%A6%BB/:2:0","tags":["算法题","编辑距离"],"title":"编辑距离","uri":"/%E7%BC%96%E8%BE%91%E8%B7%9D%E7%A6%BB/"},{"categories":["算法题"],"content":"过程 1.确定最后一步： 令，S1的长度为len1，S2的长度为len2 \\(dp[len1][len2]\\)有三种方式可以实现，一种是S1.substr(len1-1)插入一个字符使之等于S2（\\(dp[len1][len2-1] + 1\\)），一种是S2.substr(len2)删除一个字符使之等于S1（\\(dp[len1-1][len2] + 1\\)），另一种是替换最后一个字符使S1和S2相等（\\(dp[len1-1][len2-1] + 1\\)） 确定转移方程: 3.确定边界和初始状态 我们设定Dp二维数组大小是（Len+1） * （Len2+1），第0行代表 S1为空串，第0列代表S2为空串。 显然，S1变成为空串需要的每次操作是\\(dp[i][0]=i\\) S2变成为空串需要的每次操作是\\(dp[0][j] = j\\) ","date":"2021-04-03","objectID":"/%E7%BC%96%E8%BE%91%E8%B7%9D%E7%A6%BB/:3:0","tags":["算法题","编辑距离"],"title":"编辑距离","uri":"/%E7%BC%96%E8%BE%91%E8%B7%9D%E7%A6%BB/"},{"categories":["算法题"],"content":"代码 class Solution: def minDistance(self, word1: str, word2: str) -\u003e int: import numpy as np len1, len2 = len(word1), len(word2) dp = [[0]*(len2+1) for _ in range(len1+1)] # 定义 for i in range(1,len1+1): dp[i][0] = i # 边界 for j in range(1,len2+1): dp[0][j] = j # 边界 for i in range(1,len1+1): for j in range(1,len2+1): if word1[i-1] == word2[j-1]: dp[i][j] = dp[i-1][j-1] else: dp[i][j] = min(dp[i-1][j]+1, dp[i][j-1]+1, dp[i-1][j-1]+1) return int(dp[len1][len2]) ","date":"2021-04-03","objectID":"/%E7%BC%96%E8%BE%91%E8%B7%9D%E7%A6%BB/:4:0","tags":["算法题","编辑距离"],"title":"编辑距离","uri":"/%E7%BC%96%E8%BE%91%E8%B7%9D%E7%A6%BB/"},{"categories":["Machine Learning","聚类算法"],"content":"通过sklearn模块实现 import numpy as np import matplotlib.pyplot as plt from sklearn import metrics from sklearn.datasets import make_blobs from sklearn.cluster import KMeans from sklearn.datasets import load_iris %matplotlib inline X,y = make_blobs(n_samples=100,n_features=2,centers=[[-1,-1],[0,0],[1,1],[2,2]],cluster_std=[0.4,0.2,0.2,0.2])#使用make_blobs生成训练数据,生成100个样本,每个样本2个特征,共4个聚类,聚类中心分别为[-1,-1],[0,0],[1,1],[2,2],聚类方差分别为0.4,0.2,0.2,0.2 plt.scatter(X[:,0],X[:,1])#画出训练样本的散点图,散点图的横坐标为样本的第一维特征,纵坐标为样本的第二维特征 plt.show() kmeans = KMeans(n_clusters=3)#生成kmeans分类器,聚类数量为3,其余参数使用默认值。 y_pred = kmeans.fit_predict(X)#使用fit_predict方法计算聚类中心并且预测每个样本的聚类索引。 plt.scatter(X[:,0],X[:,1],c=y_pred)#画出训练样本的散点图,散点图的横坐标为样本的第一维特征,纵坐标为样本的第二维特征,将各聚类结果显示为不同的颜色 plt.show() kmeans = KMeans(n_clusters=4)#生成kmeans分类器,聚类数量为4,其余参数使用默认值。 y_pred = kmeans.fit_predict(X)#使用fit_predict方法计算聚类中心并且预测每个样本的聚类索引。 plt.scatter(X[:,0],X[:,1],c=y_pred)#画出训练样本的散点图,散点图的横坐标为样本的第一维特征,纵坐标为样本的第二维特征,将各聚类结果显示为不同的颜色 plt.show() iris = load_iris() #导入iris数据集,iris数据集包含了150个样本,分别属于3类,每个样本包含4个特征 data_train=iris.data #iris样本集的样本特征 label_train=iris.target #iris样本集的样本标签 kmeans = KMeans(n_clusters=3)#生成kmeans分类器,聚类数量为3,其余参数使用默认值。 y_predict = kmeans.fit_predict(data_train)#使用fit_predict方法计算聚类中心并且预测每个样本的聚类索引。 plt.scatter(data_train[:,0],data_train[:,2],c=y_predict)#画出训练样本的散点图,散点图的横坐标为样本的第一维特征,纵坐标为样本的第三维特征,将各聚类结果显示为不同的颜色 plt.show() ","date":"2021-03-28","objectID":"/kmeans/:1:0","tags":["Machine Learning","聚类算法","kmeans"],"title":"kmeans","uri":"/kmeans/"},{"categories":["Machine Learning","聚类算法"],"content":"手动实现 import numpy as np import matplotlib.pyplot as plt center = np.array([[0,0],[0,1]]) cls_num = 2 X = np.array([[0,0],[0,1],[2,1],[2,3],[3,4],[1,0]]) max_iter = 10 cls = np.zeros(X.shape[0]) run = True while run and max_iter \u003e 0: for i,x in enumerate(X): tmp = np.argmin(np.sum(np.power(x - center,2),axis=1)) cls[i] = tmp run = False # 重新计算聚类中心 for i in range(cls_num): data = X[cls==i] # 取相同类别的样本 new_center = np.mean(data,axis=0) # 对相同类别的x和y取平均值 if np.sum(np.abs(center[i]-new_center),axis=0) \u003e 1e-4: center[i] = new_center # 更新中心 run = True max_iter -= 1 plt.scatter(X[:,0],X[:,1],c=cls) plt.show() ## kernel kmeans 已知kmeans的核心公式为下： 这里可以看到,实际上就是计算每个样本点簇中心的距离,然后判断出到哪个簇中心距离最短,然后分给那个簇。然后下次迭代时,簇中心就按照新分配的点重新进行计算了,然后所有的点再同样计算样本点到簇中心的距离,重新分配到不同的簇中。所以这样不断迭代下去,就能够收敛了,得到最后的聚类效果。 核k-means,概括地来说,就是将数据点都投影到了一个高维的特征空间中（为啥要这么做呢,主要是突显出不同样本中的差异）,然后再在这个高维的特征空间中,进行传统的k-means聚类。主要的思想就是这么简单,比起传统普通的k-means就多了一个步核函数的操作。所以它的公式也与传统k-means很相近： 但实际中很难计算,因此需要改造, 改造成为 ","date":"2021-03-28","objectID":"/kmeans/:2:0","tags":["Machine Learning","聚类算法","kmeans"],"title":"kmeans","uri":"/kmeans/"},{"categories":["Machine Learning","聚类算法"],"content":"代码 class KernelKmeans: def __init__(self, n_clusters, max_iter, kernel): self.n_clusters = n_clusters self.max_iter = max_iter self.kernel = kernel def fit(self, X): self.centroids = X[np.random.choice(X.shape[0], self.n_clusters, replace=False)] for i in range(self.max_iter): distances = np.array([self.kernel(X, centroid) for centroid in self.centroids]) self.labels = np.argmin(distances, axis=0) self.centroids = np.array([X[self.labels == j].mean(axis=0) for j in range(self.n_clusters)], dtype=np.float32) def predict(self, X): distances = np.array([self.kernel(X, centroid) for centroid in self.centroids]) return np.argmin(distances, axis=0) def gaussian_kernel(X, y): return np.exp(-np.linalg.norm(X - y, axis=1)**2 / 2) ","date":"2021-03-28","objectID":"/kmeans/:2:1","tags":["Machine Learning","聚类算法","kmeans"],"title":"kmeans","uri":"/kmeans/"},{"categories":["算法题"],"content":"翻转二叉树 开始学习二叉树了 先来个简单题 https://leetcode-cn.com/problems/invert-binary-tree/ 很简单 # Definition for a binary tree node. # class TreeNode: # def __init__(self, x): # self.val = x # self.left = None # self.right = None class Solution: def invertTree(self, root: TreeNode) -\u003e TreeNode: if root == None: return None temp = root.left root.left = root.right root.right = temp self.invertTree(root.left) self.invertTree(root.right) return root ","date":"2021-03-24","objectID":"/%E7%BF%BB%E8%BD%AC%E4%BA%8C%E5%8F%89%E6%A0%91/:0:0","tags":["算法题","翻转二叉树"],"title":"翻转二叉树","uri":"/%E7%BF%BB%E8%BD%AC%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"categories":["算法题"],"content":"对称二叉树 ","date":"2021-03-21","objectID":"/%E5%AF%B9%E7%A7%B0%E4%BA%8C%E5%8F%89%E6%A0%91/:0:0","tags":["算法题","对称二叉树"],"title":"对称二叉树","uri":"/%E5%AF%B9%E7%A7%B0%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"categories":["算法题"],"content":"题目： https://leetcode-cn.com/problems/symmetric-tree/ ","date":"2021-03-21","objectID":"/%E5%AF%B9%E7%A7%B0%E4%BA%8C%E5%8F%89%E6%A0%91/:1:0","tags":["算法题","对称二叉树"],"title":"对称二叉树","uri":"/%E5%AF%B9%E7%A7%B0%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"categories":["算法题"],"content":"思路： 利用双向队列，每次把对称的两个对应的节点放入队列中，然后取出来比较，如果值不相等则返回false,如果一边为空 一边不为空也返回false 符合条件的话就继续搜索 ","date":"2021-03-21","objectID":"/%E5%AF%B9%E7%A7%B0%E4%BA%8C%E5%8F%89%E6%A0%91/:2:0","tags":["算法题","对称二叉树"],"title":"对称二叉树","uri":"/%E5%AF%B9%E7%A7%B0%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"categories":["算法题"],"content":"代码： # Definition for a binary tree node. # class TreeNode: # def __init__(self, val=0, left=None, right=None): # self.val = val # self.left = left # self.right = right class Solution: def isSymmetric(self, root: TreeNode) -\u003e bool: from collections import deque d = deque() d.append((root,root)) while d: left,right = d.popleft() if not left and not right: continue elif not left or not right: return False elif left.val != right.val: return False else: d.append((left.left,right.right)) d.append((left.right,right.left)) return True ","date":"2021-03-21","objectID":"/%E5%AF%B9%E7%A7%B0%E4%BA%8C%E5%8F%89%E6%A0%91/:3:0","tags":["算法题","对称二叉树"],"title":"对称二叉树","uri":"/%E5%AF%B9%E7%A7%B0%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"categories":["算法题"],"content":"合并两个有序列表 ","date":"2021-03-18","objectID":"/%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%9C%89%E5%BA%8F%E5%88%97%E8%A1%A8/:0:0","tags":["算法题","合并两个有序列表"],"title":"合并两个有序列表","uri":"/%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%9C%89%E5%BA%8F%E5%88%97%E8%A1%A8/"},{"categories":["算法题"],"content":"题目： https://leetcode-cn.com/problems/merge-two-sorted-lists/ ","date":"2021-03-18","objectID":"/%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%9C%89%E5%BA%8F%E5%88%97%E8%A1%A8/:1:0","tags":["算法题","合并两个有序列表"],"title":"合并两个有序列表","uri":"/%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%9C%89%E5%BA%8F%E5%88%97%E8%A1%A8/"},{"categories":["算法题"],"content":"思路： 利用递归的思想，比较两个当前值，因为是有序链表 ","date":"2021-03-18","objectID":"/%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%9C%89%E5%BA%8F%E5%88%97%E8%A1%A8/:2:0","tags":["算法题","合并两个有序列表"],"title":"合并两个有序列表","uri":"/%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%9C%89%E5%BA%8F%E5%88%97%E8%A1%A8/"},{"categories":["算法题"],"content":"代码： # Definition for singly-linked list. # class ListNode: # def __init__(self, val=0, next=None): # self.val = val # self.next = next class Solution: def mergeTwoLists(self, l1: ListNode, l2: ListNode) -\u003e ListNode: if l1 == None: return l2 if l2 == None: return l1 if l1.val \u003c= l2.val: l1.next = self.mergeTwoLists(l1.next,l2) return l1 else: l2.next = self.mergeTwoLists(l1,l2.next) return l2 ","date":"2021-03-18","objectID":"/%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%9C%89%E5%BA%8F%E5%88%97%E8%A1%A8/:3:0","tags":["算法题","合并两个有序列表"],"title":"合并两个有序列表","uri":"/%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%9C%89%E5%BA%8F%E5%88%97%E8%A1%A8/"},{"categories":["算法题"],"content":"可获得的最大点数 ","date":"2021-03-03","objectID":"/%E5%8F%AF%E8%8E%B7%E5%BE%97%E7%9A%84%E6%9C%80%E5%A4%A7%E7%82%B9%E6%95%B0/:0:0","tags":["算法题","可获得的最大点数"],"title":"可获得的最大点数","uri":"/%E5%8F%AF%E8%8E%B7%E5%BE%97%E7%9A%84%E6%9C%80%E5%A4%A7%E7%82%B9%E6%95%B0/"},{"categories":["算法题"],"content":"题目： https://leetcode-cn.com/problems/maximum-points-you-can-obtain-from-cards/ ","date":"2021-03-03","objectID":"/%E5%8F%AF%E8%8E%B7%E5%BE%97%E7%9A%84%E6%9C%80%E5%A4%A7%E7%82%B9%E6%95%B0/:1:0","tags":["算法题","可获得的最大点数"],"title":"可获得的最大点数","uri":"/%E5%8F%AF%E8%8E%B7%E5%BE%97%E7%9A%84%E6%9C%80%E5%A4%A7%E7%82%B9%E6%95%B0/"},{"categories":["算法题"],"content":"思路： 滑动窗口题目，限定窗口大小然后滑动即可 ","date":"2021-03-03","objectID":"/%E5%8F%AF%E8%8E%B7%E5%BE%97%E7%9A%84%E6%9C%80%E5%A4%A7%E7%82%B9%E6%95%B0/:2:0","tags":["算法题","可获得的最大点数"],"title":"可获得的最大点数","uri":"/%E5%8F%AF%E8%8E%B7%E5%BE%97%E7%9A%84%E6%9C%80%E5%A4%A7%E7%82%B9%E6%95%B0/"},{"categories":["算法题"],"content":"代码： class Solution: def maxScore(self, cardPoints: List[int], k: int) -\u003e int: n = len(cardPoints) # 滑动窗口大小为 n-k windowSize = n - k # 选前 n-k 个作为初始值 s = sum(cardPoints[:windowSize]) minSum = s for i in range(windowSize, n): # 滑动窗口每向右移动一格，增加从右侧进入窗口的元素值，并减少从左侧离开窗口的元素值 s += cardPoints[i] - cardPoints[i - windowSize] minSum = min(minSum, s) return sum(cardPoints) - minSum ","date":"2021-03-03","objectID":"/%E5%8F%AF%E8%8E%B7%E5%BE%97%E7%9A%84%E6%9C%80%E5%A4%A7%E7%82%B9%E6%95%B0/:3:0","tags":["算法题","可获得的最大点数"],"title":"可获得的最大点数","uri":"/%E5%8F%AF%E8%8E%B7%E5%BE%97%E7%9A%84%E6%9C%80%E5%A4%A7%E7%82%B9%E6%95%B0/"},{"categories":["算法题"],"content":"滑动窗口中位数 ","date":"2021-02-25","objectID":"/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E4%B8%AD%E4%BD%8D%E6%95%B0/:0:0","tags":["算法题","滑动窗口中位数"],"title":"滑动窗口中位数","uri":"/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E4%B8%AD%E4%BD%8D%E6%95%B0/"},{"categories":["算法题"],"content":"题目： https://leetcode-cn.com/problems/sliding-window-median/ ","date":"2021-02-25","objectID":"/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E4%B8%AD%E4%BD%8D%E6%95%B0/:1:0","tags":["算法题","滑动窗口中位数"],"title":"滑动窗口中位数","uri":"/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E4%B8%AD%E4%BD%8D%E6%95%B0/"},{"categories":["算法题"],"content":"思路： 很明显的滑动窗口，首先定义一个求中位数的匿名函数，然后一点一点求出来 ","date":"2021-02-25","objectID":"/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E4%B8%AD%E4%BD%8D%E6%95%B0/:2:0","tags":["算法题","滑动窗口中位数"],"title":"滑动窗口中位数","uri":"/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E4%B8%AD%E4%BD%8D%E6%95%B0/"},{"categories":["算法题"],"content":"代码： class Solution: def medianSlidingWindow(self, nums: List[int], k: int) -\u003e List[float]: median = lambda a: (a[(len(a)-1)//2] + a[len(a)//2]) / 2 res = [] for i in range(len(nums)-k+1): res.append(median(sorted(nums[i:i+k]))) return res ","date":"2021-02-25","objectID":"/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E4%B8%AD%E4%BD%8D%E6%95%B0/:3:0","tags":["算法题","滑动窗口中位数"],"title":"滑动窗口中位数","uri":"/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E4%B8%AD%E4%BD%8D%E6%95%B0/"},{"categories":["NLP"],"content":"Seq2Seq中的Attention ","date":"2021-02-23","objectID":"/attention/:0:0","tags":["NLP","Attention"],"title":"Attention","uri":"/attention/"},{"categories":["NLP"],"content":"缺陷 在seq2seq这篇文章中详细介绍了seq2seq模型的细节，但是仅仅用一个语义编码c是完全不能够表示编码器的输入的，源的可能含义的数量是无限的。当编码器被迫将所有信息放入单个向量中时，它很可能会忘记一些东西。 不仅编码器很难将所有信息放入一个向量中——这对解码器来说也很困难。解码器只看到源的一种表示。但是，在每个生成步骤中，源的不同部分可能比其他部分更有用。但在目前的情况下，解码器必须从相同的固定表示中提取相关信息——这不是一件容易的事。 这个时候就需要引入注意力机制了，注意这里的注意力机制和transformer中的self-attention是不一样的。下面详细介绍一下。注意几个名词：注意力得分、注意力权重。其中注意力得分即score的计算有多种方法，权重就是对得分进行softmax归一化。 ","date":"2021-02-23","objectID":"/attention/:1:0","tags":["NLP","Attention"],"title":"Attention","uri":"/attention/"},{"categories":["NLP"],"content":"attention 注意机制是神经网络的一部分。在每个解码器步骤中，它决定哪些源部分更重要。在此设置中，编码器不必将整个源压缩为单个向量 - 它为所有源标记提供表示（例如，所有 RNN 状态而不是最后一个）。 步骤： - 接受注意输入：解码器状态\\(h_t\\)以及所有编码器状态\\(s_1,s_2,\\dots,s_m\\) - 计算每个编码器状态的注意力分数\\(s_k\\)，注意力分数表示它对解码器状态\\(h_t\\)的相关性，使用注意力函数，接收一个解码器状态和一个编码器状态并返回一个标量分数，即图中的\\(score(h_t,s_k)\\) - 计算注意力权重：即概率分布- 使用Softmax函数 - 计算注意力输出：具有注意力机制的编码器状态的加权和 即为如图所示内容为如何计算注意力。 注意我们提到的注意力函数，这里的注意力分数的计算有很多种方法，下面介绍几种比较常见的办法： - 点积： 最简单的办法。 - 双线性函数 - 多层感知机 注意后两者都有要优化的参数的，第一个点积是直接运算，因此很简单。 在应用时可以直接将注意力的结果传输到最后的softmax，也可以将原始的\\(h_t\\)合并，下面介绍几种变体。 ","date":"2021-02-23","objectID":"/attention/:2:0","tags":["NLP","Attention"],"title":"Attention","uri":"/attention/"},{"categories":["NLP"],"content":"Bahdanau Model - 编码器使用双向的RNN - 利用上一时刻的隐层状态计算注意力输出c，然后和隐层状态一起作为当前时刻的输入，再得到结果\\(\\hat{y}\\)。这里再说一下训练的过程中当前步的输入使用的是真实的\\(y\\)，测试的时候才会使用上一步的输出作为输入。可以将上下文向量c（也就是注意力输出）与\\(x\\)拼接后作为输入。 - 注意力得分使用的是感知机。 这里引用一下李沐大佬的代码： class Seq2SeqAttentionDecoder(AttentionDecoder): def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout=0, **kwargs): super(Seq2SeqAttentionDecoder, self).__init__(**kwargs) self.attention = d2l.AdditiveAttention( num_hiddens, num_hiddens, num_hiddens, dropout) self.embedding = nn.Embedding(vocab_size, embed_size) self.rnn = nn.GRU( embed_size + num_hiddens, num_hiddens, num_layers, dropout=dropout) self.dense = nn.Linear(num_hiddens, vocab_size) def init_state(self, enc_outputs, enc_valid_lens, *args): # outputs的形状为(batch_size，num_steps，num_hiddens). # hidden_state的形状为(num_layers，batch_size，num_hiddens) outputs, hidden_state = enc_outputs return (outputs.permute(1, 0, 2), hidden_state, enc_valid_lens) def forward(self, X, state): # enc_outputs的形状为(batch_size,num_steps,num_hiddens). # hidden_state的形状为(num_layers,batch_size, # num_hiddens) enc_outputs, hidden_state, enc_valid_lens = state # 输出X的形状为(num_steps,batch_size,embed_size) X = self.embedding(X).permute(1, 0, 2) # 转换是为了方便后面循环计算。 outputs, self._attention_weights = [], [] for x in X: # query的形状为(batch_size,1,num_hiddens) query = torch.unsqueeze(hidden_state[-1], dim=1) # -1是指在最后一层最后时刻的隐藏状态，作为query # context的形状为(batch_size,1,num_hiddens) context = self.attention( query, enc_outputs, enc_outputs, enc_valid_lens) # 在特征维度上连结 x = torch.cat((context, torch.unsqueeze(x, dim=1)), dim=-1) # 将x变形为(1,batch_size,embed_size+num_hiddens) out, hidden_state = self.rnn(x.permute(1, 0, 2), hidden_state) outputs.append(out) self._attention_weights.append(self.attention.attention_weights) # 全连接层变换后，outputs的形状为 # (num_steps,batch_size,vocab_size) outputs = self.dense(torch.cat(outputs, dim=0)) return outputs.permute(1, 0, 2), [enc_outputs, hidden_state, enc_valid_lens] @property def attention_weights(self): return self._attention_weights ","date":"2021-02-23","objectID":"/attention/:3:0","tags":["NLP","Attention"],"title":"Attention","uri":"/attention/"},{"categories":["NLP"],"content":"Luong Model 这个模型的编码器比较常规，使用当前状态计算注意力输出，然后解码器中将隐层状态与注意力输出做一步结合，这样得到了新的隐层状态，然后再传递得到预测结果。 ","date":"2021-02-23","objectID":"/attention/:4:0","tags":["NLP","Attention"],"title":"Attention","uri":"/attention/"},{"categories":["NLP"],"content":"注意力对齐 可以看到解码器关注的源token。 到此seq2seq中的attention就介绍完毕了，其实还有很多细节，以后遇到了会持续补充。 Self-attention 移步transformer。Transformer MQA image.png 标准的mha中，KV heads的数量和Query heads的数量相同，每一个q head对应一个独立的kv head，但这样的开销比较大。 MQA (Multi Queries Attention): MQA比较极端，只保留一个KV Head，多个Query Heads共享相同的KV Head。这相当于不同Head的Attention差异，全部都放在了Query上，需要模型仅从不同的Query Heads上就能够关注到输入hidden states不同方面的信息。这样做的好处是，极大地降低了KV Cache的需求，但是会导致模型效果有所下降。（层内共享） # GQA 如上图所示，GQA就是在MHA和MQA之间做了一个平衡。对query heads进行分组，分成几组就对应多少个kv heads，然后每一组内的query Heads共享相同的KV head。 GQA可以在减少计算量和KV Cache同时确保模型效果不受到大的影响。 # online attention ### 3-pass \\(\\mathsf{NO}\\)TATIONS \\(\\{m_i\\}{:}\\max_{j=1}^i\\left\\{x_j\\right\\}\\), with initial value \\(m_0=-\\infty.\\) \\(\\{d_i\\}{:}\\sum_{j=1}^ie^{x_j-m_N}\\), with initial value \\(d_0=0,d_N\\) is the denominator of safe softmax. \\(\\{a_i\\}{:\\text{ the final softmax value}}.\\) BODY \\(\\textbf{for }i\\leftarrow 1, N\\textbf{ do}\\) \\[m_i\\leftarrow\\max\\left(m_{i-1},x_i\\right)\\] \\(\\mathbf{end}\\) \\(\\textbf{for }i\\leftarrow 1, N\\textbf{ do}\\) \\[d_i\\leftarrow d_{i-1}+e^{x_i-m_N}\\] \\(\\mathbf{end}\\) \\(\\textbf{for }i\\leftarrow 1, N\\textbf{ do}\\) \\[a_i\\leftarrow\\frac{e^{x_i-m_N}}{d_N}\\] \\(\\mathbf{end}\\) 这是3step计算attention的方法，每一步都需要上一步的结果才可以继续计算。这样的话由于sram中没有足够的存储空间，因此需要多次访存。 ### online attention \\[\\begin{aligned} d_i^{\\prime}\u0026 =\\sum_{j=1}^ie^{x_j-m_i} \\\\ \u0026= \\left(\\sum_{j=1}^{i-1} e^{x_j-m_i}\\right)+e^{x_i-m_i} \\\\ \u0026= \\left(\\sum_{j=1}^{i-1} e^{x_j-m_{i-1}}\\right)e^{m_{i-1}-m_i}+e^{x_i-m_i} \\\\ \u0026= d_{i-1}' e^{m_{i-1}-m_i}+e^{x_i-m_i} \\end{aligned}\\] 找到迭代式之后就可以从3step降到2step \\[\\begin{aligned}\u0026\\mathbf{for~}i\\leftarrow1,N\\textbf{ do}\\\\\u0026\u0026\u0026m_i\u0026\u0026\\leftarrow\u0026\\max\\left(m_{i-1},x_i\\right)\\\\\u0026\u0026\u0026d_i^{\\prime}\u0026\u0026\\leftarrow\u0026d_{i-1}^{\\prime}e^{m_{i-1}-m_i}+e^{x_i-m_i}\\\\\u0026\\mathbf{end}\\\\\u0026\\mathbf{for~}i\\leftarrow1,N\\textbf{ do}\\\\\u0026\u0026\u0026a_i\\leftarrow\u0026\u0026\\frac{e^{x_i-m_N}}{d_N^{\\prime}}\\\\\u0026\\mathbf{end}\\end{aligned}\\] 好像FLOPs计算量并没有减少，甚至还略有增加，因为现在每次都需要计算额外的scale x值，也就是pre-softmax logits，由于需要O(N^2)的显存无法放在SRAM中。因此： 1. 要么提前计算好x，保存在全局显存中，需要O(N^2)的显存，容易爆显存。 2. 要么在算法中online计算，每次循环中去load一部分Q，K到片上内存，计算得到x。 Attention优化的目标就是避开第一种情况，尽可能节省显存，否则，LLM根本无法处理类似100K以上这种long context的情况。而对于第二种情况，我们不需要保存中间矩阵x，节省了显存，但是计算没有节省，并且增加了HBM IO Accesses（需要不断地load Q, K）。此时，2-pass算法相对于3-pass算法，可以减少一次整体的load Q, K以及减少一次对 xi 的online recompute，因为在2-pass的第一个pass中， xi 是被两次计算共享的。类似online-softmax这种算法，对应到Attention中的应用，就是Memory Efficient Attention（注意不是FlashAttention）。 flash attention safe softmax并没有1-pass算法，那么Attention会不会有呢？有！这就是FlashAttention！ 在使用online attention的情况下，从头开始计算attention score的过程如下： \\(\\operatorname{NOTATIONS}\\) \\(Q[k,:]:\\)the \\(k\\)-th row vector of \\(Q\\) matrix. \\(\\begin{aligned}O[k,:]:\\mathrm{~the~}k\\text{-th row of output }O\\mathrm{~matrix.}\\\\\\mathbf{V}[i,i]:\\mathrm{~the~}k\\text{-th row of output }O\\mathrm{~matrix.}\\end{aligned}\\) \\(V[i,:]{:\\text{ the }i\\text{-th row of }V\\text{ matrix}}.\\) \\(\\{\\boldsymbol{o}_i\\}{:}\\sum_{j=1}^ia_jV[j,:]\\), a row vector storing partial aggregation result \\(A[k,:i]\\times V[:i,:]\\) BODY \\(\\textbf{for }i\\leftarrow 1, N\\textbf{ do}\\) \\[\\begin{aligned}x_i\u0026\\leftarrow\\quad Q[k,:]\\:K^T[:,i]\\\\m_i\u0026\\leftarrow\\quad\\max\\left(m_{i-1},x_i\\right)\\\\d_i'\u0026\\leftarrow\\quad d_{i-1}'e^{m_{i-1}-m_i}+e^{x_i-m_i}\\end{aligned}\\] \\(\\mathbf{end}\\) \\(\\textbf{for }i\\leftarrow 1, N\\textbf{ do}\\) \\[\\begin{aligned}\u0026a_i\\:\\leftarrow\\:\\frac{e^{x_i-m_N}}{d_N^{\\prime}}\\\\\u0026o_i\\:\\leftarrow\\:o_{i-1}+a_i\\:V[i,:\\:]\\end{aligned}\\] \\(\\mathbf{end}\\) \\[O[k,:]\\leftarrow\\boldsymbol{o}_N\\] 优化思路和online attention一样，将\\(o_{i}\\)的计算简化以便于可以写成迭代式。 原来的\\(o_{i}\\)使用以下方式计算，依赖于全局的\\(m_{N}\\)和\\(d_{N}\\)。 \\[\\boldsymbol{o}_i:=\\sum_{j=1}^i\\left(\\frac{e^{x_j-m_N}}{d_N^{\\prime}}V[j,:]\\right)\\] 将其改写成如下形式： \\[\\boldsymbol{o}_i^{\\prime}:=\\left(\\sum_{j=1}^i\\frac{e^{x_j-m_i}}{d_i^{\\prime}}V[j,:]\\right)\\] 这样按照上面的方式拓展下去，可以找到一个循环迭代式。 \\[\\begin{aligned} \\mathbf{o}_i^{\\prime}\u0026 =\\sum_{j=1}^i\\frac{e^{x_j-m_i}}{d'}V[j,:] \\\\ \u0026= \\left(\\sum_{j=1}^{i-1}\\frac{e^{x_j-m_i}}{d_i^{\\prime}}V[j,:] \\right)+\\frac{e^{x_i-m_i}}{d_i^{\\prime}}V[i,:] \\\\ \u0026= \\left(\\sum_{j=1}^{i-1}\\frac{e^{x_j-m_{i-1}}}{d_{i-1}^{\\prime}}\\frac{e^{x_","date":"2021-02-23","objectID":"/attention/:5:0","tags":["NLP","Attention"],"title":"Attention","uri":"/attention/"},{"categories":["NLP"],"content":"PMI 点互信息 对于两个单词之间的PMI来说，可以这样计算： \\[ PMI(w,c) = \\log \\frac{p(w,c)}{p(w)p(c)} = \\log \\frac{N(w,c) |w,c|}{N(w)N(c)} \\] ## MI 在概率论和信息论中，两个随机变量的互信息（Mutual Information，简称MI）或转移信息（transinformation）是变量间相互依赖性的量度。不同于相关系数，互信息并不局限于实值随机变量，它更加一般且决定着联合分布 p(X,Y) 和分解的边缘分布的乘积 p(X)p(Y) 的相似程度。互信息(Mutual Information)是度量两个事件集合之间的相关性(mutual dependence)。互信息最常用的单位是bit。 ","date":"2021-02-22","objectID":"/ppmi/:1:0","tags":["NLP","PPMI"],"title":"PPMI","uri":"/ppmi/"},{"categories":["NLP"],"content":"定义 正式地，两个离散随机变量 X 和 Y 的互信息可以定义为： 其中 p(x,y) 是 X 和 Y 的联合概率分布函数，而p(x)和p(y)分别是 X 和 Y 的边缘概率分布函数。 在结果上互信息与信息增益是一样的，下面是详细的推导。 应用到文本特征选择： U、C都是二值随机变量，当文档包含词项t时，U的取值为1，否则0；当文档属于类别c时，C的取值1，否则0。简单的理解就是对于文本来说，每一个token就是它的特征，取值只有有或者没有，也就是0或者1，互信息常用于文本特征的选择，也就 是选择有价值的token。在贝叶斯文本分类中用到了，特此记录。 \\[ I_k = \\sum_{\\tilde{y}=0}^1 \\bigg(p(X = k | Y = \\tilde{y})p(Y = \\tilde{y}) \\log\\frac{p(X = k | Y = \\tilde{y})}{p(X=k)} + (1-p(X = k | Y = \\tilde{y}))p(Y = \\tilde{y}) \\log\\frac{1 - p(X = k | Y = \\tilde{y})}{1 - p(X = k)}\\bigg), \\] 公式如上。\\(I_k\\)意味着单词k与Y之间的互信息。 示例代码如下： def calculateMI(dtm_ham_train, dtm_spam_train): ham_sums = np.sum(dtm_ham_train, axis=0) ham_probs = ham_sums / np.sum(ham_sums) spam_sums = np.sum(dtm_spam_train, axis=0) spam_probs = spam_sums / np.sum(spam_sums) all_sums = ham_sums + spam_sums all_probs = all_sums / sum(all_sums) mi = [] for i in range(len(all_probs)): if all_probs[i] == 0 or np.isnan(all_probs[i]): mi.append(0) else: mi.append(.5 * ham_probs[i] * np.log(ham_probs[i] / all_probs[i]) + .5 * (1 - ham_probs[i]) * np.log((1 - ham_probs[i])/(1 - all_probs[i])) + .5 * spam_probs[i] * np.log(spam_probs[i] / all_probs[i]) + .5 * (1 - spam_probs[i]) * np.log((1 - spam_probs[i])/(1 - all_probs[i]))) mi = np.array(mi) mi = np.where(np.isnan(mi), 0, mi) return mi ","date":"2021-02-22","objectID":"/ppmi/:1:1","tags":["NLP","PPMI"],"title":"PPMI","uri":"/ppmi/"},{"categories":["NLP"],"content":"PPMI ","date":"2021-02-22","objectID":"/ppmi/:2:0","tags":["NLP","PPMI"],"title":"PPMI","uri":"/ppmi/"},{"categories":["算法题"],"content":"至少有k个重复字符的最长字串 ","date":"2021-02-18","objectID":"/%E8%87%B3%E5%B0%91%E6%9C%89k%E4%B8%AA%E9%87%8D%E5%A4%8D%E5%AD%97%E7%AC%A6%E7%9A%84%E6%9C%80%E9%95%BF%E5%AD%97%E4%B8%B2/:0:0","tags":["算法题","至少有k个重复字符的最长字串"],"title":"至少有k个重复字符的最长字串","uri":"/%E8%87%B3%E5%B0%91%E6%9C%89k%E4%B8%AA%E9%87%8D%E5%A4%8D%E5%AD%97%E7%AC%A6%E7%9A%84%E6%9C%80%E9%95%BF%E5%AD%97%E4%B8%B2/"},{"categories":["算法题"],"content":"题目： https://leetcode-cn.com/problems/longest-substring-with-at-least-k-repeating-characters/ ","date":"2021-02-18","objectID":"/%E8%87%B3%E5%B0%91%E6%9C%89k%E4%B8%AA%E9%87%8D%E5%A4%8D%E5%AD%97%E7%AC%A6%E7%9A%84%E6%9C%80%E9%95%BF%E5%AD%97%E4%B8%B2/:1:0","tags":["算法题","至少有k个重复字符的最长字串"],"title":"至少有k个重复字符的最长字串","uri":"/%E8%87%B3%E5%B0%91%E6%9C%89k%E4%B8%AA%E9%87%8D%E5%A4%8D%E5%AD%97%E7%AC%A6%E7%9A%84%E6%9C%80%E9%95%BF%E5%AD%97%E4%B8%B2/"},{"categories":["算法题"],"content":"思路： 利用递归，如果s中字符c的数目小于k,则以c作分割，分成的字串再次调用函数形成递归，然后从众多结果中找寻最大长度的。 ","date":"2021-02-18","objectID":"/%E8%87%B3%E5%B0%91%E6%9C%89k%E4%B8%AA%E9%87%8D%E5%A4%8D%E5%AD%97%E7%AC%A6%E7%9A%84%E6%9C%80%E9%95%BF%E5%AD%97%E4%B8%B2/:2:0","tags":["算法题","至少有k个重复字符的最长字串"],"title":"至少有k个重复字符的最长字串","uri":"/%E8%87%B3%E5%B0%91%E6%9C%89k%E4%B8%AA%E9%87%8D%E5%A4%8D%E5%AD%97%E7%AC%A6%E7%9A%84%E6%9C%80%E9%95%BF%E5%AD%97%E4%B8%B2/"},{"categories":["算法题"],"content":"代码： class Solution(object): def longestSubstring(self, s, k): if len(s) \u003c k: return 0 for c in set(s): if s.count(c) \u003c k: return max(self.longestSubstring(t, k) for t in s.split(c)) return len(s) ","date":"2021-02-18","objectID":"/%E8%87%B3%E5%B0%91%E6%9C%89k%E4%B8%AA%E9%87%8D%E5%A4%8D%E5%AD%97%E7%AC%A6%E7%9A%84%E6%9C%80%E9%95%BF%E5%AD%97%E4%B8%B2/:3:0","tags":["算法题","至少有k个重复字符的最长字串"],"title":"至少有k个重复字符的最长字串","uri":"/%E8%87%B3%E5%B0%91%E6%9C%89k%E4%B8%AA%E9%87%8D%E5%A4%8D%E5%AD%97%E7%AC%A6%E7%9A%84%E6%9C%80%E9%95%BF%E5%AD%97%E4%B8%B2/"},{"categories":["算法题"],"content":"最长递增子序列 ","date":"2021-02-17","objectID":"/%E6%9C%80%E9%95%BF%E9%80%92%E5%A2%9E%E5%AD%90%E5%BA%8F%E5%88%97/:0:0","tags":["算法题","最长递增子序列"],"title":"最长递增子序列","uri":"/%E6%9C%80%E9%95%BF%E9%80%92%E5%A2%9E%E5%AD%90%E5%BA%8F%E5%88%97/"},{"categories":["算法题"],"content":"题目： https://leetcode-cn.com/problems/longest-increasing-subsequence/ ","date":"2021-02-17","objectID":"/%E6%9C%80%E9%95%BF%E9%80%92%E5%A2%9E%E5%AD%90%E5%BA%8F%E5%88%97/:1:0","tags":["算法题","最长递增子序列"],"title":"最长递增子序列","uri":"/%E6%9C%80%E9%95%BF%E9%80%92%E5%A2%9E%E5%AD%90%E5%BA%8F%E5%88%97/"},{"categories":["算法题"],"content":"思路： 动态规划 定义dp[i]为到nums[i]的最长递增子序列的长度，全部都初始化为1,因为本身就是长度为1的递增子序列 ","date":"2021-02-17","objectID":"/%E6%9C%80%E9%95%BF%E9%80%92%E5%A2%9E%E5%AD%90%E5%BA%8F%E5%88%97/:2:0","tags":["算法题","最长递增子序列"],"title":"最长递增子序列","uri":"/%E6%9C%80%E9%95%BF%E9%80%92%E5%A2%9E%E5%AD%90%E5%BA%8F%E5%88%97/"},{"categories":["算法题"],"content":"代码： class Solution: def lengthOfLIS(self, nums: List[int]) -\u003e int: dp = [1 for _ in range(len(nums))] for i in range(1,len(nums)): for j in range(i): if nums[j] \u003c nums[i]: dp[i] = max(dp[i],dp[j]+1) return max(dp) ","date":"2021-02-17","objectID":"/%E6%9C%80%E9%95%BF%E9%80%92%E5%A2%9E%E5%AD%90%E5%BA%8F%E5%88%97/:3:0","tags":["算法题","最长递增子序列"],"title":"最长递增子序列","uri":"/%E6%9C%80%E9%95%BF%E9%80%92%E5%A2%9E%E5%AD%90%E5%BA%8F%E5%88%97/"},{"categories":["算法题"],"content":"外观数列 https://leetcode-cn.com/problems/count-and-say/ 这题有意思 可以打表，不过打表的过程也相当于做出来了 class Solution: def countAndSay(self,n: int) -\u003e str: if n == 1: return '1' s = self.countAndSay(n - 1) n,res = 0,'' for ii,ss in enumerate(s): if ss != s[n]: res += str(ii-n) + s[n] n = ii res += str(len(s) - n) + s[-1] return res print(Solution().countAndSay(3)) 思路： ​ 递归，将上一层计算出来的东西作为迭代对象。 ","date":"2021-02-16","objectID":"/%E5%A4%96%E8%A7%82%E6%95%B0%E5%88%97/:0:0","tags":["算法题","外观数列"],"title":"外观数列","uri":"/%E5%A4%96%E8%A7%82%E6%95%B0%E5%88%97/"},{"categories":["pandas","api"],"content":"调用为np.lib.stride_tricks.as_strided() 可以分割一个数组为不同的shape块，有个问题就是什么是strides呢？可以看个例子： a = np.arange(9, dtype=np.int32).reshape(3,3) print(a) ''' [[0 1 2] [3 4 5] [6 7 8]] ''' print(a.strides) ''' (12, 4) ''' 这里（12， 4）中的12表示在内存中a[n, 0]到a[n+1, 0]跨过多少byte，4表示在内存中a[n, 0]到a[n, 1]跨过多少byte。 32int需要4byte是众所周知。 看一下函数的参数： numpy.lib.stride_tricks.as_strided(x, shape=None, strides=None, subok=False, writeable=True) x就是我们要分割的矩阵，可以当做是一个蓝图，shape，strides都是新矩阵的属性，也就是说这个函数按照给定的shape和strides来划分x，返回一个新的矩阵。 对于X： 如果卷积核的大小是2x2，stride为1，那么就需要把矩阵X转换为包含如下4个小矩阵的新矩阵A： 很明显A的维度为(2,2,2,2)。 所以shape可以确定，但strides还不确定： A = as_strided(X, shape=(2,2,2,2), strides) 下面确定strides，从图中可以确定最低维的为4，因为所有数据都在X上，所以A的各个维度的跨度都要根据X来确定，而不是A中，以1和4为例子，在X中的距离为12字节，所以现在可以确定后两维：（?,?,12,4）。 再看更高维度: 从X中可以看到，第二维的距离为4。 第一维也不多说，是12。 最后可以strides =（12，4，12，4）。 这就是整个分析的过程，可以方便卷积操作，不是嘛。 再看一个例子就结束了，估计以后会忘，记录下来。 意思就是将一个向量拓展成这样的形式，用循环的方法很容易实现： def sliding_stack_py(v, k): \"Stack sliding windows of v of length k.\" rows = [] for i in range(len(v) - k + 1): rows.append(v[i : (i + k)]) return np.array(rows) 但如果不能使用循环呢，就可以用刚说的这个函数了: def sliding_stack_np(v, k): return np.lib.stride_tricks.as_strided(v, shape=(len(v) - k + 1, k), strides=(v.strides[0], v.strides[0])) 因为原向量是1维的，所以转换后的strides为[4,4]。希望可以帮助理解。 ","date":"2021-02-14","objectID":"/as_strided/:0:0","tags":["pandas","api","as_strided"],"title":"as_strided","uri":"/as_strided/"},{"categories":["NLP"],"content":"NER(命名实体识别) 参考：https://www.jianshu.com/p/16e1f6a7aaef 命名实体识别（Named Entity Recognition，简称NER）是信息提取、问答系统、句法分析、机器翻译等应用领域的重要基础工具，在自然语言处理技术走向实用化的过程中占有重要地位。一般来说，命名实体识别的任务就是识别出待处理文本中三大类（实体类、时间类和数字类）、七小类（人名、机构名、地名、时间、日期、货币和百分比）命名实体。 举个简单的例子，在句子“小明早上8点去学校上课。”中，对其进行命名实体识别，应该能提取信息 人名：小明，时间：早上8点，地点：学校。 ","date":"2021-02-06","objectID":"/ner/:0:0","tags":["NLP","NER"],"title":"NER","uri":"/ner/"},{"categories":["算法题"],"content":"阶乘函数后K个零(首个困难题) ","date":"2021-02-05","objectID":"/%E9%98%B6%E4%B9%98%E5%87%BD%E6%95%B0%E5%90%8Ek%E4%B8%AA%E9%9B%B6%E9%A6%96%E4%B8%AA%E5%9B%B0%E9%9A%BE%E9%A2%98/:0:0","tags":["算法题","阶乘函数后K个零(首个困难题)"],"title":"阶乘函数后K个零(首个困难题)","uri":"/%E9%98%B6%E4%B9%98%E5%87%BD%E6%95%B0%E5%90%8Ek%E4%B8%AA%E9%9B%B6%E9%A6%96%E4%B8%AA%E5%9B%B0%E9%9A%BE%E9%A2%98/"},{"categories":["算法题"],"content":"题目： https://leetcode-cn.com/problems/preimage-size-of-factorial-zeroes-function/ ","date":"2021-02-05","objectID":"/%E9%98%B6%E4%B9%98%E5%87%BD%E6%95%B0%E5%90%8Ek%E4%B8%AA%E9%9B%B6%E9%A6%96%E4%B8%AA%E5%9B%B0%E9%9A%BE%E9%A2%98/:1:0","tags":["算法题","阶乘函数后K个零(首个困难题)"],"title":"阶乘函数后K个零(首个困难题)","uri":"/%E9%98%B6%E4%B9%98%E5%87%BD%E6%95%B0%E5%90%8Ek%E4%B8%AA%E9%9B%B6%E9%A6%96%E4%B8%AA%E5%9B%B0%E9%9A%BE%E9%A2%98/"},{"categories":["算法题"],"content":"思路： 首先先写个判断阶乘后有多少个零的函数，思路就是找所有相乘的数中因数有5的个数。 然后再用二分查找，找到有K个0的左界和右界，然后相减即可，就是要找的数目 class Solution: def preimageSizeFZF(self, K: int) -\u003e int: return self.findright(K) - self.findleft(K) def whatzero(self,n): dis = 5 res = 0 while dis \u003c= n: res += n // dis dis *= 5 return res def findleft(self,K): mins,maxs = 0,sys.maxsize while (mins \u003c maxs): mid = mins + (maxs-mins) // 2 if self.whatzero(mid) \u003c K: mins = mid + 1 elif self.whatzero(mid) \u003e K: maxs = mid else: maxs = mid return mins def findright(self,K): mins,maxs = 0,sys.maxsize while (mins \u003c maxs): mid = mins + (maxs-mins) // 2 if self.whatzero(mid) \u003c K: mins = mid + 1 elif self.whatzero(mid) \u003e K: maxs = mid else: mins = mid + 1 return maxs 注意这里的最大值要初始化为sys库里的maxsize 用float(“inf”)会返回nan值 ","date":"2021-02-05","objectID":"/%E9%98%B6%E4%B9%98%E5%87%BD%E6%95%B0%E5%90%8Ek%E4%B8%AA%E9%9B%B6%E9%A6%96%E4%B8%AA%E5%9B%B0%E9%9A%BE%E9%A2%98/:2:0","tags":["算法题","阶乘函数后K个零(首个困难题)"],"title":"阶乘函数后K个零(首个困难题)","uri":"/%E9%98%B6%E4%B9%98%E5%87%BD%E6%95%B0%E5%90%8Ek%E4%B8%AA%E9%9B%B6%E9%A6%96%E4%B8%AA%E5%9B%B0%E9%9A%BE%E9%A2%98/"},{"categories":["算法题"],"content":"打家劫舍 ","date":"2021-02-04","objectID":"/%E6%89%93%E5%AE%B6%E5%8A%AB%E8%88%8D/:0:0","tags":["算法题","打家劫舍"],"title":"打家劫舍","uri":"/%E6%89%93%E5%AE%B6%E5%8A%AB%E8%88%8D/"},{"categories":["算法题"],"content":"打家劫舍I ","date":"2021-02-04","objectID":"/%E6%89%93%E5%AE%B6%E5%8A%AB%E8%88%8D/:1:0","tags":["算法题","打家劫舍"],"title":"打家劫舍","uri":"/%E6%89%93%E5%AE%B6%E5%8A%AB%E8%88%8D/"},{"categories":["算法题"],"content":"题目： https://leetcode-cn.com/problems/house-robber/ ","date":"2021-02-04","objectID":"/%E6%89%93%E5%AE%B6%E5%8A%AB%E8%88%8D/:1:1","tags":["算法题","打家劫舍"],"title":"打家劫舍","uri":"/%E6%89%93%E5%AE%B6%E5%8A%AB%E8%88%8D/"},{"categories":["算法题"],"content":"思路: 一个简单题，不过踩了特例的坑。。可以暴力解决 也可以动态规划 ","date":"2021-02-04","objectID":"/%E6%89%93%E5%AE%B6%E5%8A%AB%E8%88%8D/:1:2","tags":["算法题","打家劫舍"],"title":"打家劫舍","uri":"/%E6%89%93%E5%AE%B6%E5%8A%AB%E8%88%8D/"},{"categories":["算法题"],"content":"代码: 暴力解决 class Solution: def rob(nums): if nums == []: return 0 if len(nums) == 1: return nums[0] if len(nums) == 2: return max(nums[0],nums[1]) maxs = [] #max[i]代表到i+1家的最大价钱 maxs.append(nums[0]) maxs.append(nums[1]) for i in range(2,len(nums)): maxs.append(max(maxs[:i-1])+nums[i]) #从头到这家前面的第二家最大的价钱加上这一家的价钱 return max(maxs) 动态规划 class Solution: def rob(self, nums: List[int]) -\u003e int: if len(nums) \u003c= 2: return max(nums) dp = [0] * len(nums) dp[0], dp[1] = nums[0], max(nums[0], nums[1]) for i in range(2, len(nums)): dp[i] = max(dp[i-1], dp[i-2] + nums[i]) return max(dp) ","date":"2021-02-04","objectID":"/%E6%89%93%E5%AE%B6%E5%8A%AB%E8%88%8D/:1:3","tags":["算法题","打家劫舍"],"title":"打家劫舍","uri":"/%E6%89%93%E5%AE%B6%E5%8A%AB%E8%88%8D/"},{"categories":["算法题"],"content":"打家劫舍II ","date":"2021-02-04","objectID":"/%E6%89%93%E5%AE%B6%E5%8A%AB%E8%88%8D/:2:0","tags":["算法题","打家劫舍"],"title":"打家劫舍","uri":"/%E6%89%93%E5%AE%B6%E5%8A%AB%E8%88%8D/"},{"categories":["算法题"],"content":"题目： https://leetcode-cn.com/problems/house-robber-ii/ ","date":"2021-02-04","objectID":"/%E6%89%93%E5%AE%B6%E5%8A%AB%E8%88%8D/:2:1","tags":["算法题","打家劫舍"],"title":"打家劫舍","uri":"/%E6%89%93%E5%AE%B6%E5%8A%AB%E8%88%8D/"},{"categories":["算法题"],"content":"思路： 跟上面的题目非常类似，只是加了一个限制条件，就是第一家和最后一家不能同时打劫。 这里先写一个函数，表示从start 到end 范围里面的最大值，然后在主函数里面进行选择 如果打劫第一家，就不能打劫最后一家以及不打劫第一家去打劫最后一家，这两者之间的最大值 ","date":"2021-02-04","objectID":"/%E6%89%93%E5%AE%B6%E5%8A%AB%E8%88%8D/:2:2","tags":["算法题","打家劫舍"],"title":"打家劫舍","uri":"/%E6%89%93%E5%AE%B6%E5%8A%AB%E8%88%8D/"},{"categories":["算法题"],"content":"代码： class Solution: def rob(self, nums: List[int]) -\u003e int: if len(nums) == 1: return nums[0] return max(self.dp(0,len(nums)-2,nums),self.dp(1,len(nums)-1,nums)) def dp(self,start,end,nums): dp = [0 for _ in range(len(nums)+2)] for i in range(end,start-1,-1): dp[i] = max(dp[i+1],dp[i+2]+nums[i]) return dp[start] ","date":"2021-02-04","objectID":"/%E6%89%93%E5%AE%B6%E5%8A%AB%E8%88%8D/:2:3","tags":["算法题","打家劫舍"],"title":"打家劫舍","uri":"/%E6%89%93%E5%AE%B6%E5%8A%AB%E8%88%8D/"},{"categories":["python"],"content":"import threading import time 简单的创建 def run(n): print(\"task\", n) time.sleep(1) print('2s') time.sleep(1) print('1s') time.sleep(1) print('0s') time.sleep(1) if __name__ == '__main__': t1 = threading.Thread(target=run, args=(\"t1\",)) t2 = threading.Thread(target=run, args=(\"t2\",)) t1.start() t2.start() 通过类创建 class MyThread(threading.Thread): def __init__(self, n): super(MyThread, self).__init__() # 重构run函数必须要写 self.n = n def run(self): print(\"task\", self.n) time.sleep(1) print('2s') time.sleep(1) print('1s') time.sleep(1) print('0s') time.sleep(1) if __name__ == \"__main__\": t1 = MyThread(\"t1\") t2 = MyThread(\"t2\") t1.start() t2.start() 对比没有join()和join()的区别 def run(n): print(\"task\", n) time.sleep(1) #此时子线程停1s print('3') time.sleep(1) print('2') time.sleep(1) print('1') if __name__ == '__main__': t = threading.Thread(target=run, args=(\"t1\",)) t.setDaemon(True) #把子进程设置为守护线程，必须在start()之前设置 t.start() print(\"end\") def run(n): print(\"task\", n) time.sleep(1) #此时子线程停1s print('3') time.sleep(1) print('2') time.sleep(1) print('1') if __name__ == '__main__': t = threading.Thread(target=run, args=(\"t1\",)) t.setDaemon(True) #把子进程设置为守护线程，必须在start()之前设置 t.start() t.join() # 设置主线程等待子线程结束 print(\"end\") 锁的应用 def run(n, semaphore): semaphore.acquire() #加锁 time.sleep(1) print(\"run the thread:%s\\n\" % n) semaphore.release() #释放 if __name__ == '__main__': num = 0 semaphore = threading.BoundedSemaphore(5) # 最多允许5个线程同时运行 for i in range(22): t = threading.Thread(target=run, args=(\"t-%s\" % i, semaphore)) t.start() while threading.active_count() != 1: pass # print threading.active_count() else: print('--') 事件类 event = threading.Event() def lighter(): count = 0 event.set() #初始值为绿灯 while True: if 5 \u003c count \u003c=10 : event.clear() # 红灯，清除标志位 print(\"\\33[41;1mred light is on...\\033[0m\") elif count \u003e 10: event.set() # 绿灯，设置标志位 count = 0 else: print(\"\\33[42;1mgreen light is on...\\033[0m\") time.sleep(1) count += 1 def car(name): while True: if event.is_set(): #判断是否设置了标志位（绿灯） print(\"[%s] running...\"%name) time.sleep(1) else: print(\"[%s] sees red light,waiting...\"%name) event.wait()#如果变为绿灯 print(\"[%s] green light is on,start going...\"%name) light = threading.Thread(target=lighter,) light.start() car = threading.Thread(target=car,args=(\"MINI\",)) car.start() queue队列 import threading import queue,time q=queue.Queue(maxsize=10) def Producer(name): count=1 while True: q.put(\"骨头 %s\"%count) print(\"{}生产了骨头\".format(name),count) count+=1 time.sleep(1) def Consumer(name): while True: print(\"[%s] 取到 [%s] 并且吃了它。。。\"%(name,q.get())) time.sleep(1) p=threading.Thread(target=Producer,args=('wlb',)) c=threading.Thread(target=Consumer,args=(\"dog\",)) c1=threading.Thread(target=Consumer,args=(\"cat\",)) p.start() c.start() c1.start() 互斥锁 由于线程之间是进行随机调度，并且每个线程可能只执行n条执行之后，当多个线程同时修改同一条数据时可能会出现脏数据，所以，出现了线程锁，即同一时刻允许一个线程执行操作。线程锁用于锁定资源，你可以定义多个锁, 像下面的代码, 当你需要独占某一资源时，任何一个锁都可以锁这个资源，就好比你用不同的锁都可以把相同的一个门锁住是一个道理。 由于线程之间是进行随机调度，如果有多个线程同时操作一个对象，如果没有很好地保护该对象，会造成程序结果的不可预期，我们也称此为“线程不安全”。 为了方式上面情况的发生，就出现了互斥锁(Lock) from threading import Thread,Lock import os,time def work(): global n lock.acquire() temp=n time.sleep(0.1) n=temp-1 lock.release() if __name__ == '__main__': lock=Lock() n=100 l=[] for i in range(100): p=Thread(target=work) l.append(p) p.start() for p in l: p.join() 信号量 互斥锁同时只允许一个线程更改数据，而Semaphore是同时允许一定数量的线程更改数据 ，比如厕所有3个坑，那最多只允许3个人上厕所，后面的人只能等里面有人出来了才能再进去。 import threading import time def run(n, semaphore): semaphore.acquire() #加锁 time.sleep(1) print(\"run the thread:%s\\n\" % n) semaphore.release() #释放 if __name__ == '__main__': num = 0 semaphore = threading.BoundedSemaphore(5) # 最多允许5个线程同时运行 for i in range(22): t = threading.Thread(target=run, args=(\"t-%s\" % i, semaphore)) t.start() while threading.active_count() != 1: pass # print threading.active_count() else: print('--') GIL（Global Interpreter Lock）全局解释器锁 在非python环境中，单核情况下，同时只能有一个任务执行。多核时可以支持多个线程同时执行。但是在python中，无论有多少核，同时只能执行一个线程。究其原因，这就是由于GIL的存在导致的。 GIL的全称是Global Interpreter Lock(全局解释器锁)，来源是python设计之初的考虑，为了数据安全所做的决定。某个线程想要执行，必须先拿到GIL，我们可以把GIL看作是“通行证”，并且在","date":"2021-01-21","objectID":"/thread/:0:0","tags":["python","thread"],"title":"thread","uri":"/thread/"},{"categories":["算法题"],"content":"丑数系列 ","date":"2021-01-18","objectID":"/%E4%B8%91%E6%95%B0%E7%B3%BB%E5%88%97/:0:0","tags":["算法题","丑数系列"],"title":"丑数系列","uri":"/%E4%B8%91%E6%95%B0%E7%B3%BB%E5%88%97/"},{"categories":["算法题"],"content":"1.丑数 ","date":"2021-01-18","objectID":"/%E4%B8%91%E6%95%B0%E7%B3%BB%E5%88%97/:1:0","tags":["算法题","丑数系列"],"title":"丑数系列","uri":"/%E4%B8%91%E6%95%B0%E7%B3%BB%E5%88%97/"},{"categories":["算法题"],"content":"题目： https://leetcode-cn.com/problems/ugly-number/ ","date":"2021-01-18","objectID":"/%E4%B8%91%E6%95%B0%E7%B3%BB%E5%88%97/:1:1","tags":["算法题","丑数系列"],"title":"丑数系列","uri":"/%E4%B8%91%E6%95%B0%E7%B3%BB%E5%88%97/"},{"categories":["算法题"],"content":"思路： 就是让这个数字不断地除以2.3.5 如果最后变成了1 就说明是个丑数 ","date":"2021-01-18","objectID":"/%E4%B8%91%E6%95%B0%E7%B3%BB%E5%88%97/:1:2","tags":["算法题","丑数系列"],"title":"丑数系列","uri":"/%E4%B8%91%E6%95%B0%E7%B3%BB%E5%88%97/"},{"categories":["算法题"],"content":"代码： class Solution: def isUgly(self, num: int) -\u003e bool: if num\u003c=-231 or num\u003e=231-1: return False while num \u003e1: if num %2 == 0: num=int(num/2) elif num %3 ==0: num =int(num/3) elif num %5 ==0: num=int(num/5) else: break if num == 1: return True else: return False ","date":"2021-01-18","objectID":"/%E4%B8%91%E6%95%B0%E7%B3%BB%E5%88%97/:1:3","tags":["算法题","丑数系列"],"title":"丑数系列","uri":"/%E4%B8%91%E6%95%B0%E7%B3%BB%E5%88%97/"},{"categories":["算法题"],"content":"丑数II ","date":"2021-01-18","objectID":"/%E4%B8%91%E6%95%B0%E7%B3%BB%E5%88%97/:2:0","tags":["算法题","丑数系列"],"title":"丑数系列","uri":"/%E4%B8%91%E6%95%B0%E7%B3%BB%E5%88%97/"},{"categories":["算法题"],"content":"题目： https://leetcode-cn.com/problems/ugly-number-ii/ ","date":"2021-01-18","objectID":"/%E4%B8%91%E6%95%B0%E7%B3%BB%E5%88%97/:2:1","tags":["算法题","丑数系列"],"title":"丑数系列","uri":"/%E4%B8%91%E6%95%B0%E7%B3%BB%E5%88%97/"},{"categories":["算法题"],"content":"思路： 利用三指针，维护i2 i3 i5三个指针分别指向2 3 5 ","date":"2021-01-18","objectID":"/%E4%B8%91%E6%95%B0%E7%B3%BB%E5%88%97/:2:2","tags":["算法题","丑数系列"],"title":"丑数系列","uri":"/%E4%B8%91%E6%95%B0%E7%B3%BB%E5%88%97/"},{"categories":["算法题"],"content":"代码： class Solution: def nthUglyNumber(self, n: int) -\u003e int: res = [1] # 先初始化为1 i2 = i3 = i5 = 0 # 初始化为0 for i in range(1,n): mins = min(res[i2]*2,res[i3]*3,res[i5]*5) # 从小到大找 res.append(mins) if res[i] == res[i2]*2: i2 += 1 if res[i] == res[i3]*3: i3 += 1 if res[i] == res[i5]*5: i5 += 1 return res[n-1] ","date":"2021-01-18","objectID":"/%E4%B8%91%E6%95%B0%E7%B3%BB%E5%88%97/:2:3","tags":["算法题","丑数系列"],"title":"丑数系列","uri":"/%E4%B8%91%E6%95%B0%E7%B3%BB%E5%88%97/"},{"categories":["Machine Learning","集成学习","Boosting"],"content":"梯度提升决策树(GBDT) GBDT(Gradient Boosting Decision Tree)是一种迭代的决策树算法，由多棵决策树组成，所有树的结论累加起来作为最终答案。 ","date":"2021-01-06","objectID":"/gbdt/:0:0","tags":["Machine Learning","集成学习","Boosting","GBDT"],"title":"GBDT","uri":"/gbdt/"},{"categories":["Machine Learning","集成学习","Boosting"],"content":"回归树 选择最优切分变量j与切分点s：遍历变量j，对规定的切分变量j扫描切分点s，选择使下式得到最小 值时的(j,s)对。其中Rm是被划分的输入空间， \\(\\mathrm{cm}\\) 是空间Rm对应的固定输出值。 \\[ \\min_{j, s}\\left[\\min_{c_{1}} \\sum_{x_{i} \\in R_{i}(j, s)}\\left(y_{i}-c_{1}\\right)^{2}+\\min_{c_{2}} \\sum_{x_{i} \\in R_{i}(j, s)}\\left(y_{i}-c_{1}\\right)^{2}\\right] \\] 用选定的(j,s)对，划分区域并决定相应的输出值 \\[ \\begin{gathered} R_{1}(j, s)=\\{x \\mid x^{(j)} \\leq s\\}, R_{2}(j, s)=\\{x \\mid x^{(j)}\u003es\\} \\\\\\\\ \\hat{c}_{m}=\\frac{1}{N_{m}} \\sum_{x_{i} \\in R_{m}(j, s)} y_{i} \\\\\\\\ x \\in R_{m}, m=1,2 \\end{gathered} \\] 继续对两个子区域调用上述步骤，将输入空间划分为 \\(M\\) 个区域R1,R2,..,Rm，生成决策树。 \\[ f(x)=\\sum_{m=1}^{M} \\hat{c}_{m} I\\left(x \\epsilon R_{m}\\right) \\] 当输入空间划分确定时，可以用平方误差来表示回归树对于训练数据的预测方法，用平方误差最小 的准则求解每个单元上的最优输出值。 ","date":"2021-01-06","objectID":"/gbdt/:1:0","tags":["Machine Learning","集成学习","Boosting","GBDT"],"title":"GBDT","uri":"/gbdt/"},{"categories":["Machine Learning","集成学习","Boosting"],"content":"提升树 梯度提升树是提升树（Boosting Tree）的一种改进算法，所以在讲梯度提升树之前先来说一下提升树。 先来个通俗理解：假如有个人30岁，我们首先用20岁去拟合，发现损失有10岁，这时我们用6岁去拟合剩下的损失，发现差距还有4岁，第三轮我们用3岁拟合剩下的差距，差距就只有一岁了。如果我们的迭代轮数还没有完，可以继续迭代下面，每一轮迭代，拟合的岁数误差都会减小。最后将每次拟合的岁数加起来便是模型输出的结果。 提升树算法: (1) 初始化 \\(f_{0}(x)=0\\) (2) 对 \\(m=1,2, \\ldots, M\\) (a) 计算残差 \\[ r_{m i}=y_{i}-f_{m-1}(x), i=1,2, \\ldots, N \\] 为什么残差是这种形式？ 当采用平方误差损失函数时, \\[ L(y, f(x))=(y-f(x))^2 \\] 其损失变为 \\[ \\begin{aligned} L\\left(y, f_{m-1}(x)+T\\left(x ; \\Theta_m\\right)\\right) \u0026=\\left[y-f_{m-1}(x)-T\\left(x ; \\Theta_m\\right)\\right]^2 \\\\\\\\ \u0026=\\left[r-T\\left(x ; \\Theta_m\\right)\\right]^2 \\end{aligned} \\] 这里, \\[ r=y-f_{m-1}(x) \\] 也可以用上一步的残差（定义的上一步的标签）减去拟合上一步残差的回归树。即： \\[ r_{mi} = r_{(m-1)i} - h_{m-1}(x) \\] 易证明这两种形式等价。 (b) 拟合残差 \\(r_{m i}\\) 学习一个回归树，得到 \\(h_{m}(x)\\) (c) 更新 \\(f_{m}(x)=f_{m-1}+h_{m}(x)\\) (3) 得到回归问题提升树 \\[ f_{M}(x)=\\sum_{m=1}^{M} h_{m}(x) \\] ","date":"2021-01-06","objectID":"/gbdt/:2:0","tags":["Machine Learning","集成学习","Boosting","GBDT"],"title":"GBDT","uri":"/gbdt/"},{"categories":["Machine Learning","集成学习","Boosting"],"content":"GBDT GBDT与提升树不同的是GBDT使用负梯度来近似残差。 GBDT算法: (1) 初始化弱学习器 \\[ f_{0}(x)=\\arg \\min_{c} \\sum_{i=1}^{N} L\\left(y_{i}, c\\right) \\] 对 \\(m=1,2, \\ldots, M\\) 有: 对每个样本 \\(i=1,2, \\ldots, N\\) ，计算负梯度，即残差 \\[ r_{i m}=-\\left[\\frac{\\left.\\partial L\\left(y_{i}, f\\left(x_{i}\\right)\\right)\\right)}{\\partial f\\left(x_{i}\\right)}\\right]_{f(x)=f_{m-1}(x)} \\] 一般回归的损失函数就是均方误差，但缺点是对于outlier比较敏感。 因此可以选择使用MAE或者Huber loss。所以说负梯度并不等于残差，损失函数选择MSE的时候才可以划等号。 将上步得到的残差作为样本新的真实值，并将数据 \\(\\left(x_{i}, r_{i m}\\right), i=1,2, . . N\\) 作为下棵树的训练数据，得到一颗新的回归树 \\(f_{m}(x)\\) 其对应的叶子节点区域为 \\(R_{j m}, j=1,2, \\ldots, J\\) 。其中 \\(J\\) 为回归树的叶子节点的个数。 对叶子区域 \\(j=1,2, . . J\\) 计算最佳拟合值 \\[ \\Upsilon_{j m}=\\underbrace{\\arg \\min}_{\\Upsilon} \\sum_{x_{i} \\in R_{j m}} L\\left(y_{i}, f_{m-1}\\left(x_{i}\\right)+\\Upsilon\\right) \\] 也可以理解为： \\[ \\Upsilon_{jm} = \\underbrace{\\arg \\min}_{\\Upsilon} \\sum_{x_i \\in R_{jm}} L(r_{im}, \\Upsilon) \\] 损失函数L为MSE时，就与回归树的构建类似，最佳拟合值就是划分的叶子节点的均值。可以简单理解为提升树和GBDT的区别就是计算残差的方式不同。 更新强学习器 \\[ f_{m}(x)=f_{m-1}(x)+\\sum_{j=1}^{J} \\Upsilon_{j m} I\\left(x \\in R_{j m}\\right) \\] 得到最终学习器 \\[ f(x)=f_{M}(x)=f_{0}(x)+\\sum_{m=1}^{M} \\sum_{j=1}^{J} \\Upsilon_{j m} I\\left(x \\in R_{j m}\\right) \\] 实例可以看参考里面。 ","date":"2021-01-06","objectID":"/gbdt/:3:0","tags":["Machine Learning","集成学习","Boosting","GBDT"],"title":"GBDT","uri":"/gbdt/"},{"categories":["Machine Learning","集成学习","Boosting"],"content":"与梯度下降算法的关系 ","date":"2021-01-06","objectID":"/gbdt/:4:0","tags":["Machine Learning","集成学习","Boosting","GBDT"],"title":"GBDT","uri":"/gbdt/"},{"categories":["Machine Learning","集成学习","Boosting"],"content":"代码 import numpy as np class RegressionTree: def __init__(self, max_depth=2, min_samples_split=2): self.max_depth = max_depth self.min_samples_split = min_samples_split self.tree = {} def fit(self, X, y): self.X = X self.y = y self.n_features = X.shape[1] self.n_samples = X.shape[0] self.tree = self._build_tree(X, y) def predict(self, X): return np.array([self._predict(inputs) for inputs in X]) def _build_tree(self, X, y, depth=0): m = X.shape[0] n = X.shape[1] # 1. 终止条件 if m \u003c= self.min_samples_split or depth \u003e= self.max_depth: return self._leaf(y) # 2. 找到最优分裂特征和特征值 feature, value = self._best_split(X, y) # 3. 构建子树 left_idx, right_idx = self._split(X, feature, value) left = self._build_tree(X[left_idx, :], y[left_idx], depth + 1) right = self._build_tree(X[right_idx, :], y[right_idx], depth + 1) return {\"feature\": feature, \"value\": value, \"left\": left, \"right\": right} def _leaf(self, y): return np.mean(y) def _best_split(self, X, y): m = X.shape[0] n = X.shape[1] min_mse = np.inf best_feature = None best_value = None for feature in range(n): values = np.unique(X[:, feature]) for value in values: y1 = y[X[:, feature] \u003c value] y2 = y[X[:, feature] \u003e= value] mse = np.mean(y1) - np.mean(y2) if mse \u003c min_mse: min_mse = mse best_feature = feature best_value = value return best_feature, best_value def _split(self, X, feature, value): left_idx = np.argwhere(X[:, feature] \u003c value).flatten() right_idx = np.argwhere(X[:, feature] \u003e= value).flatten() return left_idx, right_idx class GBDT: def __init__(self, n_estimators=10, learning_rate=0.1, max_depth=3): self.n_estimators = n_estimators self.learning_rate = learning_rate self.max_depth = max_depth self.trees = [] def fit(self, X, y): y_pred = np.zeros_like(y, dtype=np.float) for i in range(self.n_estimators): tree = RegressionTree(self.max_depth) tree.fit(X, -self.gradient(y, y_pred)) y_pred += self.learning_rate * tree.predict(X) self.trees.append(tree) def predict(self, X): y_pred = np.zeros((X.shape[0], ), dtype=np.float) for tree in self.trees: y_pred += self.learning_rate * tree.predict(X) return y_pred def gradient(self, y_true, y_pred): return y_true - y_pred 为什么xgboost/gbdt在调参时为什么树的深度很少就能达到很高的精度？ Boosting主要关注降低偏差，因此Boosting能基于泛化性能相当弱的学习器构建出很强的集成；Bagging主要关注降低方差，因此它在不剪枝的决策树、神经网络等学习器上效用更为明显。 对于Bagging算法来说，由于我们会并行地训练很多不同的分类器的目的就是降低这个方差(variance) ,因为采用了相互独立的基分类器多了以后，h的值自然就会靠近。所以对于每个基分类器来说，目标就是如何降低这个偏差（bias),所以我们会采用深度很深甚至不剪枝的决策树。 对于Boosting来说，每一步我们都会在上一轮的基础上更加拟合原数据，所以可以保证偏差（bias）,所以对于每个基分类器来说，问题就在于如何选择variance更小的分类器，即更简单的分类器，所以我们选择了深度很浅的决策树。 ## 参考 https://blog.csdn.net/zpalyq110/article/details/79527653 https://zhuanlan.zhihu.com/p/280222403 ","date":"2021-01-06","objectID":"/gbdt/:5:0","tags":["Machine Learning","集成学习","Boosting","GBDT"],"title":"GBDT","uri":"/gbdt/"},{"categories":["算法题"],"content":"两两交换链表中的节点 ","date":"2021-01-03","objectID":"/%E4%B8%A4%E4%B8%A4%E4%BA%A4%E6%8D%A2%E9%93%BE%E8%A1%A8%E4%B8%AD%E7%9A%84%E8%8A%82%E7%82%B9/:0:0","tags":["算法题","两两交换链表中的节点"],"title":"两两交换链表中的节点","uri":"/%E4%B8%A4%E4%B8%A4%E4%BA%A4%E6%8D%A2%E9%93%BE%E8%A1%A8%E4%B8%AD%E7%9A%84%E8%8A%82%E7%82%B9/"},{"categories":["算法题"],"content":"题目： https://leetcode-cn.com/problems/swap-nodes-in-pairs/ ","date":"2021-01-03","objectID":"/%E4%B8%A4%E4%B8%A4%E4%BA%A4%E6%8D%A2%E9%93%BE%E8%A1%A8%E4%B8%AD%E7%9A%84%E8%8A%82%E7%82%B9/:1:0","tags":["算法题","两两交换链表中的节点"],"title":"两两交换链表中的节点","uri":"/%E4%B8%A4%E4%B8%A4%E4%BA%A4%E6%8D%A2%E9%93%BE%E8%A1%A8%E4%B8%AD%E7%9A%84%E8%8A%82%E7%82%B9/"},{"categories":["算法题"],"content":"思路: 先把第二位储存起来，然后将后面的递归操作后，再把第二位指向第一位，完成换位 ","date":"2021-01-03","objectID":"/%E4%B8%A4%E4%B8%A4%E4%BA%A4%E6%8D%A2%E9%93%BE%E8%A1%A8%E4%B8%AD%E7%9A%84%E8%8A%82%E7%82%B9/:2:0","tags":["算法题","两两交换链表中的节点"],"title":"两两交换链表中的节点","uri":"/%E4%B8%A4%E4%B8%A4%E4%BA%A4%E6%8D%A2%E9%93%BE%E8%A1%A8%E4%B8%AD%E7%9A%84%E8%8A%82%E7%82%B9/"},{"categories":["算法题"],"content":"代码： # Definition for singly-linked list. # class ListNode: # def __init__(self, val=0, next=None): # self.val = val # self.next = next class Solution: #假设为[1,2,3,4] def swapPairs(self, head: ListNode) -\u003e ListNode: if not head or not head.next: #递归出口 return head newnode = head.next #储存第二位2 head.next = self.swapPairs(head.next.next) #此时为[1,4,3] newnode.next = head #[2,1,4,3] return newnode ","date":"2021-01-03","objectID":"/%E4%B8%A4%E4%B8%A4%E4%BA%A4%E6%8D%A2%E9%93%BE%E8%A1%A8%E4%B8%AD%E7%9A%84%E8%8A%82%E7%82%B9/:3:0","tags":["算法题","两两交换链表中的节点"],"title":"两两交换链表中的节点","uri":"/%E4%B8%A4%E4%B8%A4%E4%BA%A4%E6%8D%A2%E9%93%BE%E8%A1%A8%E4%B8%AD%E7%9A%84%E8%8A%82%E7%82%B9/"},{"categories":["算法题"],"content":"种花问题（新年快乐!2021第一题） 新年快乐！2021年第一题，每日一题！希望2021年LC和github可以全绿！加油！ https://leetcode-cn.com/problems/can-place-flowers/ 代码如下： class Solution: def canPlaceFlowers(self, flowerbed: List[int], n: int) -\u003e bool: flowerbed = [0] + flowerbed + [0] for i in range(1,len(flowerbed)-1): if flowerbed[i-1] == 0 and flowerbed[i] == 0 and flowerbed[i+1] == 0: n -= 1 flowerbed[i] = 1 return n \u003c= 0 思路很暴力，就是三个0在一起就可以插进去。。 主要是边界问题，这里构造了两个边界 新的一年开开心心，完成自己的目标，让自己更优秀！ ","date":"2021-01-01","objectID":"/%E7%A7%8D%E8%8A%B1%E9%97%AE%E9%A2%98%E6%96%B0%E5%B9%B4%E5%BF%AB%E4%B9%902021%E7%AC%AC%E4%B8%80%E9%A2%98/:0:0","tags":["算法题","种花问题（新年快乐!2021第一题）"],"title":"种花问题（新年快乐!2021第一题）","uri":"/%E7%A7%8D%E8%8A%B1%E9%97%AE%E9%A2%98%E6%96%B0%E5%B9%B4%E5%BF%AB%E4%B9%902021%E7%AC%AC%E4%B8%80%E9%A2%98/"},{"categories":["算法题"],"content":"零钱兑换 https://leetcode-cn.com/problems/coin-change/ 以我目前的水平做出来有点吃力，看了思路才做出来 class Solution: def coinChange(self, coins: List[int], amount: int) -\u003e int: dp = [float('inf')] * (amount + 1) dp[0] = 0 for i in range(amount+1): for coin in coins: # if i \u003e= coin: dp[i] = min(dp[i],dp[i-coin]+1) return -1 if (dp[-1] == float(\"inf\")) else dp[-1] 伪代码如下 # 伪码框架 def coinChange(coins: List[int], amount: int): # 定义：要凑出金额 n，至少要 dp(n) 个硬币 def dp(n): # 做选择，选择需要硬币最少的那个结果 for coin in coins: res = min(res, 1 + dp(n - coin)) return res # 题目要求的最终结果是 dp(amount) return dp(amount) ","date":"2020-10-10","objectID":"/%E9%9B%B6%E9%92%B1%E5%85%91%E6%8D%A2/:0:0","tags":["算法题","零钱兑换"],"title":"零钱兑换","uri":"/%E9%9B%B6%E9%92%B1%E5%85%91%E6%8D%A2/"},{"categories":["算法题"],"content":"去除重复字母 一开始看到题目感觉挺简单的，没想到对现在的我挺有难度。。 https://leetcode-cn.com/problems/remove-duplicate-letters/ #1 class Solution: def removeDuplicateLetters(s: str): res = \"\" while s: #用递归也可以 loc = min(map(s.rindex,s)) #s.rindex是返回列表各值最后出现的索引 求这个最小的索引 a = min(s[:loc+1]) #求字典序最小的 res += a s = s[s.index(a):].replace(a,\"\") #把已经加入的和与其重复的都去掉了 return res #2 #遍历字符串，压入栈，如果遇到比栈顶小的元素且当前字符后面还有与栈顶相同的元素时，移除栈顶元素 class Solution: def removeDuplicateLetters(s: str) -\u003e str: stack = [] for i, t in enumerate(s): if t in stack: continue while stack !=[] and t \u003c stack[-1] and s[i:].find(stack[-1]) != -1: stack.pop() stack.append(t) return \"\".join(stack) 两个方法，第二个方法更好想点。第一个方法是copy的 ","date":"2020-09-02","objectID":"/%E5%8E%BB%E9%99%A4%E9%87%8D%E5%A4%8D%E5%AD%97%E6%AF%8D/:0:0","tags":["算法题","去除重复字母"],"title":"去除重复字母","uri":"/%E5%8E%BB%E9%99%A4%E9%87%8D%E5%A4%8D%E5%AD%97%E6%AF%8D/"},{"categories":null,"content":" 好久没折腾博客了，总觉得mkdocs的可定义功能太少了，而且不太美观，于是将博客从mkdocs迁移到Hugo了，原本是想用hexo的，但是图片的引用改过来的话太麻烦了，所以选择了hugo。花费了一点时间迁移，主要是工程量有点大，之前写的博文内容不符合hugo的规范，所以写了一些脚本用于迁移，总体还是比较顺利，本来是想主要是想创造一个舒服的写作环境。目前是obsidian+hugo，然后部署在github pages上面。 ","date":"0001-01-01","objectID":"/about/:0:0","tags":null,"title":"","uri":"/about/"},{"categories":null,"content":"关于本站 从大一开始就折腾博客了，从一开始只会python语言，到现在会了一点点机器学习，把博客当做自己的成长过程吧，其实大部分都是直接照搬网上的东西，不过自己复现了一些代码，我认为理论与实践要统一，不能只有理论知识，但没有理论去实践，就算照着写出来也一头雾水，做调参侠，但要知道每个参数的意义。 不知道写啥了，先空着。 ","date":"0001-01-01","objectID":"/about/:1:0","tags":null,"title":"","uri":"/about/"},{"categories":null,"content":" Table file.mtime as \"最后修改时间\" WHERE tags[0] = \"Reading\" and date(today) - file.mtime \u003c= dur(7 days) Sort file.mtime desc ","date":"0001-01-01","objectID":"/reading_for_oneweek/:0:0","tags":null,"title":"","uri":"/reading_for_oneweek/"},{"categories":null,"content":" Table rows.file.link as filename WHERE todo and title != \"\u003c% tp.file.title %\u003e\" Sort file.ctime desc GROUP BY tags[1] as \"category\" ","date":"0001-01-01","objectID":"/to_writing/:0:0","tags":null,"title":"","uri":"/to_writing/"},{"categories":null,"content":" Table file.mtime as \"最后修改时间\" WHERE !todo and date(today) - file.mtime \u003c= dur(7 days) and tags[0] != \"Reading\" and title Sort file.mtime desc ","date":"0001-01-01","objectID":"/writing_for_oneweek/:0:0","tags":null,"title":"","uri":"/writing_for_oneweek/"}]