<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <meta name="author" content="vllbc">
    <link rel="canonical" href="https://vllbc.github.io/spider/base/">
    <link rel="shortcut icon" href="../../1.ico">
    
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>基础 - Vllbc's home</title>
    <link href="../../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../../css/highlight.css">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../../js/jquery-3.2.1.min.js"></script>
    <script src="../../js/bootstrap-3.3.7.min.js"></script>
    <script src="../../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "\u722c\u866b", url: "#_top", children: [
          ]},
          {title: "\u6700\u7b80\u5355\u7684\u722c\u866b\u7a0b\u5e8f\uff1a", url: "#_2", children: [
          ]},
          {title: "\u89e3\u6790\u7f51\u9875", url: "#_3", children: [
          ]},
          {title: "\u4f7f\u7528API", url: "#api", children: [
          ]},
          {title: "POST\u8bf7\u6c42", url: "#post", children: [
          ]},
          {title: "selenium", url: "#selenium", children: [
          ]},
          {title: "Scrapy", url: "#scrapy", children: [
          ]},
        ];

    </script>
    <script src="../../js/base.js"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
  <a name="_top"></a>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../thread_spider/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../thread_spider/" class="btn btn-xs btn-link">
        多线程爬虫
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../../Cookbook/chapter2/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../../Cookbook/chapter2/" class="btn btn-xs btn-link">
        第二章
      </a>
    </div>
    
  </div>

    

    <h1 id="_1"><strong>爬虫</strong></h1>
<p><strong>爬虫是我比较擅长的主题，而且它入门也是比较简单的。</strong></p>
<p><strong>爬虫的核心库是<code>requests</code>库</strong></p>
<p><strong>可以通过<code>pip install requests</code>来安装</strong></p>
<h1 id="_2"><strong>最简单的爬虫程序：</strong></h1>
<pre><code class="python">import requests
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari'}
res = requests.get(&quot;http://www.baidu.com&quot;,headers=headers)
res.encoding = 'utf-8'#注意乱码问题
print(res.text) #print(res.headers)返回头
</code></pre>

<p><strong>在上面的代码中，先导入requests库，然后调用requests库中的get()方法，对网站进行get请求，然后将返回的内容打印出来</strong></p>
<p><strong>当然有时候我们爬虫要伪装一下，在请求的时候加入头headers</strong></p>
<h1 id="_3"><strong>解析网页</strong></h1>
<p><strong>在获得了网页的内容后，发现大部分都是代码，那我们怎么样来获得自己想要的那部分内容呢，这时候就要用到网页解析库了</strong></p>
<p><strong>这里呢我推荐使用的是<code>lxml</code>,即使用<code>xpath</code>语法，也是我个人常用的，因为它的速度比较快，语法也不难。</strong></p>
<p><strong><code>pip install lxml</code>进行安装</strong></p>
<pre><code class="python">from lxml import etree
import requests
res = requests.get('https://inkplatform.gitbook.io/andrew-pytorch/')
sele = etree.HTML(res.text)
nav = sele.xpath('//*[@id=&quot;ke-cheng-yi-shen-jing-wang-luo-yu-shen-du-xue-xi&quot;]/div[1]/span/span/span/text()')
print(nav)
</code></pre>

<p><strong>这样通过xpath语法来获得一些内容</strong></p>
<h1 id="api"><strong>使用API</strong></h1>
<p><strong>API就是开发者制作的外部接口，这部分的内容可以百度一下</strong></p>
<p><strong>一般的API可以通过抓包获得</strong></p>
<p><strong>这里直接放我抓bilibili cos区图片的例子吧</strong></p>
<p><strong>API是我抓包抓来的。</strong></p>
<pre><code class="python">import requests
import json


headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36'} #模拟浏览器

urls = [f'https://api.vc.bilibili.com/link_draw/v2/Photo/list?category=cos&amp;type=hot&amp;page_num={f}&amp;page_size=50' for f in range(1,25)] #列表解析式构建urls


def get_photo(url):
    res = requests.get(url,headers=headers)
    jsons = json.loads(res.text)
    lists = jsons['data']['items'][0]['item']['pictures'] #解析json
    url_list=[]
    for list in lists:
        url_list.append(list['img_src'])
    for urld in url_list:
        ress = requests.get(urld,headers=headers)
        fp = open(f'meizitu\\{urld[-20:]}','wb')
        fp.write(ress.content)
        print(&quot;OK&quot;)
        fp.close()

#main
for url in urls:
    try:
        get_photo(url)
    except IndexError:
        pass
</code></pre>

<h1 id="post"><strong>POST请求</strong></h1>
<p><strong>使用<code>requests.post(url,data=params,headers=headers)</code></strong></p>
<p><strong>params为传入的参数</strong></p>
<p><strong>或者获取cookie 然后在headers里面传入</strong></p>
<p><strong>依旧用我爬过的例子</strong></p>
<pre><code class="python">import requests
import json
import time

params={
    'account':&quot;youraccount&quot;,
    'password':&quot;yourpassword&quot;,
    &quot;phoneVersion&quot;:19,
    &quot;platform&quot;:1,
    &quot;deviceCode&quot;:355757010701395,
    &quot;versionNumber&quot;:&quot;9.4.0&quot;,
    &quot;channel&quot;:&quot;ppMarket&quot;,
    &quot;phoneBrand&quot;:&quot;samsung&quot;,
    &quot;phoneModel&quot;:&quot;SM-G955F&quot;
}
res=requests.post(&quot;http://120.55.151.61/V2/StudentSkip/loginCheckV4.action&quot;,params)
</code></pre>

<p><strong>其实跟get差不多</strong></p>
<h1 id="selenium"><strong>selenium</strong></h1>
<p><strong>selenium是自动化工具，可以配合各浏览器使用。</strong></p>
<p><strong>用来模拟人的操作，比如说输入账号密码，点击按钮，还可以获取数据。</strong></p>
<p><strong>且也支持xpath语法是爬取异步加载网页或需要用到登录时的利器，虽然可以抓包，但不如这样来的直接。</strong></p>
<p>记录一下遇到的坑：</p>
<p>在获取某个元素时，例如用class获取的话，要用<code>browser.find_element_by_class_name</code></p>
<p><strong>注意注意注意</strong>  element不要加s 不然就返回一个列表了 2020 11.19踩坑了，特来记录！</p>
<h1 id="scrapy"><strong>Scrapy</strong></h1>
<p><strong>Scrapy是一个爬虫框架</strong></p>

  <br>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../thread_spider/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../thread_spider/" class="btn btn-xs btn-link">
        多线程爬虫
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../../Cookbook/chapter2/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../../Cookbook/chapter2/" class="btn btn-xs btn-link">
        第二章
      </a>
    </div>
    
  </div>

    <br>
</div>

<footer class="container-fluid wm-page-content">
  <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>