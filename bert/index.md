# 


# BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding

***

## <span style="background-color: #f1f8e9">ğŸ’¡ Meta Data</span>

| <span style="background-color: #dbeedd">Title</span>     | <span style="background-color: #dbeedd">Â  Â  Â  Â  Â  Â  Â  Â  BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding Â  Â  Â  Â  Â  Â </span>                                                                              |
| -------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| <span style="background-color: #f3faf4">Journal</span>   |                                                                                                                                                                                                                                          |
| <span style="background-color: #dbeedd">Authors</span>   | <span style="background-color: #dbeedd">Â  Â  Â  Â  Â  Â  Â  Â  Jacob Devlin; Ming-Wei Chang; Kenton Lee; Kristina Toutanova Â  Â  Â  Â  Â  Â </span>                                                                                                  |
| <span style="background-color: #f3faf4">Pub. date</span> | <span style="background-color: #f3faf4">Â  Â  Â  Â  Â  Â  Â  Â  2019-05-24 Â  Â  Â  Â  Â  Â </span>                                                                                                                                                    |
| <span style="background-color: #dbeedd">æœŸåˆŠæ ‡ç­¾</span>      |                                                                                                                                                                                                                                          |
| <span style="background-color: #f3faf4">DOI</span>       |                                                                                                                                                                                                                                          |
| <span style="background-color: #dbeedd">é™„ä»¶</span>        | <span style="background-color: #dbeedd"><a href="zotero://open-pdf/0_ZR95V6ZZ" rel="noopener noreferrer nofollow">Â  Â  Â  Â  Â  Â  Â  Â  Â  Devlin ç­‰ - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf Â  Â  Â </a> Â  Â  Â  Â  Â  Â </span> |

## <span style="background-color: #fff8e1">ğŸ“œ ç ”ç©¶èƒŒæ™¯ &#x26; åŸºç¡€ &#x26; ç›®çš„</span>

***

## <span style="background-color: #f1f8e9">ğŸ“Š ç ”ç©¶å†…å®¹</span>

***

## <span style="background-color: #f5f5f5">ğŸš© ç ”ç©¶ç»“è®º</span>

***

## <span style="background-color: #e0f7fa">ğŸ“Œ æ„Ÿæƒ³ &#x26; ç–‘é—®</span>

***

## <span style="background-color: #e1f5fe">ğŸ”¬ ç†è®ºæ¨å¯¼</span>

***

