<!DOCTYPE html>
<html lang="zh-CN">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title>具有逻辑回归思维的神经网络 - vllbc02&#39;s blogs</title><meta name="Description" content="vllbc&#39;s blog"><meta property="og:url" content="https://blog.vllbc.top/%E5%85%B7%E6%9C%89%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%80%9D%E7%BB%B4%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
  <meta property="og:site_name" content="vllbc02&#39;s blogs">
  <meta property="og:title" content="具有逻辑回归思维的神经网络">
  <meta property="og:description" content="# 练习1-具有神经网络思维的Logistic回归 1 数据预处理 1.1 数据加载和查看 在开始之前，我们有需要引入的库：
numpy ：是用Python进行科学计算的基本软件包。 h5py：是与H5文件中存储的数据集进行交互的常用软件包。 matplotlib：是一个著名的库，用于在Python中绘制图表。 import numpy as np import matplotlib.pyplot as plt import h5py /opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters 接下来，需要运行load_dataset函数来读取数据文件中所存储的数据，并返回：">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2021-04-01T00:00:00+00:00">
    <meta property="article:modified_time" content="2023-03-24T00:00:00+00:00">
    <meta property="article:tag" content="Deep Learning">
    <meta property="article:tag" content="项目练习">
    <meta property="article:tag" content="具有逻辑回归思维的神经网络">
    <meta property="og:image" content="https://blog.vllbc.top/images/logo.png">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="https://blog.vllbc.top/images/logo.png">
  <meta name="twitter:title" content="具有逻辑回归思维的神经网络">
  <meta name="twitter:description" content="# 练习1-具有神经网络思维的Logistic回归 1 数据预处理 1.1 数据加载和查看 在开始之前，我们有需要引入的库：
numpy ：是用Python进行科学计算的基本软件包。 h5py：是与H5文件中存储的数据集进行交互的常用软件包。 matplotlib：是一个著名的库，用于在Python中绘制图表。 import numpy as np import matplotlib.pyplot as plt import h5py /opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters 接下来，需要运行load_dataset函数来读取数据文件中所存储的数据，并返回：">
<meta name="application-name" content="vllbc02">
<meta name="apple-mobile-web-app-title" content="vllbc02">
<meta name="referrer" content="no-referrer" /><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://blog.vllbc.top/%E5%85%B7%E6%9C%89%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%80%9D%E7%BB%B4%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" /><link rel="prev" href="https://blog.vllbc.top/kmeans/" /><link rel="next" href="https://blog.vllbc.top/%E5%9B%A0%E5%AD%90%E5%88%86%E6%9E%90/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.2/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.2/css/all.min.css"></noscript><link rel="preload" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "具有逻辑回归思维的神经网络",
        "inLanguage": "zh-CN",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/blog.vllbc.top\/%E5%85%B7%E6%9C%89%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%80%9D%E7%BB%B4%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C\/"
        },"image": [{
                            "@type": "ImageObject",
                            "url": "https:\/\/blog.vllbc.top\/images\/Apple-Devices-Preview.png",
                            "width":  3200 ,
                            "height":  2048 
                        }],"genre": "posts","keywords": "Deep Learning, 项目练习, 具有逻辑回归思维的神经网络","wordcount":  6225 ,
        "url": "https:\/\/blog.vllbc.top\/%E5%85%B7%E6%9C%89%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%80%9D%E7%BB%B4%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C\/","datePublished": "2021-04-01T00:00:00+00:00","dateModified": "2023-03-24T00:00:00+00:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
            "@type": "Organization",
            "name": "xxxx","logo": {
                    "@type": "ImageObject",
                    "url": "https:\/\/blog.vllbc.top\/images\/avatar.png",
                    "width":  512 ,
                    "height":  512 
                }},"author": {
                "@type": "Person",
                "name": "vllbc"
            },"description": ""
    }
    </script></head>
    <body data-header-desktop="fixed" data-header-mobile="auto"><script>(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };

  window.addEventListener('load', (event) => {
      document.querySelectorAll("mjx-container").forEach(function(x){
        x.parentElement.classList += 'has-jax'})
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="vllbc02&#39;s blogs"><img
        class="lazyload logo"
        src="/svg/loading.min.svg"
        data-src="/images/logo.png"
        data-srcset="/images/logo.png, /images/logo.png 1.5x, /images/logo.png 2x"
        data-sizes="auto"
        alt="/images/logo.png"
        title="/images/logo.png" width="32" height="32" />vllbc02</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> 所有文章 </a><a class="menu-item" href="/tags/"> 标签 </a><a class="menu-item" href="/categories/"> 分类 </a><a class="menu-item" href="/about/"> 关于 </a><a class="menu-item" href="https://github.com/vllbc/vllbc.github.io" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw' aria-hidden='true'></i>  </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="vllbc02&#39;s blogs"><img
        class="lazyload logo"
        src="/svg/loading.min.svg"
        data-src="/images/logo.png"
        data-srcset="/images/logo.png, /images/logo.png 1.5x, /images/logo.png 2x"
        data-sizes="auto"
        alt="/images/logo.png"
        title="/images/logo.png" width="32" height="32" />vllbc02</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        取消
                    </a>
                </div><a class="menu-item" href="/posts/" title="">所有文章</a><a class="menu-item" href="/tags/" title="">标签</a><a class="menu-item" href="/categories/" title="">分类</a><a class="menu-item" href="/about/" title="">关于</a><a class="menu-item" href="https://github.com/vllbc/vllbc.github.io" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw' aria-hidden='true'></i></a><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a></div>
    </div>
</header><div class="search-dropdown desktop">
        <div id="search-dropdown-desktop"></div>
    </div>
    <div class="search-dropdown mobile">
        <div id="search-dropdown-mobile"></div>
    </div>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/base16/darcula.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script><main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">目录</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">具有逻辑回归思维的神经网络</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel="author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>vllbc</a></span>&nbsp;<span class="post-category">收录于 <a href="/categories/deep-learning/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Deep Learning</a>&nbsp;<a href="/categories/%E9%A1%B9%E7%9B%AE%E7%BB%83%E4%B9%A0/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>项目练习</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;<time datetime="2021-04-01">2021-04-01</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden="true"></i>&nbsp;约 6225 字&nbsp;
                <i class="far fa-clock fa-fw" aria-hidden="true"></i>&nbsp;预计阅读 13 分钟&nbsp;<span id="/%E5%85%B7%E6%9C%89%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%80%9D%E7%BB%B4%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="leancloud_visitors" data-flag-title="具有逻辑回归思维的神经网络">
                        <i class="far fa-eye fa-fw" aria-hidden="true"></i>&nbsp;<span class=leancloud-visitors-count></span>&nbsp;次阅读
                    </span>&nbsp;</div>
        </div><div class="details toc" id="toc-static"  data-kept="">
                <div class="details-summary toc-title">
                    <span>目录</span>
                    <span><i class="details-icon fas fa-angle-right" aria-hidden="true"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"></div>
            </div><div class="content" id="content"><h2 id="练习1-具有神经网络思维的logistic回归">#
练习1-具有神经网络思维的Logistic回归</h2>
<h2 id="数据预处理">1 数据预处理</h2>
<h3 id="数据加载和查看">1.1 数据加载和查看</h3>
<p>在开始之前，我们有需要引入的库：</p>
<ul>
<li>numpy ：是用Python进行科学计算的基本软件包。</li>
<li>h5py：是与H5文件中存储的数据集进行交互的常用软件包。</li>
<li>matplotlib：是一个著名的库，用于在Python中绘制图表。</li>
</ul>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> h5py</span></code></pre></div>
<pre><code>/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters</code></pre>
<p>接下来，需要运行load_dataset函数来读取数据文件中所存储的数据，并返回：</p>
<ul>
<li>train_set_x_orig
：保存的是训练集里面的图像数据(209张64x64的图像)；</li>
<li>train_set_y_orig
：保存的是训练集的图像对应的分类值，其中0表示不是猫，1表示是猫。</li>
<li>test_set_x_orig
：保存的是测试集里面的图像数据(50张64x64的图像)；</li>
<li>test_set_y_orig ： 保存的是测试集的图像对应的分类值。</li>
<li>classes ：
保存的是以字节类型保存的两个字符串数据，数据为：[b’non-cat’
b’cat’]。</li>
</ul>
<p>现在我们就要把这些数据加载到主程序里面：</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_dataset():</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    train_dataset <span class="op">=</span> h5py.File(<span class="st">&#39;train_catvnoncat.h5&#39;</span>, <span class="st">&quot;r&quot;</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    train_set_x_orig <span class="op">=</span> np.array(train_dataset[<span class="st">&quot;train_set_x&quot;</span>][:]) <span class="co"># your train set features</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    train_set_y_orig <span class="op">=</span> np.array(train_dataset[<span class="st">&quot;train_set_y&quot;</span>][:]) <span class="co"># your train set labels</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    test_dataset <span class="op">=</span> h5py.File(<span class="st">&#39;test_catvnoncat.h5&#39;</span>, <span class="st">&quot;r&quot;</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    test_set_x_orig <span class="op">=</span> np.array(test_dataset[<span class="st">&quot;test_set_x&quot;</span>][:]) <span class="co"># your test set features</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    test_set_y_orig <span class="op">=</span> np.array(test_dataset[<span class="st">&quot;test_set_y&quot;</span>][:]) <span class="co"># your test set labels</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    classes <span class="op">=</span> np.array(test_dataset[<span class="st">&quot;list_classes&quot;</span>][:]) <span class="co"># the list of classes</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    train_set_y_orig <span class="op">=</span> train_set_y_orig.reshape((<span class="dv">1</span>, train_set_y_orig.shape[<span class="dv">0</span>]))</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    test_set_y_orig <span class="op">=</span> test_set_y_orig.reshape((<span class="dv">1</span>, test_set_y_orig.shape[<span class="dv">0</span>]))</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>train_set_x_orig , train_set_y , test_set_x_orig , test_set_y , classes <span class="op">=</span> load_dataset()</span></code></pre></div>
<p>我们可以看一下加载的文件里面的图片都是些什么样子的以及存储的分类值。可以看到，当我们改变index值时，会出现不同索引值的图片，且train_set_y的值代表了该图像是否为一只猫。</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>index <span class="op">=</span> <span class="dv">56</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>plt.imshow(train_set_x_orig[index])</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;train_set_y=&quot;</span> <span class="op">+</span> <span class="bu">str</span>(train_set_y[<span class="dv">0</span>][index])) </span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;y=&quot;</span> <span class="op">+</span> <span class="bu">str</span>(train_set_y[:,index]) <span class="op">+</span> <span class="st">&quot;, it&#39;s a &quot;</span> <span class="op">+</span> classes[np.squeeze(train_set_y[:,index])].decode(<span class="st">&quot;utf-8&quot;</span>) <span class="op">+</span> <span class="st">&quot;&#39; picture&quot;</span>)</span></code></pre></div>
<pre><code>train_set_y=1
y=[1], it&#39;s a cat&#39; picture</code></pre>
<p><img
src="https://cdn.jsdelivr.net/gh/vllbc/img4blog//image/output_6_1.png" /></p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>index <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>plt.imshow(train_set_x_orig[index])</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;train_set_y=&quot;</span> <span class="op">+</span> <span class="bu">str</span>(train_set_y[<span class="dv">0</span>][index])) </span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;y=&quot;</span> <span class="op">+</span> <span class="bu">str</span>(train_set_y[:,index]) <span class="op">+</span> <span class="st">&quot;, it&#39;s a &quot;</span> <span class="op">+</span> classes[np.squeeze(train_set_y[:,index])].decode(<span class="st">&quot;utf-8&quot;</span>) <span class="op">+</span> <span class="st">&quot;&#39; picture&quot;</span>)</span></code></pre></div>
<pre><code>train_set_y=0
y=[0], it&#39;s a non-cat&#39; picture</code></pre>
<p><img
src="https://cdn.jsdelivr.net/gh/vllbc/img4blog//image/output_7_1.png" /></p>
<h3 id="数据变换">1.2 数据变换</h3>
<p>接下来看一看我们加载的数据的具体信息，首先介绍三个变量的含义： -
m_train ：训练集里图片的数量。 - m_test ：测试集里图片的数量。 - num_px
： 训练、测试集里面的图片的宽度和高度（均为64x64）。</p>
<p>train_set_x_orig
是一个维度为(m_​​train，num_px，num_px，3）的数组。</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>m_train <span class="op">=</span> train_set_y.shape[<span class="dv">1</span>] <span class="co">#训练集里图片的数量。</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>m_test <span class="op">=</span> test_set_y.shape[<span class="dv">1</span>] <span class="co">#测试集里图片的数量。</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>num_px <span class="op">=</span> train_set_x_orig.shape[<span class="dv">1</span>] <span class="co">#训练、测试集里面的图片的宽度和高度（均为64x64）。</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co">#现在看一看我们加载的东西的具体情况</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;训练集的数量: m_train = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(m_train))</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;测试集的数量 : m_test = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(m_test))</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;每张图片的宽/高 : num_px = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(num_px))</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;每张图片的大小 : (&quot;</span> <span class="op">+</span> <span class="bu">str</span>(num_px) <span class="op">+</span> <span class="st">&quot;, &quot;</span> <span class="op">+</span> <span class="bu">str</span>(num_px) <span class="op">+</span> <span class="st">&quot;, 3)&quot;</span>)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;训练集_图片的维数 : &quot;</span> <span class="op">+</span> <span class="bu">str</span>(train_set_x_orig.shape))</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;训练集_标签的维数 : &quot;</span> <span class="op">+</span> <span class="bu">str</span>(train_set_y.shape))</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;测试集_图片的维数: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(test_set_x_orig.shape))</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;测试集_标签的维数: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(test_set_y.shape))</span></code></pre></div>
<pre><code>训练集的数量: m_train = 209
测试集的数量 : m_test = 50
每张图片的宽/高 : num_px = 64
每张图片的大小 : (64, 64, 3)
训练集_图片的维数 : (209, 64, 64, 3)
训练集_标签的维数 : (1, 209)
测试集_图片的维数: (50, 64, 64, 3)
测试集_标签的维数: (1, 50)</code></pre>
<p>为了方便，我们要把维度为<code>(64,64,3)</code>的numpy数组重新构造为<code>(64*64*3,1)</code>的数组，要乘以3的原因是每张图片是由<code>64x64</code>像素构成的，而每个像素点由（R，G，B）三原色构成的，所以要乘以3。</p>
<p>在此之后，我们的训练和测试数据集是一个numpy数组，<strong>每列代表一个平坦的图像</strong>，应该有m_train和m_test列。</p>
<p>当你想将形状（a，b，c，d）的矩阵X平铺成形状（b * c *
d，a）的矩阵X_flatten时，可以使用以下代码：</p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co">#X_flatten = X.reshape(X.shape [0]，-1).T ＃X.T是X的转置</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="co">#将训练集的维度降低并转置。</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>train_set_x_flatten  <span class="op">=</span> train_set_x_orig.reshape(train_set_x_orig.shape[<span class="dv">0</span>],<span class="op">-</span><span class="dv">1</span>).T</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co">#将测试集的维度降低并转置。</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>test_set_x_flatten <span class="op">=</span> test_set_x_orig.reshape(test_set_x_orig.shape[<span class="dv">0</span>], <span class="op">-</span><span class="dv">1</span>).T</span></code></pre></div>
<p>这一段意思是指把数组变为209行的矩阵（因为训练集里有209张图片）我们可以用-1使得程序算出来是12288列，我再最后用一个T表示转置，这就变成了12288行，209列。</p>
<p>测试集的操作也一样。</p>
<p>然后我们看看降维之后的情况是怎么样的：</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;训练集降维最后的维度： &quot;</span> <span class="op">+</span> <span class="bu">str</span>(train_set_x_flatten.shape))</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;训练集_标签的维数 : &quot;</span> <span class="op">+</span> <span class="bu">str</span>(train_set_y.shape))</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;测试集降维之后的维度: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(test_set_x_flatten.shape))</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;测试集_标签的维数 : &quot;</span> <span class="op">+</span> <span class="bu">str</span>(test_set_y.shape))</span></code></pre></div>
<pre><code>训练集降维最后的维度： (12288, 209)
训练集_标签的维数 : (1, 209)
测试集降维之后的维度: (12288, 50)
测试集_标签的维数 : (1, 50)</code></pre>
<p>为了表示彩色图像，必须为每个像素指定红色，绿色和蓝色通道（RGB），因此像素值实际上是从0到255范围内的三个数字的向量。</p>
<p>机器学习中一个常见的预处理步骤是<strong>对数据集进行居中和标准化</strong>，这意味着可以减去每个示例中整个numpy数组的平均值，然后将每个示例除以整个numpy数组的标准偏差。</p>
<p>但对于图片数据集，它更简单，更方便，几乎可以将<strong>数据集的每一行除以255</strong>（像素通道的最大值），因为在RGB中不存在比255大的数据，所以我们可以放心的除以255，让标准化的数据位于[0,1]之间。</p>
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>train_set_x <span class="op">=</span> train_set_x_flatten <span class="op">/</span> <span class="dv">255</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>test_set_x <span class="op">=</span> test_set_x_flatten <span class="op">/</span> <span class="dv">255</span></span></code></pre></div>
<h2 id="神经网络的搭建">2 神经网络的搭建</h2>
<p>数据处理完毕后，我们需要开始搭建神经网络。 以下是数学表达式：</p>
<p>对于 <span class="math inline">\(x(i)\)</span>:</p>
<p><span class="math display">\[
{z}^{(i)}={w}^{T}{x}^{(i)}+b
\]</span></p>
<p><span class="math display">\[
\hat{y}^{(i)}=a(i)=sigmoid(z(i))
\]</span></p>
<p><span class="math display">\[
L\left( \hat{y},y \right)=-y\log(\hat{y})-(1-y)\log (1-\hat{y})
\]</span></p>
<p>然后通过对所有训练样例求和来计算成本:</p>
<p><span class="math display">\[
J\left( w,b \right)=\frac{1}{m}\sum\limits_{i=1}^{m}L\left(
\hat{y}^{(i)},y^{(i)} \right)=\frac{1}{m}\sum\limits_{i=1}^{m}\left(
-y^{(i)}\log \hat{y}^{(i)}-(1-y^{(i)})\log (1-\hat{y}^{(i)}) \right)
\]</span></p>
<p>建立神经网络的主要步骤是： 1. 定义模型结构（例如输入特征的数量） 2.
初始化模型的参数 3. 循环：</p>
<pre><code>1. 计算当前损失（正向传播）
2. 计算当前梯度（反向传播）
3. 更新参数（梯度下降）</code></pre>
<h3 id="sigmoid函数">2.1 Sigmoid函数</h3>
<p>现在构建sigmoid()，需要使用 <span class="math inline">\(sigmoid(w ^ T
x + b)\)</span> 计算来做出预测。</p>
<p>其中，sigmoid代表一个常用的逻辑函数为S形函数（Sigmoid
function），公式为： <span class="math display">\[
g\left( z \right)=\frac{1}{1+e^{-z}}
\]</span></p>
<p>接下来，你需要<strong>编写代码实现Sigmoid函数</strong>，编写后试着测试一些值，如果<code>x</code>的正值较大，则函数值应接近1；如果<code>x</code>的负值较大，则函数值应接近0。而对于<code>x</code>等于0时，则函数值为0.5。</p>
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co">###在这里填入代码###</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sigmoid(z):</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co">    参数：</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co">        z  - 任何大小的标量或numpy数组。</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co">    返回：</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="co">        s  -  sigmoid（z）</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>np.exp(<span class="op">-</span>z))</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> s</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    </span></code></pre></div>
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co">#测试sigmoid()</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;====================测试sigmoid====================&quot;</span>)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;sigmoid(0) = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(sigmoid(<span class="dv">0</span>)))</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;sigmoid(9.2) = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(sigmoid(<span class="fl">9.2</span>)))</span></code></pre></div>
<pre><code>====================测试sigmoid====================
sigmoid(0) = 0.5
sigmoid(9.2) = 0.9998989708060922</code></pre>
<h3 id="初始化参数">2.2 初始化参数</h3>
<p>接下来，在搭建神经网络之前，我们需要初始化参数w和b，将w初始化为指定维度的零向量，b初始化为0。</p>
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> initialize_with_zeros(dim):</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="co">        此函数为w创建一个维度为（dim，1）的0向量，并将b初始化为0。</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co">        参数：</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co">            dim  - 我们想要的w矢量的大小（或者这种情况下的参数数量）</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="co">        返回：</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co">            w  - 维度为（dim，1）的初始化向量。</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co">            b  - 初始化的标量（对应于偏差）</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> np.zeros((dim,<span class="dv">1</span>))</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    b <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">#使用断言来确保我要的数据是正确的</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span>(w.shape <span class="op">==</span> (dim, <span class="dv">1</span>)) <span class="co">#w的维度是(dim,1)</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span>(<span class="bu">isinstance</span>(b, <span class="bu">float</span>) <span class="kw">or</span> <span class="bu">isinstance</span>(b, <span class="bu">int</span>)) <span class="co">#b的类型是float或者是int</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (w , b)</span></code></pre></div>
<h3 id="成本函数和梯度">2.3 成本函数和梯度</h3>
<p>对参数进行初始化后，可以接着实现前向和后向传播的成本函数及其梯度，用于后续的参数学习，最小化成本。</p>
<p>接下来，你需要<strong>实现propagate函数，该函数用于实现前向传播的成本计算和后向传播的梯度计算</strong>。</p>
<p>参数<span class="math inline">\(w\)</span>和<span
class="math inline">\(b\)</span>梯度的求解：</p>
<p><span class="math display">\[
\frac{\partial J}{\partial
w}=\frac{1}{m}\sum\limits_{i=1}^{m}\frac{\partial J}{\partial
a^{(i)}}\frac{\partial a^{(i)}}{\partial  z^{(i)}}\frac{\partial
z^{(i)}}{\partial w}
\]</span></p>
<p><span class="math display">\[
\frac{\partial J}{\partial a^{(i)}}=
-\frac{y}{a^{(i)}}+\frac{1-y}{1-a^{(i)}}
\]</span></p>
<p><span class="math display">\[
\frac{\partial g(z)}{\partial
z}=-\frac{1}{(1+e^{-z})^2}(-e^{-z})=\frac{e^{-z}}{1+e^{-z}}=\frac{1}{1+e^{-z}}\times(1-\frac{1}{1+e^{-z}})=g(z)(1-g(z))
\]</span></p>
<p>所以</p>
<p><span class="math display">\[
\frac{\partial a^{(i)}}{\partial  z^{(i)}}=a^{(i)}(1-a^{(i)})
\]</span></p>
<p><span class="math display">\[
\frac{\partial z^{(i)}}{\partial w}=x^{(i)}
\]</span></p>
<p>可得，</p>
<p><span class="math display">\[
\frac{\partial J}{\partial
w}=\frac{1}{m}\sum\limits_{i=1}^{m}(a^{(i)}-y)x^{(i)}
\]</span></p>
<p>求和可以使用numpy的dot函数通过内积计算来实现。</p>
<p>同样地，推导可得，</p>
<p><span class="math display">\[
\frac{\partial J}{\partial
b}=\frac{1}{m}\sum\limits_{i=1}^{m}(a^{(i)}-y)
\]</span></p>
<p><strong>要点</strong>：</p>
<ul>
<li>参数列表和返回值需要与函数说明中相同，其中返回值dw,db需要以字典的形式进行返回；</li>
<li>在函数中需要实现正向传播计算成本和反向传播计算梯度。</li>
</ul>
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co">###在这里填入代码###</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> propagate(w, b, X, Y):</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="co">    实现前向和后向传播的成本函数及其梯度。</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co">    参数：</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="co">        w  - 权重，大小不等的数组（num_px * num_px * 3，1）</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="co">        b  - 偏差，一个标量</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="co">        X  - 矩阵类型为（num_px * num_px * 3，训练数量）</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="co">        Y  - 真正的“标签”矢量（如果非猫则为0，如果是猫则为1），矩阵维度为(1,训练数据数量)</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="co">    返回：</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a><span class="co">        cost- 逻辑回归的负对数似然成本</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="co">        dw  - 相对于w的损失梯度，因此与w相同的形状</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a><span class="co">        db  - 相对于b的损失梯度，因此与b的形状相同</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> X.shape[<span class="dv">1</span>]</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">#正向传播，计算激活值。</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>    A <span class="op">=</span> sigmoid(np.dot(w.T,X) <span class="op">+</span> b)</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">#计算成本</span></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>    cost <span class="op">=</span> <span class="op">-</span>(<span class="dv">1</span><span class="op">/</span>m)<span class="op">*</span>np.<span class="bu">sum</span>(Y<span class="op">*</span>np.log(A)<span class="op">+</span>(<span class="dv">1</span><span class="op">-</span>Y)<span class="op">*</span>np.log(<span class="dv">1</span><span class="op">-</span>A))</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">#反向传播</span></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>    dw <span class="op">=</span> (<span class="dv">1</span><span class="op">/</span>m)<span class="op">*</span>np.dot(X,(A<span class="op">-</span>Y).T)</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>    db <span class="op">=</span> (<span class="dv">1</span><span class="op">/</span>m)<span class="op">*</span>np.<span class="bu">sum</span>(A<span class="op">-</span>Y)</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>    <span class="co">#使用断言确保我的数据是正确的</span></span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span>(dw.shape <span class="op">==</span> w.shape)</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span>(db.dtype <span class="op">==</span> <span class="bu">float</span>)</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>    cost <span class="op">=</span> np.squeeze(cost)</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span>(cost.shape <span class="op">==</span> ())</span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>    <span class="co">#创建一个字典，把dw和db保存起来。</span></span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>    grads <span class="op">=</span>{<span class="st">&quot;dw&quot;</span>:dw,<span class="st">&quot;db&quot;</span>:db}</span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (grads , cost)</span></code></pre></div>
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co">#测试一下propagate</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;====================测试propagate====================&quot;</span>)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="co">#初始化一些参数</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>w, b, X, Y <span class="op">=</span> np.array([[<span class="dv">1</span>], [<span class="dv">2</span>]]), <span class="dv">2</span>, np.array([[<span class="dv">1</span>,<span class="dv">2</span>], [<span class="dv">3</span>,<span class="dv">4</span>]]), np.array([[<span class="dv">1</span>, <span class="dv">0</span>]])</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>grads, cost <span class="op">=</span> propagate(w, b, X, Y)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;dw = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(grads[<span class="st">&quot;dw&quot;</span>]))</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;db = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(grads[<span class="st">&quot;db&quot;</span>]))</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;cost = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(cost))</span></code></pre></div>
<pre><code>====================测试propagate====================
6.000064773192205
dw = [[0.99993216]
 [1.99980262]]
db = 0.49993523062470574
cost = 6.000064773192205</code></pre>
<h3 id="优化函数">2.4 优化函数</h3>
<p>接下来，你需要<strong>定义optimize函数通过使用propagate函数计算成本和梯度来最小化成本，并学习最优参数w和b</strong>。对于参数
<span class="math inline">\(\theta\)</span> ，更新规则是 $ = -
d$（梯度下降法），其中 <span class="math inline">\(\alpha\)</span>
是学习率。</p>
<p><strong>要点</strong>： -
参数列表和返回列表如函数说明中所示，注意返回值的数据类型； -
我们需要写下两个步骤并遍历它们： 1.
计算当前参数的成本和梯度，使用propagate（）。 2.
使用w和b的梯度下降法则更新参数。</p>
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co">###在这里填入代码###</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> optimize(w , b , X , Y , num_iterations , learning_rate , print_cost <span class="op">=</span> <span class="va">False</span>):</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co">    此函数通过运行梯度下降算法来优化w和b</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="co">    参数：</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="co">        w  - 权重，大小不等的数组（num_px * num_px * 3，1）</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="co">        b  - 偏差，一个标量</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a><span class="co">        X  - 维度为（num_px * num_px * 3，训练数据的数量）的数组。</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="co">        Y  - 真正的“标签”矢量（如果非猫则为0，如果是猫则为1），矩阵维度为(1,训练数据的数量)</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="co">        num_iterations  - 优化循环的迭代次数</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a><span class="co">        learning_rate  - 梯度下降更新规则的学习率</span></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a><span class="co">        print_cost  - 每100步打印一次损失值</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a><span class="co">    返回：</span></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="co">        params  - 包含权重w和偏差b的`字典`</span></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="co">        grads  - 包含权重和偏差相对于成本函数的梯度的`字典`</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a><span class="co">        costs - 优化期间计算的所有成本`列表`，将用于绘制学习曲线。</span></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>    costs <span class="op">=</span> []</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_iterations):</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>        grads, cost <span class="op">=</span> propagate(w,b,X,Y)</span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>        dw <span class="op">=</span> grads[<span class="st">&quot;dw&quot;</span>]</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>        db <span class="op">=</span> grads[<span class="st">&quot;db&quot;</span>]</span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>        w <span class="op">=</span> w <span class="op">-</span> learning_rate<span class="op">*</span>dw                                      <span class="co">#更新参数w</span></span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a>        b <span class="op">=</span> b <span class="op">-</span> learning_rate<span class="op">*</span>db                                      <span class="co">#更新参数b</span></span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a>        <span class="co">#记录成本</span></span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i <span class="op">%</span> <span class="dv">100</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a>            costs.append(cost)</span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a>        <span class="co">#打印成本数据</span></span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> (print_cost) <span class="kw">and</span> (i <span class="op">%</span> <span class="dv">100</span> <span class="op">==</span> <span class="dv">0</span>):</span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">&quot;迭代的次数: </span><span class="sc">%i</span><span class="st"> ， 误差值： </span><span class="sc">%f</span><span class="st">&quot;</span> <span class="op">%</span> (i,cost))</span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true" tabindex="-1"></a>    params  <span class="op">=</span> {</span>
<span id="cb22-38"><a href="#cb22-38" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;w&quot;</span> : w,</span>
<span id="cb22-39"><a href="#cb22-39" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;b&quot;</span> : b }</span>
<span id="cb22-40"><a href="#cb22-40" aria-hidden="true" tabindex="-1"></a>    grads <span class="op">=</span> {</span>
<span id="cb22-41"><a href="#cb22-41" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;dw&quot;</span>: dw,</span>
<span id="cb22-42"><a href="#cb22-42" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;db&quot;</span>: db } </span>
<span id="cb22-43"><a href="#cb22-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (params , grads , costs)</span></code></pre></div>
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co">#测试optimize</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;====================测试optimize====================&quot;</span>)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>w, b, X, Y <span class="op">=</span> np.array([[<span class="dv">1</span>], [<span class="dv">2</span>]]), <span class="dv">2</span>, np.array([[<span class="dv">1</span>,<span class="dv">2</span>], [<span class="dv">3</span>,<span class="dv">4</span>]]), np.array([[<span class="dv">1</span>, <span class="dv">0</span>]])</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>params , grads , costs <span class="op">=</span> optimize(w , b , X , Y , num_iterations<span class="op">=</span><span class="dv">100</span> , learning_rate <span class="op">=</span> <span class="fl">0.009</span> , print_cost <span class="op">=</span> <span class="va">False</span>)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;w = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(params[<span class="st">&quot;w&quot;</span>]))</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;b = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(params[<span class="st">&quot;b&quot;</span>]))</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;dw = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(grads[<span class="st">&quot;dw&quot;</span>]))</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;db = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(grads[<span class="st">&quot;db&quot;</span>]))</span></code></pre></div>
<pre><code>====================测试optimize====================
w = [[0.1124579 ]
 [0.23106775]]
b = 1.5593049248448891
dw = [[0.90158428]
 [1.76250842]]
db = 0.4304620716786828</code></pre>
<h3 id="实现预测函数">2.5 实现预测函数</h3>
<p>通过优化函数可以输出已学习的w和b的值，我们可以使用w和b来预测数据集X的标签。</p>
<p>接下来，你需要<strong>实现预测函数predict（）</strong>。</p>
<p>计算预测有两个步骤： 1. 计算<span
class="math inline">\(\bar{Y}=A=\sigma(w^TX+b)\)</span> 2.
将a的值变为0（如果激活值&lt;= 0.5）或者为1（如果激活值&gt; 0.5）</p>
<p>然后将预测值存储在向量Y_prediction中。</p>
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co">###在这里填入代码###</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict(w , b , X ):</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="co">    使用学习逻辑回归参数logistic （w，b）预测标签是0还是1，</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="co">    参数：</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="co">        w  - 权重，大小不等的数组（num_px * num_px * 3，1）</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="co">        b  - 偏差，一个标量</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="co">        X  - 维度为（num_px * num_px * 3，训练数据的数量）的数据</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="co">    返回：</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="co">        Y_prediction  - 包含X中所有图片的所有预测【0 | 1】的一个numpy数组（向量）</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">#计算预测猫在图片中出现的概率</span></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>    m  <span class="op">=</span> X.shape[<span class="dv">1</span>] <span class="co">#图片的数量</span></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>    Y_prediction <span class="op">=</span> np.zeros((<span class="dv">1</span>,m)) </span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>    <span class="co">#计预测猫在图片中出现的概率</span></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>    A <span class="op">=</span> sigmoid(np.dot(w.T,X)<span class="op">+</span>b)</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(A.shape[<span class="dv">1</span>]):</span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>        <span class="co">#将概率a [0，i]转换为实际预测p [0，i]</span></span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>        Y_prediction[<span class="dv">0</span>,i] <span class="op">=</span> <span class="st">&quot;1&quot;</span> <span class="cf">if</span> A[<span class="dv">0</span>,i] <span class="op">&gt;</span> <span class="fl">0.5</span> <span class="cf">else</span> <span class="st">&quot;0&quot;</span></span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>    <span class="co">#使用断言</span></span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span>(Y_prediction.shape <span class="op">==</span> (<span class="dv">1</span>,m))</span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Y_prediction</span></code></pre></div>
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co">#测试predict</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;====================测试predict====================&quot;</span>)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>w, b, X, Y <span class="op">=</span> np.array([[<span class="dv">1</span>], [<span class="dv">2</span>]]), <span class="dv">2</span>, np.array([[<span class="dv">1</span>,<span class="dv">2</span>], [<span class="dv">3</span>,<span class="dv">4</span>]]), np.array([[<span class="dv">1</span>, <span class="dv">0</span>]])</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;predictions = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(predict(w, b, X)))</span></code></pre></div>
<pre><code>====================测试predict====================
predictions = [[1. 1.]]</code></pre>
<h3 id="构建神经网络模型">2.6 构建神经网络模型</h3>
<p>回顾搭建神经网络模型的步骤： 1. 定义模型结构（例如输入特征的数量） 2.
初始化模型的参数 3. 循环：</p>
<pre><code>1. 计算当前损失（正向传播）
2. 计算当前梯度（反向传播）
3. 更新参数（梯度下降）</code></pre>
<p>我们目前已经实现了参数的初始化、成本和梯度的计算、参数更新函数以及预测函数。接下来，你需要<strong>搭建完整的神经网络模型，定义model()函数</strong>。</p>
<p><strong>要点</strong>： - 参数列表和返回列表如函数说明所示； -
需要分别计算训练集和测试集预测的准确率并输出。</p>
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> model(X_train , Y_train , X_test , Y_test , num_iterations <span class="op">=</span> <span class="dv">2000</span> , learning_rate <span class="op">=</span> <span class="fl">0.5</span> , print_cost <span class="op">=</span> <span class="va">False</span>):</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="co">    通过调用之前实现的函数来构建逻辑回归模型</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="co">    参数：</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="co">        X_train  - numpy的数组,维度为（num_px * num_px * 3，m_train）的训练集</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="co">        Y_train  - numpy的数组,维度为（1，m_train）（矢量）的训练标签集</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="co">        X_test   - numpy的数组,维度为（num_px * num_px * 3，m_test）的测试集</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="co">        Y_test   - numpy的数组,维度为（1，m_test）的（向量）的测试标签集</span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="co">        num_iterations  - 表示用于优化参数的迭代次数的超参数</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a><span class="co">        learning_rate  - 表示optimize（）更新规则中使用的学习速率的超参数</span></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a><span class="co">        print_cost  - 设置为true以每100次迭代打印成本</span></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a><span class="co">    返回：</span></span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a><span class="co">        d  - 包含有关模型信息的字典。</span></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>    w , b <span class="op">=</span> initialize_with_zeros(X_train.shape[<span class="dv">0</span>])</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>    parameters , grads , costs <span class="op">=</span> optimize(w,b,X_train,Y_train,num_iterations,learning_rate,print_cost)</span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">#从字典“参数”中检索参数w和b</span></span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>    w , b <span class="op">=</span> parameters[<span class="st">&quot;w&quot;</span>],parameters[<span class="st">&quot;b&quot;</span>]</span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a>    <span class="co">#预测测试/训练集的例子</span></span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a>    Y_prediction_test <span class="op">=</span> predict(w,b,X_test)</span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a>    Y_prediction_train <span class="op">=</span> predict(w,b,X_train)</span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a>    <span class="co">#打印训练后的准确性</span></span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;训练集准确性：&quot;</span>  , <span class="bu">format</span>(<span class="dv">100</span> <span class="op">-</span> np.mean(np.<span class="bu">abs</span>(Y_prediction_train <span class="op">-</span> Y_train)) <span class="op">*</span> <span class="dv">100</span>) ,<span class="st">&quot;%&quot;</span>)</span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;测试集准确性：&quot;</span>  , <span class="bu">format</span>(<span class="dv">100</span> <span class="op">-</span> np.mean(np.<span class="bu">abs</span>(Y_prediction_test <span class="op">-</span> Y_test)) <span class="op">*</span> <span class="dv">100</span>) ,<span class="st">&quot;%&quot;</span>)</span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb29-32"><a href="#cb29-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-33"><a href="#cb29-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb29-34"><a href="#cb29-34" aria-hidden="true" tabindex="-1"></a>    d <span class="op">=</span> {</span>
<span id="cb29-35"><a href="#cb29-35" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;costs&quot;</span> : costs,</span>
<span id="cb29-36"><a href="#cb29-36" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;Y_prediction_test&quot;</span> : Y_prediction_test,</span>
<span id="cb29-37"><a href="#cb29-37" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;Y_prediciton_train&quot;</span> : Y_prediction_train,</span>
<span id="cb29-38"><a href="#cb29-38" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;w&quot;</span> : w,</span>
<span id="cb29-39"><a href="#cb29-39" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;b&quot;</span> : b,</span>
<span id="cb29-40"><a href="#cb29-40" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;learning_rate&quot;</span> : learning_rate,</span>
<span id="cb29-41"><a href="#cb29-41" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;num_iterations&quot;</span> : num_iterations }</span>
<span id="cb29-42"><a href="#cb29-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> d</span></code></pre></div>
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;====================测试model====================&quot;</span>)     </span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="co">#这里加载的是真实的数据，请参见上面的代码部分。</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations <span class="op">=</span> <span class="dv">2000</span>, learning_rate <span class="op">=</span> <span class="fl">0.005</span>, print_cost <span class="op">=</span> <span class="va">True</span>)</span></code></pre></div>
<pre><code>====================测试model====================
迭代的次数: 0 ， 误差值： 0.693147
迭代的次数: 100 ， 误差值： 0.584508
迭代的次数: 200 ， 误差值： 0.466949
迭代的次数: 300 ， 误差值： 0.376007
迭代的次数: 400 ， 误差值： 0.331463
迭代的次数: 500 ， 误差值： 0.303273
迭代的次数: 600 ， 误差值： 0.279880
迭代的次数: 700 ， 误差值： 0.260042
迭代的次数: 800 ， 误差值： 0.242941
迭代的次数: 900 ， 误差值： 0.228004
迭代的次数: 1000 ， 误差值： 0.214820
迭代的次数: 1100 ， 误差值： 0.203078
迭代的次数: 1200 ， 误差值： 0.192544
迭代的次数: 1300 ， 误差值： 0.183033
迭代的次数: 1400 ， 误差值： 0.174399
迭代的次数: 1500 ， 误差值： 0.166521
迭代的次数: 1600 ， 误差值： 0.159305
迭代的次数: 1700 ， 误差值： 0.152667
迭代的次数: 1800 ， 误差值： 0.146542
迭代的次数: 1900 ， 误差值： 0.140872
训练集准确性： 99.04306220095694 %
测试集准确性： 70.0 %</code></pre>
<h2 id="模型结果分析">3 模型结果分析</h2>
<p>在上述的模型结果中，我们可以看到模型在训练集和测试集上的不同表现。当我们修改学习率和迭代次数时，准确率会有些许的变化。现在我们将模型训练过程中的成本优化过程可视化，直观的观察模型训练过程。</p>
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co">#绘制图</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>costs <span class="op">=</span> np.squeeze(d[<span class="st">&#39;costs&#39;</span>])</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>plt.plot(costs)</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;cost&#39;</span>)</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;iterations (per hundreds)&#39;</span>)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Learning rate =&quot;</span> <span class="op">+</span> <span class="bu">str</span>(d[<span class="st">&quot;learning_rate&quot;</span>]))</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<p><img
src="https://cdn.jsdelivr.net/gh/vllbc/img4blog//image/output_34_0.png" /></p>
<p>可以看到在每次的迭代过程中，成本值都在降低，说明模型参数正在被学习。
### 3.1 学习率的选择</p>
<p>在模型参数中有一个“学习率”的概念，学习率决定了模型更新参数的速度，如果学习率设置的过高，模型可能会“超过”最小值，反之，则会造成过慢的收敛速度。
接下来，可以比较一下在你的模型上选用不同学习率时模型的变化。</p>
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>learning_rates <span class="op">=</span> [<span class="fl">0.01</span>, <span class="fl">0.001</span>, <span class="fl">0.0001</span>]</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> {}</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> learning_rates:</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span> (<span class="st">&quot;learning rate is: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(i))</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>    models[<span class="bu">str</span>(i)] <span class="op">=</span> model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations <span class="op">=</span> <span class="dv">1500</span>, learning_rate <span class="op">=</span> i, print_cost <span class="op">=</span> <span class="va">False</span>)</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span> (<span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span> <span class="op">+</span> <span class="st">&quot;-&quot;</span> <span class="op">+</span> <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>)</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> learning_rates:</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>    plt.plot(np.squeeze(models[<span class="bu">str</span>(i)][<span class="st">&quot;costs&quot;</span>]), label<span class="op">=</span> <span class="bu">str</span>(models[<span class="bu">str</span>(i)][<span class="st">&quot;learning_rate&quot;</span>]))</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;cost&#39;</span>)</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;iterations&#39;</span>)</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>legend <span class="op">=</span> plt.legend(loc<span class="op">=</span><span class="st">&#39;upper center&#39;</span>, shadow<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>frame <span class="op">=</span> legend.get_frame()</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>frame.set_facecolor(<span class="st">&#39;0.90&#39;</span>)</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<pre><code>learning rate is: 0.01
训练集准确性： 99.52153110047847 %
测试集准确性： 68.0 %

-

learning rate is: 0.001
训练集准确性： 88.99521531100478 %
测试集准确性： 64.0 %

-

learning rate is: 0.0001
训练集准确性： 68.42105263157895 %
测试集准确性： 36.0 %

-</code></pre>
<p><img
src="https://cdn.jsdelivr.net/gh/vllbc/img4blog//image/output_36_1.png" /></p>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>更新于 2023-03-24</span>
            </div></div>
        <div class="post-info-line">
            <div class="post-info-md"><span>
                            <a class="link-to-markdown" href="/%E5%85%B7%E6%9C%89%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%80%9D%E7%BB%B4%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/index.md" target="_blank">阅读原始文档</a>
                        </span></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="分享到 X" data-sharer="x" data-url="https://blog.vllbc.top/%E5%85%B7%E6%9C%89%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%80%9D%E7%BB%B4%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" data-title="具有逻辑回归思维的神经网络" data-hashtags="Deep Learning,项目练习,具有逻辑回归思维的神经网络"><i class="fab fa-x-twitter fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="分享到 Facebook" data-sharer="facebook" data-url="https://blog.vllbc.top/%E5%85%B7%E6%9C%89%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%80%9D%E7%BB%B4%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" data-hashtag="Deep Learning"><i class="fab fa-facebook-square fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="分享到 Hacker News" data-sharer="hackernews" data-url="https://blog.vllbc.top/%E5%85%B7%E6%9C%89%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%80%9D%E7%BB%B4%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" data-title="具有逻辑回归思维的神经网络"><i class="fab fa-hacker-news fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="分享到 Line" data-sharer="line" data-url="https://blog.vllbc.top/%E5%85%B7%E6%9C%89%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%80%9D%E7%BB%B4%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" data-title="具有逻辑回归思维的神经网络"><i data-svg-src="https://cdn.jsdelivr.net/npm/simple-icons@14.9.0/icons/line.svg" aria-hidden="true"></i></a><a href="javascript:void(0);" title="分享到 微博" data-sharer="weibo" data-url="https://blog.vllbc.top/%E5%85%B7%E6%9C%89%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%80%9D%E7%BB%B4%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" data-title="具有逻辑回归思维的神经网络"><i class="fab fa-weibo fa-fw" aria-hidden="true"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/deep-learning/">Deep Learning</a>,&nbsp;<a href="/tags/%E9%A1%B9%E7%9B%AE%E7%BB%83%E4%B9%A0/">项目练习</a>,&nbsp;<a href="/tags/%E5%85%B7%E6%9C%89%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%80%9D%E7%BB%B4%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">具有逻辑回归思维的神经网络</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="/">主页</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/kmeans/" class="prev" rel="prev" title="kmeans"><i class="fas fa-angle-left fa-fw" aria-hidden="true"></i>kmeans</a>
            <a href="/%E5%9B%A0%E5%AD%90%E5%88%86%E6%9E%90/" class="next" rel="next" title="因子分析">因子分析<i class="fas fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
<div id="comments"><div id="valine" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://valine.js.org/">Valine</a>.
            </noscript></div></article>

    <link rel="stylesheet" href="/lib/valine/valine.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mapbox-gl@2.9.1/dist/mapbox-gl.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.css"><link rel="stylesheet" href="/lib/aplayer/dark.min.css"><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/valine@1.5.0/dist/Valine.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/autocomplete.js@0.38.1/dist/autocomplete.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lunr@2.3.9/lunr.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.stemmer.support.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.zh.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/sharer.js@0.5.1/sharer.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/typeit@8.6.0/dist/index.umd.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mapbox-gl@2.9.1/dist/mapbox-gl.min.js"></script><script type="text/javascript" src="/lib/mapbox-gl/mapbox-gl-language.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/meting@2.0.1/dist/Meting.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"复制到剪贴板","maxShownLines":50},"comment":{"valine":{"appId":"Gf5fGIr3qceViiX6xGtzaWwR-gzGzoHsz","appKey":"5FiaGPazjefFXh6wr3CtcX2d","avatar":"hide","el":"#valine","emojiCDN":"https://cdn.jsdelivr.net/npm/emoji-datasource-google@14.0.0/img/google/64/","emojiMaps":{"100":"1f4af.png","alien":"1f47d.png","anger":"1f4a2.png","angry":"1f620.png","anguished":"1f627.png","astonished":"1f632.png","black_heart":"1f5a4.png","blue_heart":"1f499.png","blush":"1f60a.png","bomb":"1f4a3.png","boom":"1f4a5.png","broken_heart":"1f494.png","brown_heart":"1f90e.png","clown_face":"1f921.png","cold_face":"1f976.png","cold_sweat":"1f630.png","confounded":"1f616.png","confused":"1f615.png","cry":"1f622.png","crying_cat_face":"1f63f.png","cupid":"1f498.png","dash":"1f4a8.png","disappointed":"1f61e.png","disappointed_relieved":"1f625.png","dizzy":"1f4ab.png","dizzy_face":"1f635.png","drooling_face":"1f924.png","exploding_head":"1f92f.png","expressionless":"1f611.png","face_vomiting":"1f92e.png","face_with_cowboy_hat":"1f920.png","face_with_hand_over_mouth":"1f92d.png","face_with_head_bandage":"1f915.png","face_with_monocle":"1f9d0.png","face_with_raised_eyebrow":"1f928.png","face_with_rolling_eyes":"1f644.png","face_with_symbols_on_mouth":"1f92c.png","face_with_thermometer":"1f912.png","fearful":"1f628.png","flushed":"1f633.png","frowning":"1f626.png","ghost":"1f47b.png","gift_heart":"1f49d.png","green_heart":"1f49a.png","grimacing":"1f62c.png","grin":"1f601.png","grinning":"1f600.png","hankey":"1f4a9.png","hear_no_evil":"1f649.png","heart":"2764-fe0f.png","heart_decoration":"1f49f.png","heart_eyes":"1f60d.png","heart_eyes_cat":"1f63b.png","heartbeat":"1f493.png","heartpulse":"1f497.png","heavy_heart_exclamation_mark_ornament":"2763-fe0f.png","hole":"1f573-fe0f.png","hot_face":"1f975.png","hugging_face":"1f917.png","hushed":"1f62f.png","imp":"1f47f.png","innocent":"1f607.png","japanese_goblin":"1f47a.png","japanese_ogre":"1f479.png","joy":"1f602.png","joy_cat":"1f639.png","kiss":"1f48b.png","kissing":"1f617.png","kissing_cat":"1f63d.png","kissing_closed_eyes":"1f61a.png","kissing_heart":"1f618.png","kissing_smiling_eyes":"1f619.png","laughing":"1f606.png","left_speech_bubble":"1f5e8-fe0f.png","love_letter":"1f48c.png","lying_face":"1f925.png","mask":"1f637.png","money_mouth_face":"1f911.png","nauseated_face":"1f922.png","nerd_face":"1f913.png","neutral_face":"1f610.png","no_mouth":"1f636.png","open_mouth":"1f62e.png","orange_heart":"1f9e1.png","partying_face":"1f973.png","pensive":"1f614.png","persevere":"1f623.png","pleading_face":"1f97a.png","pouting_cat":"1f63e.png","purple_heart":"1f49c.png","rage":"1f621.png","relaxed":"263a-fe0f.png","relieved":"1f60c.png","revolving_hearts":"1f49e.png","right_anger_bubble":"1f5ef-fe0f.png","robot_face":"1f916.png","rolling_on_the_floor_laughing":"1f923.png","scream":"1f631.png","scream_cat":"1f640.png","see_no_evil":"1f648.png","shushing_face":"1f92b.png","skull":"1f480.png","skull_and_crossbones":"2620-fe0f.png","sleeping":"1f634.png","sleepy":"1f62a.png","slightly_frowning_face":"1f641.png","slightly_smiling_face":"1f642.png","smile":"1f604.png","smile_cat":"1f638.png","smiley":"1f603.png","smiley_cat":"1f63a.png","smiling_face_with_3_hearts":"1f970.png","smiling_imp":"1f608.png","smirk":"1f60f.png","smirk_cat":"1f63c.png","sneezing_face":"1f927.png","sob":"1f62d.png","space_invader":"1f47e.png","sparkling_heart":"1f496.png","speak_no_evil":"1f64a.png","speech_balloon":"1f4ac.png","star-struck":"1f929.png","stuck_out_tongue":"1f61b.png","stuck_out_tongue_closed_eyes":"1f61d.png","stuck_out_tongue_winking_eye":"1f61c.png","sunglasses":"1f60e.png","sweat":"1f613.png","sweat_drops":"1f4a6.png","sweat_smile":"1f605.png","thinking_face":"1f914.png","thought_balloon":"1f4ad.png","tired_face":"1f62b.png","triumph":"1f624.png","two_hearts":"1f495.png","unamused":"1f612.png","upside_down_face":"1f643.png","weary":"1f629.png","white_frowning_face":"2639-fe0f.png","white_heart":"1f90d.png","wink":"1f609.png","woozy_face":"1f974.png","worried":"1f61f.png","yawning_face":"1f971.png","yellow_heart":"1f49b.png","yum":"1f60b.png","zany_face":"1f92a.png","zipper_mouth_face":"1f910.png","zzz":"1f4a4.png"},"enableQQ":true,"highlight":true,"lang":"zh-CN","pageSize":10,"placeholder":"如何评价这篇博文？","recordIP":true,"visitor":true}},"data":{"id-1":"这一个带有基于 \u003ca href=\"https://typeitjs.com/\"\u003eTypeIt\u003c/a\u003e 的 \u003cstrong\u003e打字动画\u003c/strong\u003e 的 \u003cem\u003e段落\u003c/em\u003e…","id-2":["\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e","\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;hello world\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e","\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e"],"id-3":{"darkStyle":"mapbox://styles/mapbox/dark-v10?optimize=true","fullscreen":true,"geolocate":true,"lat":31.233,"lightStyle":"mapbox://styles/mapbox/light-v10?optimize=true","lng":121.485,"marked":true,"navigation":true,"scale":true,"zoom":12},"id-4":{"darkStyle":"mapbox://styles/mapbox/dark-v10?optimize=true","fullscreen":true,"geolocate":true,"lat":37.453,"lightStyle":"mapbox://styles/mapbox/streets-zh-v1","lng":-122.252,"marked":false,"navigation":true,"scale":true,"zoom":10}},"mapbox":{"RTLTextPlugin":"https://api.mapbox.com/mapbox-gl-js/plugins/mapbox-gl-rtl-text/v0.2.0/mapbox-gl-rtl-text.js","accessToken":"pk.eyJ1IjoiZGlsbG9uenEiLCJhIjoiY2s2czd2M2x3MDA0NjNmcGxmcjVrZmc2cyJ9.aSjv2BNuZUfARvxRYjSVZQ"},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","lunrLanguageCode":"zh","lunrSegmentitURL":"/lib/lunr/lunr.segmentit.js","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"lunr"},"typeit":{"cursorChar":"|","cursorSpeed":1000,"data":{"id-1":["id-1"],"id-2":["id-2"]},"duration":-1,"speed":100}};</script><script type="text/javascript" src="/js/theme.min.js"></script></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line" itemscope itemtype="http://schema.org/CreativeWork"><i class="far fa-copyright fa-fw" aria-hidden="true"></i><span itemprop="copyrightYear">2020 - 2025</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank"></a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="回到顶部">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a>
        </div>

        <div id="fixed-buttons-hidden"><a href="#" id="view-comments" class="fixed-button" title="查看评论">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/valine/valine.min.css"><script src="https://cdn.jsdelivr.net/npm/valine@1.5.3/dist/Valine.min.js"></script><script src="https://cdn.jsdelivr.net/npm/autocomplete.js@0.38.1/dist/autocomplete.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lunr@2.3.9/lunr.min.js"></script><script src="/lib/lunr/lunr.stemmer.support.min.js"></script><script src="/lib/lunr/lunr.zh.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js"></script><script src="https://cdn.jsdelivr.net/npm/sharer.js@0.5.2/sharer.min.js"></script><script>window.config={"comment":{"valine":{"appId":"Gf5fGIr3qceViiX6xGtzaWwR-gzGzoHsz","appKey":"5FiaGPazjefFXh6wr3CtcX2d","avatar":"hide","el":"#valine","emojiCDN":"https://cdn.jsdelivr.net/npm/emoji-datasource-google@15.1.2/img/google/64/","emojiMaps":{"100":"1f4af.png","alien":"1f47d.png","anger":"1f4a2.png","angry":"1f620.png","anguished":"1f627.png","astonished":"1f632.png","black_heart":"1f5a4.png","blue_heart":"1f499.png","blush":"1f60a.png","bomb":"1f4a3.png","boom":"1f4a5.png","broken_heart":"1f494.png","brown_heart":"1f90e.png","clown_face":"1f921.png","cold_face":"1f976.png","cold_sweat":"1f630.png","confounded":"1f616.png","confused":"1f615.png","cry":"1f622.png","crying_cat_face":"1f63f.png","cupid":"1f498.png","dash":"1f4a8.png","disappointed":"1f61e.png","disappointed_relieved":"1f625.png","dizzy":"1f4ab.png","dizzy_face":"1f635.png","drooling_face":"1f924.png","exploding_head":"1f92f.png","expressionless":"1f611.png","face_vomiting":"1f92e.png","face_with_cowboy_hat":"1f920.png","face_with_hand_over_mouth":"1f92d.png","face_with_head_bandage":"1f915.png","face_with_monocle":"1f9d0.png","face_with_raised_eyebrow":"1f928.png","face_with_rolling_eyes":"1f644.png","face_with_symbols_on_mouth":"1f92c.png","face_with_thermometer":"1f912.png","fearful":"1f628.png","flushed":"1f633.png","frowning":"1f626.png","ghost":"1f47b.png","gift_heart":"1f49d.png","green_heart":"1f49a.png","grimacing":"1f62c.png","grin":"1f601.png","grinning":"1f600.png","hankey":"1f4a9.png","hear_no_evil":"1f649.png","heart":"2764-fe0f.png","heart_decoration":"1f49f.png","heart_eyes":"1f60d.png","heart_eyes_cat":"1f63b.png","heartbeat":"1f493.png","heartpulse":"1f497.png","heavy_heart_exclamation_mark_ornament":"2763-fe0f.png","hole":"1f573-fe0f.png","hot_face":"1f975.png","hugging_face":"1f917.png","hushed":"1f62f.png","imp":"1f47f.png","innocent":"1f607.png","japanese_goblin":"1f47a.png","japanese_ogre":"1f479.png","joy":"1f602.png","joy_cat":"1f639.png","kiss":"1f48b.png","kissing":"1f617.png","kissing_cat":"1f63d.png","kissing_closed_eyes":"1f61a.png","kissing_heart":"1f618.png","kissing_smiling_eyes":"1f619.png","laughing":"1f606.png","left_speech_bubble":"1f5e8-fe0f.png","love_letter":"1f48c.png","lying_face":"1f925.png","mask":"1f637.png","money_mouth_face":"1f911.png","nauseated_face":"1f922.png","nerd_face":"1f913.png","neutral_face":"1f610.png","no_mouth":"1f636.png","open_mouth":"1f62e.png","orange_heart":"1f9e1.png","partying_face":"1f973.png","pensive":"1f614.png","persevere":"1f623.png","pleading_face":"1f97a.png","pouting_cat":"1f63e.png","purple_heart":"1f49c.png","rage":"1f621.png","relaxed":"263a-fe0f.png","relieved":"1f60c.png","revolving_hearts":"1f49e.png","right_anger_bubble":"1f5ef-fe0f.png","robot_face":"1f916.png","rolling_on_the_floor_laughing":"1f923.png","scream":"1f631.png","scream_cat":"1f640.png","see_no_evil":"1f648.png","shushing_face":"1f92b.png","skull":"1f480.png","skull_and_crossbones":"2620-fe0f.png","sleeping":"1f634.png","sleepy":"1f62a.png","slightly_frowning_face":"1f641.png","slightly_smiling_face":"1f642.png","smile":"1f604.png","smile_cat":"1f638.png","smiley":"1f603.png","smiley_cat":"1f63a.png","smiling_face_with_3_hearts":"1f970.png","smiling_imp":"1f608.png","smirk":"1f60f.png","smirk_cat":"1f63c.png","sneezing_face":"1f927.png","sob":"1f62d.png","space_invader":"1f47e.png","sparkling_heart":"1f496.png","speak_no_evil":"1f64a.png","speech_balloon":"1f4ac.png","star-struck":"1f929.png","stuck_out_tongue":"1f61b.png","stuck_out_tongue_closed_eyes":"1f61d.png","stuck_out_tongue_winking_eye":"1f61c.png","sunglasses":"1f60e.png","sweat":"1f613.png","sweat_drops":"1f4a6.png","sweat_smile":"1f605.png","thinking_face":"1f914.png","thought_balloon":"1f4ad.png","tired_face":"1f62b.png","triumph":"1f624.png","two_hearts":"1f495.png","unamused":"1f612.png","upside_down_face":"1f643.png","weary":"1f629.png","white_frowning_face":"2639-fe0f.png","white_heart":"1f90d.png","wink":"1f609.png","woozy_face":"1f974.png","worried":"1f61f.png","yawning_face":"1f971.png","yellow_heart":"1f49b.png","yum":"1f60b.png","zany_face":"1f92a.png","zipper_mouth_face":"1f910.png","zzz":"1f4a4.png"},"enableQQ":true,"highlight":true,"lang":"zh-CN","pageSize":10,"placeholder":"如何评价这篇博文？","recordIP":true,"visitor":true}},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","lunrLanguageCode":"zh","lunrSegmentitURL":"/lib/lunr/lunr.segmentit.js","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"lunr"}};</script><script src="/js/theme.min.js"></script></body>
</html>
