<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>EM算法 - 标签 - vllbc02&#39;s blogs</title>
        <link>https://blog.vllbc.top/tags/em%E7%AE%97%E6%B3%95/</link>
        <description>EM算法 - 标签 - vllbc02&#39;s blogs</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Mon, 03 Oct 2022 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://blog.vllbc.top/tags/em%E7%AE%97%E6%B3%95/" rel="self" type="application/rss+xml" /><item>
    <title>EM算法</title>
    <link>https://blog.vllbc.top/em%E7%AE%97%E6%B3%95/</link>
    <pubDate>Mon, 03 Oct 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/em%E7%AE%97%E6%B3%95/</guid>
    <description><![CDATA[<h1 id="em算法">EM算法</h1>
<h2 id="引入">引入</h2>
<p>我们经常会从样本观察数据中，找出样本的模型参数。
最常用的方法就是极大化模型分布的对数似然函数。（最大似然估计：利用已知的样本结果，反推最有可能导致这样结果的一组参数）但是在一些情况下，我们得到的观察数据有未观察到的隐含数据，此时我们未知的有隐含数据和模型参数，因而无法直接用极大化对数似然函数得到模型分布的参数。用EM算法可以解决。</p>]]></description>
</item>
</channel>
</rss>
