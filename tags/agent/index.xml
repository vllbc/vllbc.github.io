<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Agent - 标签 - vllbc02&#39;s blogs</title>
        <link>https://blog.vllbc.top/tags/agent/</link>
        <description>Agent - 标签 - vllbc02&#39;s blogs</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Wed, 16 Jul 2025 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://blog.vllbc.top/tags/agent/" rel="self" type="application/rss+xml" /><item>
    <title>Search-R1：Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning</title>
    <link>https://blog.vllbc.top/search-r1training-llms-to-reason-and-leverage-search-engines-with-reinforcement-learning/</link>
    <pubDate>Wed, 16 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/search-r1training-llms-to-reason-and-leverage-search-engines-with-reinforcement-learning/</guid>
    <description><![CDATA[<p>好的，作为大模型领域的学术专家，我非常乐于为您深入解读这篇具有重要意义的论文《SEARCH-R
1: Training LLMs to Reason and Leverage Search Engines with
Reinforcement Learning》。</p>
<p>这篇论文的核心，是探索如何让大型语言模型（LLM）<strong>学会</strong>像人类专家一样，在解决复杂问题时，<strong>主动、智能、且迭代地使用搜索引擎</strong>。它不仅仅是简单地把搜索结果“喂”给模型，而是通过<strong>强化学习（Reinforcement
Learning,
RL）</strong>，训练模型形成一种内在的“研究”能力——知道<strong>什么时候</strong>需要信息，需要<strong>什么</strong>信息，以及如何<strong>整合</strong>这些信息来形成最终答案。</p>]]></description>
</item>
<item>
    <title>WebThinker：Empowering Large Reasoning Models with Deep Research Capability</title>
    <link>https://blog.vllbc.top/webthinkerempowering-large-reasoning-models-with-deep-research-capability/</link>
    <pubDate>Wed, 16 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/webthinkerempowering-large-reasoning-models-with-deep-research-capability/</guid>
    <description><![CDATA[<p>好的，作为大模型领域的专家，我很乐意为您深入解读这篇富有洞见的论文《WebThinker:
Empowering Large Reasoning Models with Deep Research
Capability》。这篇论文确实触及了当前大模型研究的前沿核心——如何让模型从一个静态的“知识库”转变为一个动态的“研究员”。</p>]]></description>
</item>
<item>
    <title>world_model</title>
    <link>https://blog.vllbc.top/world_model/</link>
    <pubDate>Mon, 30 Jun 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/world_model/</guid>
    <description><![CDATA[<p>我理解的agent中的world
model即可以预测采取某个action之后state的变化，这样做的好处是可以降低试错带来的时间成本或者是其它潜在的成本、风险。</p>]]></description>
</item>
<item>
    <title>agent概览</title>
    <link>https://blog.vllbc.top/agent%E6%A6%82%E8%A7%88/</link>
    <pubDate>Sat, 14 Jun 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/agent%E6%A6%82%E8%A7%88/</guid>
    <description><![CDATA[<p>根据Anthropic的定义，agent定义如下：</p>
<blockquote>
<p>At Anthropic, we categorize all these variations as <strong>agentic
systems</strong>, but draw an important architectural distinction
between <strong>workflows</strong> and <strong>agents</strong>:
<strong>Workflows</strong> are systems where LLMs and tools are
orchestrated through predefined code paths. <strong>Agents</strong>, on
the other hand, are systems where LLMs dynamically direct their own
processes and tool usage, maintaining control over how they accomplish
tasks.</p>]]></description>
</item>
</channel>
</rss>
