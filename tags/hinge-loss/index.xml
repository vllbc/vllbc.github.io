<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Hinge Loss - 标签 - vllbc02&#39;s blogs</title>
        <link>https://blog.vllbc.top/tags/hinge-loss/</link>
        <description>Hinge Loss - 标签 - vllbc02&#39;s blogs</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Mon, 13 Mar 2023 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://blog.vllbc.top/tags/hinge-loss/" rel="self" type="application/rss+xml" /><item>
    <title>hinge loss</title>
    <link>https://blog.vllbc.top/hinge-loss/</link>
    <pubDate>Mon, 13 Mar 2023 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/hinge-loss/</guid>
    <description><![CDATA[<p>在机器学习中，<strong>hinge
loss</strong>是一种损失函数，它通常用于”maximum-margin”的分类任务中，如支持向量机。数学表达式为：</p>
<p></p>
<p>其中 <span
class="math inline">\(\hat{y}\)</span> 表示预测输出，通常都是软结果（就是说输出不是0，1这种，可能是0.87。）， <span
class="math inline">\(y\)</span> 表示正确的类别。 - 如果 <span
class="math inline">\(\hat{y}y&lt;1\)</span> ，则损失为： <span
class="math inline">\(1-\hat{y}y\)</span> - 如果<span
class="math inline">\(\hat{y}y&gt;1\)</span> ，则损失为：0</p>]]></description>
</item>
</channel>
</rss>
