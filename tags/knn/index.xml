<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>KNN - 标签 - vllbc02&#39;s blogs</title>
        <link>https://blog.vllbc.top/tags/knn/</link>
        <description>KNN - 标签 - vllbc02&#39;s blogs</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Sat, 25 Jun 2022 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://blog.vllbc.top/tags/knn/" rel="self" type="application/rss+xml" /><item>
    <title>KNN</title>
    <link>https://blog.vllbc.top/knn/</link>
    <pubDate>Sat, 25 Jun 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/knn/</guid>
    <description><![CDATA[<h1 id="knn">KNN</h1>
<p>参考：<a
href="https://cuijiahua.com/blog/2017/11/ml_1_knn.html">https://cuijiahua.com/blog/2017/11/ml_1_knn.html</a></p>
<p>《统计学习方法》李航（kd树）</p>
<h2 id="简介">简介</h2>
<p>k近邻法(k-nearest neighbor, k-NN)是1967年由Cover T和Hart
P提出的一种基本分类与回归方法。它的工作原理是：存在一个样本数据集合，也称作为训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每一个数据与所属分类的对应关系。输入没有标签的新数据后，将新的数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本最相似数据(最近邻)的分类标签。一般来说，我们只选择样本数据集中前k个最相似的数据，这就是k-近邻算法中k的出处，通常k是不大于20的整数。最后，选择k个最相似数据中出现次数最多的分类，作为新数据的分类。</p>]]></description>
</item>
<item>
    <title>KNN</title>
    <link>https://blog.vllbc.top/knn/</link>
    <pubDate>Tue, 09 Nov 2021 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/knn/</guid>
    <description><![CDATA[<h2 id="导入包">导入包</h2>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.graph_objects <span class="im">as</span> go</span></code></pre></div>
<h2 id="导入数据">导入数据</h2>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(<span class="st">&quot;./datasets/Social_Network_Ads.csv&quot;</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> data.iloc[:,[<span class="dv">2</span>,<span class="dv">3</span>]].values</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> data.iloc[:,<span class="dv">4</span>].values</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># scatter = go.Scatter(x=X[:,0],y=X[:,1],mode=&#39;markers&#39;,marker={&#39;color&#39;:Y})</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># fig = go.Figure(scatter)</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># fig.show()</span></span></code></pre></div>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>X_train,X_test,Y_train,Y_test <span class="op">=</span> train_test_split(X,Y,test_size<span class="op">=</span><span class="fl">0.25</span>,random_state<span class="op">=</span><span class="dv">0</span>)</span></code></pre></div>
<h2 id="标准化">标准化</h2>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>sca <span class="op">=</span> StandardScaler()</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> sca.fit_transform(X_train)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> sca.transform(X_test)</span></code></pre></div>
<h2 id="训练模型">训练模型</h2>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">5</span>,p<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>model.fit(X_train,Y_train)</span></code></pre></div>
<pre><code>KNeighborsClassifier()</code></pre>
<h2 id="模型得分">模型得分</h2>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>model.score(X_test,Y_test)</span></code></pre></div>
<pre><code>0.93</code></pre>]]></description>
</item>
</channel>
</rss>
