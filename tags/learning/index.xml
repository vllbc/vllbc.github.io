<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Learning - 标签 - vllbc02&#39;s blogs</title>
        <link>https://blog.vllbc.top/tags/learning/</link>
        <description>Learning - 标签 - vllbc02&#39;s blogs</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Thu, 02 Mar 2023 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://blog.vllbc.top/tags/learning/" rel="self" type="application/rss+xml" /><item>
    <title>对抗训练</title>
    <link>https://blog.vllbc.top/%E5%AF%B9%E6%8A%97%E8%AE%AD%E7%BB%83/</link>
    <pubDate>Thu, 02 Mar 2023 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/%E5%AF%B9%E6%8A%97%E8%AE%AD%E7%BB%83/</guid>
    <description><![CDATA[<h1 id="min-max公式">Min-Max公式</h1>
<p>$$ <em>{} </em>{(x,y) }U[<em>{r</em>{adv}}L(,x+r_{adv},y)]</p>
<p>$$</p>
<ol type="1">
<li>内部max是为了找到worst-case的扰动，也就是攻击，其中， <span
class="math inline">\(L\)</span>为损失函数， <span
class="math inline">\(\mathbb{S}\)</span> 为扰动的范围空间。</li>
<li>外部min是为了基于该攻击方式，找到最鲁棒的模型参数，也就是防御，其中 <span
class="math inline">\(\mathbb{D}\)</span> 是输入样本的分布。
简单理解就是<strong>在输入上进行梯度上升(增大loss)，在参数上进行梯度下降(减小loss)</strong></li>
</ol>
<h1 id="加入扰动后的损失函数">加入扰动后的损失函数</h1>
<p>$$ <em>{} -P(y |x+r</em>{adv};)</p>]]></description>
</item>
<item>
    <title>Adam算法</title>
    <link>https://blog.vllbc.top/adam/</link>
    <pubDate>Sun, 11 Sep 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/adam/</guid>
    <description><![CDATA[<h2 id="moment矩">moment(矩)</h2>
<p>矩在数学中的定义，一阶矩(first moment)就是样本的均值(mean),
二阶矩就是方差（variance）。 ## 滑动平均 滑动平均(exponential moving
average)，或者叫做指数加权平均(exponentially weighted moving
average)，可以用来估计变量的局部均值，使得变量的更新与一段时间内的历史取值有关。在时间序列预测中也常用。</p>]]></description>
</item>
</channel>
</rss>
