<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>特征选择 - 标签 - vllbc02&#39;s blogs</title>
        <link>https://blog.vllbc.top/tags/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/</link>
        <description>特征选择 - 标签 - vllbc02&#39;s blogs</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Wed, 08 Mar 2023 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://blog.vllbc.top/tags/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/" rel="self" type="application/rss+xml" /><item>
    <title>特征选择</title>
    <link>https://blog.vllbc.top/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/</link>
    <pubDate>Wed, 08 Mar 2023 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/</guid>
    <description><![CDATA[<p><code>特征选择</code>是<code>特征工程</code>里的一个重要问题，其目标是<strong>寻找最优特征子集</strong>。特征选择能剔除不相关(irrelevant)或冗余(redundant
)的特征，从而达到减少特征个数，<strong>提高模型精确度，减少运行时间的目的</strong>。另一方面，选取出真正相关的特征简化模型，协助理解数据产生的过程。并且常能听到“数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已”，由此可见其重要性。但是它几乎很少出现于机器学习书本里面的某一章。然而在机器学习方面的成功很大程度上在于如果使用特征工程。</p>]]></description>
</item>
</channel>
</rss>
