<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Coding - 标签 - vllbc02&#39;s blogs</title>
        <link>https://blog.vllbc.top/tags/coding/</link>
        <description>Coding - 标签 - vllbc02&#39;s blogs</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Thu, 05 Jun 2025 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://blog.vllbc.top/tags/coding/" rel="self" type="application/rss+xml" /><item>
    <title>verl总体概览</title>
    <link>https://blog.vllbc.top/verl%E6%80%BB%E4%BD%93%E6%A6%82%E8%A7%88/</link>
    <pubDate>Thu, 05 Jun 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/verl%E6%80%BB%E4%BD%93%E6%A6%82%E8%A7%88/</guid>
    <description><![CDATA[
]]></description>
</item>
<item>
    <title>reward_mananger</title>
    <link>https://blog.vllbc.top/reward_mananger/</link>
    <pubDate>Mon, 02 Jun 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/reward_mananger/</guid>
    <description><![CDATA[<p>最原生的reward_mananger:</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NaiveRewardManager:</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;The reward manager.&quot;&quot;&quot;</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, tokenizer, num_examine, compute_score<span class="op">=</span><span class="va">None</span>, reward_fn_key<span class="op">=</span><span class="st">&quot;data_source&quot;</span>) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tokenizer <span class="op">=</span> tokenizer</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_examine <span class="op">=</span> num_examine  <span class="co"># the number of batches of decoded responses to print to the console</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.compute_score <span class="op">=</span> compute_score <span class="kw">or</span> default_compute_score</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.reward_fn_key <span class="op">=</span> reward_fn_key</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, data: DataProto, return_dict<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;We will expand this function gradually based on the available datasets&quot;&quot;&quot;</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If there is rm score, we directly return rm score. Otherwise, we compute via rm_score_fn</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">&quot;rm_scores&quot;</span> <span class="kw">in</span> data.batch.keys():</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> return_dict:</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> {<span class="st">&quot;reward_tensor&quot;</span>: data.batch[<span class="st">&quot;rm_scores&quot;</span>]}</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> data.batch[<span class="st">&quot;rm_scores&quot;</span>]</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>        reward_tensor <span class="op">=</span> torch.zeros_like(data.batch[<span class="st">&quot;responses&quot;</span>], dtype<span class="op">=</span>torch.float32)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>        reward_extra_info <span class="op">=</span> defaultdict(<span class="bu">list</span>)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>        already_print_data_sources <span class="op">=</span> {}</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(data)):</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>            data_item <span class="op">=</span> data[i]  <span class="co"># DataProtoItem</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>            prompt_ids <span class="op">=</span> data_item.batch[<span class="st">&quot;prompts&quot;</span>]</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>            prompt_length <span class="op">=</span> prompt_ids.shape[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>            valid_prompt_length <span class="op">=</span> data_item.batch[<span class="st">&quot;attention_mask&quot;</span>][:prompt_length].<span class="bu">sum</span>()</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>            valid_prompt_ids <span class="op">=</span> prompt_ids[<span class="op">-</span>valid_prompt_length:]</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>            response_ids <span class="op">=</span> data_item.batch[<span class="st">&quot;responses&quot;</span>]</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>            valid_response_length <span class="op">=</span> data_item.batch[<span class="st">&quot;attention_mask&quot;</span>][prompt_length:].<span class="bu">sum</span>()</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>            valid_response_ids <span class="op">=</span> response_ids[:valid_response_length]</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>            <span class="co"># decode</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>            prompt_str <span class="op">=</span> <span class="va">self</span>.tokenizer.decode(valid_prompt_ids, skip_special_tokens<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>            response_str <span class="op">=</span> <span class="va">self</span>.tokenizer.decode(valid_response_ids, skip_special_tokens<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>            ground_truth <span class="op">=</span> data_item.non_tensor_batch[<span class="st">&quot;reward_model&quot;</span>][<span class="st">&quot;ground_truth&quot;</span>]</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>            data_source <span class="op">=</span> data_item.non_tensor_batch[<span class="va">self</span>.reward_fn_key]</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>            extra_info <span class="op">=</span> data_item.non_tensor_batch.get(<span class="st">&quot;extra_info&quot;</span>, <span class="va">None</span>)</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>            score <span class="op">=</span> <span class="va">self</span>.compute_score(</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>                data_source<span class="op">=</span>data_source,</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>                solution_str<span class="op">=</span>response_str,</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>                ground_truth<span class="op">=</span>ground_truth,</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>                extra_info<span class="op">=</span>extra_info,</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(score, <span class="bu">dict</span>):</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>                reward <span class="op">=</span> score[<span class="st">&quot;score&quot;</span>]</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Store the information including original reward</span></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> key, value <span class="kw">in</span> score.items():</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>                    reward_extra_info[key].append(value)</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>                reward <span class="op">=</span> score</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>            reward_tensor[i, valid_response_length <span class="op">-</span> <span class="dv">1</span>] <span class="op">=</span> reward</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> data_source <span class="kw">not</span> <span class="kw">in</span> already_print_data_sources:</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>                already_print_data_sources[data_source] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> already_print_data_sources[data_source] <span class="op">&lt;</span> <span class="va">self</span>.num_examine:</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>                already_print_data_sources[data_source] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="st">&quot;[prompt]&quot;</span>, prompt_str)</span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="st">&quot;[response]&quot;</span>, response_str)</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="st">&quot;[ground_truth]&quot;</span>, ground_truth)</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> <span class="bu">isinstance</span>(score, <span class="bu">dict</span>):</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">for</span> key, value <span class="kw">in</span> score.items():</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>                        <span class="bu">print</span>(<span class="ss">f&quot;[</span><span class="sc">{</span>key<span class="sc">}</span><span class="ss">]&quot;</span>, value)</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">print</span>(<span class="st">&quot;[score]&quot;</span>, score)</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> return_dict:</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> {</span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;reward_tensor&quot;</span>: reward_tensor,</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;reward_extra_info&quot;</span>: reward_extra_info,</span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> reward_tensor</span></code></pre></div>
<p>逻辑很简单，就是通过compute_score函数来计算score。</p>]]></description>
</item>
<item>
    <title>basic</title>
    <link>https://blog.vllbc.top/basic/</link>
    <pubDate>Sun, 18 May 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/basic/</guid>
    <description><![CDATA[<h2 id="example">example</h2>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> hydra</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> omegaconf <span class="im">import</span> DictConfig, OmegaConf</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="at">@hydra.main</span>(version_base<span class="op">=</span><span class="va">None</span>, config_path<span class="op">=</span><span class="st">&quot;conf&quot;</span>, config_name<span class="op">=</span><span class="st">&quot;config.yaml&quot;</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> main(cfg: DictConfig):</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(OmegaConf.to_yaml(cfg))</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&quot;__main__&quot;</span>:</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    main()</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>]]></description>
</item>
<item>
    <title>LEGB</title>
    <link>https://blog.vllbc.top/legb/</link>
    <pubDate>Mon, 24 Mar 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/legb/</guid>
    <description><![CDATA[<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> <span class="st">&#39;global&#39;</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> outer():</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># def len(in_var):</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     print(&#39;called my len() function: &#39;, end=&quot;&quot;)</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     l = 0</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     for i in in_var:</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">#         l += 1</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     return l</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> <span class="st">&#39;local&#39;</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> inner():</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>        <span class="kw">nonlocal</span> a</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>        a <span class="op">+=</span> <span class="st">&#39; variable&#39;</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    inner()</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&#39;a is&#39;</span>, a)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># print(len(a))</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>outer()</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="co"># print(len(a))</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;a is&#39;</span>, a)</span></code></pre></div>
<p>此时为nonlocal
a，会按照local-闭包-global的顺序找到闭包变量a。a的值为local variable</p>]]></description>
</item>
<item>
    <title>debugger</title>
    <link>https://blog.vllbc.top/debugger/</link>
    <pubDate>Sun, 23 Mar 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/debugger/</guid>
    <description><![CDATA[<p>python调试工具，类似于vscode的调试工具，使用命令行进行调试。</p>
<h2 id="使用方法">使用方法</h2>
<h3 id="插入式">插入式</h3>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pdb<span class="op">;</span> pdb.set_trace()</span></code></pre></div>
<p>或者</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="bu">breakpoint</span>()</span></code></pre></div>
<h3 id="非插入式">非插入式</h3>
<pre><code>python -m pdb [-c command] (-m module | pyfile) [args ...]</code></pre>
<h2 id="常用命令">常用命令</h2>
<h3 id="h">h</h3>
<p>即help，可用命令如下 </p>]]></description>
</item>
<item>
    <title>generate</title>
    <link>https://blog.vllbc.top/generate/</link>
    <pubDate>Sun, 09 Mar 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/generate/</guid>
    <description><![CDATA[<p>理论部分在这：<a
href="../../NLP/LLM/generate相关.md">generate相关</a> ##
generate参数</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> generate(</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>        inputs: Optional[torch.Tensor] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>        generation_config: Optional[GenerationConfig] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>        logits_processor: Optional[LogitsProcessorList] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>        stopping_criteria: Optional[StoppingCriteriaList] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>        prefix_allowed_tokens_fn: Optional[Callable[[<span class="bu">int</span>, torch.Tensor], List[<span class="bu">int</span>]]] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>        synced_gpus: Optional[<span class="bu">bool</span>] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>        assistant_model: Optional[<span class="st">&quot;PreTrainedModel&quot;</span>] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>        streamer: Optional[<span class="st">&quot;BaseStreamer&quot;</span>] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>        negative_prompt_ids: Optional[torch.Tensor] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>        negative_prompt_attention_mask: Optional[torch.Tensor] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>        <span class="op">**</span>kwargs,</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    ) <span class="op">-&gt;</span> Union[GenerateOutput, torch.LongTensor]:</span></code></pre></div>
<p>在代码中可以看到在函数入口显式的定义了很多参数。他们的具体含义如下</p>]]></description>
</item>
<item>
    <title>gather和scatter</title>
    <link>https://blog.vllbc.top/gather%E5%92%8Cscatter/</link>
    <pubDate>Fri, 20 Dec 2024 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/gather%E5%92%8Cscatter/</guid>
    <description><![CDATA[<h2 id="gather">gather</h2>
<p>参数：</p>
<ul>
<li><strong>input</strong> (<a
href="https://link.zhihu.com/?target=https%3A//pytorch.org/docs/stable/tensors.html%23torch.Tensor">Tensor</a>)
– the source tensor</li>
<li><strong>dim</strong> (<a
href="https://link.zhihu.com/?target=https%3A//docs.python.org/3/library/functions.html%23int">int</a>)
– the axis along which to index</li>
<li><strong>index</strong> (<em>LongTensor</em>) – the indices of
elements to gather</li>
<li><strong>out</strong> (<a
href="https://link.zhihu.com/?target=https%3A//pytorch.org/docs/stable/tensors.html%23torch.Tensor">Tensor</a>_,__optional_)
– the destination tensor</li>
<li><strong>sparse_grad</strong> (<a
href="https://link.zhihu.com/?target=https%3A//docs.python.org/3/library/functions.html%23bool">bool</a><em>,optional</em>)
– If <code>True</code>, gradient w.r.t. <code>input</code> will be a
sparse tensor. &gt;
gather操作是scatter操作的<strong>逆操作</strong>，如果说scatter是根据index和src求self(<em>input</em>)，那么gather操作是根据self(input)和index求src。具体来说gather操作是根据index指出的索引，沿dim指定的轴收集input的值。</li>
</ul>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>out[i][j][k] <span class="op">=</span> <span class="bu">input</span>[index[i][j][k]][j][k]  <span class="co"># if dim == 0</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>out[i][j][k] <span class="op">=</span> <span class="bu">input</span>[i][index[i][j][k]][k]  <span class="co"># if dim == 1</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>out[i][j][k] <span class="op">=</span> <span class="bu">input</span>[i][j][index[i][j][k]]  <span class="co"># if dim == 2</span></span></code></pre></div>
<p>对于gather操作来说，有三个约束需要满足：</p>]]></description>
</item>
</channel>
</rss>
