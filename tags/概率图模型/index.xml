<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>概率图模型 - 标签 - vllbc02&#39;s blogs</title>
        <link>https://blog.vllbc.top/tags/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/</link>
        <description>概率图模型 - 标签 - vllbc02&#39;s blogs</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Thu, 12 May 2022 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://blog.vllbc.top/tags/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/" rel="self" type="application/rss+xml" /><item>
    <title>条件随机场</title>
    <link>https://blog.vllbc.top/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/</link>
    <pubDate>Thu, 12 May 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/</guid>
    <description><![CDATA[<h1 id="crf">CRF</h1>
<h2 id="概率图模型与无向图">概率图模型与无向图</h2>
<p>图是由结点和连接结点的边组成的集合。结点和边分别记作v和e，结点和边的集合分别记作V和E，图记作<span
class="math inline">\(G=(V, E)\)</span>。</p>
<p>无向图是指没有方向的图。</p>
<p>概率图模型是由图表示的概率分布。设有联合概率分布P(Y),
Y是一组随机变量，由无向图<span
class="math inline">\(G=(V,E)\)</span>表示概率分布P(Y)，即在图G中，结点<span
class="math inline">\(v\in V\)</span>表示一个随机变量<span
class="math inline">\(Y_v\)</span>，<span
class="math inline">\(Y=(Y_v)\_{v\in
V}\)</span>，边e表示随机变量之间的依赖关系。</p>]]></description>
</item>
<item>
    <title>HMM</title>
    <link>https://blog.vllbc.top/hmm/</link>
    <pubDate>Mon, 25 Oct 2021 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/hmm/</guid>
    <description><![CDATA[<h1 id="隐马尔科夫模型">隐马尔科夫模型</h1>
<h2 id="介绍">介绍</h2>
<p>HMM可以看做是处理序列模型的传统方法。 一般来说HMM解决三个问题：</p>
<ol type="1">
<li>评估观察序列概率。给定模型<span
class="math inline">\(\lambda=(A,B,\prod)\)</span>和观察序列<span
class="math inline">\(O=\\{o_1,o_2,\dots,o_T\\}\)</span>，计算在模型<span
class="math inline">\(\lambda\)</span>下观测序列O出现的概率<span
class="math inline">\(P(O\lvert
\lambda)\)</span>，这个问题需要用到前向后向算法，属于三个问题中最简单的。</li>
<li>预测问题，也叫解码问题。即给定模型<span
class="math inline">\(\lambda = (A,B,\prod)\)</span>和观测序列<span
class="math inline">\(O=\\{o_1,o_2,\dots,o_T\\}\)</span>，求在给定观测序列条件下，最可能出现的对应的状态序列，这个问题的求解需要用到基于动态规划的维特比算法，这个问题属于三个问题中复杂度居中的算法。</li>
<li>模型参数学习问题。即给定观测序列<span
class="math inline">\(O=\\{o_1,o_2,\dots,o_T\\}\)</span>，估计模型<span
class="math inline">\(\lambda =
(A,B,\prod)\)</span>的参数，使得该模型下观测序列的条件概率<span
class="math inline">\(P(O\lvert\lambda)\)</span>最大，这个问题的求解需要用到基于EM算法的鲍姆-韦尔奇算法。属于三个问题中最复杂的。</li>
</ol>
<h2 id="定义">定义</h2>
<p>设 <span class="math inline">\(Q\)</span> 是所有可能的状态的集合,
<span class="math inline">\(V\)</span> 是所有可能的观测的集合:</p>]]></description>
</item>
<item>
    <title>概率图模型概述</title>
    <link>https://blog.vllbc.top/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B%E6%A6%82%E8%BF%B0/</link>
    <pubDate>Fri, 13 Aug 2021 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B%E6%A6%82%E8%BF%B0/</guid>
    <description><![CDATA[<h1 id="概率图模型概述">概率图模型概述</h1>
<p></p>]]></description>
</item>
</channel>
</rss>
