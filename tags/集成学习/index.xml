<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>集成学习 - 标签 - vllbc02</title>
        <link>https://vllbc.top/tags/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/</link>
        <description>集成学习 - 标签 - vllbc02</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>m18265090197@163.com (vllbc)</managingEditor>
            <webMaster>m18265090197@163.com (vllbc)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Wed, 01 Mar 2023 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://vllbc.top/tags/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/" rel="self" type="application/rss+xml" /><item>
    <title>xgboost</title>
    <link>https://vllbc.top/xgboost/</link>
    <pubDate>Wed, 01 Mar 2023 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/xgboost/</guid>
    <description><![CDATA[]]></description>
</item>
<item>
    <title>Ensemble Learning</title>
    <link>https://vllbc.top/ensemble-learning/</link>
    <pubDate>Sat, 09 Jul 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/ensemble-learning/</guid>
    <description><![CDATA[集成学习 在机器学习的有监督学习算法中，我们的目标是学习出一个稳定的且在各个方面表现都较好的模型，但实际情况往往不这么理想，有时我们只能得到多]]></description>
</item>
<item>
    <title>Adaboost</title>
    <link>https://vllbc.top/adaboost/</link>
    <pubDate>Wed, 27 Apr 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/adaboost/</guid>
    <description><![CDATA[Boosting算法的工作机制是首先从训练集用初始权重训练出一个弱学习器1，根据弱学习的学习误差率表现来更新训练样本的权重，使得之前弱学习器]]></description>
</item>
<item>
    <title>随机森林</title>
    <link>https://vllbc.top/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/</link>
    <pubDate>Tue, 15 Mar 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/</guid>
    <description><![CDATA[]]></description>
</item>
<item>
    <title>Stacking</title>
    <link>https://vllbc.top/stacking/</link>
    <pubDate>Thu, 25 Nov 2021 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/stacking/</guid>
    <description><![CDATA[Stacking 思想简介 简单得理解，就是对于多个学习器，分别对结果进行预测，然后将预测的结果作为特征，再对结果进行预测。 上一张经典的图： 以这个5折stac]]></description>
</item>
<item>
    <title>GBDT</title>
    <link>https://vllbc.top/gbdt/</link>
    <pubDate>Wed, 06 Jan 2021 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/gbdt/</guid>
    <description><![CDATA[梯度提升决策树(GBDT) GBDT(Gradient Boosting Decision Tree)是一种迭代的决策树算法，由多棵决策树组成，所有树的结论累加起来作为最终答案。 回归树 选择最优切分变量]]></description>
</item>
</channel>
</rss>
