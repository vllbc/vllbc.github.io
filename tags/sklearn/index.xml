<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>sklearn - 标签 - vllbc02</title>
        <link>https://vllbc.top/tags/sklearn/</link>
        <description>sklearn - 标签 - vllbc02</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>m18265090197@163.com (vllbc)</managingEditor>
            <webMaster>m18265090197@163.com (vllbc)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Sun, 20 Mar 2022 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://vllbc.top/tags/sklearn/" rel="self" type="application/rss+xml" /><item>
    <title>SelectFromModel</title>
    <link>https://vllbc.top/selectfrommodel/</link>
    <pubDate>Sun, 20 Mar 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/selectfrommodel/</guid>
    <description><![CDATA[Sklearn.feature_selection.SelectFromModel 1 2 3 class sklearn.feature_selection.SelectFromModel(estimator, *, threshold=None, prefit=False, norm_order=1, max_features=None)[source] 参数 1 2 3 4 5 6 7 8 9 Parameters - estimator_：一个估算器 用来建立变压器的基本估计器。 只有当一个不适合的估计器传递给S]]></description>
</item>
<item>
    <title>CountVectorizer</title>
    <link>https://vllbc.top/countvectorizer/</link>
    <pubDate>Sat, 12 Mar 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/countvectorizer/</guid>
    <description><![CDATA[将所有词语装进一个袋子里，不考虑其词法和语序的问题，即每个词语都是独立的 句子1：我 爱 北 京 天 安 门 转换为 [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0] 句子2：我 喜 欢 上 海]]></description>
</item>
<item>
    <title>TfidfTransformer</title>
    <link>https://vllbc.top/tfidftransformer/</link>
    <pubDate>Sat, 12 Mar 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/tfidftransformer/</guid>
    <description><![CDATA[TfidfTransformer() 输入：词频TF 输出：词频逆反文档频率TF-IDF（即词频TF与逆反文档频率IDF的乘积，IDF的标准计算公式为 ：idf=log[n/(1+]]></description>
</item>
<item>
    <title>RFE</title>
    <link>https://vllbc.top/rfe/</link>
    <pubDate>Tue, 25 Jan 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/rfe/</guid>
    <description><![CDATA[sklearn.feature_selection.RFE RFE（Recursive feature elimination）：递归特征消除，用来对特征进行重要性评级。主要用于特征选择 RFE阶段 1 初始的特征集为所]]></description>
</item>
<item>
    <title>学习曲线</title>
    <link>https://vllbc.top/%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF/</link>
    <pubDate>Thu, 13 Jan 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF/</guid>
    <description><![CDATA[学习曲线能判定偏差和方差问题 1 2 3 4 5 from sklearn.model_selection import train_test_split,learning_curve import numpy as np from sklearn.svm import SVC from sklearn.datasets import load_digits import matplotlib.pyplot as plt 1 2 3 digits = load_digits() X = digits.data Y = digits.target 1 2 3 train_sizes,train_loss,test_loss = learning_curve(SVC(gamma=0.001),X,Y,cv=10, scoring=&#39;neg_mean_squared_error&#39;, train_sizes=[0.1,0.25,0.5,0.75,1]) 1 train_sizes array([ 161, 404, 808, 1212, 1617]) 1 train_loss array([[-0.]]></description>
</item>
<item>
    <title>验证曲线</title>
    <link>https://vllbc.top/%E9%AA%8C%E8%AF%81%E6%9B%B2%E7%BA%BF/</link>
    <pubDate>Thu, 13 Jan 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/%E9%AA%8C%E8%AF%81%E6%9B%B2%E7%BA%BF/</guid>
    <description><![CDATA[通过验证曲线判定过拟合于欠拟合。 验证曲线是一种通过定位过拟合于欠拟合等诸多问题的方法，帮助提高模型性能的有效工具。 验证曲线绘制的是准确率与模]]></description>
</item>
<item>
    <title>Decision Tree</title>
    <link>https://vllbc.top/decision-tree/</link>
    <pubDate>Tue, 27 Apr 2021 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/decision-tree/</guid>
    <description><![CDATA[1 2 3 import numpy as np import matplotlib.pyplot as plt import pandas as pd 1 2 3 dataset = pd.read_csv(&#39;./datasets/Social_Network_Ads.csv&#39;) X = dataset.iloc[:, [2, 3]].values y = dataset.iloc[:, 4].values 1 2 from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0) 1 2 3 4 from sklearn.preprocessing import StandardScaler sc = StandardScaler() X_train = sc.fit_transform(X_train) X_test = sc.transform(X_test) 1 2 3 from sklearn.]]></description>
</item>
<item>
    <title>KNN</title>
    <link>https://vllbc.top/knn/</link>
    <pubDate>Tue, 27 Apr 2021 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/knn/</guid>
    <description><![CDATA[导入包 1 2 3 4 import numpy as np import pandas as pd from sklearn.model_selection import train_test_split import plotly.graph_objects as go 导入数据 1 2 3 4 5 6 data = pd.read_csv(&#34;./datasets/Social_Network_Ads.csv&#34;) X = data.iloc[:,[2,3]].values Y = data.iloc[:,4].values # scatter = go.Scatter(x=X[:,0],y=X[:,1],mode=&#39;markers&#39;,marker={&#39;color&#39;:Y}) # fig = go.Figure(scatter) # fig.show() 1 X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.25,random_state=0) 标准化 1 2 3 4 from sklearn.preprocessing import StandardScaler sca = StandardScaler()]]></description>
</item>
<item>
    <title>Logistic Regression</title>
    <link>https://vllbc.top/logistic-regression/</link>
    <pubDate>Tue, 27 Apr 2021 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/logistic-regression/</guid>
    <description><![CDATA[导入包 1 2 import numpy as np import pandas as pd 导入数据 1 2 data = pd.read_csv(&#34;./datasets/Social_Network_Ads.csv&#34;) data.head() User ID Gender Age EstimatedSalary Purchased 0 15624510 Male 19 19000 0 1 15810944 Male 35 20000 0 2 15668575 Female 26 43000 0 3 15603246 Female 27 57000 0 4 15804002 Male 19 76000 0 1 2 X = data.iloc[:,[2,3]].values Y = data.iloc[:,4].values 交叉验]]></description>
</item>
<item>
    <title>SVM</title>
    <link>https://vllbc.top/svm_sklearn/</link>
    <pubDate>Tue, 27 Apr 2021 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/svm_sklearn/</guid>
    <description><![CDATA[1 2 3 import numpy as np import pandas as pd import matplotlib.pyplot as plt 1 2 3 data = pd.read_csv(&#34;./datasets/Social_Network_Ads.csv&#34;) X = data.iloc[:, [2, 3]].values y = data.iloc[:, 4].values 1 2 from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0) 1 2 3 4 from sklearn.preprocessing import StandardScaler sc = StandardScaler() X_train = sc.fit_transform(X_train) X_test = sc.fit_transform(X_test) 1 2 3 from sklearn.]]></description>
</item>
</channel>
</rss>
