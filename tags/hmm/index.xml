<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>HMM - 标签 - vllbc02&#39;s blogs</title>
        <link>https://blog.vllbc.top/tags/hmm/</link>
        <description>HMM - 标签 - vllbc02&#39;s blogs</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Mon, 25 Oct 2021 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://blog.vllbc.top/tags/hmm/" rel="self" type="application/rss+xml" /><item>
    <title>HMM</title>
    <link>https://blog.vllbc.top/hmm/</link>
    <pubDate>Mon, 25 Oct 2021 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/hmm/</guid>
    <description><![CDATA[<h1 id="隐马尔科夫模型">隐马尔科夫模型</h1>
<h2 id="介绍">介绍</h2>
<p>HMM可以看做是处理序列模型的传统方法。 一般来说HMM解决三个问题：</p>
<ol type="1">
<li>评估观察序列概率。给定模型<span
class="math inline">\(\lambda=(A,B,\prod)\)</span>和观察序列<span
class="math inline">\(O=\\{o_1,o_2,\dots,o_T\\}\)</span>，计算在模型<span
class="math inline">\(\lambda\)</span>下观测序列O出现的概率<span
class="math inline">\(P(O\lvert
\lambda)\)</span>，这个问题需要用到前向后向算法，属于三个问题中最简单的。</li>
<li>预测问题，也叫解码问题。即给定模型<span
class="math inline">\(\lambda = (A,B,\prod)\)</span>和观测序列<span
class="math inline">\(O=\\{o_1,o_2,\dots,o_T\\}\)</span>，求在给定观测序列条件下，最可能出现的对应的状态序列，这个问题的求解需要用到基于动态规划的维特比算法，这个问题属于三个问题中复杂度居中的算法。</li>
<li>模型参数学习问题。即给定观测序列<span
class="math inline">\(O=\\{o_1,o_2,\dots,o_T\\}\)</span>，估计模型<span
class="math inline">\(\lambda =
(A,B,\prod)\)</span>的参数，使得该模型下观测序列的条件概率<span
class="math inline">\(P(O\lvert\lambda)\)</span>最大，这个问题的求解需要用到基于EM算法的鲍姆-韦尔奇算法。属于三个问题中最复杂的。</li>
</ol>
<h2 id="定义">定义</h2>
<p>设 <span class="math inline">\(Q\)</span> 是所有可能的状态的集合,
<span class="math inline">\(V\)</span> 是所有可能的观测的集合:</p>]]></description>
</item>
</channel>
</rss>
