<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>NLP - 标签 - vllbc02</title>
        <link>https://vllbc.top/tags/nlp/</link>
        <description>NLP - 标签 - vllbc02</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>m18265090197@163.com (vllbc)</managingEditor>
            <webMaster>m18265090197@163.com (vllbc)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Wed, 19 Oct 2022 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://vllbc.top/tags/nlp/" rel="self" type="application/rss+xml" /><item>
    <title>Constituency Parsing</title>
    <link>https://vllbc.top/constituency-parsing/</link>
    <pubDate>Wed, 19 Oct 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/constituency-parsing/</guid>
    <description><![CDATA[]]></description>
</item>
<item>
    <title>情感分析</title>
    <link>https://vllbc.top/%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/</link>
    <pubDate>Wed, 19 Oct 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/</guid>
    <description><![CDATA[]]></description>
</item>
<item>
    <title>序列标注</title>
    <link>https://vllbc.top/%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8/</link>
    <pubDate>Tue, 11 Oct 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8/</guid>
    <description><![CDATA[序列标注任务 HMM CRF BiLSTM + CRF BERT+CRF BERT + BiLSTM + CRF]]></description>
</item>
<item>
    <title>四个基本任务</title>
    <link>https://vllbc.top/%E5%9B%9B%E4%B8%AA%E5%9F%BA%E6%9C%AC%E4%BB%BB%E5%8A%A1/</link>
    <pubDate>Sun, 09 Oct 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/%E5%9B%9B%E4%B8%AA%E5%9F%BA%E6%9C%AC%E4%BB%BB%E5%8A%A1/</guid>
    <description><![CDATA[NLP四个基本任务 词法分析 词法分析是一切自然语言处理的基础，对后续问题产生深刻的影响。 词法分析的主要任务就是将输入的句子字串转换成字序列并标]]></description>
</item>
<item>
    <title>Dependency Parsing</title>
    <link>https://vllbc.top/dependency-parsing/</link>
    <pubDate>Sun, 25 Sep 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/dependency-parsing/</guid>
    <description><![CDATA[依存关系分析 对于句法结构分析，主要有两种方式：Constituency Parsing(成分分析)与Dependency Parsing(依存分]]></description>
</item>
<item>
    <title>语言模型</title>
    <link>https://vllbc.top/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/</link>
    <pubDate>Sat, 10 Sep 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/</guid>
    <description><![CDATA[语言模型 语言模型是一个很大的主题，很多nlp的任务都是基于语言模型进行的，因此理解语言模型是很重要的。 语言模型简单说就是 计算一个句子在语言中]]></description>
</item>
<item>
    <title>条件随机场</title>
    <link>https://vllbc.top/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/</link>
    <pubDate>Wed, 31 Aug 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/</guid>
    <description><![CDATA[CRF 概率图模型与无向图 图是由结点和连接结点的边组成的集合。结点和边分别记作v和e，结点和边的集合分别记作V和E，图记作$G=(V, E)$。 无向]]></description>
</item>
<item>
    <title>概率图模型概述</title>
    <link>https://vllbc.top/%E6%A6%82%E8%BF%B0/</link>
    <pubDate>Wed, 24 Aug 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/%E6%A6%82%E8%BF%B0/</guid>
    <description><![CDATA[概率图模型概述]]></description>
</item>
<item>
    <title>BM25</title>
    <link>https://vllbc.top/bm25/</link>
    <pubDate>Sat, 30 Jul 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/bm25/</guid>
    <description><![CDATA[BM25算法 BM25算法，通常用来作搜索相关性平分。一句话概况其主要思想：对Query进行语素解析，生成语素qi；然后，对于每个搜索结果D，]]></description>
</item>
<item>
    <title>BERT</title>
    <link>https://vllbc.top/bert/</link>
    <pubDate>Fri, 29 Jul 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://vllbc.top/bert/</guid>
    <description><![CDATA[Bert BERT 的模型架构非常简单，你已经知道它是如何工作的：它只是 Transformer 的编码器。新的是训练目标和 BERT 用于下游任务的方式。 我们如何使用纯文本训练（双向）编码]]></description>
</item>
</channel>
</rss>
