<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>NLP - 标签 - vllbc02&#39;s blogs</title>
        <link>https://blog.vllbc.top/tags/nlp/</link>
        <description>NLP - 标签 - vllbc02&#39;s blogs</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Wed, 16 Jul 2025 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://blog.vllbc.top/tags/nlp/" rel="self" type="application/rss+xml" /><item>
    <title>MHA</title>
    <link>https://blog.vllbc.top/mha/</link>
    <pubDate>Wed, 16 Jul 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/mha/</guid>
    <description><![CDATA[<h2 id="self-attention">Self-attention</h2>
<p>首先介绍一下最主要的 self-attention，可以说是 self-attention
实现了上述的 token 之间交互的功能。</p>
<p>自注意力是模型的关键组成部分之一。注意和自注意之间的区别在于，自注意在相同性质的表示之间运行：例如，某个层中的所有编码器状态。</p>]]></description>
</item>
<item>
    <title>world_model</title>
    <link>https://blog.vllbc.top/world_model/</link>
    <pubDate>Mon, 30 Jun 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/world_model/</guid>
    <description><![CDATA[<p>我理解的agent中的world
model即可以预测采取某个action之后state的变化，这样做的好处是可以降低试错带来的时间成本或者是其它潜在的成本、风险。</p>]]></description>
</item>
<item>
    <title>agent概览</title>
    <link>https://blog.vllbc.top/agent%E6%A6%82%E8%A7%88/</link>
    <pubDate>Sat, 14 Jun 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/agent%E6%A6%82%E8%A7%88/</guid>
    <description><![CDATA[<p>根据Anthropic的定义，agent定义如下：</p>
<blockquote>
<p>At Anthropic, we categorize all these variations as <strong>agentic
systems</strong>, but draw an important architectural distinction
between <strong>workflows</strong> and <strong>agents</strong>:
<strong>Workflows</strong> are systems where LLMs and tools are
orchestrated through predefined code paths. <strong>Agents</strong>, on
the other hand, are systems where LLMs dynamically direct their own
processes and tool usage, maintaining control over how they accomplish
tasks.</p>]]></description>
</item>
<item>
    <title>MCTS和PRM</title>
    <link>https://blog.vllbc.top/mcts%E5%92%8Cprm/</link>
    <pubDate>Fri, 04 Apr 2025 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/mcts%E5%92%8Cprm/</guid>
    <description><![CDATA[<h2 id="核心总结">核心总结</h2>
<ul>
<li><strong>PRM和MCTS实际上是两种可以独立使用的技术，只不过，往往它们组合使用时往往能产生1+1&gt;2的效果</strong>。例如，
<ul>
<li>单独使用PRM：我们可以让模型对同一个prompt采样多个不同solution，无需MCTS，只需利用模型的temperature等随机参数让每次生成结果不同，然后用PRM对每个solution的每一步打分，最终选择分数最高的路径返回。</li>
<li>单独使用MCTS：使用MCTS生成多个解题路径时，不一定要用PRM来决定哪个节点值得扩展，可以用外部大模型（如GPT-4）来选择，也可以用模型自身的perplexity来判断。本质上，我们需要的是找到最值得扩展的节点，PRM只是挑选的众多方法之一。</li>
</ul></li>
<li><strong>PRM 和 MCTS
既可以应用于优化训练数据，也可以用来预测用</strong>
<ul>
<li>用于得到高质量训练数据：如rStar论文中，可以用PRM和MCTS的方式来迭代地筛选得到质量更好的思维链SFT数据或者RLHF数据，还可以生成更精确的reward
model训练数据。</li>
<li>用于推理：很简单，推理用MCTS的方式把 test-scaling
做上来，再结合PRM的方式从众多路径中挑选最佳答案。</li>
</ul></li>
<li><strong>PRM和MCTS的缺点</strong><br />
这方面 DeepSeek-R1和 kimi1.5的论文已经说得很情况了。</li>
<li>Process Reward Model(PRM) 在实际应用中有三大局限：
<ul>
<li>第一，难以清晰界定一般推理中的细粒度步骤，说白了，怎么定义什么为一个步骤。</li>
<li>第二，判断当前步骤的正误难度大，模型自动化标注不如人意，人工标注又难以拓展。</li>
<li>第三，引入基于模型的PRM易致reward hacking，有时为了训练 policy
model，但反而更多时间去优化 reward model 去了。</li>
</ul></li>
<li>对MCTS的看法：
<ul>
<li>文本的生成搜索空间指数级增长，为应对，给节点设扩展上限，却容易让模型陷入局部最优解困境。</li>
<li>MCTS往往要结合一个精确的PRM来用才能发挥最大效果，但PRM又有上述的问题，陷入一个死循环。</li>
</ul></li>
</ul>
<h2 id="参考">参考</h2>
<p>https://zhuanlan.zhihu.com/p/27278317894 rStar-Math: Small LLMs Can
Master Math Reasoning with Self-Evolved Deep Thinking</p>]]></description>
</item>
<item>
    <title>llama系列</title>
    <link>https://blog.vllbc.top/llama%E7%B3%BB%E5%88%97/</link>
    <pubDate>Thu, 26 Sep 2024 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/llama%E7%B3%BB%E5%88%97/</guid>
    <description><![CDATA[<h1 id="llama介绍">LLaMA介绍</h1>
<p>LLaMA 是目前为止，效果最好的开源 LLM 之一。</p>
<blockquote>
<p><strong>论文的核心思想：相比于GPT，更小的模型+更多的训练数据</strong>**也可以获得可比的效果</p>
</blockquote>
<p>基于更多 tokens
的训练集，在各种推理预算下，训练出性能最佳的一系列语言模型，称为
<code>LLaMA</code>，参数范围从 7B 到 65B 不等，与现有最佳 LLM
相比，其性能是有竞争力的。比如，LLaMA-13B 在大多数基准测试中优于
GPT-3，尽管其尺寸只有 GPT-3 的十分之一。作者相信，LLaMA 将有助于使 LLM
的使用和研究平民化，因为它可以在单个 GPU
上运行！在规模较大的情况下，LLaMA-65B 也具有与最佳大型语言模型（如
Chinchilla 或 PaLM-540B）相竞争的能力。</p>]]></description>
</item>
<item>
    <title>MoE</title>
    <link>https://blog.vllbc.top/moe/</link>
    <pubDate>Wed, 07 Aug 2024 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/moe/</guid>
    <description><![CDATA[
]]></description>
</item>
<item>
    <title>ICL</title>
    <link>https://blog.vllbc.top/icl/</link>
    <pubDate>Thu, 14 Mar 2024 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/icl/</guid>
    <description><![CDATA[<p>ICL即In-contexting Learning。 ICL 包含三种分类： - Few-shot
learning，允许输入数条示例和一则任务说明； - One-shot
learning，只允许输入一条示例和一则任务说明； - Zero-shot
learning，不允许输入任何示例，只允许输入一则任务说明。 </p>]]></description>
</item>
<item>
    <title>T5</title>
    <link>https://blog.vllbc.top/t5/</link>
    <pubDate>Sat, 09 Mar 2024 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/t5/</guid>
    <description><![CDATA[
]]></description>
</item>
<item>
    <title>seq2seq</title>
    <link>https://blog.vllbc.top/seq2seq/</link>
    <pubDate>Wed, 09 Nov 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/seq2seq/</guid>
    <description><![CDATA[<h1 id="seq2seq">Seq2Seq</h1>
<p>（本文只介绍最原始的seq2seq，带有注意力在attention文章中）</p>
<h2 id="rnn">RNN</h2>
<p>有关RNN</p>
<p>Seq2Seq是典型的Encoder-decoder框架的模型，其中编码器和解码器都采用的RNN模型或者RNN模型的变体：GRU、LSTM等。</p>]]></description>
</item>
<item>
    <title>tokenization</title>
    <link>https://blog.vllbc.top/tokenization/</link>
    <pubDate>Mon, 17 Oct 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/tokenization/</guid>
    <description><![CDATA[<h1 id="tokenization技术">Tokenization技术</h1>
<p>本文章主要说说NLP领域中的Tokenization技术，这是很基础的但也是很容易被忽视的一个步骤。在我接的单子中经常会有此类问题，并且都是外国学校的，说明外国学校还是比较注重这一块的基础的。
首先明确一个概念：token可以理解为一个符号，就代表一个语言单位，tokenize的意思就是把一个句子或语料分成token.</p>]]></description>
</item>
</channel>
</rss>
