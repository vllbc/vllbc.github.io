<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>损失函数 - 标签 - vllbc02</title>
        <link>https://blog.vllbc.top/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</link>
        <description>损失函数 - 标签 - vllbc02</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>vllbc02@163.com (vllbc)</managingEditor>
            <webMaster>vllbc02@163.com (vllbc)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Mon, 13 Mar 2023 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://blog.vllbc.top/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" rel="self" type="application/rss+xml" /><item>
    <title>hinge loss</title>
    <link>https://blog.vllbc.top/hinge-loss/</link>
    <pubDate>Mon, 13 Mar 2023 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/hinge-loss/</guid>
    <description><![CDATA[在机器学习中，hinge loss是一种损失函数，它通常用于”maximum-margin”的分类任务中，如支持向量机。数学表达式为： 其中 \(\hat{y}\) 表]]></description>
</item>
<item>
    <title>focal loss</title>
    <link>https://blog.vllbc.top/focal-loss/</link>
    <pubDate>Mon, 06 Mar 2023 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/focal-loss/</guid>
    <description><![CDATA[Focal Loss Focal Loss主要是为了解决类别不平衡的问题，Focal Loss可以运用于二分类，也可以运用于多分类。下面以二分类为例： 原始Loss 原始的二]]></description>
</item>
<item>
    <title>交叉熵损失函数</title>
    <link>https://blog.vllbc.top/%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</link>
    <pubDate>Fri, 30 Apr 2021 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</guid>
    <description><![CDATA[Softmax理解 主要记录了在使用softmax这个函数中遇到的一些问题，比较基础，但确实困扰了一段时间。 在学习word2vec中, 使用的一]]></description>
</item>
<item>
    <title>Smooth L1 Loss</title>
    <link>https://blog.vllbc.top/smooth-l1-loss/</link>
    <pubDate>Mon, 19 Apr 2021 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/smooth-l1-loss/</guid>
    <description><![CDATA[L1 Loss 也称为Mean Absolute Error，即平均绝对误差（MAE），它衡量的是预测值与真实值之间距离的平均误差幅度，作用范围为0到正无穷。 优点： 对离群]]></description>
</item>
</channel>
</rss>
