<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Transformers - 标签 - vllbc02&#39;s blogs</title>
        <link>https://blog.vllbc.top/tags/transformers/</link>
        <description>Transformers - 标签 - vllbc02&#39;s blogs</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Tue, 16 Jan 2024 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://blog.vllbc.top/tags/transformers/" rel="self" type="application/rss+xml" /><item>
    <title>trainer</title>
    <link>https://blog.vllbc.top/trainer/</link>
    <pubDate>Tue, 16 Jan 2024 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/trainer/</guid>
    <description><![CDATA[<h1 id="基本用法">基本用法</h1>
<p>下面是使用的一个例子，重点是TrainingArg和data_collator。</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> LineByLineTextDataset(tokenizer<span class="op">=</span>tokenizer, file_path<span class="op">=</span><span class="st">&#39;./text.txt&#39;</span>, block_size<span class="op">=</span><span class="dv">512</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>data_collator <span class="op">=</span> DataCollatorForLanguageModeling( tokenizer<span class="op">=</span>tokenizer, mlm<span class="op">=</span><span class="va">True</span>, mlm_probability<span class="op">=</span><span class="fl">0.15</span> ) </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>training_args <span class="op">=</span> TrainingArguments( output_dir<span class="op">=</span><span class="st">&#39;./outputs/&#39;</span>,</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>                                  overwrite_output_dir<span class="op">=</span><span class="va">True</span>, </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>                                  num_train_epochs<span class="op">=</span><span class="dv">100</span>, </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>                                  per_device_train_batch_size<span class="op">=</span><span class="dv">16</span>, </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>                                  save_steps<span class="op">=</span><span class="dv">5000</span>, ) </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> Trainer( model<span class="op">=</span>model, </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>                  args<span class="op">=</span>training_args, </span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>                  data_collator<span class="op">=</span>data_collator, </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>                  train_dataset<span class="op">=</span>dataset, ) </span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>trainer.train() </span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>trainer.save_model(<span class="st">&#39;./outputs/&#39;</span>)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
<p>的附图作简单地介绍，显而易见地，下面描述中的附图仅仅是本发明的一些实施例，对于本领域普通技术人员来讲，在不付出创造性劳动的前提下，还可以根据这些附图获得其它的附图。
[0089]
图1为本发明第一个实施例提供的一种基于大语言模型自身对上下文进行压缩的
方法的整体流程图； [0090]
图2为本发明第一个实施例提供的一种基于大语言模型自身对上下文进行压缩的
方法的Decoder-only模型架构示意图； [0091]
图3为本发明第一个实施例提供的一种基于大语言模型自身对上下文进行压缩的
方法的利用现有大语言模型训练流程图； [0092]
图4为本发明第一个实施例提供的一种基于大语言模型自身对上下文进行压缩的
方法的预训练大语言模型流程图； [0093]
图5为本发明第一个实施例提供的一种基于大语言模型自身对上下文进行压缩的
方法的推理流程图； [0094]
图6为本发明第一个实施例提供的一种基于大语言模型自身对上下文进行压缩的
方法的虚拟字符检索流程图； [0095]
图7为本发明第二个实施例提供的一种基于大语言模型自身对上下文进行压缩的
方法的各个模型的推理性能对比图； [0096]
图8为本发明第二个实施例提供的一种基于大语言模型自身对上下文进行压缩的
方法的部分压缩示例图。</p>]]></description>
</item>
<item>
    <title>pooler_output</title>
    <link>https://blog.vllbc.top/pooler_output/</link>
    <pubDate>Mon, 15 Jan 2024 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/pooler_output/</guid>
    <description><![CDATA[
]]></description>
</item>
<item>
    <title>情感分析</title>
    <link>https://blog.vllbc.top/data_collator/</link>
    <pubDate>Fri, 12 Nov 2021 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/data_collator/</guid>
    <description><![CDATA[<p>目的：<strong>手动将抽取出的样本堆叠起来，构造成batch</strong>
Trainer函数有一个参数data_collator，其值也为一个函数，用于从一个list of
elements来构造一个batch。 如下</p>]]></description>
</item>
</channel>
</rss>
