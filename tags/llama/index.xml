<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Llama - 标签 - vllbc02&#39;s blogs</title>
        <link>http://localhost:1313/tags/llama/</link>
        <description>Llama - 标签 - vllbc02&#39;s blogs</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>vllbc02@163.com (vllbc)</managingEditor>
            <webMaster>vllbc02@163.com (vllbc)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 &#43;0000</lastBuildDate><atom:link href="http://localhost:1313/tags/llama/" rel="self" type="application/rss+xml" /><item>
    <title>llama系列</title>
    <link>http://localhost:1313/llama%E7%B3%BB%E5%88%97/</link>
    <pubDate>Thu, 26 Sep 2024 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>http://localhost:1313/llama%E7%B3%BB%E5%88%97/</guid>
    <description><![CDATA[LLaMA介绍 LLaMA 是目前为止，效果最好的开源 LLM 之一。 论文的核心思想：相比于GPT，更小的模型+更多的训练数据**也可以获得可比的效果 基于更多 tokens]]></description>
</item>
</channel>
</rss>
