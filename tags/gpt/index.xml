<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>GPT - 标签 - vllbc02&#39;s blogs</title>
        <link>https://blog.vllbc.top/tags/gpt/</link>
        <description>GPT - 标签 - vllbc02&#39;s blogs</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>vllbc02@163.com (vllbc)</managingEditor>
            <webMaster>vllbc02@163.com (vllbc)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Wed, 27 Jul 2022 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://blog.vllbc.top/tags/gpt/" rel="self" type="application/rss+xml" /><item>
    <title>GPT</title>
    <link>https://blog.vllbc.top/gpt/</link>
    <pubDate>Wed, 27 Jul 2022 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/gpt/</guid>
    <description><![CDATA[GPT 预训练(从左到右的 Transformer 语言模型) GPT 是一种基于 Transformer 的从左到右的语言模型。该架构是一个 12 层的 Transformer 解码器（没有解码器-编码器）。 ## 模型架构 就是12层的]]></description>
</item>
</channel>
</rss>
