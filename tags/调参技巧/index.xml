<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>调参技巧 - 标签 - vllbc02&#39;s blogs</title>
        <link>https://blog.vllbc.top/tags/%E8%B0%83%E5%8F%82%E6%8A%80%E5%B7%A7/</link>
        <description>调参技巧 - 标签 - vllbc02&#39;s blogs</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Thu, 02 Mar 2023 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://blog.vllbc.top/tags/%E8%B0%83%E5%8F%82%E6%8A%80%E5%B7%A7/" rel="self" type="application/rss+xml" /><item>
    <title>调参技巧</title>
    <link>https://blog.vllbc.top/%E8%B0%83%E5%8F%82%E6%8A%80%E5%B7%A7/</link>
    <pubDate>Thu, 02 Mar 2023 00:00:00 &#43;0000</pubDate>
    <author>vllbc</author>
    <guid>https://blog.vllbc.top/%E8%B0%83%E5%8F%82%E6%8A%80%E5%B7%A7/</guid>
    <description><![CDATA[<ul>
<li>基本原则：快速试错。</li>
<li>小步试错，快速迭代</li>
<li>可以试试无脑的配置</li>
<li>实时打印一些结果</li>
<li>自动调参：网格搜索、random search、贝叶斯优化、</li>
<li>参数初始化</li>
<li>学习率warmup，慢慢增加，然后学习率衰减。</li>
</ul>
<h1 id="batch_size和lr">batch_size和lr</h1>
<p><strong>大的batchsize收敛到<a
href="https://zhida.zhihu.com/search?q=sharp+minimum&amp;zhida_source=entity&amp;is_preview=1">sharp
minimum</a>，而小的batchsize收敛到<a
href="https://zhida.zhihu.com/search?q=flat+minimum&amp;zhida_source=entity&amp;is_preview=1">flat
minimum</a>，后者具有更好的泛化能力。</strong>两者的区别就在于变化的趋势，一个快一个慢，如下图，造成这个现象的主要原因是小的batchsize带来的噪声有助于逃离sharp
minimum。</p>]]></description>
</item>
</channel>
</rss>
