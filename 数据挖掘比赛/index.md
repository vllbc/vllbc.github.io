# 数据挖掘比赛



# 数据挖掘比赛
## 对赛题进行理解
## 数据分析
### EDA目标
- EDA的价值在于熟悉数据集，了解数据集，对数据集进行验证来确定所获得数据集可以用于接下来的机器学习或者深度学习使用。
- 当了解了数据集之后我们下一步就是要去了解变量间的相互关系以及变量与预测值之间的存在关系。
- 引导数据科学从业者进行数据处理以及特征工程的步骤,使数据集的结构和特征集让接下来的预测问题更加可靠。
- 完成对于数据的探索性分析，并对于数据进行一些图表或者文字总结并打卡。

### 主要操作

1. 载入各种数据科学以及可视化库:
    - 数据科学库 pandas、numpy、scipy；
    - 可视化库 matplotlib、seabon；
    - 其他；
2. 载入数据：
    - 载入训练集和测试集；
    - 简略观察数据(head()+shape)；
3. 数据总览:
    - 通过describe()来熟悉数据的相关统计量
    - 通过info()来熟悉数据类型
4. 判断数据缺失和异常
    - 查看每列的存在nan情况
    - 异常值检测
5. 了解预测值的分布
    - 总体分布概况（无界约翰逊分布等）
    - 查看skewness and kurtosis
    - 查看预测值的具体频数
6. 特征分为类别特征和数字特征，并对类别特征查看unique分布
7. 数字特征分析
    - 相关性分析
    - 查看几个特征得 偏度和峰值
    - 每个数字特征得分布可视化
    - 数字特征相互之间的关系可视化
    - 多变量互相回归关系可视化
8. 类型特征分析
    - unique分布
    - 类别特征箱形图可视化
    - 类别特征的小提琴图可视化
    - 类别特征的柱形图可视化类别
    - 特征的每个类别频数可视化(count_plot)
9. 用pandas_profiling生成数据报告

### 主要步骤
1. 对于数据的初步分析（直接查看数据，或.sum(), .mean()，.descirbe()等统计函数）可以从：样本数量，训练集数量，是否有时间特征，是否是时许问题，特征所表示的含义（非匿名特征），特征类型（字符类似，int，float，time），特征的缺失情况（注意缺失的在数据中的表现形式，有些是空的有些是”NAN”符号等），特征的均值方差情况。
2. 分析记录某些特征值缺失占比30%以上样本的缺失处理，有助于后续的模型验证和调节，分析特征应该是填充（填充方式是什么，均值填充，0填充，众数填充等），还是舍去，还是先做样本分类用不同的特征模型去预测。
3. 对于异常值做专门的分析，分析特征异常的label是否为异常值（或者偏离均值较远或者事特殊符号）,异常值是否应该剔除，还是用正常值填充，是记录异常，还是机器本身异常等。
4. 对于Label做专门的分析，分析标签的分布情况等。
5. 进步分析可以通过对特征作图，特征和label联合做图（统计图，离散图），直观了解特征的分布情况，通过这一步也可以发现数据之中的一些异常值等，通过箱型图分析一些特征值的偏离情况，对于特征和特征联合作图，对于特征和label联合作图，分析其中的一些关联性。

**记录自己之前没用到的东西**
### 数据的偏度和峰度
- 数据的偏度(skewness)：dataframe.skew()
- 数据的峰度(kurtosis)：dataframe.kurt()
### log变换
一般要求预测值需要符合正态分布，因此需要先log变换一下
### sns.pairplot
用来展现变量两两之间的关系，比如线性、非线性、相关
hue参数可以指定分类。

### sns.heatmap
热度图，可以直观感受变量之间的相关程度。

更多的处理方法可以看pandas笔记

## 特征工程
### 主要步骤
1. 异常处理：
	- 通过箱线图（或 3-Sigma）分析删除异常值；
	- BOX-COX 转换（处理有偏分布）；
	- 长尾截断；
2. 特征归一化/标准化：
	- 标准化（转换为标准正态分布）；
	- 归一化（抓换到 [0,1] 区间）；
	- 针对幂律分布，可以采用公式：$log(\frac{1+x}{1+median})$
3. 数据分桶：
	- 等频分桶；
	- 等距分桶；
	- Best-KS 分桶（类似利用基尼指数进行二分类）；
	- 卡方分桶；
4. 缺失值处理：
	- 不处理（针对类似 XGBoost 等树模型）；
    - 删除（缺失数据太多）；
    - 插值补全，包括均值/中位数/众数/建模预测/多重插补/压缩感知补全/矩阵补全等；
    - 分箱，缺失值一个箱；
5. **特征构造**：
	- 构造统计量特征，报告计数、求和、比例、标准差等；
    - 时间特征，包括相对时间和绝对时间，节假日，双休日等；
    - 地理信息，包括分箱，分布编码等方法；
    - 非线性变换，包括 log/ 平方/ 根号等；
    - 特征组合，特征交叉；
    - 仁者见仁，智者见智。
6. 特征筛选：
	- 过滤式（filter）：先对数据进行特征选择，然后在训练学习器，常见的方法有 Relief/方差选择发/相关系数法/卡方检验法/互信息法；
    - 包裹式（wrapper）：直接把最终将要使用的学习器的性能作为特征子集的评价准则，常见方法有 LVM（Las Vegas Wrapper） ；
    - 嵌入式（embedding）：结合过滤式和包裹式，学习器训练过程中自动进行了特征选择，常见的有 lasso 回归；
7. 降维：
	- PCA/LDA/LCA;本博客都有介绍
	- 特征选择也是降维
## 建模调参
## 模型融合
